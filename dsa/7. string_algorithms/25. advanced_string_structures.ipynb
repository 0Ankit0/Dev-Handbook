{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 25: Advanced String Structures\n",
    "\n",
    "> *\"Strings are not just sequences\u2014they are worlds unto themselves. With advanced structures, we can navigate these worlds with unprecedented speed and insight.\"* \u2014 Anonymous\n",
    "\n",
    "---\n",
    "\n",
    "## 25.1 Introduction\n",
    "\n",
    "In Chapter 24, we explored fundamental string algorithms for pattern matching. Now we delve into **advanced string data structures** that enable powerful queries beyond simple search: finding longest repeated substrings, counting distinct substrings, constructing suffix arrays, and more. These structures are the backbone of modern bioinformatics, text indexing, and data compression.\n",
    "\n",
    "### 25.1.1 Why Advanced String Structures?\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    IMPORTANCE OF ADVANCED STRING STRUCTURES          \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                      \u2502\n",
    "\u2502  1. INDEXING: Preprocess text to answer many queries efficiently    \u2502\n",
    "\u2502     (e.g., search for any pattern in O(|P|) time).                  \u2502\n",
    "\u2502                                                                      \u2502\n",
    "\u2502  2. REPEATED PATTERNS: Find longest repeated substring, which is    \u2502\n",
    "\u2502     useful in plagiarism detection and data compression.            \u2502\n",
    "\u2502                                                                      \u2502\n",
    "\u2502  3. BIOINFORMATICS: DNA sequences are billions of characters long;  \u2502\n",
    "\u2502     suffix arrays/trees enable genome alignment and assembly.       \u2502\n",
    "\u2502                                                                      \u2502\n",
    "\u2502  4. DATA COMPRESSION: Burrows-Wheeler Transform is the core of      \u2502\n",
    "\u2502     bzip2 and modern compression tools.                             \u2502\n",
    "\u2502                                                                      \u2502\n",
    "\u2502  5. LINGUISTICS: Analyze word patterns, palindromes, and more.      \u2502\n",
    "\u2502                                                                      \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 25.2 Suffix Trees\n",
    "\n",
    "A **suffix tree** is a compressed trie of all suffixes of a string. It can be built in O(n) time and supports many string queries in O(m) time, where m is the length of the query pattern.\n",
    "\n",
    "### 25.2.1 Definition and Properties\n",
    "\n",
    "For a string S of length n, a suffix tree is a rooted tree with:\n",
    "- Exactly n leaves, each labeled with a suffix start index.\n",
    "- Each internal node has at least two children.\n",
    "- Each edge is labeled with a non-empty substring of S.\n",
    "- No two edges out of a node can have labels starting with the same character.\n",
    "- The concatenation of edge labels from root to leaf gives a suffix.\n",
    "\n",
    "**Example:** For S = \"banana$\" (with sentinel), the suffix tree has nodes representing common prefixes.\n",
    "\n",
    "**Properties:**\n",
    "- Space: O(n) nodes.\n",
    "- Construction: O(n) time (Ukkonen's algorithm).\n",
    "- Queries:\n",
    "  - **Pattern presence:** O(m) by following characters.\n",
    "  - **Number of occurrences:** O(m) by counting leaves in subtree.\n",
    "  - **Longest repeated substring:** Find deepest internal node (by string depth).\n",
    "  - **Longest common substring** of two strings: Build combined tree with markers.\n",
    "\n",
    "### 25.2.2 Ukkonen's Algorithm (Conceptual)\n",
    "\n",
    "Ukkonen's algorithm builds the suffix tree online, adding characters one by one. It uses **active point** and **suffix links** to achieve linear time.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Implicit suffix tree:** After processing first i characters, we have tree for S[0:i] (without sentinel).\n",
    "- **Active point:** A location (node, edge, length) where the next suffix extension starts.\n",
    "- **Suffix link:** Pointer from a node representing a string `x\u03b1` to the node representing `\u03b1` (useful for fast traversal).\n",
    "- **Extension rules:**\n",
    "  - Rule 1: The path for suffix already exists \u2013 do nothing.\n",
    "  - Rule 2: The path ends at a leaf \u2013 extend edge.\n",
    "  - Rule 3: The path ends at an internal node or in the middle of an edge \u2013 split edge and create new leaf.\n",
    "\n",
    "Ukkonen uses a **remainder** counter to track how many suffixes need to be added in the current phase. The algorithm is complex; we outline steps:\n",
    "\n",
    "1. Initialize tree with root node.\n",
    "2. For each character in the string:\n",
    "   - Set lastJ = -1 (for suffix link).\n",
    "   - For each suffix extension (using remainder), apply rules.\n",
    "   - When rule 3 is applied, create suffix link from previous internal node to new node.\n",
    "   - Update active point.\n",
    "\n",
    "After adding sentinel, we have the full suffix tree.\n",
    "\n",
    "**Implementation note:** A full implementation is lengthy; many libraries exist. For learning, we can implement a simpler O(n\u00b2) suffix tree to understand the structure, but production uses Ukkonen.\n",
    "\n",
    "### 25.2.3 Applications\n",
    "\n",
    "- **Exact string matching:** Find all occurrences of pattern P in O(|P| + occ).\n",
    "- **Longest repeated substring:** Find the deepest internal node (string depth).\n",
    "- **Longest common substring** of two strings: Build suffix tree for T1$T2#, find deepest node with leaves from both strings.\n",
    "- **Palindromes:** Can be found by building suffix tree of reverse string and using LCA queries.\n",
    "- **DNA assembly:** Suffix trees are used in genome assembly algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "## 25.3 Suffix Arrays\n",
    "\n",
    "A **suffix array** is a sorted array of starting indices of all suffixes of a string. It requires less memory than a suffix tree and can be augmented with an LCP (Longest Common Prefix) array to achieve similar power.\n",
    "\n",
    "### 25.3.1 Definition\n",
    "\n",
    "For a string S of length n, the suffix array SA is an array of integers 0..n-1 such that S[SA[0]:] < S[SA[1]:] < ... < S[SA[n-1]:] lexicographically.\n",
    "\n",
    "**Example:** S = \"banana$\"\n",
    "Suffixes:\n",
    "0: banana$\n",
    "1: anana$\n",
    "2: nana$\n",
    "3: ana$\n",
    "4: na$\n",
    "5: a$\n",
    "6: $\n",
    "Sorted lexicographically: $, a$, ana$, anana$, banana$, na$, nana$\n",
    "Indices: 6,5,3,1,0,4,2\n",
    "SA = [6,5,3,1,0,4,2]\n",
    "\n",
    "### 25.3.2 Construction Algorithms\n",
    "\n",
    "#### 25.3.2.1 Naive O(n\u00b2 log n) (for understanding)\n",
    "\n",
    "```python\n",
    "def suffix_array_naive(s):\n",
    "    suffixes = [(s[i:], i) for i in range(len(s))]\n",
    "    suffixes.sort()\n",
    "    return [idx for _, idx in suffixes]\n",
    "```\n",
    "\n",
    "#### 25.3.2.2 Prefix Doubling (O(n log n))\n",
    "\n",
    "This is the most common method. It sorts suffixes by their first 1,2,4,8,... characters using the previous rank.\n",
    "\n",
    "```python\n",
    "def suffix_array_doubling(s):\n",
    "    n = len(s)\n",
    "    k = 1\n",
    "    # Initial ranks based on single character\n",
    "    rank = [ord(c) for c in s]\n",
    "    tmp = [0] * n\n",
    "    sa = list(range(n))\n",
    "    \n",
    "    while k < n:\n",
    "        # Sort by (rank[i], rank[i+k] if i+k < n else -1)\n",
    "        sa.sort(key=lambda x: (rank[x], rank[x+k] if x+k < n else -1))\n",
    "        # Assign new ranks\n",
    "        tmp[sa[0]] = 0\n",
    "        for i in range(1, n):\n",
    "            prev = sa[i-1]\n",
    "            curr = sa[i]\n",
    "            prev_key = (rank[prev], rank[prev+k] if prev+k < n else -1)\n",
    "            curr_key = (rank[curr], rank[curr+k] if curr+k < n else -1)\n",
    "            tmp[curr] = tmp[prev] + (prev_key != curr_key)\n",
    "        rank, tmp = tmp, rank\n",
    "        if rank[sa[-1]] == n-1:\n",
    "            break\n",
    "        k <<= 1\n",
    "    return sa\n",
    "```\n",
    "\n",
    "**Time:** O(n log n) with comparison-based sort; using counting sort on ranks can achieve O(n) for integer alphabets.\n",
    "\n",
    "#### 25.3.2.3 SA-IS (O(n))\n",
    "\n",
    "The SA-IS algorithm (Induced Sorting) is a linear-time suffix array construction algorithm. It is complex and rarely implemented manually, but it's the basis of many fast libraries. We'll not implement here; the key idea is to recursively sort suffixes based on LMS (leftmost S-type) characters and induce the rest.\n",
    "\n",
    "### 25.3.3 LCP Array (Kasai's Algorithm)\n",
    "\n",
    "The LCP array stores the length of the longest common prefix between consecutive suffixes in the suffix array. It enables many queries.\n",
    "\n",
    "```python\n",
    "def kasai_lcp(s, sa):\n",
    "    n = len(s)\n",
    "    rank = [0] * n\n",
    "    for i, idx in enumerate(sa):\n",
    "        rank[idx] = i\n",
    "    lcp = [0] * (n - 1)\n",
    "    h = 0\n",
    "    for i in range(n):\n",
    "        if rank[i] > 0:\n",
    "            j = sa[rank[i] - 1]\n",
    "            while i + h < n and j + h < n and s[i+h] == s[j+h]:\n",
    "                h += 1\n",
    "            lcp[rank[i] - 1] = h\n",
    "            if h > 0:\n",
    "                h -= 1\n",
    "    return lcp\n",
    "```\n",
    "\n",
    "**Time:** O(n)\n",
    "\n",
    "### 25.3.4 Applications\n",
    "\n",
    "- **Pattern matching:** Binary search on suffix array to find range of suffixes starting with P. Time O(|P| log n).\n",
    "- **Longest repeated substring:** Maximum value in LCP array.\n",
    "- **Number of distinct substrings:** Sum over suffixes of (n - SA[i]) - LCP[i] (or LCP[i-1] appropriately).\n",
    "- **Longest common substring** of two strings: Concatenate with unique separators, build suffix array + LCP, find max LCP between suffixes from different strings.\n",
    "- **Burrows-Wheeler Transform:** BWT can be derived from suffix array as BWT[i] = s[SA[i] - 1] (with wrap-around).\n",
    "\n",
    "---\n",
    "\n",
    "## 25.4 Burrows-Wheeler Transform (BWT)\n",
    "\n",
    "The Burrows-Wheeler Transform is a reversible permutation that groups identical characters together, aiding compression. It is the basis of the bzip2 compression tool and the FM-index.\n",
    "\n",
    "### 25.4.1 Forward BWT\n",
    "\n",
    "Given a string S of length n (with a unique sentinel $ smaller than all characters), form all rotations, sort them lexicographically, and take the last column.\n",
    "\n",
    "**Example:** S = \"banana$\"\n",
    "Rotations (sorted):\n",
    "$banana\n",
    "a$banan\n",
    "ana$ban\n",
    "anana$b\n",
    "banana$\n",
    "na$bana\n",
    "nana$ba\n",
    "Last column: anbnaa$ (the characters at the end of each rotation)\n",
    "\n",
    "**Implementation using suffix array:**\n",
    "The BWT can be obtained directly from the suffix array:\n",
    "- For each suffix starting at SA[i], the character just before it (cyclic) is BWT[i] = S[SA[i] - 1] (with S[-1] interpreted as last character, i.e., cyclic).\n",
    "\n",
    "```python\n",
    "def bwt_from_sa(s, sa):\n",
    "    n = len(s)\n",
    "    return ''.join(s[(sa[i] - 1) % n] for i in range(n))\n",
    "```\n",
    "\n",
    "### 25.4.2 Inverse BWT\n",
    "\n",
    "Reversing the BWT requires the **last-to-first (LF) mapping**. Given the BWT string L (last column) and the first column F (which is just the sorted version of L), we can reconstruct the original string.\n",
    "\n",
    "**Steps:**\n",
    "1. Compute the first column F by sorting L.\n",
    "2. For each character in L, we know its rank (how many times it appears so far). Build an array `next` that maps from a position in L to the same character's position in F (using rank).\n",
    "3. Starting from the row that contains the sentinel, follow `next` pointers to reconstruct the original string in reverse order.\n",
    "\n",
    "```python\n",
    "def inverse_bwt(l):\n",
    "    n = len(l)\n",
    "    # Count occurrences of each character\n",
    "    from collections import Counter\n",
    "    cnt = Counter(l)\n",
    "    # Determine starting positions in F\n",
    "    chars = sorted(cnt.keys())\n",
    "    start = {}\n",
    "    total = 0\n",
    "    for c in chars:\n",
    "        start[c] = total\n",
    "        total += cnt[c]\n",
    "    # Build occurrence array for L\n",
    "    occ = {c: 0 for c in chars}\n",
    "    # For each position in L, compute its rank (occurrence count so far)\n",
    "    rank = [0] * n\n",
    "    for i, ch in enumerate(l):\n",
    "        rank[i] = occ[ch]\n",
    "        occ[ch] += 1\n",
    "    # Build next array: next[i] = start[l[i]] + rank[i]\n",
    "    next_idx = [start[l[i]] + rank[i] for i in range(n)]\n",
    "    # Find row containing sentinel (say '$')\n",
    "    sentinel_char = '$'  # adjust as needed\n",
    "    row = l.index(sentinel_char)\n",
    "    res = []\n",
    "    for _ in range(n):\n",
    "        row = next_idx[row]\n",
    "        res.append(l[row])\n",
    "    return ''.join(res)\n",
    "```\n",
    "\n",
    "### 25.4.3 FM-Index (Concept)\n",
    "\n",
    "The FM-index (Full-text index in Minute space) combines the BWT with additional data structures (wavelet trees, rank/select) to support count and locate queries in sublinear time. It is widely used in bioinformatics (e.g., Bowtie, BWA).\n",
    "\n",
    "**Key components:**\n",
    "- **BWT string L**.\n",
    "- **Occurrence array** `occ(c, i)` = number of occurrences of character c in L[0..i-1] (can be stored as wavelet tree for O(log \u03a3) access).\n",
    "- **C array** `C[c]` = number of characters in text less than c (like start positions in F).\n",
    "\n",
    "**Query for pattern P:**\n",
    "- Start with range [l, r] covering the whole suffix array.\n",
    "- For each character in P from last to first:\n",
    "  - l = C[c] + occ(c, l-1) + 1\n",
    "  - r = C[c] + occ(c, r)\n",
    "- Resulting [l, r] gives the range of suffixes starting with P.\n",
    "- Locating positions requires additional sampled suffix array values.\n",
    "\n",
    "FM-index enables counting occurrences in O(|P|) time and locating in O(|P| + occ log n) time with small memory footprint.\n",
    "\n",
    "---\n",
    "\n",
    "## 25.5 Palindromic Trees (Eertree)\n",
    "\n",
    "A **palindromic tree** (also called Eertree) is a data structure for storing all distinct palindromic substrings of a string. It can be built in O(n) time and supports queries like number of distinct palindromes, longest palindrome suffix, and counting occurrences.\n",
    "\n",
    "### 25.5.1 Structure\n",
    "\n",
    "- **Two roots:** \n",
    "  - `root0` with length -1 (odd length root, representing imaginary palindrome of length -1).\n",
    "  - `root1` with length 0 (even length root, representing empty string).\n",
    "- Each node represents a palindrome string.\n",
    "- Each node stores:\n",
    "  - `len`: length of palindrome.\n",
    "  - `link`: suffix link to the longest proper palindromic suffix.\n",
    "  - `next`: dictionary mapping character to child node (the palindrome formed by adding character to both ends).\n",
    "  - `count`: number of occurrences (can be updated during construction).\n",
    "\n",
    "### 25.5.2 Construction\n",
    "\n",
    "We process characters one by one, maintaining a pointer `last` to the longest suffix palindrome ending at current position.\n",
    "\n",
    "```python\n",
    "class Eertree:\n",
    "    def __init__(self):\n",
    "        self.nodes = []\n",
    "        # Node: (length, link, next, count)\n",
    "        self.nodes.append({'len': -1, 'link': 0, 'next': {}, 'count': 0})  # root -1\n",
    "        self.nodes.append({'len': 0, 'link': 0, 'next': {}, 'count': 0})   # root 0\n",
    "        self.s = ['']  # characters, 1-indexed\n",
    "        self.last = 1  # last node (longest suffix palindrome)\n",
    "\n",
    "    def get_link(self, node, pos):\n",
    "        # Follow suffix links until we can add character at position pos\n",
    "        while True:\n",
    "            cur_len = self.nodes[node]['len']\n",
    "            if pos - cur_len - 1 >= 0 and self.s[pos - cur_len - 1] == self.s[pos]:\n",
    "                break\n",
    "            node = self.nodes[node]['link']\n",
    "        return node\n",
    "\n",
    "    def add_char(self, ch):\n",
    "        pos = len(self.s)\n",
    "        self.s.append(ch)\n",
    "        # Find node to extend from\n",
    "        curr = self.get_link(self.last, pos)\n",
    "        # Check if palindrome already exists\n",
    "        if ch in self.nodes[curr]['next']:\n",
    "            self.last = self.nodes[curr]['next'][ch]\n",
    "            self.nodes[self.last]['count'] += 1\n",
    "            return False\n",
    "        # Create new node\n",
    "        new_len = self.nodes[curr]['len'] + 2\n",
    "        self.nodes.append({'len': new_len, 'link': 0, 'next': {}, 'count': 1})\n",
    "        new_node = len(self.nodes) - 1\n",
    "        self.nodes[curr]['next'][ch] = new_node\n",
    "        # Set suffix link\n",
    "        if new_len == 1:\n",
    "            self.nodes[new_node]['link'] = 1  # link to empty string\n",
    "        else:\n",
    "            link_node = self.get_link(self.nodes[curr]['link'], pos)\n",
    "            self.nodes[new_node]['link'] = self.nodes[link_node]['next'][ch]\n",
    "        self.last = new_node\n",
    "        return True\n",
    "\n",
    "    def build(self, s):\n",
    "        for ch in s:\n",
    "            self.add_char(ch)\n",
    "        # Propagate counts along suffix links\n",
    "        for i in range(len(self.nodes)-1, 1, -1):\n",
    "            self.nodes[self.nodes[i]['link']]['count'] += self.nodes[i]['count']\n",
    "```\n",
    "\n",
    "### 25.5.3 Applications\n",
    "\n",
    "- **Counting distinct palindromic substrings:** Number of nodes minus 2 (excluding roots).\n",
    "- **Longest palindrome substring:** Maximum node length.\n",
    "- **Number of occurrences of each palindrome:** `node['count']` after propagation.\n",
    "- **Palindrome factorization:** Split string into fewest palindromic substrings (can be done with DP + eertree).\n",
    "- **Minimum number of palindromic concatenations:** DP with eertree for quick longest palindrome suffix queries.\n",
    "\n",
    "---\n",
    "\n",
    "## 25.6 Rolling Hash Variants\n",
    "\n",
    "Rolling hashes are used for efficient string comparison and substring searching. To avoid collisions, we often use multiple hashes or larger moduli.\n",
    "\n",
    "### 25.6.1 Polynomial Rolling Hash\n",
    "\n",
    "The classic polynomial hash:\n",
    "\n",
    "H(S) = (S[0] * b^(n-1) + S[1] * b^(n-2) + ... + S[n-1]) mod M\n",
    "\n",
    "Where b is a base (e.g., 131, 137, 91138233) and M is a large prime (e.g., 10^9+7, 10^9+9).\n",
    "\n",
    "**Properties:**\n",
    "- Can compute hash of any substring in O(1) using prefix hashes.\n",
    "- Collisions possible; probability low with large M.\n",
    "\n",
    "### 25.6.2 Double Hashing\n",
    "\n",
    "To virtually eliminate collisions, use two different moduli (e.g., 10^9+7 and 10^9+9) and possibly two bases. The hash is a pair (h1, h2). The chance of both colliding is negligible.\n",
    "\n",
    "```python\n",
    "class DoubleHash:\n",
    "    def __init__(self, s, base1=131, base2=137, mod1=10**9+7, mod2=10**9+9):\n",
    "        self.base1 = base1\n",
    "        self.base2 = base2\n",
    "        self.mod1 = mod1\n",
    "        self.mod2 = mod2\n",
    "        self.n = len(s)\n",
    "        self.pref1 = [0] * (self.n + 1)\n",
    "        self.pref2 = [0] * (self.n + 1)\n",
    "        self.pow1 = [1] * (self.n + 1)\n",
    "        self.pow2 = [1] * (self.n + 1)\n",
    "        for i, ch in enumerate(s):\n",
    "            self.pref1[i+1] = (self.pref1[i] * base1 + ord(ch)) % mod1\n",
    "            self.pref2[i+1] = (self.pref2[i] * base2 + ord(ch)) % mod2\n",
    "            self.pow1[i+1] = (self.pow1[i] * base1) % mod1\n",
    "            self.pow2[i+1] = (self.pow2[i] * base2) % mod2\n",
    "\n",
    "    def get_hash(self, l, r):\n",
    "        # [l, r) 0-indexed\n",
    "        h1 = (self.pref1[r] - self.pref1[l] * self.pow1[r-l]) % self.mod1\n",
    "        h2 = (self.pref2[r] - self.pref2[l] * self.pow2[r-l]) % self.mod2\n",
    "        return (h1, h2)\n",
    "```\n",
    "\n",
    "### 25.6.3 Applications\n",
    "\n",
    "- **Rabin-Karp** (as seen in Chapter 24).\n",
    "- **Longest common prefix** via binary search on hash equality.\n",
    "- **Checking string equality** in O(1) after preprocessing.\n",
    "- **Palindrome detection:** Compare hash of substring with hash of reverse substring.\n",
    "- **Anagram detection:** Rolling hash of sorted string (or using character count hashes).\n",
    "\n",
    "---\n",
    "\n",
    "## 25.7 Summary\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502 Structure            \u2502 Construction \u2502 Query Capabilities             \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Suffix Tree          \u2502 O(n)         \u2502 Pattern search O(m), LRS, LCS  \u2502\n",
    "\u2502 Suffix Array + LCP   \u2502 O(n log n)   \u2502 Pattern search O(m log n), LRS \u2502\n",
    "\u2502 BWT + FM-index       \u2502 O(n)         \u2502 Count O(m), locate O(m+occ)    \u2502\n",
    "\u2502 Eertree              \u2502 O(n)         \u2502 Palindrome queries             \u2502\n",
    "\u2502 Rolling Hash         \u2502 O(n)         \u2502 Substring compare O(1)          \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 25.8 Practice Problems\n",
    "\n",
    "### Suffix Arrays\n",
    "1. **Longest Common Prefix** (LeetCode 14) \u2013 but for suffix array, practice with SPOJ SUBST1 (distinct substrings).\n",
    "2. **Minimum Lexicographic Rotation** (LeetCode 1163) \u2013 use suffix array.\n",
    "3. **Number of Distinct Substrings** (LeetCode 1698) \u2013 suffix array + LCP.\n",
    "4. **Longest Repeated Substring** (LeetCode 1062) \u2013 suffix array + LCP.\n",
    "\n",
    "### Suffix Trees\n",
    "5. **Implement a suffix tree** (optional, advanced).\n",
    "6. **Find all occurrences of a pattern** \u2013 simulate using suffix array.\n",
    "\n",
    "### BWT\n",
    "7. **BWT Compression** \u2013 implement forward/inverse.\n",
    "8. **FM-index** \u2013 implement basic count query.\n",
    "\n",
    "### Eertree\n",
    "9. **Count Palindromic Substrings** (LeetCode 647) \u2013 eertree gives all distinct.\n",
    "10. **Palindrome Pairs** (LeetCode 336) \u2013 can be solved with trie, but eertree for suffix palindrome.\n",
    "\n",
    "### Rolling Hash\n",
    "11. **Longest Chunked Palindrome Decomposition** (LeetCode 1147) \u2013 rolling hash.\n",
    "12. **Repeated DNA Sequences** (LeetCode 187) \u2013 rolling hash.\n",
    "\n",
    "---\n",
    "\n",
    "## 25.9 Further Reading\n",
    "\n",
    "1. **\"Algorithms on Strings, Trees, and Sequences\"** by Dan Gusfield \u2013 the definitive reference.\n",
    "2. **\"Flexible Pattern Matching in Strings\"** by Gonzalo Navarro \u2013 covers suffix arrays, BWT, FM-index.\n",
    "3. **Original Papers**:\n",
    "   - Ukkonen, E. (1995) \u2013 \"On-line construction of suffix trees\"\n",
    "   - Manber, U., & Myers, G. (1993) \u2013 \"Suffix arrays: a new method for on-line string searches\"\n",
    "   - Burrows, M., & Wheeler, D. J. (1994) \u2013 \"A block-sorting lossless data compression algorithm\"\n",
    "   - Ferragina, P., & Manzini, G. (2000) \u2013 \"Opportunistic data structures with applications\"\n",
    "   - Rubinchik, M., & Shur, A. M. (2015) \u2013 \"Eertree: An efficient data structure for processing palindromes in strings\"\n",
    "\n",
    "---\n",
    "\n",
    "> **Coming in Chapter 26**: **Bit Manipulation** \u2013 We'll explore the world of bits, bitwise operators, and clever bit-level tricks.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 25**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='24. string_matching.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='../8. specialized_topics/26. bit_manipulation.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}