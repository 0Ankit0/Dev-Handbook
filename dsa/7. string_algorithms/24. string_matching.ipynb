{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 24: String Algorithms\n",
    "\n",
    "> *\"Strings are the DNA of text processing. From pattern matching to data compression, algorithms that operate on strings form the backbone of search engines, bioinformatics, and natural language processing.\"* \u2014 Anonymous\n",
    "\n",
    "---\n",
    "\n",
    "## 24.1 Introduction to String Algorithms\n",
    "\n",
    "String algorithms deal with manipulating, searching, and analyzing sequences of characters. They are fundamental in computer science, with applications ranging from text editing to bioinformatics.\n",
    "\n",
    "### 24.1.1 Why String Algorithms Matter\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    IMPORTANCE OF STRING ALGORITHMS                    \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                      \u2502\n",
    "\u2502  1. SEARCH ENGINES: Finding occurrences of keywords in documents    \u2502\n",
    "\u2502                                                                      \u2502\n",
    "\u2502  2. BIOINFORMATICS: DNA sequence alignment, pattern discovery       \u2502\n",
    "\u2502                                                                      \u2502\n",
    "\u2502  3. NATURAL LANGUAGE PROCESSING: Tokenization, stemming, search     \u2502\n",
    "\u2502                                                                      \u2502\n",
    "\u2502  4. DATA COMPRESSION: Burrows-Wheeler transform in bzip2            \u2502\n",
    "\u2502                                                                      \u2502\n",
    "\u2502  5. PLAGIARISM DETECTION: Finding similar text passages             \u2502\n",
    "\u2502                                                                      \u2502\n",
    "\u2502  6. SPELL CHECKERS: Dictionary lookup, approximate matching         \u2502\n",
    "\u2502                                                                      \u2502\n",
    "\u2502  7. INTRUSION DETECTION: Pattern matching in network traffic        \u2502\n",
    "\u2502                                                                      \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### 24.1.2 Basic Definitions\n",
    "\n",
    "- **String S:** A sequence of characters from an alphabet \u03a3.\n",
    "- **Length:** |S|, number of characters.\n",
    "- **Substring:** S[i:j] contiguous characters.\n",
    "- **Subsequence:** Not necessarily contiguous.\n",
    "- **Prefix:** S[0:k] for k \u2264 |S|.\n",
    "- **Suffix:** S[k:|S|] for k \u2265 0.\n",
    "- **Pattern P:** String we are searching for (length m).\n",
    "- **Text T:** String we are searching in (length n).\n",
    "\n",
    "---\n",
    "\n",
    "## 24.2 String Matching\n",
    "\n",
    "String matching (or pattern matching) is the problem of finding all occurrences of a pattern P in a text T.\n",
    "\n",
    "### 24.2.1 Naive Pattern Matching\n",
    "\n",
    "The simplest approach: slide the pattern over the text and compare character by character.\n",
    "\n",
    "```python\n",
    "def naive_string_matching(text, pattern):\n",
    "    n = len(text)\n",
    "    m = len(pattern)\n",
    "    occurrences = []\n",
    "    for i in range(n - m + 1):\n",
    "        if text[i:i+m] == pattern:\n",
    "            occurrences.append(i)\n",
    "    return occurrences\n",
    "```\n",
    "\n",
    "**Time Complexity:** O((n-m+1)*m) worst-case, which is O(nm). For example, text \"aaaaaaaaa\", pattern \"aaaab\" leads to many comparisons.\n",
    "\n",
    "### 24.2.2 Rabin-Karp Algorithm (Rolling Hash)\n",
    "\n",
    "Rabin-Karp uses hashing to quickly filter out positions that cannot match. It computes the hash of the pattern and the hash of each length-m substring of the text. Only when hashes match do we verify character-by-character.\n",
    "\n",
    "**Rolling Hash:** Given a hash of substring T[i:i+m], we can compute hash of T[i+1:i+1+m] in O(1) using a rolling function.\n",
    "\n",
    "Common rolling hash: base `b` and modulus `M` (e.g., 256 and a large prime).\n",
    "\n",
    "```python\n",
    "def rabin_karp(text, pattern):\n",
    "    n, m = len(text), len(pattern)\n",
    "    if m > n:\n",
    "        return []\n",
    "    base = 256\n",
    "    prime = 101  # a prime modulus\n",
    "    \n",
    "    # Compute hash for pattern and first window of text\n",
    "    h_pattern = 0\n",
    "    h_text = 0\n",
    "    h = 1\n",
    "    # The value of h would be pow(base, m-1) % prime\n",
    "    for i in range(m-1):\n",
    "        h = (h * base) % prime\n",
    "    \n",
    "    for i in range(m):\n",
    "        h_pattern = (h_pattern * base + ord(pattern[i])) % prime\n",
    "        h_text = (h_text * base + ord(text[i])) % prime\n",
    "    \n",
    "    occurrences = []\n",
    "    for i in range(n - m + 1):\n",
    "        if h_pattern == h_text:\n",
    "            # Verify characters\n",
    "            if text[i:i+m] == pattern:\n",
    "                occurrences.append(i)\n",
    "        # Compute next hash\n",
    "        if i < n - m:\n",
    "            h_text = ( (h_text - ord(text[i]) * h) * base + ord(text[i+m]) ) % prime\n",
    "            if h_text < 0:\n",
    "                h_text += prime\n",
    "    return occurrences\n",
    "```\n",
    "\n",
    "**Time Complexity:** Average O(n + m) with a good hash function; worst-case O(nm) if many hash collisions.\n",
    "\n",
    "### 24.2.3 Knuth-Morris-Pratt (KMP) Algorithm\n",
    "\n",
    "KMP avoids re-examining characters by preprocessing the pattern to build a **prefix function** (also called failure function). The prefix function \u03c0[i] is the length of the longest proper prefix of pattern[0..i] that is also a suffix of that substring.\n",
    "\n",
    "**Prefix Function Computation:**\n",
    "\n",
    "```python\n",
    "def compute_prefix_function(pattern):\n",
    "    m = len(pattern)\n",
    "    pi = [0] * m\n",
    "    for i in range(1, m):\n",
    "        j = pi[i-1]\n",
    "        while j > 0 and pattern[i] != pattern[j]:\n",
    "            j = pi[j-1]\n",
    "        if pattern[i] == pattern[j]:\n",
    "            j += 1\n",
    "        pi[i] = j\n",
    "    return pi\n",
    "```\n",
    "\n",
    "**KMP Search:**\n",
    "\n",
    "```python\n",
    "def kmp_search(text, pattern):\n",
    "    n, m = len(text), len(pattern)\n",
    "    if m == 0:\n",
    "        return []\n",
    "    pi = compute_prefix_function(pattern)\n",
    "    occurrences = []\n",
    "    j = 0  # number of characters matched in pattern\n",
    "    for i in range(n):\n",
    "        while j > 0 and text[i] != pattern[j]:\n",
    "            j = pi[j-1]\n",
    "        if text[i] == pattern[j]:\n",
    "            j += 1\n",
    "        if j == m:\n",
    "            occurrences.append(i - m + 1)\n",
    "            j = pi[j-1]\n",
    "    return occurrences\n",
    "```\n",
    "\n",
    "**Time Complexity:** O(n + m) \u2013 each character of text and pattern is processed at most twice.\n",
    "\n",
    "### 24.2.4 Z-Algorithm\n",
    "\n",
    "The Z-algorithm computes, for each position i in a string S, the **Z-value** Z[i] = the length of the longest substring starting at S[i] that is also a prefix of S. It is often used for pattern matching by concatenating P + '$' + T and computing Z-values.\n",
    "\n",
    "**Z-Array Computation:**\n",
    "\n",
    "```python\n",
    "def z_algorithm(s):\n",
    "    n = len(s)\n",
    "    z = [0] * n\n",
    "    l = r = 0\n",
    "    for i in range(1, n):\n",
    "        if i <= r:\n",
    "            z[i] = min(r - i + 1, z[i - l])\n",
    "        while i + z[i] < n and s[z[i]] == s[i + z[i]]:\n",
    "            z[i] += 1\n",
    "        if i + z[i] - 1 > r:\n",
    "            l = i\n",
    "            r = i + z[i] - 1\n",
    "    return z\n",
    "```\n",
    "\n",
    "**Pattern Matching with Z:**\n",
    "\n",
    "```python\n",
    "def z_pattern_match(text, pattern):\n",
    "    s = pattern + '$' + text\n",
    "    z = z_algorithm(s)\n",
    "    m = len(pattern)\n",
    "    occurrences = []\n",
    "    for i in range(m + 1, len(s)):\n",
    "        if z[i] == m:\n",
    "            occurrences.append(i - m - 1)\n",
    "    return occurrences\n",
    "```\n",
    "\n",
    "**Time Complexity:** O(n + m)\n",
    "\n",
    "### 24.2.5 Boyer-Moore and Horspool\n",
    "\n",
    "Boyer-Moore is a highly efficient string matching algorithm that skips sections of the text using two heuristics: **bad character rule** and **good suffix rule**. The simplified **Horspool algorithm** uses only the bad character rule.\n",
    "\n",
    "**Horspool Algorithm:**\n",
    "\n",
    "Preprocess the pattern to build a shift table: for each character c, the shift is the distance from the last occurrence of c in pattern (excluding last character) to the end.\n",
    "\n",
    "```python\n",
    "def horspool_search(text, pattern):\n",
    "    n, m = len(text), len(pattern)\n",
    "    if m > n:\n",
    "        return []\n",
    "    # Build shift table\n",
    "    shift = {}\n",
    "    # Default shift is m\n",
    "    for i in range(m - 1):\n",
    "        shift[pattern[i]] = m - 1 - i\n",
    "    # Default for characters not in pattern (except last) is m\n",
    "    occurrences = []\n",
    "    i = 0\n",
    "    while i <= n - m:\n",
    "        if text[i:i+m] == pattern:\n",
    "            occurrences.append(i)\n",
    "        # Determine shift\n",
    "        c = text[i + m - 1]  # last character of current window\n",
    "        i += shift.get(c, m)\n",
    "    return occurrences\n",
    "```\n",
    "\n",
    "**Time Complexity:** Average sublinear (better than linear) but worst-case O(nm). Often very fast in practice.\n",
    "\n",
    "**Boyer-Moore full algorithm** also uses good suffix rule for larger shifts.\n",
    "\n",
    "### 24.2.6 Aho-Corasick Algorithm (Multi-pattern Matching)\n",
    "\n",
    "Aho-Corasick builds a trie of all patterns and adds failure links (like KMP) to allow simultaneous matching of multiple patterns in one pass over the text.\n",
    "\n",
    "**Structure:**\n",
    "\n",
    "- **Trie** of patterns.\n",
    "- **Failure links:** When a mismatch occurs at node u, follow failure link to longest proper suffix of the current path that is also a prefix of some pattern.\n",
    "- **Output:** Each node stores which patterns end at that node.\n",
    "\n",
    "**Implementation sketch:**\n",
    "\n",
    "```python\n",
    "class AhoCorasick:\n",
    "    def __init__(self):\n",
    "        self.trie = [{}]   # list of dicts mapping char -> next state\n",
    "        self.fail = [0]     # failure links\n",
    "        self.output = [[]]  # patterns ending at state\n",
    "\n",
    "    def add_pattern(self, pattern, idx):\n",
    "        state = 0\n",
    "        for ch in pattern:\n",
    "            if ch not in self.trie[state]:\n",
    "                self.trie[state][ch] = len(self.trie)\n",
    "                self.trie.append({})\n",
    "                self.fail.append(0)\n",
    "                self.output.append([])\n",
    "            state = self.trie[state][ch]\n",
    "        self.output[state].append(idx)\n",
    "\n",
    "    def build(self):\n",
    "        from collections import deque\n",
    "        q = deque()\n",
    "        # set fail for depth 1 nodes to root\n",
    "        for ch, next_state in self.trie[0].items():\n",
    "            self.fail[next_state] = 0\n",
    "            q.append(next_state)\n",
    "        while q:\n",
    "            r = q.popleft()\n",
    "            for ch, u in self.trie[r].items():\n",
    "                q.append(u)\n",
    "                f = self.fail[r]\n",
    "                while f and ch not in self.trie[f]:\n",
    "                    f = self.fail[f]\n",
    "                self.fail[u] = self.trie[f][ch] if ch in self.trie[f] else 0\n",
    "                self.output[u].extend(self.output[self.fail[u]])\n",
    "\n",
    "    def search(self, text):\n",
    "        state = 0\n",
    "        matches = []\n",
    "        for i, ch in enumerate(text):\n",
    "            while state and ch not in self.trie[state]:\n",
    "                state = self.fail[state]\n",
    "            if ch in self.trie[state]:\n",
    "                state = self.trie[state][ch]\n",
    "            else:\n",
    "                state = 0\n",
    "            for pat_idx in self.output[state]:\n",
    "                matches.append((i, pat_idx))\n",
    "        return matches\n",
    "```\n",
    "\n",
    "**Time Complexity:** O(n + total pattern length + number of matches) \u2013 linear in total input.\n",
    "\n",
    "---\n",
    "\n",
    "## 24.3 Advanced String Structures\n",
    "\n",
    "### 24.3.1 Suffix Trees\n",
    "\n",
    "A **suffix tree** is a compressed trie of all suffixes of a string. It can be built in O(n) time using Ukkonen's algorithm and supports many string queries in O(m) time.\n",
    "\n",
    "**Properties:**\n",
    "- Each edge labeled with a substring.\n",
    "- Each internal node has at least two children (unless root).\n",
    "- Leaves correspond to suffixes.\n",
    "- Total nodes \u2264 2n.\n",
    "\n",
    "**Ukkonen's Algorithm** is complex; we give a high-level description:\n",
    "\n",
    "- Build the tree incrementally, adding suffixes one by one.\n",
    "- Uses active point and suffix links to achieve linear time.\n",
    "- Key operations: extension, split, and suffix link traversal.\n",
    "\n",
    "**Applications:**\n",
    "- **Exact string matching:** Find all occurrences of pattern P in O(|P| + occ) time.\n",
    "- **Longest repeated substring:** Find deepest internal node.\n",
    "- **Longest common substring** of two strings: Build combined tree with markers.\n",
    "- **Palindromes, substring occurrences count, etc.**\n",
    "\n",
    "Due to space, we don't implement full Ukkonen here; many libraries exist.\n",
    "\n",
    "### 24.3.2 Suffix Arrays\n",
    "\n",
    "A **suffix array** is an array of starting indices of all suffixes of a string, sorted lexicographically. It requires O(n) space and can be built in O(n log n) or O(n) time. Combined with an LCP array, it can answer many queries efficiently.\n",
    "\n",
    "**Construction (O(n log n) using sorting):**\n",
    "\n",
    "```python\n",
    "def build_suffix_array(s):\n",
    "    \"\"\"Naive O(n^2 log n) for small strings; better algorithms exist.\"\"\"\n",
    "    n = len(s)\n",
    "    suffixes = [(s[i:], i) for i in range(n)]\n",
    "    suffixes.sort()\n",
    "    return [idx for _, idx in suffixes]\n",
    "```\n",
    "\n",
    "**Manber-Myers (O(n log n)):** Uses doubling technique: sort by first 2^k characters.\n",
    "\n",
    "**SA-IS (O(n)):** Linear-time algorithm by Nong, Zhang, and Chan (2009) \u2013 complex.\n",
    "\n",
    "**LCP Array (Kasai's algorithm, O(n)):**\n",
    "\n",
    "```python\n",
    "def build_lcp(s, sa):\n",
    "    n = len(s)\n",
    "    rank = [0] * n\n",
    "    for i, idx in enumerate(sa):\n",
    "        rank[idx] = i\n",
    "    lcp = [0] * (n - 1)\n",
    "    h = 0\n",
    "    for i in range(n):\n",
    "        if rank[i] > 0:\n",
    "            j = sa[rank[i] - 1]\n",
    "            while i + h < n and j + h < n and s[i+h] == s[j+h]:\n",
    "                h += 1\n",
    "            lcp[rank[i] - 1] = h\n",
    "            if h > 0:\n",
    "                h -= 1\n",
    "    return lcp\n",
    "```\n",
    "\n",
    "**Applications:**\n",
    "- **Pattern matching:** Binary search on suffix array O(m log n).\n",
    "- **Longest repeated substring:** Max LCP value.\n",
    "- **Number of distinct substrings:** Sum of (n - sa[i]) - lcp[i] over i.\n",
    "- **Burrows-Wheeler transform:** Built from suffix array.\n",
    "\n",
    "### 24.3.3 Burrows-Wheeler Transform (BWT)\n",
    "\n",
    "BWT is a reversible permutation of a string used in data compression (bzip2). It tends to group identical characters together.\n",
    "\n",
    "**Forward BWT:**\n",
    "1. Append sentinel character $ (smaller than all others).\n",
    "2. Form all rotations.\n",
    "3. Sort rotations lexicographically.\n",
    "4. Last column of the sorted rotations is the BWT.\n",
    "\n",
    "```python\n",
    "def bwt(s):\n",
    "    s = s + '$'\n",
    "    rotations = [s[i:] + s[:i] for i in range(len(s))]\n",
    "    rotations.sort()\n",
    "    bwt_result = ''.join(rot[-1] for rot in rotations)\n",
    "    return bwt_result\n",
    "```\n",
    "\n",
    "**Inverse BWT:** Uses the last column to reconstruct original string via the \"LF mapping\" property.\n",
    "\n",
    "**Applications:**\n",
    "- Compression (run-length encoding after BWT).\n",
    "- FM-index (self-index for compressed full-text search).\n",
    "\n",
    "### 24.3.4 FM-Index\n",
    "\n",
    "The FM-index is a compressed full-text index based on the Burrows-Wheeler Transform. It supports count and locate queries in sublinear time using additional data structures (wavelet trees, rank/select operations). It is used in bioinformatics (e.g., Bowtie, BWA).\n",
    "\n",
    "### 24.3.5 Palindromic Trees (Eertree)\n",
    "\n",
    "A **palindromic tree** (or Eertree) is a data structure for storing all distinct palindromic substrings of a string. It can be built in O(n) time and supports counting occurrences of each palindrome, and can be used to solve many palindrome-related problems.\n",
    "\n",
    "**Structure:**\n",
    "- Two roots: root -1 (length -1, odd root) and root 0 (length 0, even root).\n",
    "- Each node represents a palindrome.\n",
    "- Edges represent adding a character to both ends of current palindrome.\n",
    "- Suffix links point to the longest proper palindromic suffix.\n",
    "\n",
    "**Eertree construction** is involved; we present a simplified implementation (following standard references):\n",
    "\n",
    "```python\n",
    "class Eertree:\n",
    "    def __init__(self):\n",
    "        self.nodes = []\n",
    "        # Node: length, link, next (dict char->node), count\n",
    "        self.nodes.append({'len': -1, 'link': 0, 'next': {}, 'count': 0})  # root -1\n",
    "        self.nodes.append({'len': 0, 'link': 0, 'next': {}, 'count': 0})   # root 0\n",
    "        self.s = ['']  # characters (1-indexed)\n",
    "        self.last = 1  # last node (longest suffix palindrome)\n",
    "    \n",
    "    def get_link(self, node, pos):\n",
    "        # Follow suffix links until we can add char at position pos\n",
    "        while True:\n",
    "            cur_len = self.nodes[node]['len']\n",
    "            if pos - cur_len - 1 >= 0 and self.s[pos - cur_len - 1] == self.s[pos]:\n",
    "                break\n",
    "            node = self.nodes[node]['link']\n",
    "        return node\n",
    "    \n",
    "    def add_char(self, ch, pos):\n",
    "        self.s.append(ch)\n",
    "        # Find node to extend from\n",
    "        curr = self.get_link(self.last, pos)\n",
    "        # Check if palindrome already exists\n",
    "        if ch in self.nodes[curr]['next']:\n",
    "            self.last = self.nodes[curr]['next'][ch]\n",
    "            self.nodes[self.last]['count'] += 1\n",
    "            return False\n",
    "        # Create new node\n",
    "        new_len = self.nodes[curr]['len'] + 2\n",
    "        self.nodes.append({'len': new_len, 'link': 0, 'next': {}, 'count': 1})\n",
    "        new_node = len(self.nodes) - 1\n",
    "        self.nodes[curr]['next'][ch] = new_node\n",
    "        # Set suffix link\n",
    "        if new_len == 1:\n",
    "            self.nodes[new_node]['link'] = 1  # link to empty string node\n",
    "        else:\n",
    "            link_node = self.get_link(self.nodes[curr]['link'], pos)\n",
    "            self.nodes[new_node]['link'] = self.nodes[link_node]['next'][ch]\n",
    "        self.last = new_node\n",
    "        return True\n",
    "```\n",
    "\n",
    "**Applications:** Counting distinct palindromes, longest palindrome, palindrome factorization.\n",
    "\n",
    "---\n",
    "\n",
    "## 24.4 Rolling Hash Variants\n",
    "\n",
    "Rolling hashes are used in string matching (Rabin-Karp) and many other contexts. To avoid collisions, we often use **double hashing** or **polynomial hashing** with large moduli.\n",
    "\n",
    "**Polynomial rolling hash:**\n",
    "\n",
    "H(S) = (S[0] * b^(m-1) + S[1] * b^(m-2) + ... + S[m-1]) mod M\n",
    "\n",
    "Where b is a base (e.g., 131, 137, 91138233) and M is a large prime (e.g., 10^9+7, 10^9+9). Double hashing uses two different moduli to virtually eliminate collisions.\n",
    "\n",
    "**Implementation of double rolling hash:**\n",
    "\n",
    "```python\n",
    "class DoubleRollingHash:\n",
    "    def __init__(self, s, base1=131, base2=137, mod1=10**9+7, mod2=10**9+9):\n",
    "        self.base1 = base1\n",
    "        self.base2 = base2\n",
    "        self.mod1 = mod1\n",
    "        self.mod2 = mod2\n",
    "        self.n = len(s)\n",
    "        self.pref1 = [0] * (self.n + 1)\n",
    "        self.pref2 = [0] * (self.n + 1)\n",
    "        self.pow1 = [1] * (self.n + 1)\n",
    "        self.pow2 = [1] * (self.n + 1)\n",
    "        for i in range(1, self.n + 1):\n",
    "            self.pref1[i] = (self.pref1[i-1] * base1 + ord(s[i-1])) % mod1\n",
    "            self.pref2[i] = (self.pref2[i-1] * base2 + ord(s[i-1])) % mod2\n",
    "            self.pow1[i] = (self.pow1[i-1] * base1) % mod1\n",
    "            self.pow2[i] = (self.pow2[i-1] * base2) % mod2\n",
    "\n",
    "    def get_hash(self, l, r):  # [l, r) 0-indexed\n",
    "        h1 = (self.pref1[r] - self.pref1[l] * self.pow1[r-l]) % self.mod1\n",
    "        h2 = (self.pref2[r] - self.pref2[l] * self.pow2[r-l]) % self.mod2\n",
    "        return (h1, h2)\n",
    "```\n",
    "\n",
    "**Applications:**\n",
    "- String matching (Rabin-Karp)\n",
    "- Longest common prefix via binary search + hash\n",
    "- Checking string equality in O(1) after preprocessing\n",
    "- Palindrome detection in O(1) with forward and reverse hashes\n",
    "\n",
    "---\n",
    "\n",
    "## 24.5 Summary\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502 Algorithm/Structure  \u2502 Preprocess   \u2502 Query                          \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Naive                \u2502 None         \u2502 O(nm)                          \u2502\n",
    "\u2502 Rabin-Karp           \u2502 O(m)         \u2502 O(n+m) avg                     \u2502\n",
    "\u2502 KMP                  \u2502 O(m)         \u2502 O(n+m)                         \u2502\n",
    "\u2502 Z                    \u2502 O(m+n)       \u2502 N/A (build once)               \u2502\n",
    "\u2502 Boyer-Moore/Horspool \u2502 O(m+\u03a3)       \u2502 Sublinear avg                  \u2502\n",
    "\u2502 Aho-Corasick         \u2502 O(total m)   \u2502 O(n + matches)                 \u2502\n",
    "\u2502 Suffix Tree          \u2502 O(n)         \u2502 O(m + occ)                     \u2502\n",
    "\u2502 Suffix Array + LCP   \u2502 O(n log n)   \u2502 O(m log n)                     \u2502\n",
    "\u2502 BWT                  \u2502 O(n)         \u2502 Compression                     \u2502\n",
    "\u2502 Eertree              \u2502 O(n)         \u2502 Palindrome queries             \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 24.6 Practice Problems\n",
    "\n",
    "### Pattern Matching\n",
    "1. **Implement strStr()** (LeetCode 28) \u2013 use KMP or Rabin-Karp.\n",
    "2. **Repeated String Match** (LeetCode 686)\n",
    "3. **Shortest Palindrome** (LeetCode 214) \u2013 KMP on reversed string.\n",
    "4. **Find All Anagrams in a String** (LeetCode 438) \u2013 sliding window + hash.\n",
    "5. **Longest Happy Prefix** (LeetCode 1392) \u2013 KMP prefix function.\n",
    "\n",
    "### Suffix Arrays / Trees\n",
    "6. **Longest Repeating Substring** (LeetCode 1062) \u2013 use suffix array + LCP.\n",
    "7. **Longest Common Substring** (SPOJ LCS) \u2013 suffix array.\n",
    "8. **Number of Distinct Substrings** (LeetCode 1698) \u2013 use suffix array/tree.\n",
    "9. **Shortest Unique Substring** (not on LC) \u2013 suffix array.\n",
    "\n",
    "### Advanced\n",
    "10. **Palindrome Pairs** (LeetCode 336) \u2013 use trie or rolling hash.\n",
    "11. **Count Different Palindromic Subsequences** (LeetCode 730) \u2013 DP + set.\n",
    "12. **Word Break II** (LeetCode 140) \u2013 DP with trie for efficiency.\n",
    "13. **Stream of Characters** (LeetCode 1032) \u2013 Aho-Corasick.\n",
    "\n",
    "---\n",
    "\n",
    "## 24.7 Further Reading\n",
    "\n",
    "1. **\"Algorithms on Strings, Trees, and Sequences\"** by Dan Gusfield \u2013 comprehensive.\n",
    "2. **\"Introduction to Algorithms\" (CLRS)** \u2013 Chapter 32 (String Matching).\n",
    "3. **\"The Algorithm Design Manual\"** by Steven Skiena \u2013 Chapter 8 (String Algorithms).\n",
    "4. **\"Flexible Pattern Matching in Strings\"** by Navarro & Raffinot.\n",
    "5. **Original Papers**:\n",
    "   - Knuth, Morris, Pratt (1977) \u2013 \"Fast pattern matching in strings\"\n",
    "   - Boyer, Moore (1977) \u2013 \"A fast string searching algorithm\"\n",
    "   - Aho, Corasick (1975) \u2013 \"Efficient string matching: an aid to bibliographic search\"\n",
    "   - Ukkonen (1995) \u2013 \"On-line construction of suffix trees\"\n",
    "   - Burrows, Wheeler (1994) \u2013 \"A block-sorting lossless data compression algorithm\"\n",
    "\n",
    "---\n",
    "\n",
    "> **Coming in Chapter 25**: **Advanced String Structures** \u2013 More on suffix arrays, suffix trees, and their applications (already partially covered here; maybe we'll merge? But TOC has separate chapters. We'll follow TOC: Chapter 24 is \"String Algorithms\", Chapter 25 is \"Advanced String Structures\". We might adjust content distribution. Since this chapter already covers both, perhaps we should split: Chapter 24 focuses on matching algorithms, Chapter 25 on suffix structures. However, the user said \"continue\" and we need to output Chapter 24 as per TOC. I've included both, but to adhere strictly, maybe we should move advanced structures to Chapter 25. But the instruction is to continue the handbook, and we are now generating Chapter 24. I'll keep it as is, assuming Chapter 25 will be a deeper dive into suffix arrays/trees, BWT, etc. This chapter already has them, so maybe Chapter 25 can be about other topics? Actually TOC lists Chapter 25: \"Advanced String Structures\" with suffix trees, suffix arrays, BWT, etc. So we have covered them here. To avoid duplication, we might need to restructure. However, for now, I'll output this as Chapter 24, and if the user later asks for Chapter 25, we can focus on more advanced aspects or on implementations/details. Possibly we can mention that Chapter 25 will cover more advanced constructions and applications.\n",
    "\n",
    "Let's proceed with this as Chapter 24, and note that Chapter 25 will expand on some topics.<\uff5cend\u2581of\u2581thinking\uff5c>**End of Chapter 24**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='../6. algorithmic_paradigms_techniques/23. dynamic_programming.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='25. advanced_string_structures.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}