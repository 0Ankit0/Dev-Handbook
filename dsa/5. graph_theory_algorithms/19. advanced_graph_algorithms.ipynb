{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 19: Advanced Graph Algorithms\n",
    "\n",
    "> *\"Beyond the basics lies a world of powerful techniques—network flows, matching, and decompositions—that unlock solutions to some of the most challenging problems in computer science.\"* — Anonymous\n",
    "\n",
    "---\n",
    "\n",
    "## 19.1 Introduction to Advanced Graph Algorithms\n",
    "\n",
    "While fundamental graph algorithms like BFS, DFS, shortest paths, and MSTs solve a wide range of problems, many real-world applications require more sophisticated techniques. This chapter explores advanced graph algorithms that:\n",
    "\n",
    "- **Model and optimize flow** through networks (transportation, communication, supply chains).\n",
    "- **Find optimal matchings** (assignments, pairing).\n",
    "- **Decompose trees** for efficient query processing.\n",
    "- **Search heuristically** for optimal paths in large state spaces.\n",
    "\n",
    "These algorithms are essential in operations research, bioinformatics, network design, and competitive programming.\n",
    "\n",
    "---\n",
    "\n",
    "## 19.2 Network Flow\n",
    "\n",
    "Network flow problems deal with moving a commodity from sources to sinks through a network with capacity constraints. The **maximum flow problem** seeks to maximize the amount of flow, while **minimum cost flow** adds cost per unit.\n",
    "\n",
    "### 19.2.1 Flow Networks: Definitions\n",
    "\n",
    "A **flow network** is a directed graph G = (V, E) with:\n",
    "- A **source** s (no incoming edges)\n",
    "- A **sink** t (no outgoing edges)\n",
    "- A **capacity** function c(u,v) ≥ 0 for each edge\n",
    "- A **flow** f(u,v) satisfying:\n",
    "  1. Capacity constraint: 0 ≤ f(u,v) ≤ c(u,v)\n",
    "  2. Flow conservation: For all u ∈ V \\ {s,t}, ∑_{v} f(v,u) = ∑_{v} f(u,v) (inflow = outflow)\n",
    "\n",
    "The **value** of a flow is |f| = ∑_{v} f(s,v) - ∑_{v} f(v,s) (net outflow from source).\n",
    "\n",
    "**Residual network:** For a given flow, the residual capacity is:\n",
    "- Forward residual: c_f(u,v) = c(u,v) - f(u,v)\n",
    "- Backward residual: c_f(v,u) = f(u,v) (allows \"undoing\" flow)\n",
    "\n",
    "An **augmenting path** is a path from s to t in the residual network.\n",
    "\n",
    "**Max-flow min-cut theorem:** The maximum flow value equals the capacity of the minimum s-t cut (partition of vertices with s in one side, t in the other, minimizing sum of capacities of edges crossing from source side to sink side).\n",
    "\n",
    "### 19.2.2 Ford-Fulkerson Method\n",
    "\n",
    "The Ford-Fulkerson method repeatedly finds augmenting paths and increases flow until no more exist.\n",
    "\n",
    "```python\n",
    "def ford_fulkerson(graph, source, sink):\n",
    "    \"\"\"\n",
    "    graph: adjacency matrix or dict with capacities\n",
    "    Returns max flow value.\n",
    "    \"\"\"\n",
    "    n = len(graph)\n",
    "    # Residual graph initially same as capacities\n",
    "    residual = [row[:] for row in graph]\n",
    "    parent = [-1] * n\n",
    "    max_flow = 0\n",
    "\n",
    "    def bfs(s, t):\n",
    "        # Find augmenting path using BFS (Edmonds-Karp)\n",
    "        visited = [False] * n\n",
    "        queue = [s]\n",
    "        visited[s] = True\n",
    "        while queue:\n",
    "            u = queue.pop(0)\n",
    "            for v in range(n):\n",
    "                if not visited[v] and residual[u][v] > 0:\n",
    "                    parent[v] = u\n",
    "                    if v == t:\n",
    "                        return True\n",
    "                    visited[v] = True\n",
    "                    queue.append(v)\n",
    "        return False\n",
    "\n",
    "    while bfs(source, sink):\n",
    "        # Find bottleneck capacity along path\n",
    "        path_flow = float('inf')\n",
    "        v = sink\n",
    "        while v != source:\n",
    "            u = parent[v]\n",
    "            path_flow = min(path_flow, residual[u][v])\n",
    "            v = u\n",
    "        # Update residual network\n",
    "        v = sink\n",
    "        while v != source:\n",
    "            u = parent[v]\n",
    "            residual[u][v] -= path_flow\n",
    "            residual[v][u] += path_flow\n",
    "            v = u\n",
    "        max_flow += path_flow\n",
    "    return max_flow\n",
    "```\n",
    "\n",
    "**Time Complexity:** O(E * |f*|) where |f*| is max flow value. With integer capacities, it terminates but can be slow if capacities are large.\n",
    "\n",
    "### 19.2.3 Edmonds-Karp Algorithm\n",
    "\n",
    "Edmonds-Karp is the Ford-Fulkerson method with BFS for augmenting paths (as implemented above). BFS ensures each augmenting path is the shortest in terms of number of edges, leading to polynomial time.\n",
    "\n",
    "**Complexity:** O(V E²) (each BFS O(E), number of augmentations O(VE)).\n",
    "\n",
    "### 19.2.4 Dinic's Algorithm\n",
    "\n",
    "Dinic's algorithm improves upon Edmonds-Karp by using level graphs and blocking flows. It works in phases: BFS to build level graph, then DFS to send blocking flow.\n",
    "\n",
    "```python\n",
    "from collections import deque\n",
    "\n",
    "def dinic_max_flow(graph, source, sink):\n",
    "    \"\"\"\n",
    "    graph: adjacency list with edges having 'capacity' attribute\n",
    "    We'll represent graph as dict: graph[u] = [Edge(v, capacity, rev_index)]\n",
    "    \"\"\"\n",
    "    n = len(graph)\n",
    "    level = [-1] * n\n",
    "    it = [0] * n\n",
    "    \n",
    "    class Edge:\n",
    "        def __init__(self, to, rev, capacity):\n",
    "            self.to = to\n",
    "            self.rev = rev\n",
    "            self.capacity = capacity\n",
    "    \n",
    "    # Build residual graph as adjacency list of Edge objects\n",
    "    adj = [[] for _ in range(n)]\n",
    "    for u in range(n):\n",
    "        for v, cap in graph[u]:\n",
    "            forward = Edge(v, len(adj[v]), cap)\n",
    "            backward = Edge(u, len(adj[u]), 0)\n",
    "            adj[u].append(forward)\n",
    "            adj[v].append(backward)\n",
    "    \n",
    "    def bfs():\n",
    "        for i in range(n):\n",
    "            level[i] = -1\n",
    "        queue = deque([source])\n",
    "        level[source] = 0\n",
    "        while queue:\n",
    "            u = queue.popleft()\n",
    "            for e in adj[u]:\n",
    "                if e.capacity > 0 and level[e.to] < 0:\n",
    "                    level[e.to] = level[u] + 1\n",
    "                    queue.append(e.to)\n",
    "        return level[sink] >= 0\n",
    "    \n",
    "    def dfs(u, flow):\n",
    "        if u == sink:\n",
    "            return flow\n",
    "        for i in range(it[u], len(adj[u])):\n",
    "            e = adj[u][i]\n",
    "            if e.capacity > 0 and level[u] < level[e.to]:\n",
    "                pushed = dfs(e.to, min(flow, e.capacity))\n",
    "                if pushed > 0:\n",
    "                    e.capacity -= pushed\n",
    "                    adj[e.to][e.rev].capacity += pushed\n",
    "                    return pushed\n",
    "            it[u] += 1\n",
    "        return 0\n",
    "    \n",
    "    max_flow = 0\n",
    "    while bfs():\n",
    "        it = [0] * n\n",
    "        while True:\n",
    "            pushed = dfs(source, float('inf'))\n",
    "            if pushed == 0:\n",
    "                break\n",
    "            max_flow += pushed\n",
    "    return max_flow\n",
    "```\n",
    "\n",
    "**Complexity:** O(V² E) worst-case, but often faster in practice. For unit capacity networks, O(min(V^(2/3), sqrt(E)) * E).\n",
    "\n",
    "### 19.2.5 Applications of Max Flow\n",
    "\n",
    "#### Maximum Bipartite Matching (as Flow)\n",
    "Create a source connected to left set, edges from left to right with capacity 1, right to sink with capacity 1. Max flow equals maximum matching.\n",
    "\n",
    "#### Minimum Cut\n",
    "The min s-t cut corresponds to max flow (by max-flow min-cut theorem). Used in image segmentation (graph cuts), network reliability.\n",
    "\n",
    "#### Edge-Disjoint Paths\n",
    "Max flow gives maximum number of edge-disjoint paths from s to t (each edge capacity 1).\n",
    "\n",
    "#### Circulation with Demands\n",
    "Supply/demand problems can be modeled as flow with lower bounds.\n",
    "\n",
    "---\n",
    "\n",
    "## 19.3 Maximum Bipartite Matching\n",
    "\n",
    "A **matching** in a graph is a set of edges without common vertices. In a bipartite graph (U ∪ V, E), a **maximum matching** pairs as many vertices as possible.\n",
    "\n",
    "### 19.3.1 Hopcroft-Karp Algorithm\n",
    "\n",
    "Hopcroft-Karp is the fastest known algorithm for maximum bipartite matching, running in O(E √V).\n",
    "\n",
    "```python\n",
    "from collections import deque\n",
    "\n",
    "def hopcroft_karp(graph, U, V):\n",
    "    \"\"\"\n",
    "    graph: adjacency list for vertices in U (0..U-1) to V (0..V-1)\n",
    "    Returns: matching size and matching array for U (pair_U[u] = v or -1)\n",
    "    \"\"\"\n",
    "    pair_U = [-1] * U\n",
    "    pair_V = [-1] * V\n",
    "    dist = [0] * U\n",
    "    \n",
    "    def bfs():\n",
    "        q = deque()\n",
    "        for u in range(U):\n",
    "            if pair_U[u] == -1:\n",
    "                dist[u] = 0\n",
    "                q.append(u)\n",
    "            else:\n",
    "                dist[u] = float('inf')\n",
    "        found = False\n",
    "        while q:\n",
    "            u = q.popleft()\n",
    "            for v in graph[u]:\n",
    "                pu = pair_V[v]\n",
    "                if pu != -1 and dist[pu] == float('inf'):\n",
    "                    dist[pu] = dist[u] + 1\n",
    "                    q.append(pu)\n",
    "                elif pu == -1:\n",
    "                    found = True\n",
    "        return found\n",
    "    \n",
    "    def dfs(u):\n",
    "        for v in graph[u]:\n",
    "            pu = pair_V[v]\n",
    "            if pu == -1 or (dist[pu] == dist[u] + 1 and dfs(pu)):\n",
    "                pair_U[u] = v\n",
    "                pair_V[v] = u\n",
    "                return True\n",
    "        dist[u] = float('inf')\n",
    "        return False\n",
    "    \n",
    "    matching = 0\n",
    "    while bfs():\n",
    "        for u in range(U):\n",
    "            if pair_U[u] == -1 and dfs(u):\n",
    "                matching += 1\n",
    "    return matching, pair_U\n",
    "```\n",
    "\n",
    "**Algorithm phases:** BFS builds layers of unmatched vertices, DFS finds augmenting paths. Works in O(√V) phases.\n",
    "\n",
    "---\n",
    "\n",
    "## 19.4 Min-Cost Max-Flow\n",
    "\n",
    "Given a flow network with costs per unit flow on edges, find a maximum flow of minimum total cost. This problem combines max flow with shortest paths.\n",
    "\n",
    "### 19.4.1 Successive Shortest Path Algorithm\n",
    "\n",
    "Repeatedly find cheapest augmenting path (in terms of cost) using potentials (Johnson's reweighting) to handle negative costs.\n",
    "\n",
    "```python\n",
    "import heapq\n",
    "\n",
    "def min_cost_max_flow(graph, source, sink):\n",
    "    \"\"\"\n",
    "    graph: adjacency list of (to, capacity, cost)\n",
    "    Returns (max_flow, min_cost)\n",
    "    \"\"\"\n",
    "    n = len(graph)\n",
    "    # Build residual graph with Edge objects\n",
    "    adj = [[] for _ in range(n)]\n",
    "    for u in range(n):\n",
    "        for v, cap, cost in graph[u]:\n",
    "            forward = [v, cap, cost, len(adj[v])]\n",
    "            backward = [u, 0, -cost, len(adj[u])]\n",
    "            adj[u].append(forward)\n",
    "            adj[v].append(backward)\n",
    "    \n",
    "    pot = [0] * n  # potentials for Johnson's\n",
    "    prev_node = [0] * n\n",
    "    prev_edge = [0] * n\n",
    "    dist = [0] * n\n",
    "    INF = float('inf')\n",
    "    flow = 0\n",
    "    flow_cost = 0\n",
    "    \n",
    "    while True:\n",
    "        # Dijkstra with potentials\n",
    "        for i in range(n):\n",
    "            dist[i] = INF\n",
    "        dist[source] = 0\n",
    "        pq = [(0, source)]\n",
    "        while pq:\n",
    "            d, u = heapq.heappop(pq)\n",
    "            if d != dist[u]:\n",
    "                continue\n",
    "            for i, e in enumerate(adj[u]):\n",
    "                v, cap, cost, _ = e\n",
    "                if cap > 0 and dist[v] > dist[u] + cost + pot[u] - pot[v]:\n",
    "                    dist[v] = dist[u] + cost + pot[u] - pot[v]\n",
    "                    prev_node[v] = u\n",
    "                    prev_edge[v] = i\n",
    "                    heapq.heappush(pq, (dist[v], v))\n",
    "        if dist[sink] == INF:\n",
    "            break\n",
    "        # Update potentials\n",
    "        for i in range(n):\n",
    "            if dist[i] < INF:\n",
    "                pot[i] += dist[i]\n",
    "        # Find bottleneck\n",
    "        aug_flow = INF\n",
    "        v = sink\n",
    "        while v != source:\n",
    "            u = prev_node[v]\n",
    "            e = adj[u][prev_edge[v]]\n",
    "            aug_flow = min(aug_flow, e[1])\n",
    "            v = u\n",
    "        # Update residual graph\n",
    "        v = sink\n",
    "        while v != source:\n",
    "            u = prev_node[v]\n",
    "            e = adj[u][prev_edge[v]]\n",
    "            e[1] -= aug_flow\n",
    "            rev = adj[v][e[3]]\n",
    "            rev[1] += aug_flow\n",
    "            flow_cost += aug_flow * e[2]\n",
    "            v = u\n",
    "        flow += aug_flow\n",
    "    return flow, flow_cost\n",
    "```\n",
    "\n",
    "**Complexity:** O(F * E log V) where F is max flow value. With potentials, Dijkstra runs in O(E log V) per augmentation.\n",
    "\n",
    "### 19.4.2 Cycle Canceling Algorithm\n",
    "\n",
    "Another approach: first find any max flow, then repeatedly find negative-cost cycles in the residual network and cancel them to reduce cost.\n",
    "\n",
    "**Applications:** Transportation problems, assignment problems (with costs), minimum-cost matching.\n",
    "\n",
    "---\n",
    "\n",
    "## 19.5 Heavy-Light Decomposition (HLD)\n",
    "\n",
    "Heavy-Light Decomposition is a technique to decompose a tree into paths (heavy paths) to answer path queries efficiently (e.g., maximum edge weight on path, sum of values, etc.) in O(log² n) time.\n",
    "\n",
    "### 19.5.1 Definitions\n",
    "\n",
    "- **Size** of a node: number of nodes in its subtree.\n",
    "- **Heavy child:** The child with the largest subtree size (ties broken arbitrarily).\n",
    "- **Light edge:** Edge from a node to a child that is not heavy.\n",
    "- **Heavy path:** A maximal path where all edges are heavy.\n",
    "\n",
    "HLD decomposes the tree into O(log n) heavy paths. Each node belongs to exactly one heavy path.\n",
    "\n",
    "### 19.5.2 Decomposition Algorithm\n",
    "\n",
    "```python\n",
    "class HeavyLightDecomposition:\n",
    "    def __init__(self, adj, root=0):\n",
    "        self.n = len(adj)\n",
    "        self.adj = adj\n",
    "        self.parent = [-1] * self.n\n",
    "        self.depth = [0] * self.n\n",
    "        self.size = [1] * self.n\n",
    "        self.heavy = [-1] * self.n  # heavy child\n",
    "        self.head = [0] * self.n    # top of heavy path\n",
    "        self.pos = [0] * self.n      # position in linear order (for segment tree)\n",
    "        self.cur_pos = 0\n",
    "        \n",
    "        self.dfs_size(root, -1)\n",
    "        self.decompose(root, -1, root)\n",
    "    \n",
    "    def dfs_size(self, u, p):\n",
    "        self.parent[u] = p\n",
    "        max_size = 0\n",
    "        for v in self.adj[u]:\n",
    "            if v == p:\n",
    "                continue\n",
    "            self.depth[v] = self.depth[u] + 1\n",
    "            self.dfs_size(v, u)\n",
    "            self.size[u] += self.size[v]\n",
    "            if self.size[v] > max_size:\n",
    "                max_size = self.size[v]\n",
    "                self.heavy[u] = v\n",
    "    \n",
    "    def decompose(self, u, p, h):\n",
    "        self.head[u] = h\n",
    "        self.pos[u] = self.cur_pos\n",
    "        self.cur_pos += 1\n",
    "        if self.heavy[u] != -1:\n",
    "            self.decompose(self.heavy[u], u, h)\n",
    "        for v in self.adj[u]:\n",
    "            if v != p and v != self.heavy[u]:\n",
    "                self.decompose(v, u, v)\n",
    "    \n",
    "    def query_path(self, u, v):\n",
    "        # Template: process path u-v using segment tree over pos\n",
    "        res = 0  # or appropriate initial value\n",
    "        while self.head[u] != self.head[v]:\n",
    "            if self.depth[self.head[u]] < self.depth[self.head[v]]:\n",
    "                u, v = v, u\n",
    "            # query from pos[head[u]] to pos[u]\n",
    "            # res = combine(res, seg_query(pos[head[u]], pos[u]))\n",
    "            u = self.parent[self.head[u]]\n",
    "        if self.depth[u] > self.depth[v]:\n",
    "            u, v = v, u\n",
    "        # now u is LCA, query from pos[u] to pos[v] (excluding u if edge values)\n",
    "        # res = combine(res, seg_query(pos[u], pos[v]))\n",
    "        return res\n",
    "```\n",
    "\n",
    "### 19.5.3 Applications\n",
    "\n",
    "- **Path queries:** Max/min/sum on path between two nodes (using segment tree on `pos` array).\n",
    "- **Path updates:** Add a value to all nodes on a path.\n",
    "- **LCA queries:** HLD can also compute LCA by climbing paths.\n",
    "\n",
    "**Complexity:** Each climb up a heavy path reduces depth, O(log n) climbs; each climb uses segment tree O(log n). Total O(log² n) per query.\n",
    "\n",
    "---\n",
    "\n",
    "## 19.6 Centroid Decomposition\n",
    "\n",
    "Centroid decomposition recursively splits a tree at its centroid (node whose removal yields subtrees each of size ≤ n/2). This creates a decomposition tree of height O(log n) used for solving path counting problems.\n",
    "\n",
    "### 19.6.1 Definition\n",
    "\n",
    "The **centroid** of a tree is a node such that when removed, each resulting component has size ≤ n/2. Every tree has at least one centroid.\n",
    "\n",
    "### 19.6.2 Decomposition Algorithm\n",
    "\n",
    "```python\n",
    "class CentroidDecomposition:\n",
    "    def __init__(self, adj):\n",
    "        self.adj = adj\n",
    "        self.n = len(adj)\n",
    "        self.deleted = [False] * self.n\n",
    "        self.subtree_size = [0] * self.n\n",
    "        self.parent_centroid = [-1] * self.n  # parent in centroid tree\n",
    "    \n",
    "    def dfs_size(self, u, p):\n",
    "        self.subtree_size[u] = 1\n",
    "        for v in self.adj[u]:\n",
    "            if v != p and not self.deleted[v]:\n",
    "                self.dfs_size(v, u)\n",
    "                self.subtree_size[u] += self.subtree_size[v]\n",
    "    \n",
    "    def find_centroid(self, u, p, total_size):\n",
    "        for v in self.adj[u]:\n",
    "            if v != p and not self.deleted[v] and self.subtree_size[v] > total_size // 2:\n",
    "                return self.find_centroid(v, u, total_size)\n",
    "        return u\n",
    "    \n",
    "    def decompose(self, root, parent_centroid=-1):\n",
    "        # Compute sizes\n",
    "        self.dfs_size(root, -1)\n",
    "        # Find centroid\n",
    "        c = self.find_centroid(root, -1, self.subtree_size[root])\n",
    "        self.parent_centroid[c] = parent_centroid\n",
    "        # Mark centroid as deleted\n",
    "        self.deleted[c] = True\n",
    "        # Recurse on each component\n",
    "        for v in self.adj[c]:\n",
    "            if not self.deleted[v]:\n",
    "                self.decompose(v, c)\n",
    "        return c\n",
    "    \n",
    "    def build(self):\n",
    "        return self.decompose(0)\n",
    "```\n",
    "\n",
    "### 19.6.3 Applications\n",
    "\n",
    "- **Counting paths with constraints:** e.g., number of paths of length exactly k, paths with sum ≤ K, etc.\n",
    "- **Divide-and-conquer on trees:** Solve problems by considering paths passing through centroid, then recurse.\n",
    "\n",
    "**Complexity:** O(n log n) total if each level processes O(n) work.\n",
    "\n",
    "---\n",
    "\n",
    "## 19.7 A* Search Algorithm (Recap)\n",
    "\n",
    "A* (A-star) is a heuristic search algorithm for finding the shortest path from a start node to a goal node. It was covered briefly in Chapter 17, but we expand here with emphasis on heuristics.\n",
    "\n",
    "### 19.7.1 Algorithm\n",
    "\n",
    "A* maintains for each node n:\n",
    "- `g(n)`: actual cost from start to n\n",
    "- `h(n)`: heuristic estimate of cost from n to goal\n",
    "- `f(n) = g(n) + h(n)`\n",
    "\n",
    "It expands nodes with smallest f, using a priority queue. The heuristic must be **admissible** (never overestimates true cost) for optimality, and **consistent** (or monotone) for efficiency.\n",
    "\n",
    "### 19.7.2 Heuristics\n",
    "\n",
    "Common heuristics:\n",
    "- **Manhattan distance** for grid movement (4-direction).\n",
    "- **Euclidean distance** for continuous space.\n",
    "- **Octile distance** for 8-direction grids.\n",
    "- **Pattern databases** for puzzles (15-puzzle).\n",
    "\n",
    "### 19.7.3 Properties\n",
    "\n",
    "- Optimal if heuristic is admissible.\n",
    "- With consistent heuristic, A* never re-opens nodes.\n",
    "- Time complexity: O(b^d) worst-case but often much better in practice.\n",
    "\n",
    "---\n",
    "\n",
    "## 19.8 Summary and Comparison\n",
    "\n",
    "```\n",
    "┌──────────────────────┬──────────────┬───────────────┬────────────────────────────┐\n",
    "│ Algorithm            │ Time         │ Space         │ Use Case                   │\n",
    "├──────────────────────┼──────────────┼───────────────┼────────────────────────────┤\n",
    "│ Ford-Fulkerson       │ O(E|f|)      │ O(V+E)        │ Small capacities           │\n",
    "│ Edmonds-Karp         │ O(VE²)       │ O(V+E)        │ General max flow           │\n",
    "│ Dinic                │ O(V²E)       │ O(V+E)        │ Max flow, esp. unit caps   │\n",
    "│ Hopcroft-Karp        │ O(E√V)       │ O(V+E)        │ Maximum bipartite matching │\n",
    "│ Min-cost max-flow    │ O(F E log V) │ O(V+E)        │ Flow with costs            │\n",
    "│ Heavy-Light Decomp    │ O(n) build   │ O(n)          │ Path queries on trees      │\n",
    "│                      │ O(log² n)/q   │               │                            │\n",
    "│ Centroid Decomp       │ O(n log n)   │ O(n)          │ Path counting on trees     │\n",
    "└──────────────────────┴──────────────┴───────────────┴────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 19.9 Practice Problems\n",
    "\n",
    "### Problem 1: Maximum Flow (LeetCode 1514) – Actually LeetCode 1514 is \"Path with Maximum Probability\", not flow. For flow: LeetCode 1462? Better: Classic problems: \"Maximum Flow\" on UVA, SPOJ.\n",
    "\n",
    "### Problem 2: Minimum Cost to Connect Two Groups of Points (LeetCode 1595)\n",
    "Solve using min-cost max-flow.\n",
    "\n",
    "### Problem 3: Bipartite Matching (LeetCode 1349) – Maximum Students Taking Exam.\n",
    "\n",
    "### Problem 4: Path Queries on Tree (LeetCode 1483) – Kth Ancestor, can use HLD.\n",
    "\n",
    "### Problem 5: Count Paths with Sum (LeetCode 437) – but on tree, can use centroid decomposition.\n",
    "\n",
    "### Problem 6: Network Flow for Project Selection (max-weight closure)\n",
    "Given projects with profits and prerequisites, find max profit subset.\n",
    "\n",
    "### Problem 7: A* for Sliding Puzzle (LeetCode 773) – Sliding Puzzle, use Manhattan heuristic.\n",
    "\n",
    "### Problem 8: Minimum Path Cover in DAG (can be reduced to max matching)\n",
    "\n",
    "---\n",
    "\n",
    "## 19.10 Further Reading\n",
    "\n",
    "1. **\"Introduction to Algorithms\" (CLRS)** – Chapters 26 (Max Flow), 27 (Matching), 29 (Linear Programming)\n",
    "2. **\"Algorithm Design\"** by Kleinberg & Tardos – Chapters 7 (Network Flow)\n",
    "3. **\"The Algorithm Design Manual\"** by Steven Skiena – Chapter 8 (Network Flow)\n",
    "4. **\"Competitive Programming\"** by Halim & Halim – Sections on flow, matching, tree decompositions\n",
    "5. **Original Papers**:\n",
    "   - Edmonds, J., & Karp, R. M. (1972) – \"Theoretical improvements in algorithmic efficiency for network flow problems\"\n",
    "   - Dinic, E. A. (1970) – \"Algorithm for solution of a problem of maximum flow in a network with power estimation\"\n",
    "   - Hopcroft, J. E., & Karp, R. M. (1973) – \"An n^(5/2) algorithm for maximum matchings in bipartite graphs\"\n",
    "   - Sleator, D. D., & Tarjan, R. E. (1983) – \"A data structure for dynamic trees\" (related to HLD)\n",
    "\n",
    "---\n",
    "\n",
    "> **Coming in Chapter 20**: **Recursion and Backtracking** – We'll dive into recursive problem-solving, backtracking frameworks, and constraint satisfaction.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 19**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
