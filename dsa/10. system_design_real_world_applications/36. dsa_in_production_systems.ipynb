{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 36: DSA in Production Systems\n",
    "\n",
    "> *\"In production, data structures are not just academic exercises—they are the backbone of systems that serve millions of users. Efficiency, reliability, and scalability are paramount.\"* — Anonymous\n",
    "\n",
    "---\n",
    "\n",
    "## 36.1 Introduction\n",
    "\n",
    "While the previous chapters focused on the theory and implementation of data structures, this chapter bridges the gap to real‑world engineering. In production systems, we face constraints such as massive scale, concurrency, fault tolerance, and hardware limitations. The data structures we choose must not only be asymptotically efficient but also perform well under these conditions.\n",
    "\n",
    "### 36.1.1 Why Production Systems Differ\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    PRODUCTION CONSIDERATIONS                          │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                      │\n",
    "│  1. SCALE: Millions or billions of items, terabytes of data.        │\n",
    "│  2. CONCURRENCY: Thousands of simultaneous requests.                │\n",
    "│  3. PERSISTENCE: Data must survive crashes (disk storage).          │\n",
    "│  4. DISTRIBUTION: Data spread across multiple machines.             │\n",
    "│  5. REAL‑TIME RESPONSES: Sub‑millisecond latency requirements.      │\n",
    "│  6. FAULT TOLERANCE: System must handle failures gracefully.        │\n",
    "│                                                                      │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "In this chapter, we explore how classic data structures are adapted and combined to meet these demands in production systems.\n",
    "\n",
    "---\n",
    "\n",
    "## 36.2 Database Indexing Structures\n",
    "\n",
    "Databases rely on indexing to provide fast access to data without scanning entire tables. Two dominant index structures are **B+ Trees** and **LSM Trees**.\n",
    "\n",
    "### 36.2.1 B+ Trees\n",
    "\n",
    "B+ trees are the standard index structure in relational databases (MySQL InnoDB, PostgreSQL, Oracle). They are a variant of B‑trees where all data resides in leaves, and internal nodes only store keys (routing information). Leaves are linked for efficient range scans.\n",
    "\n",
    "**Why B+ Trees?**\n",
    "- **High fanout:** Each node holds many keys (order = block size / key size), so the tree height is small (typically 3–4 levels even for billions of rows).\n",
    "- **Disk‑optimized:** Nodes correspond to disk pages, minimizing I/O.\n",
    "- **Range queries:** Leaf linkage allows sequential scans without going back up the tree.\n",
    "\n",
    "**Operations:**\n",
    "- **Search:** Follow path from root to leaf; one disk read per level.\n",
    "- **Insert:** Find leaf, insert key; if leaf overflows, split and propagate.\n",
    "- **Delete:** Find leaf, remove key; if underflow, borrow from sibling or merge.\n",
    "\n",
    "**Example (conceptual):**\n",
    "```\n",
    "Root: [50, 100]\n",
    "         /    |    \\\n",
    "    [10,20] [60,70] [110,120]   (internal nodes)\n",
    "       |       |        |\n",
    "    data    data     data       (leaf nodes)\n",
    "     ↓       ↓         ↓\n",
    "    [10,20] [60,70]  [110,120]  (leaves linked)\n",
    "```\n",
    "\n",
    "### 36.2.2 LSM Trees (Log‑Structured Merge Trees)\n",
    "\n",
    "LSM trees are used in modern NoSQL databases (Cassandra, RocksDB, LevelDB) and are optimized for high write throughput.\n",
    "\n",
    "**Structure:**\n",
    "- **Memtable:** An in‑memory balanced tree (often a skip list or red‑black tree) that accepts writes. Writes are appended to a write‑ahead log (WAL) for durability.\n",
    "- **SSTables (Sorted String Tables):** When the memtable is full, it is flushed to disk as an immutable SSTable. Each SSTable is a sorted file.\n",
    "- **Compaction:** Background process merges SSTables to keep the number of files manageable and to remove deleted or outdated entries.\n",
    "\n",
    "**Advantages:**\n",
    "- **Write‑optimized:** Writes are O(log n) in‑memory and then sequential disk writes.\n",
    "- **Reads:** May need to check multiple SSTables; **bloom filters** are often used to avoid checking files that definitely do not contain the key.\n",
    "- **Space amplification:** Compaction trades off write amplification for read performance.\n",
    "\n",
    "**Trade‑offs:**\n",
    "- Read amplification (checking multiple files) can be high, mitigated by caching and bloom filters.\n",
    "- Compaction consumes I/O and CPU.\n",
    "\n",
    "**Implementation sketch (simplified):**\n",
    "```python\n",
    "# Not actual production code; illustrates concept\n",
    "class LSMTree:\n",
    "    def __init__(self):\n",
    "        self.memtable = {}  # in‑memory sorted structure (e.g., sorted dict)\n",
    "        self.sstables = []  # list of on‑disk sorted files\n",
    "        self.wal = open(\"wal.log\", \"a\")\n",
    "\n",
    "    def put(self, key, value):\n",
    "        self.wal.write(f\"{key},{value}\\n\")\n",
    "        self.memtable[key] = value\n",
    "        if len(self.memtable) > THRESHOLD:\n",
    "            self.flush()\n",
    "\n",
    "    def get(self, key):\n",
    "        if key in self.memtable:\n",
    "            return self.memtable[key]\n",
    "        for sstable in reversed(self.sstables):  # newest first\n",
    "            if key in sstable:\n",
    "                return sstable[key]\n",
    "        return None\n",
    "\n",
    "    def flush(self):\n",
    "        # write memtable to new SSTable\n",
    "        sstable = sorted(self.memtable.items())\n",
    "        filename = f\"sstable_{len(self.sstables)}.data\"\n",
    "        with open(filename, \"w\") as f:\n",
    "            for k, v in sstable:\n",
    "                f.write(f\"{k},{v}\\n\")\n",
    "        self.sstables.append(filename)\n",
    "        self.memtable.clear()\n",
    "        self.wal.truncate(0)  # truncate WAL (in practice, rotate)\n",
    "```\n",
    "\n",
    "**In production**, LSM trees use skip lists for memtables, bloom filters for fast negative lookups, and sophisticated compaction strategies (size‑tiered, leveled).\n",
    "\n",
    "---\n",
    "\n",
    "## 36.3 Caching Strategies\n",
    "\n",
    "Caches store frequently accessed data in fast memory (RAM) to reduce latency and load on backend systems. Two classic eviction policies are **LRU** and **LFU**.\n",
    "\n",
    "### 36.3.1 LRU Cache (Least Recently Used)\n",
    "\n",
    "LRU evicts the item that has not been used for the longest time. It requires:\n",
    "- Fast lookup (hash map)\n",
    "- Fast way to move an item to the front on access (doubly linked list)\n",
    "\n",
    "**Implementation using `OrderedDict` (Python) or `LinkedHashMap` (Java):**\n",
    "\n",
    "```python\n",
    "from collections import OrderedDict\n",
    "\n",
    "class LRUCache:\n",
    "    def __init__(self, capacity):\n",
    "        self.cache = OrderedDict()\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def get(self, key):\n",
    "        if key not in self.cache:\n",
    "            return -1\n",
    "        self.cache.move_to_end(key)  # mark as recently used\n",
    "        return self.cache[key]\n",
    "\n",
    "    def put(self, key, value):\n",
    "        if key in self.cache:\n",
    "            self.cache.move_to_end(key)\n",
    "        self.cache[key] = value\n",
    "        if len(self.cache) > self.capacity:\n",
    "            self.cache.popitem(last=False)  # remove least recently used\n",
    "```\n",
    "\n",
    "**Manual implementation with dict + doubly linked list** (common interview question):\n",
    "\n",
    "```python\n",
    "class Node:\n",
    "    def __init__(self, key, val):\n",
    "        self.key = key\n",
    "        self.val = val\n",
    "        self.prev = None\n",
    "        self.next = None\n",
    "\n",
    "class LRUCache:\n",
    "    def __init__(self, capacity):\n",
    "        self.cap = capacity\n",
    "        self.cache = {}\n",
    "        self.head = Node(0, 0)\n",
    "        self.tail = Node(0, 0)\n",
    "        self.head.next = self.tail\n",
    "        self.tail.prev = self.head\n",
    "\n",
    "    def _remove(self, node):\n",
    "        node.prev.next = node.next\n",
    "        node.next.prev = node.prev\n",
    "\n",
    "    def _add(self, node):\n",
    "        node.prev = self.head\n",
    "        node.next = self.head.next\n",
    "        self.head.next.prev = node\n",
    "        self.head.next = node\n",
    "\n",
    "    def get(self, key):\n",
    "        if key in self.cache:\n",
    "            node = self.cache[key]\n",
    "            self._remove(node)\n",
    "            self._add(node)\n",
    "            return node.val\n",
    "        return -1\n",
    "\n",
    "    def put(self, key, value):\n",
    "        if key in self.cache:\n",
    "            self._remove(self.cache[key])\n",
    "        node = Node(key, value)\n",
    "        self._add(node)\n",
    "        self.cache[key] = node\n",
    "        if len(self.cache) > self.cap:\n",
    "            lru = self.tail.prev\n",
    "            self._remove(lru)\n",
    "            del self.cache[lru.key]\n",
    "```\n",
    "\n",
    "### 36.3.2 LFU Cache (Least Frequently Used)\n",
    "\n",
    "LFU evicts the item with the lowest access frequency. If multiple items have the same frequency, evict the least recently used among them (LRU tie‑breaker).\n",
    "\n",
    "Implementation is more complex; often uses a hash map from frequency to a doubly linked list of nodes, plus another hash map from key to node. Frequency counts are updated on access.\n",
    "\n",
    "**High‑level design:**\n",
    "- `key_node` map: key → (value, freq, node in freq list)\n",
    "- `freq_list` map: freq → doubly linked list of keys with that frequency\n",
    "- On access, move key from current freq list to freq+1 list (creating list if needed).\n",
    "\n",
    "**Time:** O(1) per operation.\n",
    "\n",
    "**Example code (simplified, not full production):**\n",
    "\n",
    "```python\n",
    "class LFUCache:\n",
    "    def __init__(self, capacity):\n",
    "        self.cap = capacity\n",
    "        self.key_node = {}  # key -> (value, freq, node_in_freq_list)\n",
    "        self.freq_nodes = {}  # freq -> doubly linked list (head, tail)\n",
    "        self.min_freq = 0\n",
    "\n",
    "    def _add_to_freq(self, key, freq):\n",
    "        # add key to freq list (as most recent)\n",
    "        pass\n",
    "\n",
    "    def _remove_from_freq(self, key, freq):\n",
    "        # remove key from freq list\n",
    "        pass\n",
    "\n",
    "    def get(self, key):\n",
    "        if key not in self.key_node:\n",
    "            return -1\n",
    "        value, freq, _ = self.key_node[key]\n",
    "        self._remove_from_freq(key, freq)\n",
    "        self._add_to_freq(key, freq+1)\n",
    "        if freq == self.min_freq and len(self.freq_nodes[freq]) == 0:\n",
    "            self.min_freq += 1\n",
    "        self.key_node[key] = (value, freq+1, None)\n",
    "        return value\n",
    "\n",
    "    def put(self, key, value):\n",
    "        if self.cap == 0:\n",
    "            return\n",
    "        if key in self.key_node:\n",
    "            # update value and increase freq\n",
    "            self.key_node[key] = (value, self.key_node[key][1], None)\n",
    "            self.get(key)  # to increase freq\n",
    "            return\n",
    "        if len(self.key_node) >= self.cap:\n",
    "            # evict from min_freq list (LRU among min freq)\n",
    "            evict_key = self._pop_lru(self.min_freq)\n",
    "            del self.key_node[evict_key]\n",
    "        self.key_node[key] = (value, 1, None)\n",
    "        self._add_to_freq(key, 1)\n",
    "        self.min_freq = 1\n",
    "```\n",
    "\n",
    "**Note:** In production, caches like Redis use approximations (e.g., **approximate LRU**) to reduce overhead.\n",
    "\n",
    "---\n",
    "\n",
    "## 36.4 Rate Limiting\n",
    "\n",
    "Rate limiting controls the rate of requests to an API or service to prevent abuse and ensure fair usage. Common algorithms:\n",
    "\n",
    "### 36.4.1 Token Bucket\n",
    "\n",
    "- A bucket holds tokens (capacity). Tokens are added at a fixed rate (e.g., 10 per second).\n",
    "- When a request arrives, it consumes one token if available; otherwise, the request is denied.\n",
    "- Simple, allows bursts up to capacity.\n",
    "\n",
    "**Implementation (pseudocode):**\n",
    "```python\n",
    "class TokenBucket:\n",
    "    def __init__(self, rate, capacity):\n",
    "        self.rate = rate\n",
    "        self.capacity = capacity\n",
    "        self.tokens = capacity\n",
    "        self.last_refill = time.time()\n",
    "\n",
    "    def allow(self):\n",
    "        now = time.time()\n",
    "        # refill based on elapsed time\n",
    "        elapsed = now - self.last_refill\n",
    "        self.tokens = min(self.capacity, self.tokens + elapsed * self.rate)\n",
    "        self.last_refill = now\n",
    "        if self.tokens >= 1:\n",
    "            self.tokens -= 1\n",
    "            return True\n",
    "        return False\n",
    "```\n",
    "\n",
    "### 36.4.2 Leaky Bucket\n",
    "\n",
    "- Requests are processed at a constant rate. Think of a bucket with a leak; requests drip out at a fixed rate. If the bucket overflows, requests are discarded.\n",
    "- Smooths bursts but does not allow bursts beyond capacity.\n",
    "\n",
    "**Implementation:** Use a queue; when a request arrives, if the queue is full, drop it; otherwise, enqueue and process at a fixed rate from a background thread.\n",
    "\n",
    "### 36.4.3 Sliding Window Log\n",
    "\n",
    "- Keep a log of request timestamps. For each request, count how many timestamps fall within the last window (e.g., last minute). If count < limit, allow.\n",
    "- Memory‑intensive if many requests.\n",
    "\n",
    "**Implementation with a deque:**\n",
    "```python\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "class SlidingWindowLog:\n",
    "    def __init__(self, limit, window_sec):\n",
    "        self.limit = limit\n",
    "        self.window = window_sec\n",
    "        self.requests = deque()\n",
    "\n",
    "    def allow(self):\n",
    "        now = time.time()\n",
    "        # remove old requests\n",
    "        while self.requests and self.requests[0] < now - self.window:\n",
    "            self.requests.popleft()\n",
    "        if len(self.requests) < self.limit:\n",
    "            self.requests.append(now)\n",
    "            return True\n",
    "        return False\n",
    "```\n",
    "\n",
    "### 36.4.4 Sliding Window Counter (e.g., Redis)\n",
    "\n",
    "- Hybrid approach: track counts in small buckets (e.g., per second) and sum over the sliding window. Less memory than full log, more accurate than fixed window.\n",
    "\n",
    "---\n",
    "\n",
    "## 36.5 Consistent Hashing and Load Balancing\n",
    "\n",
    "In distributed systems, we need to distribute data or requests across multiple servers. Simple modulo hashing (`hash(key) % N`) fails when servers are added or removed, causing massive redistribution. **Consistent hashing** solves this.\n",
    "\n",
    "### 36.5.1 How It Works\n",
    "\n",
    "- Each server is assigned one or more points on a hash ring (using a hash function like MD5).\n",
    "- Each key is hashed to a point on the ring, and the key is assigned to the nearest server clockwise.\n",
    "- When a server is added, only keys between its predecessor and itself are remapped; others stay put.\n",
    "- To handle imbalance, **virtual nodes** (multiple points per server) are used.\n",
    "\n",
    "**Implementation sketch:**\n",
    "\n",
    "```python\n",
    "import hashlib\n",
    "import bisect\n",
    "\n",
    "class ConsistentHash:\n",
    "    def __init__(self, nodes=None, replicas=100):\n",
    "        self.replicas = replicas\n",
    "        self.ring = {}\n",
    "        self.sorted_keys = []\n",
    "        if nodes:\n",
    "            for node in nodes:\n",
    "                self.add_node(node)\n",
    "\n",
    "    def _hash(self, key):\n",
    "        return int(hashlib.md5(key.encode()).hexdigest(), 16)\n",
    "\n",
    "    def add_node(self, node):\n",
    "        for i in range(self.replicas):\n",
    "            h = self._hash(f\"{node}:{i}\")\n",
    "            self.ring[h] = node\n",
    "            bisect.insort(self.sorted_keys, h)\n",
    "\n",
    "    def remove_node(self, node):\n",
    "        for i in range(self.replicas):\n",
    "            h = self._hash(f\"{node}:{i}\")\n",
    "            del self.ring[h]\n",
    "            self.sorted_keys.remove(h)\n",
    "\n",
    "    def get_node(self, key):\n",
    "        if not self.ring:\n",
    "            return None\n",
    "        h = self._hash(key)\n",
    "        idx = bisect.bisect_right(self.sorted_keys, h) % len(self.sorted_keys)\n",
    "        return self.ring[self.sorted_keys[idx]]\n",
    "```\n",
    "\n",
    "**Use cases:** Distributed caches (Memcached, Redis Cluster), load balancers, partitioners in databases (Cassandra uses consistent hashing with virtual nodes).\n",
    "\n",
    "---\n",
    "\n",
    "## 36.6 Probabilistic Data Structures\n",
    "\n",
    "When exact answers are too expensive (time or memory), probabilistic structures provide approximations with bounded error. They are widely used in big data and streaming.\n",
    "\n",
    "### 36.6.1 Bloom Filters\n",
    "\n",
    "A Bloom filter is a space‑efficient probabilistic data structure for set membership. It may return **false positives** but never false negatives.\n",
    "\n",
    "**How it works:**\n",
    "- A bit array of size m.\n",
    "- k independent hash functions, each mapping an element to a bit position.\n",
    "- **Insert:** Set all k bits to 1.\n",
    "- **Query:** Check if all k bits are 1; if any is 0, element is definitely not present; if all are 1, element *may* be present.\n",
    "\n",
    "**Choosing parameters:**\n",
    "- For desired false positive rate p and expected number of elements n:\n",
    "  - Optimal m = - (n ln p) / (ln 2)²\n",
    "  - Optimal k = (m/n) ln 2\n",
    "\n",
    "**Implementation:**\n",
    "```python\n",
    "import math\n",
    "import mmh3  # non‑cryptographic hash\n",
    "\n",
    "class BloomFilter:\n",
    "    def __init__(self, n, p):\n",
    "        self.m = int(- (n * math.log(p)) / (math.log(2)**2))\n",
    "        self.k = int((self.m / n) * math.log(2))\n",
    "        self.bits = [False] * self.m\n",
    "\n",
    "    def add(self, item):\n",
    "        for i in range(self.k):\n",
    "            idx = mmh3.hash(item, i) % self.m\n",
    "            self.bits[idx] = True\n",
    "\n",
    "    def contains(self, item):\n",
    "        for i in range(self.k):\n",
    "            idx = mmh3.hash(item, i) % self.m\n",
    "            if not self.bits[idx]:\n",
    "                return False\n",
    "        return True\n",
    "```\n",
    "\n",
    "**Use cases:** Cache filtering (avoid disk lookups for non‑existent keys), web URL deduplication, databases (LSM trees use bloom filters to reduce reads).\n",
    "\n",
    "### 36.6.2 Count‑Min Sketch\n",
    "\n",
    "A Count‑Min Sketch is a probabilistic data structure for estimating frequencies of events in a stream. It uses a matrix of counters and multiple hash functions.\n",
    "\n",
    "**How it works:**\n",
    "- 2D array of width w and depth d (counters).\n",
    "- d hash functions, each mapping an element to a column in its row.\n",
    "- **Update:** For each hash function, increment the corresponding counter.\n",
    "- **Query:** Take the minimum of the counters across all rows (since collisions can only overestimate).\n",
    "\n",
    "**Parameters:**\n",
    "- Given desired error ε and confidence δ:\n",
    "  - w = ceil(e/ε)\n",
    "  - d = ceil(ln(1/δ))\n",
    "\n",
    "**Implementation:**\n",
    "```python\n",
    "import math\n",
    "import mmh3\n",
    "\n",
    "class CountMinSketch:\n",
    "    def __init__(self, epsilon, delta):\n",
    "        self.width = int(math.ceil(math.e / epsilon))\n",
    "        self.depth = int(math.ceil(math.log(1.0 / delta)))\n",
    "        self.counters = [[0] * self.width for _ in range(self.depth)]\n",
    "\n",
    "    def update(self, item, count=1):\n",
    "        for i in range(self.depth):\n",
    "            idx = mmh3.hash(item, i) % self.width\n",
    "            self.counters[i][idx] += count\n",
    "\n",
    "    def estimate(self, item):\n",
    "        res = float('inf')\n",
    "        for i in range(self.depth):\n",
    "            idx = mmh3.hash(item, i) % self.width\n",
    "            res = min(res, self.counters[i][idx])\n",
    "        return res\n",
    "```\n",
    "\n",
    "**Use cases:** Heavy hitters, frequency estimation in streams, network traffic monitoring.\n",
    "\n",
    "### 36.6.3 HyperLogLog\n",
    "\n",
    "HyperLogLog estimates the **cardinality** (number of distinct elements) of a multiset using very little memory (e.g., 1.5 KB for billions of distinct items).\n",
    "\n",
    "**How it works:**\n",
    "- Hash each element to a binary string.\n",
    "- Observe the position of the leftmost 1‑bit (rank).\n",
    "- Keep the maximum rank observed across multiple registers.\n",
    "- Use harmonic mean to combine registers and correct bias.\n",
    "\n",
    "**Implementation** is more involved; libraries like `hyperloglog` exist.\n",
    "\n",
    "**Use cases:** Counting unique visitors, distinct IP addresses, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## 36.7 Summary\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    DSA IN PRODUCTION SYSTEMS SUMMARY                  │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                      │\n",
    "│  Indexing: B+ Trees (disk‑optimized, range queries)                │\n",
    "│            LSM Trees (write‑optimized, compaction)                  │\n",
    "│                                                                      │\n",
    "│  Caching: LRU (dict + linked list), LFU (frequency lists)           │\n",
    "│                                                                      │\n",
    "│  Rate Limiting: Token Bucket, Leaky Bucket, Sliding Window Log      │\n",
    "│                                                                      │\n",
    "│  Load Balancing: Consistent Hashing (ring, virtual nodes)           │\n",
    "│                                                                      │\n",
    "│  Probabilistic: Bloom Filters (membership, false positives)         │\n",
    "│                 Count‑Min Sketch (frequency)                         │\n",
    "│                 HyperLogLog (cardinality)                            │\n",
    "│                                                                      │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 36.8 Practice Problems\n",
    "\n",
    "1. **Implement an LRU cache** (LeetCode 146).\n",
    "2. **Implement an LFU cache** (LeetCode 460).\n",
    "3. **Design a rate limiter** for an API (system design problem).\n",
    "4. **Implement a Bloom filter** with given capacity and false positive rate.\n",
    "5. **Use Count‑Min Sketch** to find top‑k frequent items in a stream (with heap).\n",
    "6. **Design a distributed key‑value store** (like Cassandra) – discuss partitioning using consistent hashing.\n",
    "7. **Explain why a B+ tree is used for database indexing** rather than a hash table.\n",
    "8. **Compare LSM trees and B+ trees** in terms of read/write performance.\n",
    "9. **Design a web crawler** that avoids revisiting URLs using a Bloom filter.\n",
    "10. **Estimate the number of unique IPs** visiting a website using HyperLogLog (conceptually).\n",
    "\n",
    "---\n",
    "\n",
    "## 36.9 Further Reading\n",
    "\n",
    "1. **\"Designing Data‑Intensive Applications\"** by Martin Kleppmann – Covers LSM trees, consistent hashing, and more.\n",
    "2. **\"Database Internals\"** by Alex Petrov – Deep dive into B‑trees, LSM trees.\n",
    "3. **\"High Performance MySQL\"** – Indexing chapter.\n",
    "4. **\"Redis in Action\"** – Caching strategies.\n",
    "5. **Original Papers**:\n",
    "   - Bloom, B. H. (1970) – \"Space/time trade‑offs in hash coding with allowable errors\"\n",
    "   - Cormode, G., & Muthukrishnan, S. (2005) – \"An improved data stream summary: the count‑min sketch and its applications\"\n",
    "   - Flajolet, P., Fusy, É., Gandouet, O., & Meunier, F. (2007) – \"HyperLogLog: the analysis of a near‑optimal cardinality estimation algorithm\"\n",
    "   - Karger, D., et al. (1997) – \"Consistent hashing and random trees: distributed caching protocols for relieving hot spots on the World Wide Web\"\n",
    "\n",
    "---\n",
    "\n",
    "> **Coming in Chapter 37**: **Concurrency and Parallel Algorithms** – We'll explore lock‑free data structures, concurrent hash maps, parallel sorting, and the Map‑Reduce paradigm.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 36**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
