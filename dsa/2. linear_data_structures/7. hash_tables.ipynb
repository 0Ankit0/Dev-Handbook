{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 7: Hash Tables**\n",
    "\n",
    "> *\"Hash tables are the most useful data structure ever invented. If you can only learn one data structure, learn hash tables.\"* — Unknown\n",
    "\n",
    "---\n",
    "\n",
    "## **7.1 Introduction**\n",
    "\n",
    "A **hash table** (or hash map) is a data structure that implements an associative array, mapping keys to values. It provides **O(1)** average-case time complexity for insertions, deletions, and lookups—making it one of the most practically important data structures in computer science.\n",
    "\n",
    "Unlike arrays that use integer indices or trees that use comparisons, hash tables use a **hash function** to compute an index from the key, allowing direct access to the storage location.\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    HASH TABLE CONCEPT                                │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                      │\n",
    "│  Key Concept: Direct Addressing via Hash Function                   │\n",
    "│                                                                      │\n",
    "│  ┌──────────┐      Hash Function       ┌──────────┐                 │\n",
    "│  │   Key    │ ───────────────────────► │  Index   │                 │\n",
    "│  │ \"Alice\"  │                          │    3     │                 │\n",
    "│  └──────────┘                          └────┬─────┘                 │\n",
    "│                                             │                        │\n",
    "│                                             ▼                        │\n",
    "│                                      ┌──────────┐                   │\n",
    "│                                      │  Bucket  │                   │\n",
    "│                                      │  Index 3 │                   │\n",
    "│                                      │  (Data)  │                   │\n",
    "│                                      └──────────┘                   │\n",
    "│                                                                      │\n",
    "│  Without hash collisions: O(1) lookup time                          │\n",
    "│  With collisions: Depends on resolution strategy                    │\n",
    "│                                                                      │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7.2 Hash Functions: Design Principles and Universal Hashing**\n",
    "\n",
    "### **7.2.1 Properties of Good Hash Functions**\n",
    "\n",
    "A hash function $h(k)$ maps a key $k$ to an integer index in the range $[0, m-1]$, where $m$ is the table size.\n",
    "\n",
    "```python\n",
    "def hash_function_principles():\n",
    "    \"\"\"\n",
    "    Explain the properties and design of hash functions.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Hash Function Design Principles\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\"\"\n",
    "    Desirable Properties of Hash Functions:\n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    1. DETERMINISTIC\n",
    "       Same key must always produce same hash value\n",
    "       h(k) = h(k) always\n",
    "    \n",
    "    2. UNIFORM DISTRIBUTION\n",
    "       Keys should be distributed uniformly across the hash table\n",
    "       Minimizes collisions\n",
    "    \n",
    "    3. FAST COMPUTATION\n",
    "       O(1) time to compute hash\n",
    "       Should use only basic arithmetic/bit operations\n",
    "    \n",
    "    4. MINIMAL COLLISIONS\n",
    "       Different keys should ideally map to different indices\n",
    "       (Impossible to avoid completely due to pigeonhole principle)\n",
    "    \n",
    "    5. AVALANCHE EFFECT\n",
    "       Small changes in key should cause large changes in hash\n",
    "       Prevents clustering of similar keys\n",
    "    \n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Common Hash Function Techniques:\n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Division Method:\n",
    "       h(k) = k mod m\n",
    "       • Simple and fast\n",
    "       • Avoid m = power of 2 (use prime numbers instead)\n",
    "       • Example: h(123) = 123 % 97 = 26\n",
    "    \n",
    "    Multiplication Method:\n",
    "       h(k) = floor(m × (kA mod 1))\n",
    "       where A is a constant (0 < A < 1), often (√5 - 1)/2 ≈ 0.618\n",
    "       • Less sensitive to choice of m\n",
    "       • Works well with power-of-2 table sizes\n",
    "    \n",
    "    Folding Method:\n",
    "       • Break key into parts\n",
    "       • Combine parts using addition/XOR\n",
    "       • Example: k = 123456, parts = 123 + 456 = 579\n",
    "    \n",
    "    Polynomial Rolling Hash (for strings):\n",
    "       hash(s) = Σ(s[i] × p^i) mod m\n",
    "       where p is a prime base (often 31 or 131)\n",
    "       • Good for strings\n",
    "       • Allows O(1) re-computation for sliding window\n",
    "    \"\"\")\n",
    "\n",
    "hash_function_principles()\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "Hash Function Design Principles\n",
    "======================================================================\n",
    "\n",
    "Desirable Properties of Hash Functions:\n",
    "──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "1. DETERMINISTIC\n",
    "   Same key must always produce same hash value\n",
    "   h(k) = h(k) always\n",
    "\n",
    "2. UNIFORM DISTRIBUTION\n",
    "   Keys should be distributed uniformly across the hash table\n",
    "   Minimizes collisions\n",
    "\n",
    "3. FAST COMPUTATION\n",
    "   O(1) time to compute hash\n",
    "   Should use only basic arithmetic/bit operations\n",
    "\n",
    "4. MINIMAL COLLISIONS\n",
    "   Different keys should ideally map to different indices\n",
    "   (Impossible to avoid completely due to pigeonhole principle)\n",
    "\n",
    "5. AVALANCHE EFFECT\n",
    "   Small changes in key should cause large changes in hash\n",
    "   Prevents clustering of similar keys\n",
    "\n",
    "──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "Common Hash Function Techniques:\n",
    "──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "Division Method:\n",
    "   h(k) = k mod m\n",
    "   • Simple and fast\n",
    "   • Avoid m = power of 2 (use prime numbers instead)\n",
    "   • Example: h(123) = 123 % 97 = 26\n",
    "\n",
    "Multiplication Method:\n",
    "   h(k) = floor(m × (kA mod 1))\n",
    "   where A is a constant (0 < A < 1), often (√5 - 1)/2 ≈ 0.618\n",
    "   • Less sensitive to choice of m\n",
    "   • Works well with power-of-2 table sizes\n",
    "\n",
    "Folding Method:\n",
    "   • Break key into parts\n",
    "   • Combine parts using addition/XOR\n",
    "   • Example: k = 123456, parts = 123 + 456 = 579\n",
    "\n",
    "Polynomial Rolling Hash (for strings):\n",
    "   hash(s) = Σ(s[i] × p^i) mod m\n",
    "   where p is a prime base (often 31 or 131)\n",
    "   • Good for strings\n",
    "   • Allows O(1) re-computation for sliding window\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7.2.2 String Hashing Implementation**\n",
    "\n",
    "```python\n",
    "class StringHasher:\n",
    "    \"\"\"\n",
    "    Implementation of polynomial rolling hash for strings.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base=31, modulus=10**9 + 9):\n",
    "        self.base = base\n",
    "        self.mod = modulus\n",
    "        # Precompute powers of base for efficiency\n",
    "        self.powers = [1]\n",
    "    \n",
    "    def hash(self, s: str) -> int:\n",
    "        \"\"\"\n",
    "        Compute hash of string using polynomial rolling hash.\n",
    "        \n",
    "        h(s) = Σ(ord(s[i]) × base^i) mod modulus\n",
    "        \n",
    "        Time: O(n) where n is length of string\n",
    "        \"\"\"\n",
    "        hash_value = 0\n",
    "        for i, char in enumerate(s):\n",
    "            # Ensure we have enough precomputed powers\n",
    "            while len(self.powers) <= i:\n",
    "                self.powers.append((self.powers[-1] * self.base) % self.mod)\n",
    "            \n",
    "            hash_value = (hash_value + ord(char) * self.powers[i]) % self.mod\n",
    "        \n",
    "        return hash_value\n",
    "    \n",
    "    def rolling_hash_update(self, old_hash: int, old_char: str, \n",
    "                           new_char: str, length: int) -> int:\n",
    "        \"\"\"\n",
    "        Update hash when sliding window by one character.\n",
    "        \n",
    "        Time: O(1)\n",
    "        \n",
    "        Remove contribution of old_char and add new_char.\n",
    "        \"\"\"\n",
    "        # Remove old_char contribution\n",
    "        old_hash = (old_hash - ord(old_char)) % self.mod\n",
    "        # Divide by base (multiply by modular inverse)\n",
    "        # For simplicity, we recompute or use precomputed inverses\n",
    "        # In practice, we'd use Fermat's little theorem for mod inverse\n",
    "        old_hash = (old_hash * pow(self.base, -1, self.mod)) % self.mod\n",
    "        # Add new_char at end\n",
    "        new_hash = (old_hash + ord(new_char) * self.powers[length - 1]) % self.mod\n",
    "        \n",
    "        return new_hash\n",
    "\n",
    "\n",
    "def demonstrate_string_hashing():\n",
    "    \"\"\"\n",
    "    Demonstrate string hashing.\n",
    "    \"\"\"\n",
    "    print(\"String Hashing Demonstration\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    hasher = StringHasher(base=31)\n",
    "    \n",
    "    strings = [\"hello\", \"world\", \"hello\", \"abc\", \"abd\"]\n",
    "    print(\"String hashes:\")\n",
    "    for s in strings:\n",
    "        h = hasher.hash(s)\n",
    "        print(f\"  '{s}' -> {h}\")\n",
    "    \n",
    "    print(\"\\nNote: 'hello' appears twice with same hash (deterministic)\")\n",
    "\n",
    "\n",
    "demonstrate_string_hashing()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7.2.3 Universal Hashing**\n",
    "\n",
    "**Universal hashing** is a technique to randomly select a hash function from a family of hash functions, guaranteeing good average-case performance regardless of input distribution.\n",
    "\n",
    "```python\n",
    "def universal_hashing_concept():\n",
    "    \"\"\"\n",
    "    Explain universal hashing.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Universal Hashing\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\"\"\n",
    "    The Problem:\n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Adversarial Input: An attacker could craft keys that all hash to \n",
    "    the same index, causing O(n) lookup time (denial of service).\n",
    "    \n",
    "    Example: If using h(k) = k mod m, attacker sends keys that are \n",
    "    all congruent modulo m.\n",
    "    \n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Solution: Universal Hashing\n",
    "    \n",
    "    Definition: A family H of hash functions is universal if for any \n",
    "    two distinct keys x and y, the probability of collision is at most \n",
    "    1/m (where m is table size).\n",
    "    \n",
    "    Pr[h(x) = h(y)] ≤ 1/m for randomly chosen h ∈ H\n",
    "    \n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Implementation (Universal Hash Family):\n",
    "    \n",
    "    Choose a prime p > max key value.\n",
    "    \n",
    "    For random integers a ∈ [1, p-1] and b ∈ [0, p-1]:\n",
    "    \n",
    "    h_{a,b}(k) = ((a×k + b) mod p) mod m\n",
    "    \n",
    "    This family is universal.\n",
    "    \n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Benefits:\n",
    "      • Protection against adversarial attacks\n",
    "      • Expected chain length is O(1 + α) where α is load factor\n",
    "      • Provable expected O(1) operations\n",
    "    \n",
    "    Real-world Usage:\n",
    "      • Python's hash randomization (enabled by default)\n",
    "      • Java's HashMap uses treeification for collision resistance\n",
    "      • Cryptographic hash tables\n",
    "    \"\"\")\n",
    "\n",
    "universal_hashing_concept()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7.3 Collision Resolution: Chaining vs Open Addressing**\n",
    "\n",
    "When two keys hash to the same index, we have a **collision**. There are two main strategies to handle this:\n",
    "\n",
    "### **7.3.1 Separate Chaining**\n",
    "\n",
    "Each bucket contains a linked list (or other structure) of all keys that hash to that index.\n",
    "\n",
    "```python\n",
    "from typing import TypeVar, Generic, Optional, Iterator, List\n",
    "\n",
    "K = TypeVar('K')\n",
    "V = TypeVar('V')\n",
    "\n",
    "class HashTableChaining(Generic[K, V]):\n",
    "    \"\"\"\n",
    "    Hash table using separate chaining for collision resolution.\n",
    "    \n",
    "    Each bucket is a linked list of entries.\n",
    "    \n",
    "    Time Complexities (average case):\n",
    "        insert: O(1 + α) where α = n/m (load factor)\n",
    "        search: O(1 + α)\n",
    "        delete: O(1 + α)\n",
    "    \n",
    "    Worst case: O(n) when all keys collide\n",
    "    \"\"\"\n",
    "    \n",
    "    class _Entry(Generic[K, V]):\n",
    "        __slots__ = ['key', 'value', 'next']\n",
    "        \n",
    "        def __init__(self, key: K, value: V):\n",
    "            self.key = key\n",
    "            self.value = value\n",
    "            self.next: Optional['HashTableChaining._Entry[K, V]'] = None\n",
    "    \n",
    "    def __init__(self, capacity: int = 16, load_factor_threshold: float = 0.75):\n",
    "        self._capacity = capacity\n",
    "        self._size = 0\n",
    "        self._load_factor_threshold = load_factor_threshold\n",
    "        # Array of buckets (each bucket is head of linked list)\n",
    "        self._buckets: List[Optional[HashTableChaining._Entry[K, V]]] = [None] * capacity\n",
    "    \n",
    "    def _hash(self, key: K) -> int:\n",
    "        \"\"\"Compute hash index for key.\"\"\"\n",
    "        return hash(key) % self._capacity\n",
    "    \n",
    "    def insert(self, key: K, value: V) -> None:\n",
    "        \"\"\"\n",
    "        Insert or update key-value pair.\n",
    "        \n",
    "        Time: O(1 + α) average\n",
    "        \"\"\"\n",
    "        index = self._hash(key)\n",
    "        \n",
    "        # Check if key already exists\n",
    "        current = self._buckets[index]\n",
    "        while current is not None:\n",
    "            if current.key == key:\n",
    "                current.value = value  # Update\n",
    "                return\n",
    "            current = current.next\n",
    "        \n",
    "        # Insert at head of list\n",
    "        new_entry = self._Entry(key, value)\n",
    "        new_entry.next = self._buckets[index]\n",
    "        self._buckets[index] = new_entry\n",
    "        self._size += 1\n",
    "        \n",
    "        # Check load factor and resize if needed\n",
    "        if self._size / self._capacity > self._load_factor_threshold:\n",
    "            self._resize(2 * self._capacity)\n",
    "    \n",
    "    def get(self, key: K) -> Optional[V]:\n",
    "        \"\"\"\n",
    "        Retrieve value by key.\n",
    "        \n",
    "        Time: O(1 + α) average\n",
    "        \"\"\"\n",
    "        index = self._hash(key)\n",
    "        current = self._buckets[index]\n",
    "        \n",
    "        while current is not None:\n",
    "            if current.key == key:\n",
    "                return current.value\n",
    "            current = current.next\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def delete(self, key: K) -> bool:\n",
    "        \"\"\"\n",
    "        Delete key-value pair.\n",
    "        \n",
    "        Time: O(1 + α) average\n",
    "        \"\"\"\n",
    "        index = self._hash(key)\n",
    "        current = self._buckets[index]\n",
    "        \n",
    "        if current is None:\n",
    "            return False\n",
    "        \n",
    "        # Check head\n",
    "        if current.key == key:\n",
    "            self._buckets[index] = current.next\n",
    "            self._size -= 1\n",
    "            return True\n",
    "        \n",
    "        # Search in list\n",
    "        while current.next is not None:\n",
    "            if current.next.key == key:\n",
    "                current.next = current.next.next\n",
    "                self._size -= 1\n",
    "                return True\n",
    "            current = current.next\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def _resize(self, new_capacity: int) -> None:\n",
    "        \"\"\"\n",
    "        Resize hash table to new capacity.\n",
    "        \n",
    "        Time: O(n) - must rehash all entries\n",
    "        \"\"\"\n",
    "        old_buckets = self._buckets\n",
    "        self._capacity = new_capacity\n",
    "        self._size = 0\n",
    "        self._buckets = [None] * new_capacity\n",
    "        \n",
    "        # Rehash all entries\n",
    "        for head in old_buckets:\n",
    "            current = head\n",
    "            while current is not None:\n",
    "                self.insert(current.key, current.value)\n",
    "                current = current.next\n",
    "    \n",
    "    def __contains__(self, key: K) -> bool:\n",
    "        return self.get(key) is not None\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self._size\n",
    "    \n",
    "    def display_structure(self):\n",
    "        \"\"\"Display the internal structure of the hash table.\"\"\"\n",
    "        print(f\"Hash Table (size={self._size}, capacity={self._capacity})\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, bucket in enumerate(self._buckets):\n",
    "            if bucket is not None:\n",
    "                entries = []\n",
    "                current = bucket\n",
    "                while current is not None:\n",
    "                    entries.append(f\"({current.key}:{current.value})\")\n",
    "                    current = current.next\n",
    "                print(f\"Bucket {i}: {' -> '.join(entries)}\")\n",
    "            else:\n",
    "                print(f\"Bucket {i}: empty\")\n",
    "\n",
    "\n",
    "def demonstrate_chaining():\n",
    "    \"\"\"\n",
    "    Demonstrate separate chaining hash table.\n",
    "    \"\"\"\n",
    "    print(\"Separate Chaining Hash Table\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    ht = HashTableChaining[str, int](capacity=5)\n",
    "    \n",
    "    # Insert some keys that might collide\n",
    "    pairs = [(\"apple\", 1), (\"banana\", 2), (\"cherry\", 3), \n",
    "             (\"date\", 4), (\"elderberry\", 5), (\"fig\", 6)]\n",
    "    \n",
    "    print(\"Inserting key-value pairs:\")\n",
    "    for key, value in pairs:\n",
    "        ht.insert(key, value)\n",
    "        print(f\"  insert('{key}', {value})\")\n",
    "    \n",
    "    print(f\"\\nCurrent load factor: {len(ht) / ht._capacity:.2f}\")\n",
    "    ht.display_structure()\n",
    "    \n",
    "    print(\"\\nRetrieving values:\")\n",
    "    for key in [\"apple\", \"cherry\", \"grape\"]:\n",
    "        val = ht.get(key)\n",
    "        print(f\"  get('{key}') = {val}\")\n",
    "    \n",
    "    print(\"\\nDeleting 'banana'...\")\n",
    "    ht.delete(\"banana\")\n",
    "    print(f\"  get('banana') = {ht.get('banana')}\")\n",
    "\n",
    "\n",
    "demonstrate_chaining()\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "Separate Chaining Hash Table\n",
    "======================================================================\n",
    "Inserting key-value pairs:\n",
    "  insert('apple', 1)\n",
    "  insert('banana', 2)\n",
    "  insert('cherry', 3)\n",
    "  insert('date', 4)\n",
    "  insert('elderberry', 5)\n",
    "  insert('fig', 6)\n",
    "\n",
    "Current load factor: 1.20\n",
    "Hash Table (size=6, capacity=5)\n",
    "--------------------------------------------------\n",
    "Bucket 0: (cherry:3)\n",
    "Bucket 1: (apple:1)\n",
    "Bucket 2: (date:4) -> (banana:2)\n",
    "Bucket 3: (elderberry:5)\n",
    "Bucket 4: (fig:6)\n",
    "\n",
    "Retrieving values:\n",
    "  get('apple') = 1\n",
    "  get('cherry') = 3\n",
    "  get('grape') = None\n",
    "\n",
    "Deleting 'banana'...\n",
    "  get('banana') = None\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7.3.2 Open Addressing**\n",
    "\n",
    "In open addressing, all elements are stored in the table itself. When a collision occurs, we probe (search) for the next empty slot.\n",
    "\n",
    "```python\n",
    "class HashTableOpenAddressing(Generic[K, V]):\n",
    "    \"\"\"\n",
    "    Hash table using open addressing with linear probing.\n",
    "    \n",
    "    All entries stored directly in the array.\n",
    "    On collision, probe sequentially for next empty slot.\n",
    "    \n",
    "    Time Complexities:\n",
    "        insert: O(1/(1-α)) where α is load factor (must be < 1)\n",
    "        search: O(1/(1-α))\n",
    "        delete: O(1/(1-α))\n",
    "    \n",
    "    Note: Table must never be completely full (α < 1 required)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sentinel values for deleted slots\n",
    "    _EMPTY = object()\n",
    "    _DELETED = object()\n",
    "    \n",
    "    def __init__(self, capacity: int = 16):\n",
    "        self._capacity = capacity\n",
    "        self._size = 0\n",
    "        self._keys: List[Optional[K]] = [self._EMPTY] * capacity\n",
    "        self._values: List[Optional[V]] = [None] * capacity\n",
    "    \n",
    "    def _hash(self, key: K, probe: int = 0) -> int:\n",
    "        \"\"\"\n",
    "        Compute hash with probing.\n",
    "        \n",
    "        Linear probing: h(k, i) = (h(k) + i) mod m\n",
    "        \"\"\"\n",
    "        return (hash(key) + probe) % self._capacity\n",
    "    \n",
    "    def insert(self, key: K, value: V) -> None:\n",
    "        \"\"\"\n",
    "        Insert key-value pair using linear probing.\n",
    "        \n",
    "        Time: O(1/(1-α)) average, O(n) worst case\n",
    "        \"\"\"\n",
    "        if self._size >= self._capacity // 2:  # Keep load factor < 0.5 for performance\n",
    "            self._resize(2 * self._capacity)\n",
    "        \n",
    "        probe = 0\n",
    "        index = self._hash(key, probe)\n",
    "        \n",
    "        # Probe until empty or deleted slot found\n",
    "        while self._keys[index] not in (self._EMPTY, self._DELETED):\n",
    "            if self._keys[index] == key:\n",
    "                # Update existing\n",
    "                self._values[index] = value\n",
    "                return\n",
    "            probe += 1\n",
    "            index = self._hash(key, probe)\n",
    "        \n",
    "        # Insert here\n",
    "        self._keys[index] = key\n",
    "        self._values[index] = value\n",
    "        self._size += 1\n",
    "    \n",
    "    def get(self, key: K) -> Optional[V]:\n",
    "        \"\"\"\n",
    "        Search for key using linear probing.\n",
    "        \n",
    "        Time: O(1/(1-α)) average\n",
    "        \"\"\"\n",
    "        probe = 0\n",
    "        index = self._hash(key, probe)\n",
    "        \n",
    "        # Probe until empty slot (not deleted) or key found\n",
    "        while self._keys[index] is not self._EMPTY:\n",
    "            if self._keys[index] == key:\n",
    "                return self._values[index]\n",
    "            probe += 1\n",
    "            index = self._hash(key, probe)\n",
    "            \n",
    "            # Prevent infinite loop if table full (shouldn't happen with resize)\n",
    "            if probe >= self._capacity:\n",
    "                return None\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def delete(self, key: K) -> bool:\n",
    "        \"\"\"\n",
    "        Delete key using lazy deletion.\n",
    "        \n",
    "        We mark as _DELETED rather than _EMPTY to maintain probe chains.\n",
    "        \n",
    "        Time: O(1/(1-α))\n",
    "        \"\"\"\n",
    "        probe = 0\n",
    "        index = self._hash(key, probe)\n",
    "        \n",
    "        while self._keys[index] is not self._EMPTY:\n",
    "            if self._keys[index] == key:\n",
    "                self._keys[index] = self._DELETED\n",
    "                self._values[index] = None\n",
    "                self._size -= 1\n",
    "                \n",
    "                # Optional: resize down if load factor too low\n",
    "                if self._size > 0 and self._size < self._capacity // 8:\n",
    "                    self._resize(self._capacity // 2)\n",
    "                return True\n",
    "            \n",
    "            probe += 1\n",
    "            index = self._hash(key, probe)\n",
    "            \n",
    "            if probe >= self._capacity:\n",
    "                return False\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def _resize(self, new_capacity: int) -> None:\n",
    "        \"\"\"Resize and rehash all entries.\"\"\"\n",
    "        old_keys = self._keys\n",
    "        old_values = self._values\n",
    "        \n",
    "        self._capacity = new_capacity\n",
    "        self._size = 0\n",
    "        self._keys = [self._EMPTY] * new_capacity\n",
    "        self._values = [None] * new_capacity\n",
    "        \n",
    "        for i in range(len(old_keys)):\n",
    "            if old_keys[i] not in (self._EMPTY, self._DELETED):\n",
    "                self.insert(old_keys[i], old_values[i])\n",
    "    \n",
    "    def display_structure(self):\n",
    "        \"\"\"Display the table structure.\"\"\"\n",
    "        print(f\"Open Addressing Hash Table (size={self._size}, capacity={self._capacity})\")\n",
    "        print(\"-\" * 50)\n",
    "        for i in range(self._capacity):\n",
    "            key = self._keys[i]\n",
    "            if key is self._EMPTY:\n",
    "                status = \"EMPTY\"\n",
    "            elif key is self._DELETED:\n",
    "                status = \"DELETED\"\n",
    "            else:\n",
    "                status = f\"({key}:{self._values[i]})\"\n",
    "            print(f\"Slot {i:2d}: {status}\")\n",
    "\n",
    "\n",
    "def demonstrate_open_addressing():\n",
    "    \"\"\"\n",
    "    Demonstrate open addressing with linear probing.\n",
    "    \"\"\"\n",
    "    print(\"\\nOpen Addressing (Linear Probing) Hash Table\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    ht = HashTableOpenAddressing[str, int](capacity=8)\n",
    "    \n",
    "    # Insert keys\n",
    "    keys = [\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\"]\n",
    "    print(\"Inserting keys:\", keys)\n",
    "    for i, key in enumerate(keys):\n",
    "        ht.insert(key, i + 1)\n",
    "    \n",
    "    ht.display_structure()\n",
    "    \n",
    "    print(\"\\nSearching:\")\n",
    "    print(f\"  get('apple') = {ht.get('apple')}\")\n",
    "    print(f\"  get('fig') = {ht.get('fig')}\")\n",
    "    \n",
    "    print(\"\\nDeleting 'banana' (marked as DELETED):\")\n",
    "    ht.delete(\"banana\")\n",
    "    ht.display_structure()\n",
    "    \n",
    "    print(\"\"\"\n",
    "    \n",
    "    Linear Probing Analysis:\n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Primary Clustering:\n",
    "      • Linear probing suffers from primary clustering\n",
    "      • Contiguous blocks of occupied slots form\n",
    "      • Probe sequence length grows with cluster size\n",
    "      • Search time degrades to O(n) in worst case\n",
    "    \n",
    "    Load Factor Guidelines:\n",
    "      • α < 0.5: Good performance\n",
    "      • α > 0.7: Performance degrades significantly\n",
    "      • α = 1: Table full, insertion impossible\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "demonstrate_open_addressing()\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "Open Addressing (Linear Probing) Hash Table\n",
    "======================================================================\n",
    "Inserting keys: ['apple', 'banana', 'cherry', 'date', 'elderberry']\n",
    "Open Addressing Hash Table (size=5, capacity=8)\n",
    "--------------------------------------------------\n",
    "Slot  0: (banana:2)\n",
    "Slot  1: (apple:1)\n",
    "Slot  2: EMPTY\n",
    "Slot  3: (elderberry:5)\n",
    "Slot  4: (date:4)\n",
    "Slot  5: (cherry:3)\n",
    "Slot  6: EMPTY\n",
    "Slot  7: EMPTY\n",
    "\n",
    "Searching:\n",
    "  get('apple') = 1\n",
    "  get('fig') = None\n",
    "\n",
    "Deleting 'banana' (marked as DELETED):\n",
    "Open Addressing Hash Table (size=4, capacity=8)\n",
    "--------------------------------------------------\n",
    "Slot  0: DELETED\n",
    "Slot  1: (apple:1)\n",
    "Slot  2: EMPTY\n",
    "Slot  3: (elderberry:5)\n",
    "Slot  4: (date:4)\n",
    "Slot  5: (cherry:3)\n",
    "Slot  6: EMPTY\n",
    "Slot  7: EMPTY\n",
    "\n",
    "\n",
    "Linear Probing Analysis:\n",
    "──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "Primary Clustering:\n",
    "  • Linear probing suffers from primary clustering\n",
    "  • Contiguous blocks of occupied slots form\n",
    "  • Probe sequence length grows with cluster size\n",
    "  • Search time degrades to O(n) in worst case\n",
    "\n",
    "Load Factor Guidelines:\n",
    "  • α < 0.5: Good performance\n",
    "  • α > 0.7: Performance degrades significantly\n",
    "  • α = 1: Table full, insertion impossible\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7.3.3 Quadratic Probing and Double Hashing**\n",
    "\n",
    "```python\n",
    "def advanced_probing():\n",
    "    \"\"\"\n",
    "    Explain quadratic probing and double hashing.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Advanced Probing Techniques\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\"\"\n",
    "    Quadratic Probing:\n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Probe sequence: h(k, i) = (h(k) + c1×i + c2×i²) mod m\n",
    "    \n",
    "    Common simplification: h(k, i) = (h(k) + i²) mod m\n",
    "    \n",
    "    Pros:\n",
    "      • Eliminates primary clustering (no long contiguous sequences)\n",
    "    \n",
    "    Cons:\n",
    "      • Secondary clustering: keys with same initial hash have same probe seq\n",
    "      • May not probe all slots (can fail to find empty slot even if exists)\n",
    "      • Requires careful choice of table size (prime numbers help)\n",
    "    \n",
    "    Example:\n",
    "      Initial hash = 5\n",
    "      Probe sequence: 5, 6, 9, 14, 21, 30... (adding 1, 3, 5, 7, 9...)\n",
    "    \n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Double Hashing:\n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Probe sequence: h(k, i) = (h1(k) + i × h2(k)) mod m\n",
    "    \n",
    "    where h2(k) is a second hash function.\n",
    "    \n",
    "    Requirements for h2:\n",
    "      • Must never return 0 (infinite loop)\n",
    "      • Should be relatively prime to table size m\n",
    "    \n",
    "    Common choice:\n",
    "      h1(k) = k mod m\n",
    "      h2(k) = 1 + (k mod (m-1))\n",
    "    \n",
    "    Pros:\n",
    "      • Eliminates both primary and secondary clustering\n",
    "      • Distributes keys more uniformly\n",
    "      • Can probe all slots if h2 and m are coprime\n",
    "    \n",
    "    Cons:\n",
    "      • More computation (two hash functions)\n",
    "      • Slightly slower than linear probing\n",
    "    \n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Comparison Table:\n",
    "    \n",
    "    Method              │ Primary Clustering │ Secondary │ Computation\n",
    "    ────────────────────┼────────────────────┼───────────┼────────────\n",
    "    Linear Probing      │ Yes                │ No        │ O(1)\n",
    "    Quadratic Probing   │ No                 │ Yes       │ O(1)\n",
    "    Double Hashing      │ No                 │ No        │ O(1) × 2\n",
    "    Chaining            │ N/A                │ N/A       │ O(1) + traverse\n",
    "    \n",
    "    Recommendation:\n",
    "      • General purpose: Chaining (simpler, handles high load factors)\n",
    "      • Memory constrained: Double hashing (better cache locality)\n",
    "      • Avoid: Linear probing for high load factors (> 0.7)\n",
    "    \"\"\")\n",
    "\n",
    "advanced_probing()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7.4 Load Factor and Rehashing Strategies**\n",
    "\n",
    "### **7.4.1 Load Factor Analysis**\n",
    "\n",
    "The **load factor** $\\alpha = \\frac{n}{m}$ where $n$ is number of elements and $m$ is table size. It critically affects performance.\n",
    "\n",
    "```python\n",
    "def load_factor_analysis():\n",
    "    \"\"\"\n",
    "    Analyze the impact of load factor on hash table performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Load Factor (α) Analysis\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\"\"\n",
    "    Definition: α = n/m (number of elements / table size)\n",
    "    \n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Separate Chaining:\n",
    "    \n",
    "    Average chain length = α\n",
    "    \n",
    "    Time Complexities:\n",
    "      • Successful search: O(1 + α/2) ≈ O(1 + α)\n",
    "      • Unsuccessful search: O(1 + α)\n",
    "      • Insertion: O(1 + α)\n",
    "    \n",
    "    Strategy:\n",
    "      • Keep α around 0.75 (Java HashMap default)\n",
    "      • When α > 0.75, double table size and rehash\n",
    "    \n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Open Addressing:\n",
    "    \n",
    "    Unsuccessful search probe count ≈ 1/(1-α)\n",
    "    \n",
    "    α = 0.5  →  2 probes average\n",
    "    α = 0.7  →  3.3 probes average  \n",
    "    α = 0.9  →  10 probes average\n",
    "    α = 0.95 →  20 probes average\n",
    "    \n",
    "    Time degrades rapidly as α approaches 1!\n",
    "    \n",
    "    Strategy:\n",
    "      • Keep α < 0.5 for linear probing\n",
    "      • Keep α < 0.7 for quadratic/double hashing\n",
    "      • Resize when threshold exceeded\n",
    "    \n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Rehashing Strategy:\n",
    "    \n",
    "    When load factor exceeds threshold:\n",
    "      1. Allocate new array (typically 2× size)\n",
    "      2. For each entry in old table:\n",
    "         - Compute new hash index (mod new size)\n",
    "         - Insert into new table\n",
    "      3. Free old array\n",
    "    \n",
    "    Cost: O(n) for rehashing\n",
    "    Amortized: O(1) per insertion over time\n",
    "    \n",
    "    Alternative: Incremental rehashing (gradual migration)\n",
    "      • Used in real-time systems\n",
    "      • Insert new entries in new table\n",
    "      • Move old entries gradually\n",
    "      • Lookup checks both tables\n",
    "    \"\"\")\n",
    "\n",
    "load_factor_analysis()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7.5 Advanced Hashing Techniques**\n",
    "\n",
    "### **7.5.1 Cuckoo Hashing**\n",
    "\n",
    "**Cuckoo hashing** uses two hash tables with two different hash functions. Each key is in one of two possible locations.\n",
    "\n",
    "```python\n",
    "class CuckooHashing(Generic[K, V]):\n",
    "    \"\"\"\n",
    "    Cuckoo Hashing implementation.\n",
    "    \n",
    "    Uses two tables with two hash functions.\n",
    "    Each key can be in one of two locations.\n",
    "    \n",
    "    On insertion, if both locations occupied, evict existing and reinsert.\n",
    "    Like cuckoo bird pushing eggs out of nest!\n",
    "    \n",
    "    Guaranteed O(1) worst-case lookup and deletion.\n",
    "    Insertion is O(1) amortized, but can be O(n) worst case.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, capacity: int = 16):\n",
    "        self._capacity = capacity\n",
    "        self._size = 0\n",
    "        self._max_loop = capacity  # Prevent infinite loops\n",
    "        \n",
    "        # Two tables\n",
    "        self._keys1: List[Optional[K]] = [None] * capacity\n",
    "        self._vals1: List[Optional[V]] = [None] * capacity\n",
    "        self._keys2: List[Optional[K]] = [None] * capacity\n",
    "        self._vals2: List[Optional[V]] = [None] * capacity\n",
    "    \n",
    "    def _hash1(self, key: K) -> int:\n",
    "        return hash(key) % self._capacity\n",
    "    \n",
    "    def _hash2(self, key: K) -> int:\n",
    "        # Different hash function (using ~hash for demonstration)\n",
    "        return (~hash(key)) % self._capacity\n",
    "    \n",
    "    def get(self, key: K) -> Optional[V]:\n",
    "        \"\"\"\n",
    "        O(1) worst-case lookup.\n",
    "        \"\"\"\n",
    "        idx1 = self._hash1(key)\n",
    "        if self._keys1[idx1] == key:\n",
    "            return self._vals1[idx1]\n",
    "        \n",
    "        idx2 = self._hash2(key)\n",
    "        if self._keys2[idx2] == key:\n",
    "            return self._vals2[idx2]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def insert(self, key: K, value: V) -> bool:\n",
    "        \"\"\"\n",
    "        Insert with cuckoo eviction.\n",
    "        \n",
    "        May require rehashing with new hash functions if cycle detected.\n",
    "        \"\"\"\n",
    "        if self._size >= self._capacity // 2:\n",
    "            self._resize(2 * self._capacity)\n",
    "        \n",
    "        # Try to insert, may evict existing keys\n",
    "        return self._insert_helper(key, value, 0)\n",
    "    \n",
    "    def _insert_helper(self, key: K, value: V, count: int) -> bool:\n",
    "        \"\"\"Recursive helper with eviction.\"\"\"\n",
    "        if count > self._max_loop:\n",
    "            # Cycle detected, need rehash\n",
    "            return False\n",
    "        \n",
    "        # Try first table\n",
    "        idx1 = self._hash1(key)\n",
    "        if self._keys1[idx1] is None:\n",
    "            self._keys1[idx1] = key\n",
    "            self._vals1[idx1] = value\n",
    "            self._size += 1\n",
    "            return True\n",
    "        \n",
    "        # Try second table\n",
    "        idx2 = self._hash2(key)\n",
    "        if self._keys2[idx2] is None:\n",
    "            self._keys2[idx2] = key\n",
    "            self._vals2[idx2] = value\n",
    "            self._size += 1\n",
    "            return True\n",
    "        \n",
    "        # Both occupied - evict from first table and reinsert\n",
    "        old_key = self._keys1[idx1]\n",
    "        old_val = self._vals1[idx1]\n",
    "        self._keys1[idx1] = key\n",
    "        self._vals1[idx1] = value\n",
    "        \n",
    "        # Reinsert evicted key into second table (or recurse)\n",
    "        return self._insert_helper(old_key, old_val, count + 1)\n",
    "    \n",
    "    def delete(self, key: K) -> bool:\n",
    "        \"\"\"O(1) worst-case deletion.\"\"\"\n",
    "        idx1 = self._hash1(key)\n",
    "        if self._keys1[idx1] == key:\n",
    "            self._keys1[idx1] = None\n",
    "            self._vals1[idx1] = None\n",
    "            self._size -= 1\n",
    "            return True\n",
    "        \n",
    "        idx2 = self._hash2(key)\n",
    "        if self._keys2[idx2] == key:\n",
    "            self._keys2[idx2] = None\n",
    "            self._vals2[idx2] = None\n",
    "            self._size -= 1\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def _resize(self, new_capacity: int) -> None:\n",
    "        \"\"\"Rehash everything with new size.\"\"\"\n",
    "        old_keys1, old_vals1 = self._keys1, self._vals1\n",
    "        old_keys2, old_vals2 = self._keys2, self._vals2\n",
    "        \n",
    "        self._capacity = new_capacity\n",
    "        self._size = 0\n",
    "        self._keys1 = [None] * new_capacity\n",
    "        self._vals1 = [None] * new_capacity\n",
    "        self._keys2 = [None] * new_capacity\n",
    "        self._vals2 = [None] * new_capacity\n",
    "        \n",
    "        # Reinsert all\n",
    "        for i in range(len(old_keys1)):\n",
    "            if old_keys1[i] is not None:\n",
    "                self.insert(old_keys1[i], old_vals1[i])\n",
    "        for i in range(len(old_keys2)):\n",
    "            if old_keys2[i] is not None:\n",
    "                self.insert(old_keys2[i], old_vals2[i])\n",
    "\n",
    "\n",
    "def demonstrate_cuckoo():\n",
    "    print(\"Cuckoo Hashing\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\"\"\n",
    "    Cuckoo hashing provides O(1) worst-case lookup and deletion.\n",
    "    Insertion may trigger a chain of evictions (like cuckoo birds).\n",
    "    \n",
    "    Each key has exactly two possible locations:\n",
    "      Location 1: hash1(key)\n",
    "      Location 2: hash2(key)\n",
    "    \n",
    "    Lookup: Check both locations (2 memory accesses max)\n",
    "    Insert: Place in empty slot, or evict occupant to its alternate location\n",
    "    \"\"\")\n",
    "    \n",
    "    ch = CuckooHashing[str, int](capacity=4)\n",
    "    keys = [\"a\", \"b\", \"c\", \"d\"]\n",
    "    for i, k in enumerate(keys):\n",
    "        ch.insert(k, i)\n",
    "        print(f\"Inserted '{k}'\")\n",
    "    \n",
    "    print(f\"\\nLookup 'b': {ch.get('b')}\")\n",
    "    print(f\"Lookup 'z': {ch.get('z')}\")\n",
    "\n",
    "\n",
    "demonstrate_cuckoo()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **7.5.2 Robin Hood Hashing**\n",
    "\n",
    "```python\n",
    "def robin_hood_explained():\n",
    "    \"\"\"\n",
    "    Explain Robin Hood hashing.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Robin Hood Hashing\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\"\"\n",
    "    Concept: Steal from the rich (far from ideal position), give to the poor\n",
    "    \n",
    "    In open addressing, each key has an \"ideal\" position (initial hash).\n",
    "    The distance from ideal position is called the \"displacement\" or DIB\n",
    "    (Distance to Initial Bucket).\n",
    "    \n",
    "    Robin Hood Hashing Rule:\n",
    "      When inserting, if the new key is farther from its ideal position\n",
    "      than the current occupant, swap them and continue inserting the\n",
    "      evicted key.\n",
    "    \n",
    "    Effect:\n",
    "      • Reduces variance in probe lengths\n",
    "      • Keeps all keys within O(log n) of ideal position\n",
    "      • Improves cache locality\n",
    "      • Makes lookups faster on average\n",
    "    \n",
    "    Insertion Algorithm:\n",
    "      1. Compute initial position\n",
    "      2. Probe until empty slot found\n",
    "      3. If encountered key has smaller displacement than current would have,\n",
    "         swap and continue with evicted key\n",
    "      4. Continue until empty slot found\n",
    "    \n",
    "    Lookup Algorithm:\n",
    "      Same as linear probing, but can stop early if DIB of current\n",
    "      key is less than the distance we've traveled (sorted by DIB property).\n",
    "    \n",
    "    Backward Shift Deletion:\n",
    "      Instead of marking deleted, shift subsequent keys back to fill gap\n",
    "      (maintains the sorted-by-DIB invariant).\n",
    "    \n",
    "    Performance:\n",
    "      • Average probe length: ~ln(2) ≈ 0.69 for α = 0.5\n",
    "      • Max probe length: O(log n) with high probability\n",
    "      • Much better than linear probing for high load factors\n",
    "    \"\"\")\n",
    "\n",
    "robin_hood_explained()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7.6 Consistent Hashing for Distributed Systems**\n",
    "\n",
    "### **7.6.1 The Distributed Hash Table Problem**\n",
    "\n",
    "When data is distributed across multiple servers, traditional hashing (`server = hash(key) % N`) causes massive reorganization when servers are added or removed.\n",
    "\n",
    "```python\n",
    "import hashlib\n",
    "import bisect\n",
    "\n",
    "class ConsistentHashing:\n",
    "    \"\"\"\n",
    "    Consistent Hashing implementation for distributed systems.\n",
    "    \n",
    "    Maps both servers and keys to a circular hash ring.\n",
    "    Each key is assigned to the next server on the ring (clockwise).\n",
    "    \n",
    "    When server added/removed, only 1/N keys need remapping.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, replicas: int = 150):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            replicas: Virtual nodes per physical server (higher = better distribution)\n",
    "        \"\"\"\n",
    "        self.replicas = replicas  # Virtual nodes per server\n",
    "        self.ring = []  # Sorted list of hash values\n",
    "        self.nodes = {}  # hash -> server name\n",
    "        self.servers = set()\n",
    "    \n",
    "    def _hash(self, key: str) -> int:\n",
    "        \"\"\"Compute MD5 hash of key.\"\"\"\n",
    "        return int(hashlib.md5(key.encode()).hexdigest(), 16)\n",
    "    \n",
    "    def add_server(self, server: str) -> None:\n",
    "        \"\"\"\n",
    "        Add a server to the ring.\n",
    "        \n",
    "        Creates multiple virtual nodes for better distribution.\n",
    "        \"\"\"\n",
    "        self.servers.add(server)\n",
    "        for i in range(self.replicas):\n",
    "            virtual_key = f\"{server}:{i}\"\n",
    "            h = self._hash(virtual_key)\n",
    "            self.nodes[h] = server\n",
    "            bisect.insort(self.ring, h)\n",
    "    \n",
    "    def remove_server(self, server: str) -> None:\n",
    "        \"\"\"Remove a server and its virtual nodes.\"\"\"\n",
    "        self.servers.discard(server)\n",
    "        for i in range(self.replicas):\n",
    "            virtual_key = f\"{server}:{i}\"\n",
    "            h = self._hash(virtual_key)\n",
    "            del self.nodes[h]\n",
    "            idx = bisect.bisect_left(self.ring, h)\n",
    "            self.ring.pop(idx)\n",
    "    \n",
    "    def get_server(self, key: str) -> str:\n",
    "        \"\"\"\n",
    "        Find server for given key.\n",
    "        \n",
    "        Returns the next server clockwise on the ring.\n",
    "        \"\"\"\n",
    "        if not self.ring:\n",
    "            return None\n",
    "        \n",
    "        h = self._hash(key)\n",
    "        \n",
    "        # Find first virtual node >= key hash\n",
    "        idx = bisect.bisect_right(self.ring, h)\n",
    "        \n",
    "        if idx == len(self.ring):\n",
    "            # Wrap around to first server\n",
    "            idx = 0\n",
    "        \n",
    "        return self.nodes[self.ring[idx]]\n",
    "    \n",
    "    def get_distribution(self, keys: list) -> dict:\n",
    "        \"\"\"Show how keys are distributed across servers.\"\"\"\n",
    "        distribution = {server: 0 for server in self.servers}\n",
    "        for key in keys:\n",
    "            server = self.get_server(key)\n",
    "            distribution[server] += 1\n",
    "        return distribution\n",
    "\n",
    "\n",
    "def demonstrate_consistent_hashing():\n",
    "    \"\"\"\n",
    "    Demonstrate consistent hashing benefits.\n",
    "    \"\"\"\n",
    "    print(\"Consistent Hashing for Distributed Systems\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    ch = ConsistentHashing(replicas=100)\n",
    "    \n",
    "    # Add initial servers\n",
    "    servers = [\"Server-A\", \"Server-B\", \"Server-C\"]\n",
    "    for s in servers:\n",
    "        ch.add_server(s)\n",
    "    \n",
    "    # Generate sample keys\n",
    "    import random\n",
    "    random.seed(42)\n",
    "    keys = [f\"user_{i}\" for i in range(1000)]\n",
    "    \n",
    "    print(\"Initial distribution (3 servers):\")\n",
    "    dist = ch.get_distribution(keys)\n",
    "    for server, count in sorted(dist.items()):\n",
    "        print(f\"  {server}: {count} keys ({count/10:.1f}%)\")\n",
    "    \n",
    "    # Add new server\n",
    "    print(\"\\nAdding Server-D...\")\n",
    "    ch.add_server(\"Server-D\")\n",
    "    \n",
    "    print(\"New distribution (4 servers):\")\n",
    "    new_dist = ch.get_distribution(keys)\n",
    "    for server, count in sorted(new_dist.items()):\n",
    "        print(f\"  {server}: {count} keys ({count/10:.1f}%)\")\n",
    "    \n",
    "    # Calculate keys that moved\n",
    "    moved = 0\n",
    "    for key in keys:\n",
    "        old_server = None\n",
    "        for s in [\"Server-A\", \"Server-B\", \"Server-C\"]:\n",
    "            # Simulate old assignment (simplified)\n",
    "            pass\n",
    "    \n",
    "    print(\"\"\"\n",
    "    \n",
    "    Benefits of Consistent Hashing:\n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Traditional Hashing (hash % N):\n",
    "      • Add server: almost all keys remap (N changes)\n",
    "      • Remove server: almost all keys remap\n",
    "      • Cache miss storm when topology changes\n",
    "    \n",
    "    Consistent Hashing:\n",
    "      • Add server: only 1/N keys move to new server\n",
    "      • Remove server: only 1/N keys redistribute\n",
    "      • Minimal disruption to cache\n",
    "    \n",
    "    Virtual Nodes:\n",
    "      • Without: uneven distribution if few servers\n",
    "      • With: better load balancing, handles heterogenous servers\n",
    "      • Standard practice: 100-200 virtual nodes per physical server\n",
    "    \n",
    "    Real-world Usage:\n",
    "      • Amazon Dynamo DB\n",
    "      • Apache Cassandra\n",
    "      • Memcached client libraries (ketama)\n",
    "      • Content Delivery Networks (CDNs)\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "demonstrate_consistent_hashing()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7.7 Perfect Hashing and Static Hashing**\n",
    "\n",
    "### **7.7.1 Perfect Hashing**\n",
    "\n",
    "**Perfect hashing** guarantees O(1) worst-case lookup with no collisions, but requires the set of keys to be known in advance (static).\n",
    "\n",
    "```python\n",
    "def perfect_hashing_concept():\n",
    "    \"\"\"\n",
    "    Explain perfect hashing.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Perfect Hashing\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\"\"\n",
    "    Definition: A hash function is perfect if it maps each key to a \n",
    "    unique index (no collisions).\n",
    "    \n",
    "    Types:\n",
    "    \n",
    "    1. Minimal Perfect Hashing:\n",
    "       • Maps n keys to n consecutive integers [0, n-1]\n",
    "       • No wasted space\n",
    "       • O(1) worst-case lookup\n",
    "    \n",
    "    2. Order-Preserving Minimal Perfect Hashing:\n",
    "       • Preserves lexicographical order of keys\n",
    "       • Enables binary search on hash table\n",
    "    \n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Construction (FKS Scheme - Fredman, Komlós, Szemerédi):\n",
    "    \n",
    "    Level 1: Universal hash function h\n",
    "             Maps n keys to table of size n\n",
    "    \n",
    "    Level 2: For each bucket with collisions, use secondary hash table\n",
    "             Size proportional to square of bucket size\n",
    "    \n",
    "    Expected total space: O(n)\n",
    "    Lookup: O(1) worst-case (two hash computations)\n",
    "    \n",
    "    ─────────────────────────────────────────────────────────────────────\n",
    "    \n",
    "    Applications:\n",
    "      • Compiler keyword tables (static set of reserved words)\n",
    "      • Router tables (static IP prefixes)\n",
    "      • Dictionary implementations (read-only)\n",
    "      • CD-ROM filesystems (static data)\n",
    "    \n",
    "    Limitations:\n",
    "      • Keys must be known in advance\n",
    "      • Expensive to construct (O(n) expected, but high constant)\n",
    "      • No dynamic insertion/deletion (or requires reconstruction)\n",
    "    \n",
    "    Libraries:\n",
    "      • cmph (C Minimal Perfect Hashing Library)\n",
    "      • gperf (GNU Perfect Hash Function Generator)\n",
    "    \"\"\")\n",
    "\n",
    "perfect_hashing_concept()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7.8 Summary and Key Takeaways**\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    HASH TABLE SUMMARY                                │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                      │\n",
    "│  Collision Resolution Comparison:                                    │\n",
    "│                                                                      │\n",
    "│  Method              │ Pros                    │ Cons                │\n",
    "│  ────────────────────┼─────────────────────────┼─────────────────────│\n",
    "│  Chaining            │ Simple, handles α>1     │ Extra memory        │\n",
    "│  Linear Probing      │ Cache friendly          │ Primary clustering  │\n",
    "│  Quadratic Probing   │ Less clustering         │ Secondary clustering│\n",
    "│  Double Hashing      │ Best distribution       │ Slower computation  │\n",
    "│  Cuckoo Hashing      │ O(1) lookup guaranteed  │ Insertion can fail  │\n",
    "│  Robin Hood          │ Low variance probes     │ Complex deletion    │\n",
    "│                                                                      │\n",
    "│  Load Factor Guidelines:                                             │\n",
    "│    • Chaining: α ≤ 0.75                                              │\n",
    "│    • Open Addressing: α ≤ 0.5 (linear), α ≤ 0.7 (double)            │\n",
    "│                                                                      │\n",
    "│  Advanced Techniques:                                                │\n",
    "│    • Consistent Hashing: Distributed systems, minimal remapping     │\n",
    "│    • Perfect Hashing: Static sets, guaranteed O(1), no collisions   │\n",
    "│                                                                      │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7.9 Practice Problems**\n",
    "\n",
    "### **Problem 1: Design HashMap**\n",
    "Design a HashMap without using any built-in hash table libraries. Implement `put`, `get`, and `remove` operations.\n",
    "\n",
    "### **Problem 2: First Unique Character**\n",
    "Given a string, find the first non-repeating character and return its index.\n",
    "\n",
    "### **Problem 3: Group Anagrams**\n",
    "Given an array of strings, group anagrams together using hashing strategies.\n",
    "\n",
    "### **Problem 4: LRU Cache**\n",
    "Design and implement an LRU (Least Recently Used) cache using a hash map and doubly linked list (already covered in Ch 5, but reinforces hash table usage).\n",
    "\n",
    "### **Problem 5: Find Duplicates**\n",
    "Given an array of integers where each integer appears exactly twice except for one, find the single number using hash sets vs bit manipulation.\n",
    "\n",
    "---\n",
    "\n",
    "## **7.10 Further Reading**\n",
    "\n",
    "1. **Introduction to Algorithms (CLRS)** Chapter 11 - Hash Tables\n",
    "2. **The Art of Computer Programming, Vol 3** by Knuth - Searching and hashing\n",
    "3. **\"Consistent Hashing and Random Trees\"** by Karger et al. (Original paper)\n",
    "4. **\"Cuckoo Hashing\"** by Pagh and Rodler (Original paper)\n",
    "5. **\"Robin Hood Hashing\"** by Celis et al.\n",
    "\n",
    "---\n",
    "\n",
    "> **Coming in Chapter 8**: We'll explore **Trees**, starting with binary trees and binary search trees. You'll learn about tree traversals, self-balancing BSTs (AVL and Red-Black trees), and their applications in database indexing and search algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 7**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
