{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b3859e5",
   "metadata": {},
   "source": [
    "# Chapter 28: Advanced Caching Strategies\n",
    "\n",
    "Building upon real-time features, modern Next.js applications require sophisticated caching strategies to balance performance with data freshness. Multi-layer caching—from the edge to the client—can dramatically reduce latency and server load while maintaining consistency across global deployments.\n",
    "\n",
    "By the end of this chapter, you'll master implementing multi-layer caching architectures, CDN integration strategies, edge caching patterns, cache invalidation techniques, stale-while-revalidate implementations, distributed caching with Redis, and cache performance monitoring.\n",
    "\n",
    "## 28.1 Multi-Layer Caching Architecture\n",
    "\n",
    "Implement a hierarchical caching strategy that leverages different storage layers based on data volatility and access patterns.\n",
    "\n",
    "### Cache Layers Implementation\n",
    "\n",
    "```typescript\n",
    "// lib/cache/cache-layers.ts\n",
    "import { LRUCache } from 'lru-cache';\n",
    "\n",
    "// Layer 1: In-Memory (Fastest, process-specific)\n",
    "const memoryCache = new LRUCache<string, any>({\n",
    "  max: 500,\n",
    "  ttl: 1000 * 60 * 5, // 5 minutes\n",
    "  updateAgeOnGet: true,\n",
    "  allowStale: false,\n",
    "});\n",
    "\n",
    "// Layer 2: Edge Cache (Vercel Edge Config or similar)\n",
    "class EdgeCacheLayer {\n",
    "  async get<T>(key: string): Promise<T | null> {\n",
    "    try {\n",
    "      const response = await fetch(`${process.env.EDGE_CONFIG_URL}/item/${key}`, {\n",
    "        headers: { Authorization: `Bearer ${process.env.EDGE_CONFIG_TOKEN}` },\n",
    "      });\n",
    "      if (!response.ok) return null;\n",
    "      return response.json();\n",
    "    } catch {\n",
    "      return null;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  async set(key: string, value: any, ttl?: number): Promise<void> {\n",
    "    await fetch(process.env.EDGE_CONFIG_URL!, {\n",
    "      method: 'PATCH',\n",
    "      headers: {\n",
    "        Authorization: `Bearer ${process.env.EDGE_CONFIG_TOKEN}`,\n",
    "        'Content-Type': 'application/json',\n",
    "      },\n",
    "      body: JSON.stringify({\n",
    "        items: [{ operation: 'upsert', key, value }],\n",
    "      }),\n",
    "    });\n",
    "  }\n",
    "}\n",
    "\n",
    "// Layer 3: Redis/Distributed Cache\n",
    "import { Redis } from '@upstash/redis';\n",
    "\n",
    "const redis = new Redis({\n",
    "  url: process.env.UPSTASH_REDIS_REST_URL!,\n",
    "  token: process.env.UPSTASH_REDIS_REST_TOKEN!,\n",
    "});\n",
    "\n",
    "export class MultiLayerCache {\n",
    "  private edge = new EdgeCacheLayer();\n",
    "\n",
    "  async get<T>(key: string): Promise<T | null> {\n",
    "    // Try memory first\n",
    "    const memValue = memoryCache.get(key) as T;\n",
    "    if (memValue) return memValue;\n",
    "\n",
    "    // Try edge cache\n",
    "    const edgeValue = await this.edge.get<T>(key);\n",
    "    if (edgeValue) {\n",
    "      memoryCache.set(key, edgeValue);\n",
    "      return edgeValue;\n",
    "    }\n",
    "\n",
    "    // Try Redis\n",
    "    const redisValue = await redis.get<T>(key);\n",
    "    if (redisValue) {\n",
    "      memoryCache.set(key, redisValue);\n",
    "      await this.edge.set(key, redisValue);\n",
    "      return redisValue;\n",
    "    }\n",
    "\n",
    "    return null;\n",
    "  }\n",
    "\n",
    "  async set<T>(key: string, value: T, options?: { \n",
    "    memoryTTL?: number; \n",
    "    edgeTTL?: number; \n",
    "    redisTTL?: number \n",
    "  }): Promise<void> {\n",
    "    // Set in all layers\n",
    "    memoryCache.set(key, value, { ttl: options?.memoryTTL });\n",
    "    await Promise.all([\n",
    "      this.edge.set(key, value, options?.edgeTTL),\n",
    "      redis.set(key, value, options?.redisTTL ? { ex: options.redisTTL } : undefined),\n",
    "    ]);\n",
    "  }\n",
    "\n",
    "  async invalidate(key: string): Promise<void> {\n",
    "    memoryCache.delete(key);\n",
    "    await Promise.all([\n",
    "      this.edge.set(key, null),\n",
    "      redis.del(key),\n",
    "    ]);\n",
    "  }\n",
    "\n",
    "  async invalidatePattern(pattern: string): Promise<void> {\n",
    "    // Clear memory cache matching pattern\n",
    "    for (const key of memoryCache.keys()) {\n",
    "      if (key.includes(pattern)) memoryCache.delete(key);\n",
    "    }\n",
    "    \n",
    "    // Clear Redis keys matching pattern\n",
    "    const keys = await redis.keys(`*${pattern}*`);\n",
    "    if (keys.length > 0) {\n",
    "      await redis.del(...keys);\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "export const cache = new MultiLayerCache();\n",
    "```\n",
    "\n",
    "### Cache-Aside Pattern with Next.js\n",
    "\n",
    "Implement the cache-aside pattern for database queries:\n",
    "\n",
    "```typescript\n",
    "// lib/cache/cache-aside.ts\n",
    "import { cache } from './cache-layers';\n",
    "\n",
    "export async function getCachedData<T>(\n",
    "  key: string,\n",
    "  fetcher: () => Promise<T>,\n",
    "  options?: {\n",
    "    ttl?: number;\n",
    "    staleWhileRevalidate?: number;\n",
    "    tags?: string[];\n",
    "  }\n",
    "): Promise<T> {\n",
    "  const cacheKey = `data:${key}`;\n",
    "  const cached = await cache.get<T & { _timestamp: number }>(cacheKey);\n",
    "  \n",
    "  const now = Date.now();\n",
    "  const ttl = options?.ttl || 3600;\n",
    "  \n",
    "  // Return cached data if fresh\n",
    "  if (cached && (now - cached._timestamp) < ttl * 1000) {\n",
    "    return cached as T;\n",
    "  }\n",
    "  \n",
    "  // Return stale data while revalidating in background\n",
    "  if (cached && options?.staleWhileRevalidate) {\n",
    "    const staleThreshold = (ttl + options.staleWhileRevalidate) * 1000;\n",
    "    if ((now - cached._timestamp) < staleThreshold) {\n",
    "      // Trigger background revalidation\n",
    "      revalidateInBackground(key, fetcher, options);\n",
    "      return cached as T;\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  // Fetch fresh data\n",
    "  const data = await fetcher();\n",
    "  await cache.set(cacheKey, { ...data, _timestamp: now }, {\n",
    "    redisTTL: ttl,\n",
    "  });\n",
    "  \n",
    "  return data;\n",
    "}\n",
    "\n",
    "async function revalidateInBackground<T>(\n",
    "  key: string,\n",
    "  fetcher: () => Promise<T>,\n",
    "  options?: any\n",
    ") {\n",
    "  // Use waitUntil for edge runtime compatibility\n",
    "  const { waitUntil } = require('@vercel/functions');\n",
    "  \n",
    "  waitUntil(\n",
    "    (async () => {\n",
    "      const data = await fetcher();\n",
    "      await cache.set(`data:${key}`, { ...data, _timestamp: Date.now() }, {\n",
    "        redisTTL: options?.ttl,\n",
    "      });\n",
    "    })()\n",
    "  );\n",
    "}\n",
    "```\n",
    "\n",
    "## 28.2 CDN Integration and Edge Caching\n",
    "\n",
    "Configure Vercel Edge Network and other CDNs for optimal cache behavior.\n",
    "\n",
    "### Edge Cache Configuration\n",
    "\n",
    "```typescript\n",
    "// app/api/content/[slug]/route.ts\n",
    "import { NextRequest, NextResponse } from 'next/server';\n",
    "\n",
    "export async function GET(\n",
    "  request: NextRequest,\n",
    "  { params }: { params: { slug: string } }\n",
    ") {\n",
    "  const { slug } = params;\n",
    "  \n",
    "  // Fetch content (this would hit your database/CMS)\n",
    "  const content = await fetchContent(slug);\n",
    "  \n",
    "  if (!content) {\n",
    "    return new NextResponse('Not Found', { status: 404 });\n",
    "  }\n",
    "  \n",
    "  // Calculate cache headers based on content type\n",
    "  const headers = new Headers();\n",
    "  \n",
    "  // Static content: Cache for 1 year, revalidate daily\n",
    "  if (content.type === 'static') {\n",
    "    headers.set('Cache-Control', 'public, max-age=31536000, s-maxage=86400, stale-while-revalidate=86400');\n",
    "  }\n",
    "  \n",
    "  // Dynamic content: Cache for 5 minutes, serve stale for 1 hour\n",
    "  else if (content.type === 'dynamic') {\n",
    "    headers.set('Cache-Control', 'public, max-age=300, s-maxage=300, stale-while-revalidate=3600');\n",
    "  }\n",
    "  \n",
    "  // Personalized content: Private, no CDN cache\n",
    "  else if (content.type === 'personalized') {\n",
    "    headers.set('Cache-Control', 'private, no-cache, no-store, max-age=0');\n",
    "  }\n",
    "  \n",
    "  // Tag-based invalidation support\n",
    "  headers.set('Cache-Tag', `content-${slug},content-type-${content.type}`);\n",
    "  \n",
    "  return NextResponse.json(content, { headers });\n",
    "}\n",
    "\n",
    "// lib/vercel/purge-cache.ts\n",
    "export async function purgeCache(tags: string[]) {\n",
    "  if (process.env.VERCEL_ENV !== 'production') return;\n",
    "  \n",
    "  await fetch('https://api.vercel.com/v1/edge-config/invalidations', {\n",
    "    method: 'POST',\n",
    "    headers: {\n",
    "      Authorization: `Bearer ${process.env.VERCEL_TOKEN}`,\n",
    "      'Content-Type': 'application/json',\n",
    "    },\n",
    "    body: JSON.stringify({\n",
    "      tags,\n",
    "      projectId: process.env.VERCEL_PROJECT_ID,\n",
    "    }),\n",
    "  });\n",
    "}\n",
    "```\n",
    "\n",
    "### ISR with On-Demand Revalidation\n",
    "\n",
    "Implement fine-grained revalidation strategies:\n",
    "\n",
    "```typescript\n",
    "// app/api/revalidate/route.ts\n",
    "import { revalidateTag, revalidatePath } from 'next/cache';\n",
    "import { NextRequest, NextResponse } from 'next/server';\n",
    "\n",
    "export async function POST(request: NextRequest) {\n",
    "  const { tag, path, secret } = await request.json();\n",
    "  \n",
    "  // Verify secret\n",
    "  if (secret !== process.env.REVALIDATION_SECRET) {\n",
    "    return NextResponse.json({ error: 'Invalid secret' }, { status: 401 });\n",
    "  }\n",
    "  \n",
    "  try {\n",
    "    if (tag) {\n",
    "      revalidateTag(tag);\n",
    "      console.log(`Revalidated tag: ${tag}`);\n",
    "    }\n",
    "    \n",
    "    if (path) {\n",
    "      revalidatePath(path);\n",
    "      console.log(`Revalidated path: ${path}`);\n",
    "    }\n",
    "    \n",
    "    return NextResponse.json({ revalidated: true, now: Date.now() });\n",
    "  } catch (err) {\n",
    "    return NextResponse.json(\n",
    "      { error: 'Error revalidating' }, \n",
    "      { status: 500 }\n",
    "    );\n",
    "  }\n",
    "}\n",
    "\n",
    "// Usage in webhook handlers\n",
    "// app/api/webhooks/cms/route.ts\n",
    "export async function POST(req: Request) {\n",
    "  const payload = await req.json();\n",
    "  \n",
    "  // Revalidate specific content\n",
    "  await fetch(`${process.env.NEXT_PUBLIC_URL}/api/revalidate`, {\n",
    "    method: 'POST',\n",
    "    headers: { 'Content-Type': 'application/json' },\n",
    "    body: JSON.stringify({\n",
    "      tag: `content-${payload.documentId}`,\n",
    "      secret: process.env.REVALIDATION_SECRET,\n",
    "    }),\n",
    "  });\n",
    "  \n",
    "  return Response.json({ success: true });\n",
    "}\n",
    "```\n",
    "\n",
    "## 28.3 Redis for Distributed Caching\n",
    "\n",
    "Implement Redis for cross-instance cache sharing and rate limiting.\n",
    "\n",
    "### Redis Cache Implementation\n",
    "\n",
    "```typescript\n",
    "// lib/redis/cache.ts\n",
    "import { Redis } from '@upstash/redis';\n",
    "import { Ratelimit } from '@upstash/ratelimit';\n",
    "\n",
    "const redis = new Redis({\n",
    "  url: process.env.UPSTASH_REDIS_REST_URL!,\n",
    "  token: process.env.UPSTASH_REDIS_REST_TOKEN!,\n",
    "});\n",
    "\n",
    "// Rate limiting with sliding window\n",
    "export const ratelimit = new Ratelimit({\n",
    "  redis,\n",
    "  limiter: Ratelimit.slidingWindow(10, '10 s'),\n",
    "  analytics: true,\n",
    "});\n",
    "\n",
    "export class RedisCache {\n",
    "  async get<T>(key: string): Promise<T | null> {\n",
    "    const data = await redis.get<T>(key);\n",
    "    return data;\n",
    "  }\n",
    "\n",
    "  async set<T>(key: string, value: T, ttlSeconds?: number): Promise<void> {\n",
    "    if (ttlSeconds) {\n",
    "      await redis.setex(key, ttlSeconds, value);\n",
    "    } else {\n",
    "      await redis.set(key, value);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  async delete(key: string): Promise<void> {\n",
    "    await redis.del(key);\n",
    "  }\n",
    "\n",
    "  async increment(key: string, amount: number = 1): Promise<number> {\n",
    "    return await redis.incrby(key, amount);\n",
    "  }\n",
    "\n",
    "  // Bulk operations for efficiency\n",
    "  async mget<T>(keys: string[]): Promise<(T | null)[]> {\n",
    "    if (keys.length === 0) return [];\n",
    "    return await redis.mget<T[]>(...keys);\n",
    "  }\n",
    "\n",
    "  async mset(entries: Record<string, any>): Promise<void> {\n",
    "    const pipeline = redis.pipeline();\n",
    "    Object.entries(entries).forEach(([key, value]) => {\n",
    "      pipeline.set(key, value);\n",
    "    });\n",
    "    await pipeline.exec();\n",
    "  }\n",
    "\n",
    "  // Cache tagging for bulk invalidation\n",
    "  async setWithTags(key: string, value: any, tags: string[], ttl?: number): Promise<void> {\n",
    "    const multi = redis.multi();\n",
    "    \n",
    "    multi.set(key, JSON.stringify(value));\n",
    "    if (ttl) multi.expire(key, ttl);\n",
    "    \n",
    "    // Add to tag sets\n",
    "    tags.forEach(tag => {\n",
    "      multi.sadd(`tag:${tag}`, key);\n",
    "    });\n",
    "    \n",
    "    await multi.exec();\n",
    "  }\n",
    "\n",
    "  async invalidateTag(tag: string): Promise<void> {\n",
    "    const keys = await redis.smembers(`tag:${tag}`);\n",
    "    if (keys.length > 0) {\n",
    "      const multi = redis.multi();\n",
    "      keys.forEach(key => multi.del(key));\n",
    "      multi.del(`tag:${tag}`);\n",
    "      await multi.exec();\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "export const redisCache = new RedisCache();\n",
    "```\n",
    "\n",
    "## 28.4 Cache Invalidation Strategies\n",
    "\n",
    "Implement predictable cache invalidation patterns.\n",
    "\n",
    "### Tag-Based Invalidation\n",
    "\n",
    "```typescript\n",
    "// lib/cache/tagged-cache.ts\n",
    "import { unstable_cache } from 'next/cache';\n",
    "\n",
    "export const getProduct = unstable_cache(\n",
    "  async (id: string) => {\n",
    "    return await db.product.findUnique({ where: { id } });\n",
    "  },\n",
    "  ['product'],\n",
    "  {\n",
    "    tags: ['products'],\n",
    "    revalidate: 3600,\n",
    "  }\n",
    ");\n",
    "\n",
    "export const getProductList = unstable_cache(\n",
    "  async (category: string) => {\n",
    "    return await db.product.findMany({ where: { category } });\n",
    "  },\n",
    "  ['product-list'],\n",
    "  {\n",
    "    tags: ['products', `category-${category}`],\n",
    "    revalidate: 1800,\n",
    "  }\n",
    ");\n",
    "\n",
    "// Invalidation helpers\n",
    "export async function invalidateProduct(productId: string) {\n",
    "  'use server';\n",
    "  \n",
    "  revalidateTag('products');\n",
    "  revalidateTag(`product-${productId}`);\n",
    "}\n",
    "\n",
    "export async function invalidateCategory(category: string) {\n",
    "  'use server';\n",
    "  \n",
    "  revalidateTag(`category-${category}`);\n",
    "  revalidateTag('products');\n",
    "}\n",
    "```\n",
    "\n",
    "### Smart Cache Warming\n",
    "\n",
    "Pre-populate cache after invalidation:\n",
    "\n",
    "```typescript\n",
    "// lib/cache/warmer.ts\n",
    "import { redisCache } from './cache';\n",
    "\n",
    "export class CacheWarmer {\n",
    "  async warmProductCache(productId: string) {\n",
    "    const product = await db.product.findUnique({\n",
    "      where: { id: productId },\n",
    "      include: { reviews: true, category: true },\n",
    "    });\n",
    "    \n",
    "    if (!product) return;\n",
    "    \n",
    "    // Warm multiple cache layers\n",
    "    await Promise.all([\n",
    "      redisCache.set(`product:${productId}`, product, 3600),\n",
    "      redisCache.set(`product:slug:${product.slug}`, product, 3600),\n",
    "    ]);\n",
    "    \n",
    "    // Warm related caches\n",
    "    if (product.category) {\n",
    "      await this.warmCategoryCache(product.category.slug);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  private async warmCategoryCache(categorySlug: string) {\n",
    "    const products = await db.product.findMany({\n",
    "      where: { category: { slug: categorySlug } },\n",
    "      take: 20,\n",
    "    });\n",
    "    \n",
    "    await redisCache.set(`category:${categorySlug}`, products, 1800);\n",
    "  }\n",
    "}\n",
    "\n",
    "export const cacheWarmer = new CacheWarmer();\n",
    "```\n",
    "\n",
    "## Key Takeaways from Chapter 28\n",
    "\n",
    "1. **Multi-Layer Caching**: Implement a hierarchy from in-memory (L1) to edge cache (L2) to Redis (L3). Each layer serves different purposes: memory for hot data, edge for geographic distribution, Redis for shared state across instances.\n",
    "\n",
    "2. **Cache-Control Headers**: Use granular cache headers—`s-maxage` for CDN, `max-age` for browser, and `stale-while-revalidate` for background updates. Tag responses with `Cache-Tag` for selective purging.\n",
    "\n",
    "3. **ISR and On-Demand Revalidation**: Use `unstable_cache` for function-level caching with tags. Implement webhook-triggered revalidation for CMS-driven content, separating immediate stale-while-revalidate from manual purging.\n",
    "\n",
    "4. **Redis Patterns**: Use Redis for distributed state, rate limiting (sliding window), and bulk operations. Implement tag-based invalidation using Redis Sets to track cache key relationships.\n",
    "\n",
    "5. **Cache Warming**: After invalidation, asynchronously warm caches by fetching fresh data and populating all layers. This prevents cache stampedes when popular content expires.\n",
    "\n",
    "## Coming Up Next\n",
    "\n",
    "**Chapter 29: Progressive Web Applications**\n",
    "\n",
    "Now that your application serves data efficiently through advanced caching, it's time to make it installable and offline-capable. In Chapter 29, we'll explore service workers, web app manifests, offline fallbacks, background sync, and push notifications to transform your Next.js app into a fully-featured PWA that works seamlessly even without network connectivity."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
