{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 15: Production Readiness and Day 2 Operations\n",
    "\n",
    "Deploying your application to the cloud is a major milestone, but it’s only the beginning. Once your application is live, you enter the world of **Day 2 operations**—keeping it running smoothly, monitoring its health, responding to incidents, scaling to meet demand, and managing secrets securely. In this chapter, we’ll take the e‑commerce application we deployed to Azure Container Apps and make it production‑ready. You’ll learn how to:\n",
    "\n",
    "- Ship logs and metrics to Azure Monitor and Application Insights for centralized observability.\n",
    "- Configure auto‑scaling rules so your services can handle load and save costs.\n",
    "- Move secrets from environment variables to Azure Key Vault, using managed identities for secure access.\n",
    "- Set up distributed tracing to debug cross‑service issues.\n",
    "- Implement best practices for health checks and readiness probes.\n",
    "\n",
    "By the end, your application will be robust, observable, and ready for real users.\n",
    "\n",
    "---\n",
    "\n",
    "### 15.1 The Gap Between Development and Production\n",
    "\n",
    "In development, you rely on the Aspire Dashboard for logs, traces, and metrics. It’s a fantastic tool for the inner loop, but it’s not designed for production. In production, you need:\n",
    "\n",
    "- **Long‑term retention** of logs and metrics.\n",
    "- **Centralized aggregation** from all instances and services.\n",
    "- **Alerting** on anomalies (e.g., high error rate, low disk space).\n",
    "- **Role‑based access control** for who can view data.\n",
    "- **Integration with incident management** tools.\n",
    "\n",
    "Azure provides a suite of monitoring services: **Log Analytics** for log storage and querying, **Application Insights** for application performance monitoring (APM), and **Azure Monitor** for metrics and alerts. These services integrate seamlessly with .NET and with Azure Container Apps.\n",
    "\n",
    "---\n",
    "\n",
    "### 15.2 Logging and Monitoring in Production\n",
    "\n",
    "#### 15.2.1 Shipping Logs to Azure Log Analytics\n",
    "\n",
    "Azure Container Apps can automatically send container stdout/stderr logs to a Log Analytics workspace. When you provision an ACA environment, you can link it to a Log Analytics workspace. In our `azd` deployment, this is already set up.\n",
    "\n",
    "To view logs:\n",
    "\n",
    "1. In the Azure portal, navigate to your Container App (e.g., `apiservice`).\n",
    "2. Under **Monitoring**, select **Logs**.\n",
    "3. Run a query like:\n",
    "\n",
    "   ```kusto\n",
    "   ContainerAppConsoleLogs_CL\n",
    "   | where ContainerAppName_s == \"apiservice\"\n",
    "   | project TimeGenerated, Log_s\n",
    "   | order by TimeGenerated desc\n",
    "   ```\n",
    "\n",
    "This shows raw console logs. However, structured logs (like those from `ILogger`) are even better. Our services use `builder.AddServiceDefaults()`, which configures OpenTelemetry logging. To send structured logs to Log Analytics, we need to use an OpenTelemetry exporter that speaks to Log Analytics. The easiest way is to use Application Insights, which can ingest logs, traces, and metrics.\n",
    "\n",
    "#### 15.2.2 Application Insights for Traces, Metrics, and Logs\n",
    "\n",
    "Application Insights is a feature of Azure Monitor that provides powerful application performance monitoring. It can collect:\n",
    "\n",
    "- **Requests**: incoming HTTP requests.\n",
    "- **Dependencies**: calls to databases, HTTP services, queues.\n",
    "- **Exceptions**: thrown exceptions.\n",
    "- **Traces**: custom log messages.\n",
    "- **Metrics**: custom and system metrics.\n",
    "\n",
    "To enable Application Insights, we need to:\n",
    "\n",
    "- Add the Application Insights SDK or the OpenTelemetry Azure Monitor exporter to each service.\n",
    "- Configure the connection string via an environment variable.\n",
    "- Ensure the exporter sends telemetry to Application Insights.\n",
    "\n",
    "##### Step 1: Add the OpenTelemetry Azure Monitor Exporter\n",
    "\n",
    "In each service project (API, Web, Worker), install the NuGet package:\n",
    "\n",
    "```bash\n",
    "dotnet add package Azure.Monitor.OpenTelemetry.Exporter\n",
    "```\n",
    "\n",
    "##### Step 2: Configure OpenTelemetry to Use Azure Monitor\n",
    "\n",
    "In `Program.cs`, after `AddServiceDefaults()`, we need to modify the OpenTelemetry setup to add the Azure Monitor exporter. However, `AddServiceDefaults` already configures OpenTelemetry with an OTLP exporter (pointing to the Aspire Dashboard). We need to either replace that or add a second exporter. In production, we don’t want to send telemetry to the Aspire Dashboard (which isn’t running). So we can conditionally add the Azure Monitor exporter based on the environment.\n",
    "\n",
    "In `Program.cs`:\n",
    "\n",
    "```csharp\n",
    "if (builder.Environment.IsProduction())\n",
    "{\n",
    "    builder.Services.AddOpenTelemetry()\n",
    "        .UseAzureMonitor(options =>\n",
    "        {\n",
    "            options.ConnectionString = builder.Configuration[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"];\n",
    "        });\n",
    "}\n",
    "else\n",
    "{\n",
    "    // In development, the defaults already send to Aspire Dashboard\n",
    "}\n",
    "```\n",
    "\n",
    "But note: `AddServiceDefaults` already calls `AddOpenTelemetry` with metrics and tracing. We can’t call it again without interfering. The recommended approach is to modify the ServiceDefaults project to be more flexible, or to remove the default exporter and add our own. For simplicity, we'll conditionally clear the default exporters and add Azure Monitor.\n",
    "\n",
    "In `Program.cs`, after `AddServiceDefaults`, we can do:\n",
    "\n",
    "```csharp\n",
    "builder.Services.Configure<OpenTelemetryLoggerOptions>(logging => logging.ClearExporters());\n",
    "builder.Services.ConfigureOpenTelemetryMeterProvider(metrics => metrics.ClearExporters());\n",
    "builder.Services.ConfigureOpenTelemetryTracerProvider(tracing => tracing.ClearExporters());\n",
    "\n",
    "// Then add Azure Monitor\n",
    "builder.Services.AddOpenTelemetry()\n",
    "    .UseAzureMonitor(options =>\n",
    "    {\n",
    "        options.ConnectionString = builder.Configuration[\"APPLICATIONINSIGHTS_CONNECTION_STRING\"];\n",
    "    });\n",
    "```\n",
    "\n",
    "This is a bit hacky. A cleaner approach is to have a feature flag or environment variable that tells `AddServiceDefaults` to not add exporters, and then we add them manually. You could modify the ServiceDefaults project to accept a delegate for configuring exporters. We'll skip that complexity here.\n",
    "\n",
    "##### Step 3: Set the Application Insights Connection String\n",
    "\n",
    "In your ACA environment, you can set environment variables. With `azd`, you can add the connection string as a secret. First, create an Application Insights resource (you can add it to your Bicep). Then, set the environment variable `APPLICATIONINSIGHTS_CONNECTION_STRING` in the Container App definitions.\n",
    "\n",
    "In Bicep, you might have:\n",
    "\n",
    "```bicep\n",
    "resource appInsights 'Microsoft.Insights/components@2020-02-02' = {\n",
    "  name: '${resourceBaseName}-ai'\n",
    "  location: location\n",
    "  kind: 'web'\n",
    "  properties: {\n",
    "    Application_Type: 'web'\n",
    "  }\n",
    "}\n",
    "\n",
    "// Then in Container App environment variables:\n",
    "environmentVariables: [\n",
    "  {\n",
    "    name: 'APPLICATIONINSIGHTS_CONNECTION_STRING'\n",
    "    value: appInsights.properties.ConnectionString\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "`azd` can also automatically create an Application Insights instance and inject its connection string if you use the right patterns.\n",
    "\n",
    "##### Step 4: Verify\n",
    "\n",
    "After redeploying, go to the Application Insights resource in the Azure portal. You should see requests, dependencies, traces, and exceptions. You can also query logs using Kusto.\n",
    "\n",
    "#### 15.2.3 Distributed Tracing with Application Insights\n",
    "\n",
    "One of the most powerful features of Application Insights is **distributed tracing**. When a request flows from the web frontend to the API to the database, Application Insights correlates these operations into a single **transaction**. You can see the entire call stack, including dependencies, and pinpoint where time is spent.\n",
    "\n",
    "Because we used `AddServiceDefaults`, our services already propagate trace context via W3C TraceContext. The Azure Monitor exporter will send this trace data, and Application Insights will stitch it together.\n",
    "\n",
    "In the portal, go to Application Insights → **Transaction search** or **Performance** and click on an operation to see the end‑to‑end trace.\n",
    "\n",
    "---\n",
    "\n",
    "### 15.3 Configuring Auto‑Scaling in Azure Container Apps\n",
    "\n",
    "Azure Container Apps supports several scaling rules:\n",
    "\n",
    "- **HTTP scaling**: based on the number of concurrent HTTP requests.\n",
    "- **Event‑driven scaling** (KEDA): based on queue length, Kafka offset, etc.\n",
    "- **CPU/Memory scaling**: based on resource usage.\n",
    "- **Custom scaling** (using KEDA scalers).\n",
    "\n",
    "By default, a Container App scales to zero when idle (if you set `minReplicas` to 0). This is cost‑effective but may cause cold starts. You can adjust `minReplicas` and `maxReplicas` based on your needs.\n",
    "\n",
    "#### 15.3.1 Adding HTTP Scaling Rules\n",
    "\n",
    "In your Bicep or Container App configuration, you can define scaling rules. For example, to scale the API based on HTTP traffic:\n",
    "\n",
    "```bicep\n",
    "resource apiService 'Microsoft.App/containerApps@2023-05-01' = {\n",
    "  // ...\n",
    "  properties: {\n",
    "    template: {\n",
    "      // ...\n",
    "      scale: {\n",
    "        minReplicas: 0\n",
    "        maxReplicas: 10\n",
    "        rules: [\n",
    "          {\n",
    "            name: 'http-scale'\n",
    "            http: {\n",
    "              metadata: {\n",
    "                concurrentRequests: '100'\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "This scales out when the number of concurrent HTTP requests exceeds 100 per replica.\n",
    "\n",
    "#### 15.3.2 Event‑Driven Scaling for the Worker\n",
    "\n",
    "Our worker service consumes from RabbitMQ. To scale it based on queue length, we need a KEDA scaler for RabbitMQ. First, we need to ensure RabbitMQ itself is accessible (if using RabbitMQ as a container in ACA, we need to expose it internally). Alternatively, if using Azure Service Bus, KEDA has built‑in support.\n",
    "\n",
    "Assuming we have a RabbitMQ host, we can add a scaling rule:\n",
    "\n",
    "```bicep\n",
    "scale: {\n",
    "  minReplicas: 0\n",
    "  maxReplicas: 20\n",
    "  rules: [\n",
    "    {\n",
    "      name: 'rabbitmq-queue'\n",
    "      custom: {\n",
    "        type: 'rabbitmq'\n",
    "        metadata: {\n",
    "          queueName: 'order-created-queue'\n",
    "          host: 'rabbitmq.default.svc.cluster.local:5672' // if in same cluster\n",
    "          protocol: 'amqp'\n",
    "          mode: 'QueueLength'\n",
    "          value: '10' // scale when queue length exceeds 10\n",
    "        }\n",
    "        auth: [\n",
    "          // secrets reference if needed\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "This requires the RabbitMQ scaler to be available in the ACA environment (it is by default, as KEDA is pre‑installed). You also need to provide credentials via secrets.\n",
    "\n",
    "#### 15.3.3 Setting Scaling in the AppHost (Aspire Way)\n",
    "\n",
    "Aspire allows you to add scaling annotations that `azd` can translate into ACA scaling rules. For example:\n",
    "\n",
    "```csharp\n",
    "var workerService = builder.AddProject<Projects.MyAspireApp_WorkerService>(\"workerservice\")\n",
    "    .WithKedaScale(trigger: \"rabbitmq\", metadata: new Dictionary<string, string>\n",
    "    {\n",
    "        [\"queueName\"] = \"order-created-queue\",\n",
    "        [\"host\"] = \"rabbitmq:5672\",\n",
    "        [\"value\"] = \"10\"\n",
    "    });\n",
    "```\n",
    "\n",
    "However, this feature is evolving. Check the latest Aspire documentation for `WithKedaScale` or similar.\n",
    "\n",
    "For now, we'll manually edit the Bicep after `azd` generates it, or we can use `azd` hooks to modify the manifests.\n",
    "\n",
    "---\n",
    "\n",
    "### 15.4 Secrets Management with Azure Key Vault\n",
    "\n",
    "In development, we used parameters and user secrets. In production, we should store secrets in Azure Key Vault and use managed identities to access them. ACA supports both direct secret references and integration with Key Vault via secrets.\n",
    "\n",
    "#### 15.4.1 Creating a Key Vault and Storing Secrets\n",
    "\n",
    "You can add a Key Vault resource to your Bicep:\n",
    "\n",
    "```bicep\n",
    "resource keyVault 'Microsoft.KeyVault/vaults@2022-07-01' = {\n",
    "  name: '${resourceBaseName}-kv'\n",
    "  location: location\n",
    "  properties: {\n",
    "    sku: { name: 'standard' }\n",
    "    tenantId: subscription().tenantId\n",
    "    accessPolicies: [\n",
    "      // Grant access to the managed identity of your Container Apps\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "To grant the Container App access, you need to enable managed identity on the Container App and then set an access policy.\n",
    "\n",
    "#### 15.4.2 Using Managed Identity\n",
    "\n",
    "Each Container App can have a system‑assigned or user‑assigned managed identity. When you enable it, Azure AD creates an identity for the app. You can then grant that identity access to Key Vault.\n",
    "\n",
    "In Bicep:\n",
    "\n",
    "```bicep\n",
    "resource apiService 'Microsoft.App/containerApps@2023-05-01' = {\n",
    "  identity: {\n",
    "    type: 'SystemAssigned'\n",
    "  }\n",
    "  // ...\n",
    "}\n",
    "```\n",
    "\n",
    "Then, in the Key Vault access policies:\n",
    "\n",
    "```bicep\n",
    "resource keyVault 'Microsoft.KeyVault/vaults@2022-07-01' existing = {\n",
    "  name: kvName\n",
    "}\n",
    "\n",
    "resource keyVaultAccessPolicy 'Microsoft.KeyVault/vaults/accessPolicies@2022-07-01' = {\n",
    "  parent: keyVault\n",
    "  name: 'add'\n",
    "  properties: {\n",
    "    accessPolicies: [\n",
    "      {\n",
    "        tenantId: subscription().tenantId\n",
    "        objectId: apiService.identity.principalId\n",
    "        permissions: {\n",
    "          secrets: ['get', 'list']\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "#### 15.4.3 Referencing Secrets in Container Apps\n",
    "\n",
    "In your Container App definition, you can reference secrets from Key Vault either by directly specifying the secret identifier and relying on the app's managed identity, or by pulling them into Container App secrets.\n",
    "\n",
    "The simpler approach is to use **Container App secrets** that are backed by Key Vault. You define a secret in the Container App that references a Key Vault secret, and the system automatically retrieves it.\n",
    "\n",
    "In Bicep:\n",
    "\n",
    "```bicep\n",
    "resource apiService 'Microsoft.App/containerApps@2023-05-01' = {\n",
    "  properties: {\n",
    "    configuration: {\n",
    "      secrets: [\n",
    "        {\n",
    "          name: 'postgres-password'\n",
    "          keyVaultUrl: 'https://myvault.vault.azure.net/secrets/postgres-password'\n",
    "          identity: apiService.identity.principalId // or use a reference to the identity resource\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    template: {\n",
    "      containers: [\n",
    "        {\n",
    "          env: [\n",
    "            {\n",
    "              name: 'ConnectionStrings__productsdb'\n",
    "              secretRef: 'postgres-password' // combine with other parts\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "But you need to build the full connection string. Usually, you'd have the password in Key Vault and the host/username in environment variables. You could store the entire connection string in Key Vault.\n",
    "\n",
    "#### 15.4.4 Passing Secrets to the Application\n",
    "\n",
    "In the application code, you don't need to change anything if you're using the connection string from configuration. The environment variable `ConnectionStrings__productsdb` will contain the full connection string (including password). If the password comes from Key Vault, it will be injected at runtime.\n",
    "\n",
    "---\n",
    "\n",
    "### 15.5 Hands‑on: Production‑Ready Enhancements\n",
    "\n",
    "Now let's apply these concepts to our deployed e‑commerce application.\n",
    "\n",
    "#### Step 1: Add Application Insights\n",
    "\n",
    "1. Add the `Azure.Monitor.OpenTelemetry.Exporter` package to all service projects.\n",
    "2. Modify each `Program.cs` to conditionally use Azure Monitor in production, as described.\n",
    "3. Update the Bicep (or `azd` infra) to include an Application Insights resource.\n",
    "4. Set the environment variable `APPLICATIONINSIGHTS_CONNECTION_STRING` for each Container App, referencing the resource.\n",
    "\n",
    "#### Step 2: Configure Scaling\n",
    "\n",
    "1. In the Bicep for the API service, add an HTTP scaling rule with `concurrentRequests: 50`.\n",
    "2. For the worker, add a KEDA RabbitMQ scaling rule (if you have RabbitMQ). You'll need to ensure the worker has the RabbitMQ connection string as a secret, and that the scaler can access RabbitMQ. Since RabbitMQ is also running in ACA, you can use its internal service name.\n",
    "\n",
    "#### Step 3: Move Secrets to Key Vault\n",
    "\n",
    "1. Add a Key Vault resource to the Bicep.\n",
    "2. Enable system‑assigned managed identity on each Container App.\n",
    "3. Grant those identities `get` and `list` permissions to Key Vault secrets.\n",
    "4. Move the PostgreSQL password and the RabbitMQ password to Key Vault secrets.\n",
    "5. In the Container App configuration, reference these secrets using `keyVaultUrl` and `identity`.\n",
    "6. Update the environment variables to use the secrets.\n",
    "\n",
    "#### Step 4: Redeploy with `azd up`\n",
    "\n",
    "Run `azd up` again. It will update the infrastructure and redeploy the containers.\n",
    "\n",
    "#### Step 5: Verify\n",
    "\n",
    "- Go to Application Insights and see that telemetry is flowing.\n",
    "- Load test the API (e.g., using Apache Bench) to trigger scaling. Watch the replica count increase in the Azure portal.\n",
    "- Ensure the application still works with secrets from Key Vault.\n",
    "\n",
    "---\n",
    "\n",
    "### 15.6 Summary\n",
    "\n",
    "In this chapter, we transformed our development‑focused Aspire application into a production‑ready system. You learned:\n",
    "\n",
    "- How to ship logs, traces, and metrics to Azure Monitor and Application Insights.\n",
    "- How to configure auto‑scaling in Azure Container Apps for both HTTP and event‑driven workloads.\n",
    "- How to manage secrets securely using Azure Key Vault and managed identities.\n",
    "- The importance of observability, scaling, and security as part of Day 2 operations.\n",
    "\n",
    "With these practices, your application is equipped to handle real users, scale on demand, and remain observable. In the final chapter, we’ll look at **Real‑World Project Structure and Best Practices**, including organizing large Aspire solutions, versioning strategies, and CI/CD pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "**Exercises**\n",
    "\n",
    "1. Set up a dashboard in Azure Monitor Workbooks to visualize key metrics (request rate, error rate, queue length).\n",
    "2. Configure an alert rule that sends an email when the error rate exceeds 5% over 5 minutes.\n",
    "3. Implement a health check endpoint that verifies connectivity to the database and Key Vault, and configure ACA to use it for liveness/readiness probes.\n",
    "4. Rotate a secret in Key Vault and verify that the application picks up the new value without restart (if using secret references, it should be dynamic).\n",
    "\n",
    "In Chapter 16, we’ll explore **Real‑World Project Structure and Best Practices** to help you organize and maintain large‑scale Aspire applications."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
