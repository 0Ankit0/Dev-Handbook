{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 8: Storage and Blobs\n",
    "\n",
    "In our e\u2011commerce application, we\u2019ve built services for products, orders, and messaging. But every modern web application also needs to handle **files**\u2014product images, user avatars, receipts, etc. Storing files in a database or on the local file system is not scalable or resilient. Instead, we use **blob storage**, a service optimized for storing large amounts of unstructured data.\n",
    "\n",
    "Azure Blob Storage is a cloud\u2011scale object store that integrates seamlessly with .NET. With .NET Aspire, adding blob storage to your application is as simple as adding a component and defining a resource in the AppHost. In this chapter, you\u2019ll learn how to:\n",
    "\n",
    "- Model Azure Storage (blobs, queues, tables) in the AppHost.\n",
    "- Use the `Aspire.Azure.Storage.Blobs` component to upload and download files.\n",
    "- Run the Azurite emulator locally for development.\n",
    "- Implement product image upload in your API and display images in the web frontend.\n",
    "- Generate shared access signatures (SAS) for secure, time\u2011limited access.\n",
    "\n",
    "By the end, your e\u2011commerce site will support product images stored in the cloud.\n",
    "\n",
    "---\n",
    "\n",
    "### 8.1 Why Blob Storage?\n",
    "\n",
    "Traditional approaches to file storage include:\n",
    "\n",
    "- **Database BLOB columns**: Stores files in the database. This increases database size, backup time, and can hurt performance.\n",
    "- **Local file system**: Not scalable across multiple instances, and data can be lost if the instance is replaced.\n",
    "- **Network attached storage (NAS)**: Complex and still a single point of failure.\n",
    "\n",
    "Azure Blob Storage solves these problems by providing:\n",
    "\n",
    "- **High durability and availability** (replicated across regions).\n",
    "- **Scalability** to petabytes.\n",
    "- **Access control** via shared access signatures (SAS) or Azure AD.\n",
    "- **Integration with CDN** for fast global delivery.\n",
    "- **Cost\u2011effectiveness** with tiered storage (hot, cool, archive).\n",
    "\n",
    "In a microservices architecture, blob storage is often used as a central repository for files that multiple services need to access.\n",
    "\n",
    "---\n",
    "\n",
    "### 8.2 .NET Aspire Storage Components\n",
    "\n",
    "Aspire provides components for Azure Storage services:\n",
    "\n",
    "- **`Aspire.Azure.Storage.Blobs`**: for working with blob containers and blobs.\n",
    "- **`Aspire.Azure.Storage.Queues`**: for working with Azure Queue Storage (a simple message queue).\n",
    "- **`Aspire.Azure.Storage.Tables`**: for working with Azure Table Storage (NoSQL key\u2011value store).\n",
    "\n",
    "These components register the appropriate SDK clients (`BlobServiceClient`, `QueueServiceClient`, `TableServiceClient`) and add health checks, logging, and distributed tracing.\n",
    "\n",
    "For local development, you can use the **Azurite** emulator, which runs in a Docker container and simulates Azure Storage APIs. The Aspire hosting package makes it trivial to add Azurite to your AppHost.\n",
    "\n",
    "---\n",
    "\n",
    "### 8.3 Adding Azure Storage to the AppHost\n",
    "\n",
    "First, install the hosting package for Azure Storage:\n",
    "\n",
    "```bash\n",
    "cd MyAspireApp.AppHost\n",
    "dotnet add package Aspire.Hosting.Azure.Storage\n",
    "```\n",
    "\n",
    "Now in `Program.cs`, you can add an Azure Storage resource. To use the Azurite emulator locally, call `RunAsEmulator()`:\n",
    "\n",
    "```csharp\n",
    "var storage = builder.AddAzureStorage(\"storage\")\n",
    "    .RunAsEmulator();  // Runs Azurite container\n",
    "```\n",
    "\n",
    "From this storage resource, you can create child resources for blobs, queues, and tables:\n",
    "\n",
    "```csharp\n",
    "var blobs = storage.AddBlobs(\"productimages\");\n",
    "var queues = storage.AddQueues(\"orderimagesqueue\");\n",
    "```\n",
    "\n",
    "Now reference these from your services. For example, the API service will need to upload images, so give it a reference to the blobs:\n",
    "\n",
    "```csharp\n",
    "var apiService = builder.AddProject<Projects.MyAspireApp_ApiService>(\"apiservice\")\n",
    "    .WithReference(blobs)   // injects connection string for blobs\n",
    "    .WithReference(productsDb)\n",
    "    .WithReference(messaging)\n",
    "    .WithReference(appConfig);\n",
    "```\n",
    "\n",
    "The connection string will be injected as `ConnectionStrings__productimages`. If you\u2019re using the emulator, the connection string points to the local Azurite instance.\n",
    "\n",
    "If you want to use a real Azure Storage account in development, you can omit `RunAsEmulator()` and provide a connection string via a parameter:\n",
    "\n",
    "```csharp\n",
    "var storageConnectionString = builder.AddParameter(\"storage-connectionstring\", secret: true);\n",
    "var storage = builder.AddAzureStorage(\"storage\")\n",
    "    .WithConnectionString(storageConnectionString);\n",
    "```\n",
    "\n",
    "Then store the connection string in user secrets or environment variables.\n",
    "\n",
    "---\n",
    "\n",
    "### 8.4 Using the Blob Storage Component in the API Service\n",
    "\n",
    "In the API service project, add the client component:\n",
    "\n",
    "```bash\n",
    "cd ../MyAspireApp.ApiService\n",
    "dotnet add package Aspire.Azure.Storage.Blobs\n",
    "```\n",
    "\n",
    "In `Program.cs`, register the blob client:\n",
    "\n",
    "```csharp\n",
    "builder.AddAzureBlobClient(\"productimages\");\n",
    "```\n",
    "\n",
    "This registers `BlobServiceClient` in DI, configured with the connection string from `ConnectionStrings:productimages`.\n",
    "\n",
    "#### 8.4.1 Creating a Container\n",
    "\n",
    "Before uploading blobs, you need a container. Typically, you\u2019d create it on startup if it doesn\u2019t exist. Add the following after `app.Build()` but before `app.Run()`:\n",
    "\n",
    "```csharp\n",
    "using Azure.Storage.Blobs;\n",
    "\n",
    "var blobServiceClient = app.Services.GetRequiredService<BlobServiceClient>();\n",
    "var containerClient = blobServiceClient.GetBlobContainerClient(\"product-images\");\n",
    "await containerClient.CreateIfNotExistsAsync();\n",
    "```\n",
    "\n",
    "This ensures the container exists. In production, you might create containers manually or via infrastructure as code, but for development this is convenient.\n",
    "\n",
    "#### 8.4.2 Upload Endpoint\n",
    "\n",
    "Now let\u2019s create an endpoint to upload an image for a product. We\u2019ll assume the product ID is provided and the image file is sent as `multipart/form-data`.\n",
    "\n",
    "Add the necessary using statements and an endpoint in `Program.cs`:\n",
    "\n",
    "```csharp\n",
    "using Azure.Storage.Blobs;\n",
    "using Azure.Storage.Blobs.Models;\n",
    "\n",
    "app.MapPost(\"/products/{productId}/image\", async (int productId, IFormFile file, BlobServiceClient blobServiceClient) =>\n",
    "{\n",
    "    if (file == null || file.Length == 0)\n",
    "        return Results.BadRequest(\"No file uploaded.\");\n",
    "\n",
    "    // Allowed file types (e.g., images only)\n",
    "    var allowedExtensions = new[] { \".jpg\", \".jpeg\", \".png\", \".gif\" };\n",
    "    var extension = Path.GetExtension(file.FileName).ToLowerInvariant();\n",
    "    if (!allowedExtensions.Contains(extension))\n",
    "        return Results.BadRequest(\"Invalid file type.\");\n",
    "\n",
    "    // Generate a unique blob name (could include product ID and a GUID to avoid collisions)\n",
    "    var blobName = $\"{productId}/{Guid.NewGuid():N}{extension}\";\n",
    "    var containerClient = blobServiceClient.GetBlobContainerClient(\"product-images\");\n",
    "    var blobClient = containerClient.GetBlobClient(blobName);\n",
    "\n",
    "    // Upload the file\n",
    "    using var stream = file.OpenReadStream();\n",
    "    await blobClient.UploadAsync(stream, new BlobUploadOptions\n",
    "    {\n",
    "        HttpHeaders = new BlobHttpHeaders { ContentType = file.ContentType }\n",
    "    });\n",
    "\n",
    "    // Store the blob URI in the product record (you'd update the product in the database)\n",
    "    // For simplicity, we'll just return the URL.\n",
    "    var blobUrl = blobClient.Uri.ToString();\n",
    "    return Results.Ok(new { ImageUrl = blobUrl });\n",
    "})\n",
    ".WithName(\"UploadProductImage\")\n",
    ".Accepts<IFormFile>(\"multipart/form-data\")\n",
    ".Produces(200);\n",
    "```\n",
    "\n",
    "This endpoint:\n",
    "\n",
    "- Validates the file presence and type.\n",
    "- Generates a blob name that includes the product ID and a unique identifier.\n",
    "- Uploads the file to the container with the appropriate content type.\n",
    "- Returns the URL of the uploaded blob.\n",
    "\n",
    "In a real application, you\u2019d also update the product record in the database with this URL (or store it in a separate product\u2011images table). For now, we\u2019ll just return the URL.\n",
    "\n",
    "#### 8.4.3 Serving Images\n",
    "\n",
    "The blob URL returned from Azure Storage (or Azurite) is publicly accessible if the container allows anonymous access. For security, you might want to keep containers private and generate SAS URLs. We\u2019ll cover that later.\n",
    "\n",
    "To test, you can run the app and use a tool like Postman or a simple HTML form to upload an image.\n",
    "\n",
    "---\n",
    "\n",
    "### 8.5 Displaying Images in the Web Frontend\n",
    "\n",
    "In the web frontend, we need to display product images. First, let\u2019s modify the product model to include an image URL. Since we don\u2019t have a full product catalog yet, we\u2019ll assume the product data comes from the API.\n",
    "\n",
    "Update the `Product` class in the web frontend (or shared contracts) to have an `ImageUrl` property. Then, when fetching products, the API should include the image URL. For simplicity, we\u2019ll just show an image after upload.\n",
    "\n",
    "Create a simple Razor page in the web frontend to upload and display an image. In `Components/Pages/UploadImage.razor`:\n",
    "\n",
    "```razor\n",
    "@page \"/upload-image/{productId:int}\"\n",
    "@inject HttpClient Http\n",
    "@inject IConfiguration Config\n",
    "\n",
    "<h3>Upload Image for Product @ProductId</h3>\n",
    "\n",
    "<InputFile OnChange=\"OnFileSelected\" />\n",
    "<button @onclick=\"UploadFile\" disabled=\"@(selectedFile == null)\">Upload</button>\n",
    "\n",
    "@if (!string.IsNullOrEmpty(imageUrl))\n",
    "{\n",
    "    <div>\n",
    "        <h4>Uploaded Image:</h4>\n",
    "        <img src=\"@imageUrl\" style=\"max-width: 300px;\" />\n",
    "    </div>\n",
    "}\n",
    "\n",
    "@code {\n",
    "    [Parameter] public int ProductId { get; set; }\n",
    "\n",
    "    private IBrowserFile? selectedFile;\n",
    "    private string? imageUrl;\n",
    "\n",
    "    private void OnFileSelected(InputFileChangeEventArgs e)\n",
    "    {\n",
    "        selectedFile = e.File;\n",
    "    }\n",
    "\n",
    "    private async Task UploadFile()\n",
    "    {\n",
    "        if (selectedFile == null) return;\n",
    "\n",
    "        using var content = new MultipartFormDataContent();\n",
    "        using var fileStream = selectedFile.OpenReadStream(maxAllowedSize: 10 * 1024 * 1024); // 10 MB limit\n",
    "        var streamContent = new StreamContent(fileStream);\n",
    "        content.Add(streamContent, \"file\", selectedFile.Name);\n",
    "\n",
    "        var response = await Http.PostAsync($\"/products/{ProductId}/image\", content);\n",
    "        if (response.IsSuccessStatusCode)\n",
    "        {\n",
    "            var result = await response.Content.ReadFromJsonAsync<UploadResponse>();\n",
    "            imageUrl = result?.ImageUrl;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    private class UploadResponse\n",
    "    {\n",
    "        public string ImageUrl { get; set; } = string.Empty;\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Add a navigation link to this page.\n",
    "\n",
    "Now run the application, navigate to `/upload-image/1` (assuming product ID 1 exists), select an image, and upload. You should see the image displayed.\n",
    "\n",
    "---\n",
    "\n",
    "### 8.6 Using the Azurite Emulator\n",
    "\n",
    "When you added `.RunAsEmulator()` in the AppHost, Aspire automatically starts an Azurite container. Azurite provides blob, queue, and table services on local ports. You can verify it's running by looking at the dashboard\u2014you\u2019ll see a resource named `storage` with child `productimages` (blobs). Clicking on the endpoint will show the Azurite URL (e.g., `http://localhost:10000/devstoreaccount1`).\n",
    "\n",
    "Azurite persists data in a Docker volume by default, so blobs survive container restarts. If you want to reset, you can remove the volume.\n",
    "\n",
    "The connection string injected into your service points to this emulator. It looks like:\n",
    "\n",
    "```\n",
    "DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://127.0.0.1:10000/devstoreaccount1;\n",
    "```\n",
    "\n",
    "This is automatically generated by Aspire.\n",
    "\n",
    "---\n",
    "\n",
    "### 8.7 Generating Shared Access Signatures (SAS)\n",
    "\n",
    "In many scenarios, you don\u2019t want your blobs to be publicly readable. Instead, you generate temporary, limited\u2011permission URLs called **Shared Access Signatures (SAS)**. For example, you might generate a URL that allows reading a specific blob for the next 5 minutes.\n",
    "\n",
    "To generate a SAS token, you need access to the storage account key or use Azure AD authentication. With the `BlobServiceClient`, you can generate a SAS for a blob:\n",
    "\n",
    "```csharp\n",
    "public static string GenerateSasUri(BlobClient blobClient, DateTimeOffset expiresOn)\n",
    "{\n",
    "    // Create a user delegation key if using Azure AD, or use account key SAS.\n",
    "    // Here we use account key SAS for simplicity.\n",
    "    var sasBuilder = new BlobSasBuilder\n",
    "    {\n",
    "        BlobContainerName = blobClient.BlobContainerName,\n",
    "        BlobName = blobClient.Name,\n",
    "        Resource = \"b\", // b for blob\n",
    "        ExpiresOn = expiresOn\n",
    "    };\n",
    "    sasBuilder.SetPermissions(BlobSasPermissions.Read);\n",
    "\n",
    "    // Generate the SAS URI\n",
    "    Uri sasUri = blobClient.GenerateSasUri(sasBuilder);\n",
    "    return sasUri.ToString();\n",
    "}\n",
    "```\n",
    "\n",
    "To use this, you need the storage account key. In the emulator, the key is well\u2011known; in production, you\u2019d store it securely (e.g., in Key Vault). With Aspire, you can inject the connection string and extract the account key and name.\n",
    "\n",
    "For a more secure approach, use **user delegation SAS** which requires Azure AD and does not expose the account key. But that\u2019s beyond this chapter.\n",
    "\n",
    "You can modify the upload endpoint to return a SAS URL instead of the public URL. But note: if the container is private, the public URL won't work; you must use SAS. So in a production setup, you'd typically return a SAS URL for immediate access, and perhaps store the blob path in the database.\n",
    "\n",
    "---\n",
    "\n",
    "### 8.8 Advanced: Image Processing with Queues\n",
    "\n",
    "Often, after uploading an image, you want to perform processing\u2014resize, generate thumbnails, extract metadata. This is a perfect job for a background worker. You can use Azure Queue Storage (or Service Bus) to trigger processing.\n",
    "\n",
    "Add a queue to the AppHost:\n",
    "\n",
    "```csharp\n",
    "var queues = storage.AddQueues(\"imageprocessing\");\n",
    "```\n",
    "\n",
    "Reference it from the API and a new worker service.\n",
    "\n",
    "In the API, after uploading the blob, enqueue a message with the blob name and product ID:\n",
    "\n",
    "```csharp\n",
    "var queueClient = new QueueClient(storageConnectionString, \"imageprocessing\");\n",
    "await queueClient.SendMessageAsync(JsonSerializer.Serialize(new { BlobName = blobName, ProductId = productId }));\n",
    "```\n",
    "\n",
    "Then create a worker service that listens to the queue, processes the image (e.g., using SixLabors.ImageSharp), and uploads a thumbnail to another container.\n",
    "\n",
    "This demonstrates the power of combining blob storage with messaging.\n",
    "\n",
    "---\n",
    "\n",
    "### 8.9 Hands\u2011on: Add Product Images to Your E\u2011Commerce App\n",
    "\n",
    "Let's extend our application with a complete product image feature.\n",
    "\n",
    "**Step 1: Update the AppHost** as shown above (add storage with emulator, blobs, and optionally queues).\n",
    "\n",
    "**Step 2: Add the blob component to ApiService** and create the upload endpoint.\n",
    "\n",
    "**Step 3: Add a simple product list page in the web frontend** that shows product images. For that, you'll need to modify the API to return product data including image URL. Store the image URL in the database when uploading.\n",
    "\n",
    "To keep the database updated, after successful upload, update the product record:\n",
    "\n",
    "```csharp\n",
    "// Inside the upload endpoint, after upload, update the product\n",
    "using var dbConnection = await dataSource.OpenConnectionAsync();\n",
    "await dbConnection.ExecuteAsync(\n",
    "    \"UPDATE Products SET ImageUrl = @ImageUrl WHERE Id = @ProductId\",\n",
    "    new { ImageUrl = blobUrl, ProductId = productId });\n",
    "```\n",
    "\n",
    "Now when fetching products, the API can return the image URL.\n",
    "\n",
    "**Step 4: Create a product list page** in the web frontend that calls `GET /products` and displays images.\n",
    "\n",
    "**Step 5: (Optional) Add a thumbnail generation worker** using queues and the `Aspose.Azure.Storage.Queues` component.\n",
    "\n",
    "---\n",
    "\n",
    "### 8.10 Summary\n",
    "\n",
    "In this chapter, you learned how to integrate Azure Blob Storage into your Aspire application:\n",
    "\n",
    "- **Azure Storage hosting packages** let you add storage resources and run Azurite locally.\n",
    "- **Blob components** register `BlobServiceClient` and add health checks, telemetry.\n",
    "- You implemented file upload and download, using both public and SAS URLs.\n",
    "- You saw how to combine blobs with queues for background processing.\n",
    "\n",
    "With product images, your e\u2011commerce site becomes much more realistic. In the next chapter, we\u2019ll dive into **Advanced Orchestration and Patterns**, exploring custom resources, lifecycle hooks, and more sophisticated service discovery. You\u2019ll learn how to extend Aspire\u2019s orchestration to meet complex requirements.\n",
    "\n",
    "---\n",
    "\n",
    "**Exercises**\n",
    "\n",
    "1. Modify the upload endpoint to generate a SAS URL valid for 24 hours and return that instead of the public URL. Test that the SAS URL works when the container is private.\n",
    "2. Add a second blob container for storing product thumbnails. Create a background worker (using a new project) that listens to a queue and generates a thumbnail for each uploaded image, then stores it in the thumbnails container.\n",
    "3. Explore the Azurite emulator\u2019s data volume. Locate the volume used by Aspire and inspect the stored blobs.\n",
    "4. In the web frontend, add an image gallery for a product that shows multiple images (modify the database to allow multiple images per product).\n",
    "\n",
    "In Chapter 9, we\u2019ll explore **Advanced Orchestration and Patterns** to take your Aspire skills to the next level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='7. externalizing_configuration_with_aspire.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='../3. advanced_orchestration_and_patterns/9. custom_resources_and_lifecycle_hooks.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}