{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc338f99",
   "metadata": {},
   "source": [
    "# **Chapter 47: Project 4 - Streaming/Media App**\n",
    "\n",
    "---\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Architect a media streaming application with proper lifecycle management for video/audio playback\n",
    "- Implement video playback using `video_player` and `chewie` with custom controls and error handling\n",
    "- Configure background audio playback with lock screen controls, metadata, and remote command center integration\n",
    "- Implement DRM (Digital Rights Management) using Widevine (Android) and FairPlay (iOS) for content protection\n",
    "- Support adaptive bitrate streaming (HLS for iOS, DASH for Android) for optimal quality across network conditions\n",
    "- Integrate casting protocols (Chromecast via Google Cast SDK, AirPlay via AVRoutePickerView)\n",
    "- Implement Picture-in-Picture (PiP) mode for multitasking during playback\n",
    "- Manage media downloads for offline viewing with encrypted storage\n",
    "\n",
    "---\n",
    "\n",
    "## **Prerequisites**\n",
    "\n",
    "- Completed Chapter 46: Project 3 - Productivity/Task Management App (complex state management)\n",
    "- Completed Chapter 38: Plugin Development (understanding of platform channels for DRM/casting)\n",
    "- Understanding of video codecs (H.264, H.265/HEVC) and container formats (MP4, MKV, HLS, DASH)\n",
    "- Familiarity with media streaming concepts (bitrate, resolution, buffering)\n",
    "- Apple Developer account (for FairPlay DRM testing on iOS)\n",
    "- Google Cast SDK registration (for Chromecast integration)\n",
    "\n",
    "---\n",
    "\n",
    "## **47.1 Architecture Overview**\n",
    "\n",
    "Media apps require careful lifecycle management due to the heavy resource usage of video decoders and the complexity of background audio sessions.\n",
    "\n",
    "### **Architecture Pattern: BLoC with Player Service**\n",
    "\n",
    "```\n",
    "lib/\n",
    "\u251c\u2500\u2500 core/\n",
    "\u2502   \u2514\u2500\u2500 player/\n",
    "\u2502       \u251c\u2500\u2500 media_player_service.dart      # Singleton managing native players\n",
    "\u2502       \u251c\u2500\u2500 player_bloc.dart               # State: playing, paused, buffering, error\n",
    "\u2502       \u2514\u2500\u2500 player_controls.dart           # UI components\n",
    "\u251c\u2500\u2500 features/\n",
    "\u2502   \u251c\u2500\u2500 video_player/\n",
    "\u2502   \u2502   \u251c\u2500\u2500 presentation/\n",
    "\u2502   \u2502   \u2502   \u251c\u2500\u2500 video_screen.dart        # Full-screen video UI\n",
    "\u2502   \u2502   \u2502   \u2514\u2500\u2500 pip_manager.dart         # Picture-in-Picture\n",
    "\u2502   \u2502   \u2514\u2500\u2500 logic/\n",
    "\u2502   \u2502       \u2514\u2500\u2500 video_bloc.dart\n",
    "\u2502   \u251c\u2500\u2500 audio_player/\n",
    "\u2502   \u2502   \u251c\u2500\u2500 service/\n",
    "\u2502   \u2502   \u2502   \u2514\u2500\u2500 audio_handler.dart       # audio_service implementation\n",
    "\u2502   \u2502   \u2514\u2500\u2500 presentation/\n",
    "\u2502   \u2502       \u2514\u2500\u2500 mini_player.dart          # Persistent bottom player\n",
    "\u2502   \u2514\u2500\u2500 downloads/\n",
    "\u2502       \u251c\u2500\u2500 data/\n",
    "\u2502       \u2502   \u2514\u2500\u2500 download_manager.dart      # DRM-aware downloads\n",
    "\u2502       \u2514\u2500\u2500 encryption/\n",
    "\u2514\u2500\u2500 platform/\n",
    "    \u2514\u2500\u2500 drm/\n",
    "        \u251c\u2500\u2500 widevine_manager.dart         # Android DRM\n",
    "        \u2514\u2500\u2500 fairplay_manager.dart         # iOS DRM\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **Media Player Service**: A singleton that wraps the native `VideoPlayerController` and `AudioPlayer`. Ensures only one media item plays at a time and manages system audio focus.\n",
    "- **Audio Handler**: Required for background audio. Implements `BaseAudioHandler` from `audio_service` to provide metadata to the system (lock screen, CarPlay, Android Auto).\n",
    "- **DRM Managers**: Platform-specific implementations using MethodChannels to access native DRM APIs (ExoPlayer for Android, AVPlayer for iOS).\n",
    "\n",
    "---\n",
    "\n",
    "## **47.2 Video Playback Implementation**\n",
    "\n",
    "Using `video_player` for low-level control and `chewie` for UI, or building custom controls for branded experiences.\n",
    "\n",
    "### **Basic Video Player Setup**\n",
    "\n",
    "```dart\n",
    "// lib/core/player/media_player_service.dart\n",
    "import 'package:video_player/video_player.dart';\n",
    "import 'package:flutter/services.dart';\n",
    "\n",
    "@singleton\n",
    "class MediaPlayerService {\n",
    "  VideoPlayerController? _videoController;\n",
    "  final StreamController<PlayerState> _stateController = StreamController.broadcast();\n",
    "  \n",
    "  Stream<PlayerState> get stateStream => _stateController.stream;\n",
    "  VideoPlayerController? get controller => _videoController;\n",
    "\n",
    "  Future<void> initializeVideo({\n",
    "    required String url,\n",
    "    Map<String, String>? headers,\n",
    "    bool autoPlay = false,\n",
    "  }) async {\n",
    "    // Dispose previous controller to free resources\n",
    "    await _videoController?.dispose();\n",
    "    \n",
    "    // Create new controller based on URL type\n",
    "    if (url.contains('.m3u8')) {\n",
    "      // HLS streaming\n",
    "      _videoController = VideoPlayerController.network(\n",
    "        url,\n",
    "        formatHint: VideoFormat.hls,\n",
    "        httpHeaders: headers ?? {},\n",
    "      );\n",
    "    } else if (url.contains('.mpd')) {\n",
    "      // DASH streaming (Android only)\n",
    "      _videoController = VideoPlayerController.network(\n",
    "        url,\n",
    "        formatHint: VideoFormat.dash,\n",
    "        httpHeaders: headers ?? {},\n",
    "      );\n",
    "    } else {\n",
    "      // Progressive download (MP4)\n",
    "      _videoController = VideoPlayerController.network(url);\n",
    "    }\n",
    "\n",
    "    // Initialize and setup listeners\n",
    "    await _videoController!.initialize();\n",
    "    \n",
    "    _videoController!.addListener(_onPlayerStateChanged);\n",
    "    \n",
    "    if (autoPlay) {\n",
    "      await play();\n",
    "    }\n",
    "    \n",
    "    _stateController.add(PlayerState.ready);\n",
    "  }\n",
    "\n",
    "  void _onPlayerStateChanged() {\n",
    "    if (_videoController == null) return;\n",
    "    \n",
    "    final value = _videoController!.value;\n",
    "    \n",
    "    if (value.isBuffering) {\n",
    "      _stateController.add(PlayerState.buffering);\n",
    "    } else if (value.isPlaying) {\n",
    "      _stateController.add(PlayerState.playing);\n",
    "    } else if (value.position >= value.duration) {\n",
    "      _stateController.add(PlayerState.completed);\n",
    "    } else {\n",
    "      _stateController.add(PlayerState.paused);\n",
    "    }\n",
    "    \n",
    "    // Handle errors\n",
    "    if (value.hasError) {\n",
    "      _stateController.add(PlayerState.error(value.errorDescription));\n",
    "    }\n",
    "  }\n",
    "\n",
    "  Future<void> play() async {\n",
    "    await _videoController?.play();\n",
    "    // Request audio focus\n",
    "    await _setAudioFocus();\n",
    "  }\n",
    "\n",
    "  Future<void> pause() async {\n",
    "    await _videoController?.pause();\n",
    "  }\n",
    "\n",
    "  Future<void> seekTo(Duration position) async {\n",
    "    await _videoController?.seekTo(position);\n",
    "  }\n",
    "\n",
    "  Future<void> setPlaybackSpeed(double speed) async {\n",
    "    await _videoController?.setPlaybackSpeed(speed);\n",
    "  }\n",
    "\n",
    "  Future<void> dispose() async {\n",
    "    await _videoController?.dispose();\n",
    "    _videoController = null;\n",
    "    await _stateController.close();\n",
    "  }\n",
    "\n",
    "  Future<void> _setAudioFocus() async {\n",
    "    // Configure audio session for video playback\n",
    "    final session = await AudioSession.instance;\n",
    "    await session.configure(const AudioSessionConfiguration(\n",
    "      avAudioSessionCategory: AVAudioSessionCategory.playback,\n",
    "      avAudioSessionMode: AVAudioSessionMode.moviePlayback,\n",
    "    ));\n",
    "    await session.setActive(true);\n",
    "  }\n",
    "}\n",
    "\n",
    "enum PlayerState {\n",
    "  idle,\n",
    "  ready,\n",
    "  playing,\n",
    "  paused,\n",
    "  buffering,\n",
    "  completed,\n",
    "  error(String? message);\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **Format Hints**: Explicitly setting `VideoFormat.hls` or `VideoFormat.dash` helps the underlying native player (ExoPlayer on Android, AVPlayer on iOS) choose the correct demuxer.\n",
    "- **Resource Management**: Always `dispose()` the previous controller before creating a new one. Video decoders are hardware-accelerated and consume significant GPU/CPU resources.\n",
    "- **Audio Session**: Configures the system audio focus. Prevents the video from being silent when the device is on silent mode (critical for user experience).\n",
    "\n",
    "### **Custom Video Controls**\n",
    "\n",
    "```dart\n",
    "// lib/features/video_player/presentation/widgets/custom_controls.dart\n",
    "class CustomVideoControls extends StatelessWidget {\n",
    "  final VideoPlayerController controller;\n",
    "  final VoidCallback onCast;\n",
    "  final VoidCallback onEnterPip;\n",
    "\n",
    "  const CustomVideoControls({\n",
    "    super.key,\n",
    "    required this.controller,\n",
    "    required this.onCast,\n",
    "    required this.onEnterPip,\n",
    "  });\n",
    "\n",
    "  @override\n",
    "  Widget build(BuildContext context) {\n",
    "    return ValueListenableBuilder<VideoPlayerValue>(\n",
    "      valueListenable: controller,\n",
    "      builder: (context, value, child) {\n",
    "        return Stack(\n",
    "          children: [\n",
    "            // Gradient overlay for visibility\n",
    "            Positioned(\n",
    "              bottom: 0,\n",
    "              left: 0,\n",
    "              right: 0,\n",
    "              child: Container(\n",
    "                height: 80,\n",
    "                decoration: BoxDecoration(\n",
    "                  gradient: LinearGradient(\n",
    "                    begin: Alignment.topCenter,\n",
    "                    end: Alignment.bottomCenter,\n",
    "                    colors: [\n",
    "                      Colors.transparent,\n",
    "                      Colors.black.withOpacity(0.7),\n",
    "                    ],\n",
    "                  ),\n",
    "                ),\n",
    "              ),\n",
    "            ),\n",
    "            \n",
    "            // Controls\n",
    "            Positioned(\n",
    "              bottom: 0,\n",
    "              left: 0,\n",
    "              right: 0,\n",
    "              child: Row(\n",
    "                children: [\n",
    "                  // Play/Pause\n",
    "                  IconButton(\n",
    "                    icon: Icon(\n",
    "                      value.isPlaying ? Icons.pause : Icons.play_arrow,\n",
    "                      color: Colors.white,\n",
    "                    ),\n",
    "                    onPressed: () {\n",
    "                      value.isPlaying ? controller.pause() : controller.play();\n",
    "                    },\n",
    "                  ),\n",
    "                  \n",
    "                  // Progress bar\n",
    "                  Expanded(\n",
    "                    child: VideoProgressIndicator(\n",
    "                      controller,\n",
    "                      allowScrubbing: true,\n",
    "                      colors: const VideoProgressColors(\n",
    "                        playedColor: Colors.red,\n",
    "                        bufferedColor: Colors.grey,\n",
    "                        backgroundColor: Colors.white24,\n",
    "                      ),\n",
    "                    ),\n",
    "                  ),\n",
    "                  \n",
    "                  // Duration\n",
    "                  Text(\n",
    "                    '${_formatDuration(value.position)} / ${_formatDuration(value.duration)}',\n",
    "                    style: const TextStyle(color: Colors.white),\n",
    "                  ),\n",
    "                  \n",
    "                  // Cast button\n",
    "                  IconButton(\n",
    "                    icon: const Icon(Icons.cast, color: Colors.white),\n",
    "                    onPressed: onCast,\n",
    "                  ),\n",
    "                  \n",
    "                  // PiP button (iPad/Android tablets)\n",
    "                  if (Platform.isIOS || Platform.isAndroid)\n",
    "                    IconButton(\n",
    "                      icon: const Icon(Icons.picture_in_picture, color: Colors.white),\n",
    "                      onPressed: onEnterPip,\n",
    "                    ),\n",
    "                  \n",
    "                  // Fullscreen toggle\n",
    "                  IconButton(\n",
    "                    icon: const Icon(Icons.fullscreen, color: Colors.white),\n",
    "                    onPressed: () {\n",
    "                      // Toggle orientation or enter immersive mode\n",
    "                      _toggleFullscreen(context);\n",
    "                    },\n",
    "                  ),\n",
    "                ],\n",
    "              ),\n",
    "            ),\n",
    "            \n",
    "            // Buffering indicator\n",
    "            if (value.isBuffering)\n",
    "              const Center(\n",
    "                child: CircularProgressIndicator(),\n",
    "              ),\n",
    "          ],\n",
    "        );\n",
    "      },\n",
    "    );\n",
    "  }\n",
    "\n",
    "  String _formatDuration(Duration duration) {\n",
    "    String twoDigits(int n) => n.toString().padLeft(2, '0');\n",
    "    final hours = twoDigits(duration.inHours);\n",
    "    final minutes = twoDigits(duration.inMinutes.remainder(60));\n",
    "    final seconds = twoDigits(duration.inSeconds.remainder(60));\n",
    "    \n",
    "    return duration.inHours > 0 \n",
    "        ? '$hours:$minutes:$seconds' \n",
    "        : '$minutes:$seconds';\n",
    "  }\n",
    "\n",
    "  void _toggleFullscreen(BuildContext context) {\n",
    "    if (MediaQuery.of(context).orientation == Orientation.portrait) {\n",
    "      SystemChrome.setPreferredOrientations([\n",
    "        DeviceOrientation.landscapeLeft,\n",
    "        DeviceOrientation.landscapeRight,\n",
    "      ]);\n",
    "      SystemChrome.setEnabledSystemUIMode(SystemUiMode.immersiveSticky);\n",
    "    } else {\n",
    "      SystemChrome.setPreferredOrientations([DeviceOrientation.portraitUp]);\n",
    "      SystemChrome.setEnabledSystemUIMode(SystemUiMode.edgeToEdge);\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **ValueListenableBuilder**: Efficiently rebuilds only when the video player state changes (position, buffering status, etc.).\n",
    "- **Immersive Mode**: Hides system UI (status bar, navigation) during fullscreen video playback.\n",
    "- **Scrubbing**: `VideoProgressIndicator` with `allowScrubbing: true` enables drag-to-seek functionality.\n",
    "- **Orientation Management**: Programmatically forcing landscape for fullscreen video is standard UX for media apps.\n",
    "\n",
    "---\n",
    "\n",
    "## **47.3 Background Audio Playback**\n",
    "\n",
    "For music or podcast features, implement background audio with lock screen controls using `audio_service` and `just_audio`.\n",
    "\n",
    "```dart\n",
    "// lib/features/audio_player/service/audio_handler.dart\n",
    "import 'package:audio_service/audio_service.dart';\n",
    "import 'package:just_audio/just_audio.dart';\n",
    "\n",
    "class AudioPlayerHandler extends BaseAudioHandler with QueueHandler, SeekHandler {\n",
    "  final _player = AudioPlayer();\n",
    "  final _playlist = ConcatenatingAudioSource(children: []);\n",
    "\n",
    "  AudioPlayerHandler() {\n",
    "    _init();\n",
    "  }\n",
    "\n",
    "  Future<void> _init() async {\n",
    "    // Load empty playlist\n",
    "    await _player.setAudioSource(_playlist);\n",
    "    \n",
    "    // Propagate player events to audio_service\n",
    "    _player.playbackEventStream.map(_transformEvent).pipe(playbackState);\n",
    "    \n",
    "    // Handle media item changes\n",
    "    _player.currentIndexStream.listen((index) {\n",
    "      if (index != null && index < queue.value.length) {\n",
    "        mediaItem.add(queue.value[index]);\n",
    "      }\n",
    "    });\n",
    "  }\n",
    "\n",
    "  PlaybackState _transformEvent(PlaybackEvent event) {\n",
    "    return PlaybackState(\n",
    "      controls: [\n",
    "        MediaControl.skipToPrevious,\n",
    "        if (_player.playing) MediaControl.pause else MediaControl.play,\n",
    "        MediaControl.stop,\n",
    "        MediaControl.skipToNext,\n",
    "      ],\n",
    "      systemActions: const {\n",
    "        MediaAction.seek,\n",
    "        MediaAction.seekForward,\n",
    "        MediaAction.seekBackward,\n",
    "      },\n",
    "      androidCompactActionIndices: const [0, 1, 3],\n",
    "      processingState: const {\n",
    "        ProcessingState.idle: AudioProcessingState.idle,\n",
    "        ProcessingState.loading: AudioProcessingState.loading,\n",
    "        ProcessingState.buffering: AudioProcessingState.buffering,\n",
    "        ProcessingState.ready: AudioProcessingState.ready,\n",
    "        ProcessingState.completed: AudioProcessingState.completed,\n",
    "      }[_player.processingState]!,\n",
    "      playing: _player.playing,\n",
    "      updatePosition: _player.position,\n",
    "      bufferedPosition: _player.bufferedPosition,\n",
    "      speed: _player.speed,\n",
    "      queueIndex: _player.currentIndex,\n",
    "    );\n",
    "  }\n",
    "\n",
    "  Future<void> addQueueItem(MediaItem mediaItem) async {\n",
    "    final audioSource = AudioSource.uri(\n",
    "      Uri.parse(mediaItem.extras!['url']),\n",
    "      tag: mediaItem,\n",
    "    );\n",
    "    await _playlist.add(audioSource);\n",
    "    queue.add([...queue.value, mediaItem]);\n",
    "  }\n",
    "\n",
    "  @override\n",
    "  Future<void> play() => _player.play();\n",
    "\n",
    "  @override\n",
    "  Future<void> pause() => _player.pause();\n",
    "\n",
    "  @override\n",
    "  Future<void> seek(Duration position) => _player.seek(position);\n",
    "\n",
    "  @override\n",
    "  Future<void> skipToQueueItem(int index) async {\n",
    "    await _player.seek(Duration.zero, index: index);\n",
    "    play();\n",
    "  }\n",
    "\n",
    "  @override\n",
    "  Future<void> skipToNext() => _player.seekToNext();\n",
    "\n",
    "  @override\n",
    "  Future<void> skipToPrevious() => _player.seekToPrevious();\n",
    "\n",
    "  @override\n",
    "  Future<void> stop() async {\n",
    "    await _player.stop();\n",
    "    await super.stop();\n",
    "  }\n",
    "}\n",
    "\n",
    "// Initialization in main.dart\n",
    "void main() async {\n",
    "  WidgetsFlutterBinding.ensureInitialized();\n",
    "  \n",
    "  await AudioService.init(\n",
    "    builder: () => AudioPlayerHandler(),\n",
    "    config: const AudioServiceConfig(\n",
    "      androidNotificationChannelId: 'com.example.audio.channel',\n",
    "      androidNotificationChannelName: 'Audio Playback',\n",
    "      androidNotificationOngoing: true,\n",
    "      androidStopForegroundOnPause: false,\n",
    "    ),\n",
    "  );\n",
    "  \n",
    "  runApp(MyApp());\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **BaseAudioHandler**: Abstract base class from `audio_service`. Implementing `QueueHandler` and `SeekHandler` mixins provides queue and seeking capabilities.\n",
    "- **AudioSource**: `just_audio` supports various sources: `AudioSource.uri` for network files, `AudioSource.file` for local downloads, `HlsAudioSource` for HLS streams.\n",
    "- **Notification Channel**: `androidNotificationChannelId` creates a persistent notification on Android that keeps the service alive in the background.\n",
    "- **MediaItem**: Standard metadata format (title, artist, album art, duration) displayed on lock screen and CarPlay/Android Auto.\n",
    "\n",
    "---\n",
    "\n",
    "## **47.4 DRM Implementation**\n",
    "\n",
    "Protecting premium content requires platform-specific DRM implementations.\n",
    "\n",
    "### **Android Widevine Implementation**\n",
    "\n",
    "```dart\n",
    "// lib/platform/drm/widevine_manager.dart\n",
    "import 'package:flutter/services.dart';\n",
    "\n",
    "class WidevineManager {\n",
    "  static const MethodChannel _channel = \n",
    "      MethodChannel('com.example.app/drm');\n",
    "\n",
    "  /// Initialize DRM session for a video\n",
    "  static Future<DrmSession> initializeWidevine({\n",
    "    required String licenseUrl,\n",
    "    required Map<String, String> headers,\n",
    "  }) async {\n",
    "    try {\n",
    "      final result = await _channel.invokeMethod<Map>('initializeWidevine', {\n",
    "        'licenseUrl': licenseUrl,\n",
    "        'headers': headers,\n",
    "      });\n",
    "      \n",
    "      return DrmSession(\n",
    "        sessionId: result!['sessionId'],\n",
    "        licenseAcquired: result['licenseAcquired'],\n",
    "      );\n",
    "    } catch (e) {\n",
    "      throw DrmException('Failed to initialize Widevine: $e');\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /// Release DRM session\n",
    "  static Future<void> releaseSession(String sessionId) async {\n",
    "    await _channel.invokeMethod('releaseDrmSession', {\n",
    "      'sessionId': sessionId,\n",
    "    });\n",
    "  }\n",
    "}\n",
    "\n",
    "class DrmSession {\n",
    "  final String sessionId;\n",
    "  final bool licenseAcquired;\n",
    "\n",
    "  DrmSession({\n",
    "    required this.sessionId,\n",
    "    required this.licenseAcquired,\n",
    "  });\n",
    "}\n",
    "\n",
    "// Android native implementation (Kotlin)\n",
    "/*\n",
    "class DrmPlugin : FlutterPlugin, MethodCallHandler {\n",
    "    private lateinit var context: Context\n",
    "    \n",
    "    override fun onMethodCall(call: MethodCall, result: Result) {\n",
    "        when (call.method) {\n",
    "            \"initializeWidevine\" -> {\n",
    "                val licenseUrl = call.argument<String>(\"licenseUrl\")!!\n",
    "                val headers = call.argument<Map<String, String>>(\"headers\")!!\n",
    "                \n",
    "                try {\n",
    "                    val mediaDrm = MediaDrm(WIDEVINE_UUID)\n",
    "                    val sessionId = mediaDrm.openSession()\n",
    "                    \n",
    "                    // Execute key request\n",
    "                    val keyRequest = mediaDrm.getKeyRequest(\n",
    "                        sessionId,\n",
    "                        initData,\n",
    "                        \"cenc\",\n",
    "                        MediaDrm.KEY_TYPE_STREAMING,\n",
    "                        headers\n",
    "                    )\n",
    "                    \n",
    "                    // Network request to license server\n",
    "                    val license = fetchLicense(licenseUrl, keyRequest.data, headers)\n",
    "                    mediaDrm.provideKeyResponse(sessionId, license)\n",
    "                    \n",
    "                    result.success(mapOf(\n",
    "                        \"sessionId\" to sessionId.toBase64(),\n",
    "                        \"licenseAcquired\" to true\n",
    "                    ))\n",
    "                } catch (e: Exception) {\n",
    "                    result.error(\"DRM_ERROR\", e.message, null)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "*/\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **Widevine**: Google's DRM system on Android. `MediaDrm` class manages the cryptographic session.\n",
    "- **License Acquisition**: The player requests a license from the DRM server. The license contains decryption keys for the content.\n",
    "- **Security Levels**: Widevine has L1 (hardware decryption), L2 (software decryption), and L3 (software only, least secure). Check `securityLevel` to ensure device compatibility.\n",
    "- **MethodChannel**: Required because Flutter's `video_player` doesn't expose DRM APIs directly. You must implement custom platform code or use plugins like `better_player` or `flutter_vlc_player` that support DRM.\n",
    "\n",
    "### **iOS FairPlay Implementation**\n",
    "\n",
    "```swift\n",
    "// iOS native implementation\n",
    "import Flutter\n",
    "import AVFoundation\n",
    "\n",
    "public class DrmPlugin: NSObject, FlutterPlugin {\n",
    "    public static func register(with registrar: FlutterPluginRegistrar) {\n",
    "        let channel = FlutterMethodChannel(name: \"com.example.app/drm\", binaryMessenger: registrar.messenger())\n",
    "        let instance = DrmPlugin()\n",
    "        registrar.addMethodCallDelegate(instance, channel: channel)\n",
    "    }\n",
    "    \n",
    "    public func handle(_ call: FlutterMethodCall, result: @escaping FlutterResult) {\n",
    "        if call.method == \"initializeFairPlay\" {\n",
    "            guard let args = call.arguments as? [String: Any],\n",
    "                  let certificateUrl = args[\"certificateUrl\"] as? String,\n",
    "                  let licenseUrl = args[\"licenseUrl\"] as? String else {\n",
    "                result(FlutterError(code: \"INVALID_ARGS\", message: nil, details: nil))\n",
    "                return\n",
    "            }\n",
    "            \n",
    "            // FairPlay requires application certificate\n",
    "            guard let certData = try? Data(contentsOf: URL(string: certificateUrl)!) else {\n",
    "                result(FlutterError(code: \"CERT_ERROR\", message: \"Failed to load certificate\", details: nil))\n",
    "                return\n",
    "            }\n",
    "            \n",
    "            // Store certificate and license URL for AVContentKeySession\n",
    "            FairPlaySessionManager.shared.setup(\n",
    "                certificate: certData,\n",
    "                licenseUrl: licenseUrl\n",
    "            )\n",
    "            \n",
    "            result([\"status\": \"initialized\"])\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// Usage with AVPlayer\n",
    "class FairPlayResourceLoaderDelegate: NSObject, AVAssetResourceLoaderDelegate {\n",
    "    func resourceLoader(_ resourceLoader: AVAssetResourceLoader, \n",
    "                       shouldWaitForLoadingOfRequestedResource loadingRequest: AVAssetResourceLoadingRequest) -> Bool {\n",
    "        // Handle FairPlay key requests here\n",
    "        // 1. Extract SPC (Server Playback Context)\n",
    "        // 2. Send to license server\n",
    "        // 3. Provide CKC (Content Key Context) to player\n",
    "        return true\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **FairPlay**: Apple's DRM system. Requires an \"Application Certificate\" from Apple, signed with your developer certificate.\n",
    "- **AVContentKeySession**: iOS API for managing DRM keys. The resource loader delegate intercepts key requests from the player.\n",
    "- **SPC/CKC**: FairPlay uses a challenge-response protocol. The player generates an SPC (challenge), sends it to the license server, and receives a CKC (response) containing the decryption key.\n",
    "\n",
    "---\n",
    "\n",
    "## **47.5 Adaptive Streaming (HLS/DASH)**\n",
    "\n",
    "Implementing adaptive bitrate streaming to adjust quality based on network conditions.\n",
    "\n",
    "```dart\n",
    "// lib/core/player/adaptive_streaming.dart\n",
    "class AdaptiveStreamingConfig {\n",
    "  /// For HLS (iOS native, Android via ExoPlayer)\n",
    "  static VideoPlayerController createHlsPlayer(String url) {\n",
    "    return VideoPlayerController.network(\n",
    "      url,\n",
    "      formatHint: VideoFormat.hls,\n",
    "      // On iOS, AVPlayer automatically handles variant selection\n",
    "      // On Android, ExoPlayer uses adaptive track selection\n",
    "    );\n",
    "  }\n",
    "\n",
    "  /// For DASH (Android primarily, iOS via third-party)\n",
    "  static VideoPlayerController createDashPlayer(String url) {\n",
    "    if (Platform.isAndroid) {\n",
    "      return VideoPlayerController.network(\n",
    "        url,\n",
    "        formatHint: VideoFormat.dash,\n",
    "      );\n",
    "    } else {\n",
    "      // iOS doesn't support DASH natively, convert to HLS or use plugin\n",
    "      throw UnsupportedError('DASH not supported on iOS');\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "// Quality selection (manual override)\n",
    "class QualitySelector extends StatelessWidget {\n",
    "  final VideoPlayerController controller;\n",
    "  final List<VideoQuality> availableQualities;\n",
    "\n",
    "  const QualitySelector({\n",
    "    super.key,\n",
    "    required this.controller,\n",
    "    required this.availableQualities,\n",
    "  });\n",
    "\n",
    "  @override\n",
    "  Widget build(BuildContext context) {\n",
    "    return PopupMenuButton<VideoQuality>(\n",
    "      icon: const Icon(Icons.settings),\n",
    "      onSelected: (quality) => _setQuality(quality),\n",
    "      itemBuilder: (context) {\n",
    "        return [\n",
    "          const PopupMenuItem(\n",
    "            value: null,\n",
    "            child: Text('Auto'),\n",
    "          ),\n",
    "          ...availableQualities.map((q) {\n",
    "            return PopupMenuItem(\n",
    "              value: q,\n",
    "              child: Text('${q.height}p'),\n",
    "            );\n",
    "          }),\n",
    "        ];\n",
    "      },\n",
    "    );\n",
    "  }\n",
    "\n",
    "  void _setQuality(VideoQuality? quality) {\n",
    "    // Note: video_player doesn't expose track selection APIs directly\n",
    "    // Requires native implementation or plugins like better_player\n",
    "    if (quality == null) {\n",
    "      // Enable ABR (Adaptive Bitrate)\n",
    "      _enableAdaptiveBitrate();\n",
    "    } else {\n",
    "      // Force specific track\n",
    "      _forceQuality(quality);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  void _enableAdaptiveBitrate() {\n",
    "    // Platform channel to ExoPlayer/AVPlayer\n",
    "    // ExoPlayer: trackSelector.setParameters(\n",
    "    //   trackSelector.buildUponParameters().setMaxVideoSizeSd()\n",
    "    // )\n",
    "  }\n",
    "\n",
    "  void _forceQuality(VideoQuality quality) {\n",
    "    // Platform channel to select specific track\n",
    "  }\n",
    "}\n",
    "\n",
    "class VideoQuality {\n",
    "  final int height; // 720, 1080, etc.\n",
    "  final int bitrate;\n",
    "  final String codec;\n",
    "\n",
    "  VideoQuality({\n",
    "    required this.height,\n",
    "    required this.bitrate,\n",
    "    required this.codec,\n",
    "  });\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **HLS (HTTP Live Streaming)**: Apple's protocol. Uses `.m3u8` playlist files containing multiple variant streams (360p, 720p, 1080p). The player automatically switches based on bandwidth.\n",
    "- **DASH (Dynamic Adaptive Streaming)**: MPEG standard, uses `.mpd` manifest files. Better supported on Android via ExoPlayer.\n",
    "- **Track Selection**: Standard `video_player` doesn't expose APIs to manually select quality. For advanced control, use `better_player` or implement platform channels to ExoPlayer's `DefaultTrackSelector`.\n",
    "\n",
    "---\n",
    "\n",
    "## **47.6 Casting Support (Chromecast/AirPlay)**\n",
    "\n",
    "### **Chromecast Integration**\n",
    "\n",
    "```dart\n",
    "// lib/features/cast/chromecast_manager.dart\n",
    "import 'package:google_cast/google_cast.dart';\n",
    "\n",
    "class ChromecastManager {\n",
    "  final GoogleCastContext _castContext = GoogleCastContext.instance;\n",
    "  final StreamController<CastState> _stateController = StreamController.broadcast();\n",
    "\n",
    "  Stream<CastState> get stateStream => _stateController.stream;\n",
    "\n",
    "  Future<void> initialize() async {\n",
    "    await _castContext.setOptions(\n",
    "      GoogleCastOptions(\n",
    "        receiverApplicationId: GoogleCastContext.defaultMediaReceiver,\n",
    "      ),\n",
    "    );\n",
    "    \n",
    "    // Listen for session state changes\n",
    "    GoogleCastSessionManager.instance.currentSession?.stateStream.listen((state) {\n",
    "      _stateController.add(state);\n",
    "    });\n",
    "  }\n",
    "\n",
    "  Future<void> castVideo(String url, MediaMetadata metadata) async {\n",
    "    final session = GoogleCastSessionManager.instance.currentSession;\n",
    "    if (session == null || !session.isConnected) {\n",
    "      // Show device picker\n",
    "      await GoogleCastContext.instance.showCastDialog();\n",
    "      return;\n",
    "    }\n",
    "\n",
    "    final mediaInfo = GoogleCastMediaInformation(\n",
    "      contentId: url,\n",
    "      contentType: 'video/mp4',\n",
    "      streamType: GoogleCastStreamType.buffered,\n",
    "      metadata: GoogleCastMediaMetadata(\n",
    "        type: GoogleCastMediaMetadataType.movie,\n",
    "        title: metadata.title,\n",
    "        subtitle: metadata.subtitle,\n",
    "        images: [\n",
    "          GoogleCastImage(\n",
    "            url: metadata.posterUrl,\n",
    "            width: 480,\n",
    "            height: 720,\n",
    "          ),\n",
    "        ],\n",
    "      ),\n",
    "    );\n",
    "\n",
    "    final request = GoogleCastMediaLoadRequest(mediaInfo);\n",
    "    await session.remoteMediaClient?.load(request);\n",
    "  }\n",
    "\n",
    "  Future<void> stopCasting() async {\n",
    "    await GoogleCastSessionManager.instance.endSession();\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **Google Cast SDK**: Requires registration at [Google Cast SDK Developer Console](https://developers.google.com/cast/docs/registration) to get an App ID.\n",
    "- **Sender App**: Flutter app acts as the \"sender\". It discovers Cast devices on the network and controls playback.\n",
    "- **Receiver**: The Chromecast runs a receiver app (usually the Default Media Receiver for video, or a custom Styled Receiver).\n",
    "- **MediaInformation**: Metadata sent to the Chromecast for display on the TV (title, poster art, progress).\n",
    "\n",
    "### **AirPlay Integration**\n",
    "\n",
    "```dart\n",
    "// lib/features/cast/airplay_button.dart\n",
    "import 'package:flutter/services.dart';\n",
    "\n",
    "class AirPlayButton extends StatelessWidget {\n",
    "  static const platform = MethodChannel('com.example.app/airplay');\n",
    "\n",
    "  const AirPlayButton({super.key});\n",
    "\n",
    "  @override\n",
    "  Widget build(BuildContext context) {\n",
    "    if (!Platform.isIOS) return const SizedBox();\n",
    "\n",
    "    return InkWell(\n",
    "      onTap: _showAirPlayPicker,\n",
    "      child: Container(\n",
    "        width: 44,\n",
    "        height: 44,\n",
    "        child: const UiKitView(\n",
    "          viewType: 'AirPlayRoutePickerView',\n",
    "          creationParams: <String, dynamic>{\n",
    "            'activeTintColor': '#FFFFFF',\n",
    "            'tintColor': '#FFFFFF',\n",
    "          },\n",
    "          creationParamsCodec: StandardMessageCodec(),\n",
    "        ),\n",
    "      ),\n",
    "    );\n",
    "  }\n",
    "\n",
    "  void _showAirPlayPicker() async {\n",
    "    try {\n",
    "      await platform.invokeMethod('showAirPlayPicker');\n",
    "    } catch (e) {\n",
    "      print('Failed to show AirPlay picker: $e');\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "// iOS native implementation\n",
    "/*\n",
    "import AVKit\n",
    "\n",
    "class AirPlayView: NSObject, FlutterPlatformView {\n",
    "    func view() -> UIView {\n",
    "        let routePickerView = AVRoutePickerView()\n",
    "        routePickerView.tintColor = .white\n",
    "        routePickerView.activeTintColor = .white\n",
    "        return routePickerView\n",
    "    }\n",
    "}\n",
    "*/\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **AVRoutePickerView**: iOS native button that automatically handles AirPlay device discovery and connection. The system handles the UI (picker sheet).\n",
    "- **PlatformView**: Embeds the native iOS view into the Flutter widget tree using `UiKitView`.\n",
    "- **AirPlay**: Automatically routes audio/video to Apple TV or AirPlay-compatible speakers. For video, the system handles the stream URL; your app just needs to initiate the connection.\n",
    "\n",
    "---\n",
    "\n",
    "## **47.7 Picture-in-Picture (PiP)**\n",
    "\n",
    "Allowing video to play in a floating window while the user navigates other apps.\n",
    "\n",
    "```dart\n",
    "// lib/features/video_player/presentation/pip_manager.dart\n",
    "import 'package:flutter/services.dart';\n",
    "\n",
    "class PipManager {\n",
    "  static const MethodChannel _channel = \n",
    "      MethodChannel('com.example.app/pip');\n",
    "\n",
    "  /// Check if PiP is supported on this device\n",
    "  static Future<bool> isSupported() async {\n",
    "    if (!Platform.isIOS && !Platform.isAndroid) return false;\n",
    "    \n",
    "    try {\n",
    "      return await _channel.invokeMethod<bool>('isPipSupported') ?? false;\n",
    "    } catch (e) {\n",
    "      return false;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /// Enter PiP mode\n",
    "  static Future<void> enterPipMode() async {\n",
    "    try {\n",
    "      await _channel.invokeMethod('enterPipMode');\n",
    "    } catch (e) {\n",
    "      throw PipException('Failed to enter PiP: $e');\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /// Configure PiP aspect ratio (iOS only)\n",
    "  static Future<void> configureAspectRatio(double width, double height) async {\n",
    "    if (Platform.isIOS) {\n",
    "      await _channel.invokeMethod('configurePipAspectRatio', {\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "      });\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "// Android native implementation\n",
    "/*\n",
    "class PipPlugin : FlutterPlugin, MethodCallHandler, ActivityAware {\n",
    "    private lateinit var activity: Activity\n",
    "    \n",
    "    override fun onMethodCall(call: MethodCall, result: Result) {\n",
    "        when (call.method) {\n",
    "            \"enterPipMode\" -> {\n",
    "                if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.O) {\n",
    "                    val params = PictureInPictureParams.Builder()\n",
    "                        .setAspectRatio(Rational(16, 9))\n",
    "                        .build()\n",
    "                    activity.enterPictureInPictureMode(params)\n",
    "                    result.success(null)\n",
    "                } else {\n",
    "                    result.error(\"UNSUPPORTED\", \"PiP requires Android 8.0+\", null)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "*/\n",
    "\n",
    "// iOS native implementation\n",
    "/*\n",
    "import AVKit\n",
    "import Flutter\n",
    "\n",
    "class PipPlugin: NSObject, FlutterPlugin {\n",
    "    var pipController: AVPictureInPictureController?\n",
    "    \n",
    "    func handle(_ call: FlutterMethodCall, result: @escaping FlutterResult) {\n",
    "        if call.method == \"enterPipMode\" {\n",
    "            guard let playerLayer = videoPlayerView.playerLayer else {\n",
    "                result(FlutterError(code: \"NO_PLAYER\", message: nil, details: nil))\n",
    "                return\n",
    "            }\n",
    "            \n",
    "            pipController = AVPictureInPictureController(playerLayer: playerLayer)\n",
    "            pipController?.startPictureInPicture()\n",
    "            result(nil)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "*/\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **Android PiP**: Uses `PictureInPictureParams` to configure aspect ratio. Requires `android:supportsPictureInPicture=\"true\"` in AndroidManifest.xml activity declaration.\n",
    "- **iOS PiP**: Uses `AVPictureInPictureController` which requires the app to have the \"Background Mode: Audio, AirPlay, and Picture in Picture\" capability enabled in Xcode.\n",
    "- **Aspect Ratio**: Should match the video content (16:9 for landscape, 9:16 for portrait) to avoid black bars.\n",
    "\n",
    "---\n",
    "\n",
    "## **47.8 Offline Downloads with Encryption**\n",
    "\n",
    "Allowing users to download content for offline viewing while protecting against unauthorized copying.\n",
    "\n",
    "```dart\n",
    "// lib/features/downloads/data/download_manager.dart\n",
    "import 'package:flutter_downloader/flutter_downloader.dart';\n",
    "import 'package:encrypt/encrypt.dart';\n",
    "\n",
    "class EncryptedDownloadManager {\n",
    "  final _downloadQueue = <DownloadTask>[];\n",
    "  \n",
    "  Future<String> downloadVideo({\n",
    "    required String url,\n",
    "    required String videoId,\n",
    "    required String licenseKey, // For decryption\n",
    "  }) async {\n",
    "    // Create encrypted filename\n",
    "    final fileName = '$videoId.enc';\n",
    "    final savePath = await _getDownloadPath();\n",
    "    final fullPath = '$savePath/$fileName';\n",
    "    \n",
    "    // Start download\n",
    "    final taskId = await FlutterDownloader.enqueue(\n",
    "      url: url,\n",
    "      savedDir: savePath,\n",
    "      fileName: fileName,\n",
    "      showNotification: true,\n",
    "      openFileFromNotification: false,\n",
    "      saveInPublicStorage: false,\n",
    "    );\n",
    "    \n",
    "    // Store metadata in local DB\n",
    "    await _storeDownloadMetadata(\n",
    "      taskId: taskId!,\n",
    "      videoId: videoId,\n",
    "      filePath: fullPath,\n",
    "      encryptionKey: licenseKey,\n",
    "    );\n",
    "    \n",
    "    return taskId;\n",
    "  }\n",
    "\n",
    "  Future<String> getDecryptedFilePath(String videoId) async {\n",
    "    final metadata = await _getDownloadMetadata(videoId);\n",
    "    final encryptedFile = File(metadata.filePath);\n",
    "    \n",
    "    if (!await encryptedFile.exists()) {\n",
    "      throw DownloadException('File not found');\n",
    "    }\n",
    "    \n",
    "    // Decrypt to temporary file for playback\n",
    "    final tempDir = await getTemporaryDirectory();\n",
    "    final tempPath = '${tempDir.path}/$videoId.mp4';\n",
    "    \n",
    "    final key = Key.fromBase64(metadata.encryptionKey);\n",
    "    final iv = IV.fromLength(16);\n",
    "    final encrypter = Encrypter(AES(key, mode: AESMode.cbc));\n",
    "    \n",
    "    final encryptedBytes = await encryptedFile.readAsBytes();\n",
    "    final decrypted = encrypter.decryptBytes(Encrypted(encryptedBytes), iv: iv);\n",
    "    \n",
    "    await File(tempPath).writeAsBytes(decrypted);\n",
    "    \n",
    "    // Schedule cleanup of temp file after playback\n",
    "    _scheduleTempCleanup(tempPath);\n",
    "    \n",
    "    return tempPath;\n",
    "  }\n",
    "\n",
    "  Future<String> _getDownloadPath() async {\n",
    "    final dir = await getApplicationDocumentsDirectory();\n",
    "    final downloadDir = Directory('${dir.path}/downloads');\n",
    "    if (!await downloadDir.exists()) {\n",
    "      await downloadDir.create(recursive: true);\n",
    "    }\n",
    "    return downloadDir.path;\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **flutter_downloader**: Handles background downloads with progress notifications. Downloads to app-private storage.\n",
    "- **AES Encryption**: Encrypts the downloaded file using a key derived from the DRM license or user credentials. This prevents users from extracting the raw MP4 from the app sandbox.\n",
    "- **Temporary Decryption**: Decrypts to a temporary file only during playback. The temp file is deleted after use to prevent copying.\n",
    "- **Secure Storage**: The encryption key should be stored in Android Keystore/iOS Keychain, not in the database.\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "In this chapter, we built a comprehensive streaming/media application:\n",
    "\n",
    "### **Key Takeaways:**\n",
    "\n",
    "1. **Video Lifecycle**: Always dispose controllers to free hardware decoders. Use `ValueListenableBuilder` for efficient UI updates.\n",
    "2. **Background Audio**: Implement `AudioHandler` from `audio_service` to provide lock screen controls and enable background playback.\n",
    "3. **DRM Protection**: Use Widevine (Android) and FairPlay (iOS) via platform channels. Requires native implementation as Flutter's video_player doesn't expose DRM APIs.\n",
    "4. **Adaptive Streaming**: HLS for iOS, DASH for Android. The player automatically selects quality based on bandwidth.\n",
    "5. **Casting**: Chromecast requires the Google Cast SDK and a receiver app. AirPlay uses `AVRoutePickerView` for native device selection.\n",
    "6. **Picture-in-Picture**: Requires native implementation using `PictureInPictureParams` (Android) and `AVPictureInPictureController` (iOS).\n",
    "7. **Offline Downloads**: Download to encrypted storage. Decrypt temporarily for playback to prevent unauthorized sharing.\n",
    "\n",
    "### **Performance Considerations:**\n",
    "- \u2705 Use `cached_network_image` for video thumbnails\n",
    "- \u2705 Preload video metadata but don't initialize multiple players simultaneously\n",
    "- \u2705 Release audio focus when not playing\n",
    "- \u2705 Use `androidStopForegroundOnPause: false` to keep notification active during buffering\n",
    "\n",
    "---\n",
    "\n",
    "## **Next Steps**\n",
    "\n",
    "In the next chapter, **Chapter 48: Performance Optimization**, we will explore advanced techniques for ensuring 60fps performance in complex Flutter applications. You'll learn how to use DevTools for profiling, implement custom painters for optimized rendering, manage memory leaks, and optimize shader compilation for first-frame rendering.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 47**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='46. task_management_app.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='../13. Advanced_topics_and_reference/48. performance_optimization.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}