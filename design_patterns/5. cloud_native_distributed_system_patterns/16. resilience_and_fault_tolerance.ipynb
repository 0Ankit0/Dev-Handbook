{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Chapter 16: Resilience and Fault Tolerance\n",
    "\n",
    "## Opening Context\n",
    "\n",
    "In a distributed system, failures are not a matter of **if** but **when**. Networks glitch, services crash, databases time out, and resources become exhausted. In a monolithic application, a failure often means the entire application is down. In a microservices architecture, the stakes are different: a failure in one service can cascade, consuming resources and bringing down dependent services\u2014a phenomenon known as **cascading failure**.\n",
    "\n",
    "Building resilient systems requires deliberate design. We must assume that dependencies will fail and protect our services from being dragged down with them. This chapter explores three essential patterns for fault tolerance:\n",
    "\n",
    "1. **Circuit Breaker** \u2013 Prevents repeated calls to a failing service, giving it time to recover and avoiding wasted resources.\n",
    "2. **Retry with Exponential Backoff** \u2013 Handles transient failures by retrying operations with increasing delays.\n",
    "3. **Bulkhead** \u2013 Isolates failures by partitioning resources, so a problem in one part doesn\u2019t sink the whole system.\n",
    "\n",
    "These patterns, inspired by electrical engineering and shipbuilding, form the bedrock of resilient distributed systems. By the end of this chapter, you\u2019ll know how to apply them to keep your applications stable even when things go wrong.\n",
    "\n",
    "---\n",
    "\n",
    "## 16.1 Circuit Breaker Pattern\n",
    "\n",
    "### Intent\n",
    "*Protect a system from repeatedly trying to execute an operation that is likely to fail, allowing it to recover and preventing cascading failures.*\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Imagine an e\u2011commerce frontend service that calls a `payment\u2011service` to process credit cards. If the payment service becomes slow or starts failing (e.g., due to a database outage), the frontend service might continue to send requests, each waiting for a timeout. This has several negative consequences:\n",
    "\n",
    "- **Resource exhaustion** \u2013 The frontend service holds onto threads/connections while waiting, potentially exhausting its own resources.\n",
    "- **User frustration** \u2013 Users experience long waits and eventual errors.\n",
    "- **Cascading failure** \u2013 The frontend\u2019s resource exhaustion can cause it to fail, affecting other functionalities that don\u2019t even use payment.\n",
    "\n",
    "What\u2019s needed is a way to **stop trying** when failure is likely, and to **try again** later when the service may have recovered.\n",
    "\n",
    "### The Solution: Circuit Breaker\n",
    "\n",
    "The Circuit Breaker pattern, named after its electrical counterpart, introduces a state machine that monitors for failures. When failures reach a threshold, the circuit **trips** and subsequent calls fail immediately (or with a fallback) without attempting the operation. After a timeout, the circuit transitions to a **half\u2011open** state, allowing a limited number of test requests to see if the service has recovered.\n",
    "\n",
    "**States**:\n",
    "- **Closed** \u2013 Normal operation. Requests pass through; failures are counted. When failures exceed a threshold, the circuit opens.\n",
    "- **Open** \u2013 Requests fail immediately. After a timeout, the circuit transitions to half\u2011open.\n",
    "- **Half\u2011Open** \u2013 A limited number of test requests are allowed. If they succeed, the circuit closes; if they fail, it opens again.\n",
    "\n",
    "### Implementation Example\n",
    "\n",
    "Let\u2019s implement a simple circuit breaker in TypeScript that wraps an asynchronous function.\n",
    "\n",
    "```typescript\n",
    "// circuit-breaker.ts\n",
    "export class CircuitBreaker {\n",
    "  private state: 'CLOSED' | 'OPEN' | 'HALF_OPEN' = 'CLOSED';\n",
    "  private failureCount: number = 0;\n",
    "  private readonly failureThreshold: number;\n",
    "  private readonly timeout: number;\n",
    "  private nextAttempt: number = Date.now();\n",
    "\n",
    "  constructor(failureThreshold: number = 3, timeout: number = 10000) {\n",
    "    this.failureThreshold = failureThreshold;\n",
    "    this.timeout = timeout;\n",
    "  }\n",
    "\n",
    "  async call<T>(fn: () => Promise<T>): Promise<T> {\n",
    "    if (this.state === 'OPEN') {\n",
    "      if (Date.now() > this.nextAttempt) {\n",
    "        this.state = 'HALF_OPEN';\n",
    "      } else {\n",
    "        throw new Error('Circuit breaker is OPEN');\n",
    "      }\n",
    "    }\n",
    "\n",
    "    try {\n",
    "      const result = await fn();\n",
    "      this.onSuccess();\n",
    "      return result;\n",
    "    } catch (err) {\n",
    "      this.onFailure();\n",
    "      throw err;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  private onSuccess(): void {\n",
    "    this.failureCount = 0;\n",
    "    if (this.state === 'HALF_OPEN') {\n",
    "      this.state = 'CLOSED';\n",
    "    }\n",
    "  }\n",
    "\n",
    "  private onFailure(): void {\n",
    "    this.failureCount++;\n",
    "    if (this.state === 'HALF_OPEN' || this.failureCount >= this.failureThreshold) {\n",
    "      this.trip();\n",
    "    }\n",
    "  }\n",
    "\n",
    "  private trip(): void {\n",
    "    this.state = 'OPEN';\n",
    "    this.nextAttempt = Date.now() + this.timeout;\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "- The constructor sets the failure threshold (how many failures before opening) and the timeout (how long to stay open).\n",
    "- `call()` checks the current state. If open and the timeout has passed, it moves to half\u2011open.\n",
    "- In half\u2011open or closed, it attempts the function.\n",
    "- On success, it resets failure count and closes the circuit if it was half\u2011open.\n",
    "- On failure, it increments the count; if the threshold is reached (or if already half\u2011open), it trips the circuit (opens it).\n",
    "\n",
    "#### Usage Example\n",
    "\n",
    "```typescript\n",
    "// payment-client.ts\n",
    "import { CircuitBreaker } from './circuit-breaker';\n",
    "\n",
    "class PaymentClient {\n",
    "  private breaker = new CircuitBreaker(3, 10000); // 3 failures, 10s timeout\n",
    "\n",
    "  async processPayment(amount: number): Promise<string> {\n",
    "    return this.breaker.call(async () => {\n",
    "      // Simulate call to external payment service\n",
    "      const response = await fetch('https://payment.example.com/charge', {\n",
    "        method: 'POST',\n",
    "        body: JSON.stringify({ amount })\n",
    "      });\n",
    "      if (!response.ok) throw new Error('Payment failed');\n",
    "      return response.json();\n",
    "    });\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "- The `processPayment` method wraps the external call with the circuit breaker.\n",
    "- If the payment service fails three times within a short period, the circuit opens and subsequent calls will throw immediately without hitting the network.\n",
    "- After 10 seconds, the circuit allows a single test request. If it succeeds, normal operation resumes.\n",
    "\n",
    "### Real\u2011World Considerations\n",
    "\n",
    "- **Timeouts** \u2013 The circuit breaker should work in conjunction with timeouts. If a call takes too long, it\u2019s considered a failure.\n",
    "- **Fallbacks** \u2013 In open state, you might provide a fallback value or use cached data.\n",
    "- **Monitoring** \u2013 Expose metrics (state, failure count) for dashboards and alerts.\n",
    "- **Library Support** \u2013 In production, use battle\u2011tested libraries like **Polly** (.NET), **resilience4j** (Java), or **opossum** (Node.js).\n",
    "\n",
    "---\n",
    "\n",
    "## 16.2 Retry with Exponential Backoff\n",
    "\n",
    "### Intent\n",
    "*Automatically retry failed operations when the failure is transient, increasing the delay between retries to avoid overwhelming the system.*\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Transient failures\u2014network glitches, temporary unavailability, database deadlocks\u2014are common in distributed systems. Simply giving up after the first failure would make the system unnecessarily brittle. However, retrying immediately and repeatedly can make things worse: if the service is struggling, a flood of retries can delay its recovery.\n",
    "\n",
    "### The Solution: Retry with Exponential Backoff\n",
    "\n",
    "Instead of retrying immediately, we wait a short time, then a longer time, and so on, often adding **jitter** (randomness) to avoid all clients retrying simultaneously (the **thundering herd** problem). The delay typically follows a formula like:\n",
    "\n",
    "```\n",
    "delay = baseDelay * (2 ^ attempt) + jitter\n",
    "```\n",
    "\n",
    "#### Implementation Example\n",
    "\n",
    "```typescript\n",
    "// retry.ts\n",
    "export async function retryWithBackoff<T>(\n",
    "  fn: () => Promise<T>,\n",
    "  maxRetries: number = 3,\n",
    "  baseDelay: number = 100, // milliseconds\n",
    "  maxDelay: number = 10000\n",
    "): Promise<T> {\n",
    "  let lastError: Error;\n",
    "  \n",
    "  for (let attempt = 0; attempt <= maxRetries; attempt++) {\n",
    "    try {\n",
    "      return await fn();\n",
    "    } catch (error) {\n",
    "      lastError = error;\n",
    "      if (attempt === maxRetries) break;\n",
    "      \n",
    "      // Calculate delay with exponential backoff and jitter\n",
    "      const delay = Math.min(\n",
    "        baseDelay * Math.pow(2, attempt) + Math.random() * 100,\n",
    "        maxDelay\n",
    "      );\n",
    "      \n",
    "      console.log(`Retry attempt ${attempt + 1} after ${delay}ms`);\n",
    "      await new Promise(resolve => setTimeout(resolve, delay));\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  throw lastError;\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "- The function attempts the operation up to `maxRetries + 1` times.\n",
    "- After each failure, it calculates an exponential delay (`baseDelay * 2^attempt`) and adds jitter (random up to 100ms) to spread out retries.\n",
    "- The delay is capped at `maxDelay` to prevent excessively long waits.\n",
    "- If all retries fail, the last error is thrown.\n",
    "\n",
    "#### Usage Example\n",
    "\n",
    "```typescript\n",
    "// database-client.ts\n",
    "import { retryWithBackoff } from './retry';\n",
    "\n",
    "async function queryDatabase(sql: string): Promise<any> {\n",
    "  return retryWithBackoff(async () => {\n",
    "    // Simulate database call that may fail transiently\n",
    "    const result = await db.execute(sql);\n",
    "    return result;\n",
    "  }, 3, 200, 5000);\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "- The database query is wrapped with retry logic. If it fails due to a transient error (e.g., deadlock), it will retry up to three times with increasing delays.\n",
    "- The `maxDelay` of 5 seconds ensures we don\u2019t wait too long between retries.\n",
    "\n",
    "### Important Considerations\n",
    "\n",
    "- **Idempotency** \u2013 Retries are safe only if the operation is idempotent (executing it multiple times has the same effect as once). For non\u2011idempotent operations (e.g., creating a resource), you must ensure that duplicates are handled (e.g., using request IDs).\n",
    "- **Which errors to retry** \u2013 Not all errors are retryable. Client errors (4xx) usually indicate a problem with the request and should not be retried; server errors (5xx) or network timeouts are good candidates.\n",
    "- **Retry storms** \u2013 Exponential backoff with jitter helps, but you also need circuit breakers to stop retries when a service is genuinely down.\n",
    "\n",
    "### Integration with Circuit Breaker\n",
    "\n",
    "Retry and circuit breaker work well together. The typical pattern is:\n",
    "\n",
    "1. Apply retry with backoff for transient failures.\n",
    "2. If retries fail, the circuit breaker counts that as a failure.\n",
    "3. When the circuit opens, retries are bypassed entirely (or a fallback is used).\n",
    "\n",
    "This way, you get both local resilience and system\u2011wide protection.\n",
    "\n",
    "---\n",
    "\n",
    "## 16.3 Bulkhead Pattern\n",
    "\n",
    "### Intent\n",
    "*Isolate failures by partitioning resources (like thread pools, connection pools, or queues) so that a problem in one part of the system does not bring down the whole system.*\n",
    "\n",
    "### The Problem\n",
    "\n",
    "In a typical application, all outbound calls might share the same thread pool or connection pool. If one downstream service becomes slow or unresponsive, it can exhaust the entire pool, causing requests to other, healthy services to wait or fail. This is a form of **resource contention** leading to cascading failure.\n",
    "\n",
    "For example, suppose your application has a connection pool of 10 connections to a database. If a poorly optimised query suddenly takes 30 seconds, it could tie up all 10 connections, leaving no connections for other queries\u2014even quick ones. The application appears dead.\n",
    "\n",
    "### The Solution: Bulkhead\n",
    "\n",
    "The Bulkhead pattern, named after the compartments in a ship that prevent water from flooding the entire vessel, divides resources into isolated pools. If one compartment fails, the others remain operational.\n",
    "\n",
    "In software, we create separate thread pools, connection pools, or queues for different downstream dependencies. For instance, you might have:\n",
    "- A pool of 5 connections for the payment service.\n",
    "- A pool of 5 connections for the inventory service.\n",
    "- A pool of 10 connections for the database (shared, but still isolated from the others).\n",
    "\n",
    "#### Implementation Example: Separate HTTP Client Pools\n",
    "\n",
    "Using Node.js with `axios`, we can create separate instances with their own connection limits.\n",
    "\n",
    "```typescript\n",
    "// http-clients.ts\n",
    "import axios, { AxiosInstance } from 'axios';\n",
    "\n",
    "// Create a dedicated client for payment service with max 2 concurrent connections\n",
    "export const paymentClient: AxiosInstance = axios.create({\n",
    "  baseURL: 'https://payment.example.com',\n",
    "  timeout: 5000,\n",
    "  // In Node.js, axios uses the http/https agent for connection pooling\n",
    "  // We can configure maxSockets to limit concurrent connections\n",
    "});\n",
    "\n",
    "// Set max concurrent connections to 2 for this client\n",
    "import http from 'http';\n",
    "import https from 'https';\n",
    "\n",
    "paymentClient.defaults.httpAgent = new http.Agent({ keepAlive: true, maxSockets: 2 });\n",
    "paymentClient.defaults.httpsAgent = new https.Agent({ keepAlive: true, maxSockets: 2 });\n",
    "\n",
    "// Similarly for inventory service\n",
    "export const inventoryClient: AxiosInstance = axios.create({\n",
    "  baseURL: 'https://inventory.example.com',\n",
    "  timeout: 5000,\n",
    "});\n",
    "inventoryClient.defaults.httpAgent = new http.Agent({ keepAlive: true, maxSockets: 5 });\n",
    "inventoryClient.defaults.httpsAgent = new https.Agent({ keepAlive: true, maxSockets: 5 });\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "- Each client has its own connection pool (`maxSockets` limits concurrent connections).\n",
    "- If the payment service slows down, it can at most consume 2 connections. The inventory service still has its own 5 connections available.\n",
    "- This isolation prevents one slow dependency from exhausting all available connections.\n",
    "\n",
    "#### Implementation Example: Thread Pools (Conceptual)\n",
    "\n",
    "In languages with explicit thread pools (Java, C#), you might assign each dependency a separate thread pool.\n",
    "\n",
    "```java\n",
    "// Java example (pseudo)\n",
    "ExecutorService paymentPool = Executors.newFixedThreadPool(2);\n",
    "ExecutorService inventoryPool = Executors.newFixedThreadPool(5);\n",
    "\n",
    "// Submit tasks to appropriate pools\n",
    "Future<PaymentResult> paymentFuture = paymentPool.submit(() -> callPayment());\n",
    "Future<InventoryResult> inventoryFuture = inventoryPool.submit(() -> callInventory());\n",
    "```\n",
    "\n",
    "#### Semaphore\u2011Based Bulkhead\n",
    "\n",
    "For finer control, you can use semaphores to limit concurrent calls to a specific operation.\n",
    "\n",
    "```typescript\n",
    "// semaphore-bulkhead.ts\n",
    "import { Semaphore } from 'async-mutex';\n",
    "\n",
    "class Bulkhead {\n",
    "  private semaphore: Semaphore;\n",
    "\n",
    "  constructor(maxConcurrent: number) {\n",
    "    this.semaphore = new Semaphore(maxConcurrent);\n",
    "  }\n",
    "\n",
    "  async run<T>(fn: () => Promise<T>): Promise<T> {\n",
    "    const [value, release] = await this.semaphore.acquire();\n",
    "    try {\n",
    "      return await fn();\n",
    "    } finally {\n",
    "      release();\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "// Usage\n",
    "const paymentBulkhead = new Bulkhead(2);\n",
    "\n",
    "async function callPaymentWithBulkhead(amount: number) {\n",
    "  return paymentBulkhead.run(() => paymentClient.post('/charge', { amount }));\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "- The semaphore ensures at most `maxConcurrent` calls are in flight at once.\n",
    "- Additional calls wait until a slot is free.\n",
    "- This protects the caller from being overwhelmed by responses, and also limits load on the downstream service.\n",
    "\n",
    "### Bulkhead at Different Levels\n",
    "\n",
    "- **Connection pools** \u2013 Limit concurrent connections to a service.\n",
    "- **Thread pools** \u2013 Isolate processing of different types of tasks.\n",
    "- **Queues** \u2013 Use separate queues for different priorities or tenants.\n",
    "- **Semaphores** \u2013 Limit concurrent execution of specific code paths.\n",
    "\n",
    "### Trade\u2011offs\n",
    "\n",
    "- **Resource underutilisation** \u2013 If you allocate too many small pools, you may waste resources that could be shared. You need to size pools based on expected load.\n",
    "- **Complexity** \u2013 Managing multiple pools adds configuration overhead.\n",
    "- **Monitoring** \u2013 You need to monitor each pool\u2019s usage to detect issues.\n",
    "\n",
    "### Combining Patterns\n",
    "\n",
    "In a resilient system, you often combine bulkheads with circuit breakers and retries. For example:\n",
    "- Use a bulkhead to limit concurrent calls to a service.\n",
    "- Wrap the call with a circuit breaker to stop calling when the service is failing.\n",
    "- Use retries for transient failures, but respect the bulkhead limits.\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary\n",
    "\n",
    "This chapter covered three foundational patterns for building resilient distributed systems:\n",
    "\n",
    "1. **Circuit Breaker** \u2013 Prevents cascading failures by stopping calls to a failing service and allowing recovery time. It acts as a state machine that opens after a threshold of failures and tests the waters before closing again.\n",
    "\n",
    "2. **Retry with Exponential Backoff** \u2013 Handles transient failures by retrying operations with increasing delays and jitter. It must be used with idempotent operations and combined with circuit breakers to avoid hammering a struggling service.\n",
    "\n",
    "3. **Bulkhead** \u2013 Isolates failures by partitioning resources (connection pools, thread pools, semaphores). This ensures that a problem in one dependency does not exhaust resources needed by others.\n",
    "\n",
    "**Key Insight**: Resilience is not a single pattern but a combination of them. Circuit breakers stop the bleeding, retries handle temporary glitches, and bulkheads contain the damage. Together, they form a robust defence against the inevitable failures of distributed systems.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Chapter Preview\n",
    "\n",
    "**Chapter 17: Data Management in Distributed Systems (CQRS, Event Sourcing, Saga, Sharding)**\n",
    "\n",
    "In distributed systems, data is rarely stored in a single database. We must manage consistency, scalability, and complex queries across services. Chapter 17 will explore patterns for data management: **CQRS** (Command Query Responsibility Segregation) separates writes and reads, **Event Sourcing** stores state as a sequence of events, **Saga** manages distributed transactions, and **Sharding** partitions data across multiple databases. These patterns help you design scalable, consistent, and auditable data layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='../4. architectural_patterns/15. service_oriented_architecture.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='17. data_management_in_distributed_systems.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}