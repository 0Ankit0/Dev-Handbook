{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 40: Security Testing Techniques**\n",
    "\n",
    "---\n",
    "\n",
    "## **40.1 OWASP Testing Guide Methodology**\n",
    "\n",
    "### **40.1.1 Overview of OWASP Testing Framework**\n",
    "\n",
    "The OWASP Testing Guide provides a comprehensive framework for testing web application security. It represents the industry standard for structured security assessment, organized into 12 categories covering all aspects of web application security.\n",
    "\n",
    "**The 12 Testing Categories:**\n",
    "\n",
    "```\n",
    "OWASP Testing Framework:\n",
    "\n",
    "1. Information Gathering          7. Cryptography\n",
    "2. Configuration and Deployment   8. Error Handling\n",
    "3. Identity Management            9. Business Logic\n",
    "4. Authentication                 10. Client-side\n",
    "5. Authorization                  11. API Testing\n",
    "6. Session Management             12. Denial of Service\n",
    "```\n",
    "\n",
    "### **40.1.2 Information Gathering (OTG-INFO)**\n",
    "\n",
    "Information gathering is the foundation of security testing. The more you know about the target, the more effective your testing will be.\n",
    "\n",
    "**Reconnaissance Techniques:**\n",
    "\n",
    "```python\n",
    "# Automated Information Gathering Script\n",
    "import requests\n",
    "import dns.resolver\n",
    "import whois\n",
    "import socket\n",
    "import ssl\n",
    "import subprocess\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "class InformationGathering:\n",
    "    def __init__(self, target):\n",
    "        self.target = target\n",
    "        self.base_url = f\"http://{target}\" if not target.startswith('http') else target\n",
    "        self.findings = {}\n",
    "    \n",
    "    def dns_enumeration(self):\n",
    "        \"\"\"\n",
    "        DNS reconnaissance and subdomain discovery\n",
    "        \"\"\"\n",
    "        dns_info = {\n",
    "            'a_records': [],\n",
    "            'mx_records': [],\n",
    "            'ns_records': [],\n",
    "            'txt_records': [],\n",
    "            'subdomains': []\n",
    "        }\n",
    "        \n",
    "        # Basic DNS records\n",
    "        try:\n",
    "            dns_info['a_records'] = [str(rdata) for rdata in dns.resolver.resolve(self.target, 'A')]\n",
    "            dns_info['mx_records'] = [str(rdata.exchange) for rdata in dns.resolver.resolve(self.target, 'MX')]\n",
    "            dns_info['ns_records'] = [str(rdata) for rdata in dns.resolver.resolve(self.target, 'NS')]\n",
    "            dns_info['txt_records'] = [str(rdata) for rdata in dns.resolver.resolve(self.target, 'TXT')]\n",
    "        except Exception as e:\n",
    "            print(f\"DNS lookup error: {e}\")\n",
    "        \n",
    "        # Subdomain enumeration using wordlist\n",
    "        common_subdomains = ['www', 'mail', 'ftp', 'admin', 'api', 'dev', 'test', 'staging', 'blog', 'shop']\n",
    "        \n",
    "        for sub in common_subdomains:\n",
    "            subdomain = f\"{sub}.{self.target}\"\n",
    "            try:\n",
    "                ip = socket.gethostbyname(subdomain)\n",
    "                dns_info['subdomains'].append({\n",
    "                    'subdomain': subdomain,\n",
    "                    'ip': ip\n",
    "                })\n",
    "            except socket.gaierror:\n",
    "                pass\n",
    "        \n",
    "        self.findings['dns'] = dns_info\n",
    "        return dns_info\n",
    "    \n",
    "    def web_fingerprinting(self):\n",
    "        \"\"\"\n",
    "        Identify technologies, frameworks, and server information\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = requests.get(self.base_url, timeout=10)\n",
    "            headers = response.headers\n",
    "            \n",
    "            fingerprint = {\n",
    "                'server': headers.get('Server', 'Not disclosed'),\n",
    "                'powered_by': headers.get('X-Powered-By', 'Not disclosed'),\n",
    "                'framework': None,\n",
    "                'cms': None,\n",
    "                'technologies': []\n",
    "            }\n",
    "            \n",
    "            # Framework detection via headers\n",
    "            if 'django' in headers.get('Server', '').lower() or 'csrftoken' in str(headers):\n",
    "                fingerprint['framework'] = 'Django'\n",
    "                fingerprint['technologies'].append('Python')\n",
    "            \n",
    "            if 'express' in headers.get('X-Powered-By', '').lower():\n",
    "                fingerprint['framework'] = 'Express.js'\n",
    "                fingerprint['technologies'].append('Node.js')\n",
    "            \n",
    "            if 'asp.net' in headers.get('X-Powered-By', '').lower():\n",
    "                fingerprint['framework'] = 'ASP.NET'\n",
    "                fingerprint['technologies'].append('.NET')\n",
    "            \n",
    "            # CMS Detection via meta tags\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            generator = soup.find('meta', attrs={'name': 'generator'})\n",
    "            if generator:\n",
    "                fingerprint['cms'] = generator.get('content')\n",
    "            \n",
    "            # Check for common paths\n",
    "            tech_indicators = {\n",
    "                'wp-content': 'WordPress',\n",
    "                'drupal': 'Drupal',\n",
    "                'joomla': 'Joomla',\n",
    "                'rails': 'Ruby on Rails',\n",
    "                'laravel': 'Laravel',\n",
    "                'react': 'React',\n",
    "                'vue': 'Vue.js',\n",
    "                'angular': 'Angular'\n",
    "            }\n",
    "            \n",
    "            for indicator, tech in tech_indicators.items():\n",
    "                if indicator in response.text.lower():\n",
    "                    fingerprint['technologies'].append(tech)\n",
    "            \n",
    "            # SSL/TLS Information\n",
    "            try:\n",
    "                context = ssl.create_default_context()\n",
    "                with socket.create_connection((self.target, 443), timeout=5) as sock:\n",
    "                    with context.wrap_socket(sock, server_hostname=self.target) as ssock:\n",
    "                        cert = ssock.getpeercert()\n",
    "                        cipher = ssock.cipher()\n",
    "                        version = ssock.version()\n",
    "                        \n",
    "                        fingerprint['ssl'] = {\n",
    "                            'version': version,\n",
    "                            'cipher': cipher[0],\n",
    "                            'cert_issuer': cert.get('issuer'),\n",
    "                            'cert_subject': cert.get('subject'),\n",
    "                            'not_after': cert.get('notAfter')\n",
    "                        }\n",
    "            except Exception as e:\n",
    "                fingerprint['ssl'] = {'error': str(e)}\n",
    "            \n",
    "            self.findings['fingerprint'] = fingerprint\n",
    "            return fingerprint\n",
    "            \n",
    "        except requests.RequestException as e:\n",
    "            return {'error': str(e)}\n",
    "    \n",
    "    def enumerate_endpoints(self):\n",
    "        \"\"\"\n",
    "        Discover hidden files and directories\n",
    "        \"\"\"\n",
    "        common_paths = [\n",
    "            '/robots.txt', '/sitemap.xml', '/.git/', '/.env',\n",
    "            '/admin/', '/login/', '/api/', '/backup/', '/config/',\n",
    "            '/phpinfo.php', '/.htaccess', '/web.config',\n",
    "            '/swagger-ui.html', '/api-docs', '/graphql',\n",
    "            '/actuator/', '/health', '/metrics'\n",
    "        ]\n",
    "        \n",
    "        discovered = []\n",
    "        \n",
    "        for path in common_paths:\n",
    "            url = f\"{self.base_url}{path}\"\n",
    "            try:\n",
    "                response = requests.get(url, timeout=5, allow_redirects=False)\n",
    "                \n",
    "                if response.status_code in [200, 401, 403]:\n",
    "                    discovered.append({\n",
    "                        'path': path,\n",
    "                        'status': response.status_code,\n",
    "                        'content_length': len(response.content),\n",
    "                        'content_type': response.headers.get('Content-Type')\n",
    "                    })\n",
    "                    \n",
    "                    # Special handling for specific files\n",
    "                    if path == '/robots.txt':\n",
    "                        self.parse_robots_txt(response.text)\n",
    "                        \n",
    "            except requests.RequestException:\n",
    "                continue\n",
    "        \n",
    "        self.findings['endpoints'] = discovered\n",
    "        return discovered\n",
    "    \n",
    "    def parse_robots_txt(self, content):\n",
    "        \"\"\"\n",
    "        Parse robots.txt for sensitive paths\n",
    "        \"\"\"\n",
    "        disallowed = []\n",
    "        for line in content.split('\\n'):\n",
    "            if line.lower().startswith('disallow:'):\n",
    "                path = line.split(':', 1)[1].strip()\n",
    "                disallowed.append(path)\n",
    "        \n",
    "        self.findings['robots_disallowed'] = disallowed\n",
    "        return disallowed\n",
    "    \n",
    "    def whois_lookup(self):\n",
    "        \"\"\"\n",
    "        Domain registration information\n",
    "        \"\"\"\n",
    "        try:\n",
    "            w = whois.whois(self.target)\n",
    "            whois_info = {\n",
    "                'registrar': w.registrar,\n",
    "                'creation_date': str(w.creation_date),\n",
    "                'expiration_date': str(w.expiration_date),\n",
    "                'name_servers': w.name_servers,\n",
    "                'emails': w.emails,\n",
    "                'org': w.org\n",
    "            }\n",
    "            self.findings['whois'] = whois_info\n",
    "            return whois_info\n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "    \n",
    "    def generate_info_report(self):\n",
    "        \"\"\"\n",
    "        Generate comprehensive information gathering report\n",
    "        \"\"\"\n",
    "        report = {\n",
    "            'target': self.target,\n",
    "            'scan_date': str(datetime.now()),\n",
    "            'findings': self.findings,\n",
    "            'risk_assessment': self.assess_information_exposure()\n",
    "        }\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def assess_information_exposure(self):\n",
    "        \"\"\"\n",
    "        Assess risks from exposed information\n",
    "        \"\"\"\n",
    "        risks = []\n",
    "        \n",
    "        if self.findings.get('fingerprint', {}).get('server') != 'Not disclosed':\n",
    "            risks.append(\"Server version disclosure - potential for targeted exploits\")\n",
    "        \n",
    "        if '.git' in str(self.findings.get('endpoints', [])):\n",
    "            risks.append(\"CRITICAL: Git repository exposed - source code leakage\")\n",
    "        \n",
    "        if '.env' in str(self.findings.get('endpoints', [])):\n",
    "            risks.append(\"CRITICAL: Environment file exposed - credential leakage\")\n",
    "        \n",
    "        if 'admin' in str(self.findings.get('endpoints', [])).lower():\n",
    "            risks.append(\"Admin interface exposed - brute force target\")\n",
    "        \n",
    "        return risks\n",
    "\n",
    "# Usage Example\n",
    "# scanner = InformationGathering(\"example.com\")\n",
    "# scanner.dns_enumeration()\n",
    "# scanner.web_fingerprinting()\n",
    "# scanner.enumerate_endpoints()\n",
    "# print(scanner.generate_info_report())\n",
    "```\n",
    "\n",
    "### **40.1.3 Configuration and Deployment Management Testing**\n",
    "\n",
    "Testing for security misconfigurations in the application infrastructure:\n",
    "\n",
    "```python\n",
    "# Configuration Security Testing\n",
    "class ConfigurationTester:\n",
    "    def __init__(self, target_url):\n",
    "        self.target = target_url\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def test_http_methods(self):\n",
    "        \"\"\"\n",
    "        Test for dangerous HTTP methods (PUT, DELETE, TRACE, etc.)\n",
    "        \"\"\"\n",
    "        methods = ['GET', 'POST', 'PUT', 'DELETE', 'PATCH', 'OPTIONS', 'TRACE', 'HEAD']\n",
    "        results = {}\n",
    "        \n",
    "        for method in methods:\n",
    "            try:\n",
    "                response = self.session.request(method, self.target)\n",
    "                results[method] = {\n",
    "                    'status': response.status_code,\n",
    "                    'allowed': response.status_code not in [405, 501],\n",
    "                    'headers': dict(response.headers)\n",
    "                }\n",
    "                \n",
    "                # Check for TRACE (XST - Cross-Site Tracing)\n",
    "                if method == 'TRACE' and response.status_code == 200:\n",
    "                    results[method]['warning'] = 'TRACE enabled - XST vulnerability'\n",
    "                \n",
    "            except Exception as e:\n",
    "                results[method] = {'error': str(e)}\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def test_security_headers(self):\n",
    "        \"\"\"\n",
    "        Verify security headers implementation\n",
    "        \"\"\"\n",
    "        required_headers = {\n",
    "            'Strict-Transport-Security': {\n",
    "                'required': True,\n",
    "                'check': lambda v: 'max-age=' in v and int(v.split('max-age=')[1].split(';')[0]) >= 31536000\n",
    "            },\n",
    "            'X-Content-Type-Options': {\n",
    "                'required': True,\n",
    "                'expected': 'nosniff'\n",
    "            },\n",
    "            'X-Frame-Options': {\n",
    "                'required': True,\n",
    "                'check': lambda v: v.upper() in ['DENY', 'SAMEORIGIN']\n",
    "            },\n",
    "            'Content-Security-Policy': {\n",
    "                'required': True,\n",
    "                'check': lambda v: len(v) > 10  # Basic check for presence\n",
    "            },\n",
    "            'Referrer-Policy': {\n",
    "                'required': True\n",
    "            },\n",
    "            'Permissions-Policy': {\n",
    "                'required': False  # Optional but recommended\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = self.session.get(self.target)\n",
    "        headers = {k.lower(): v for k, v in response.headers.items()}\n",
    "        \n",
    "        findings = []\n",
    "        for header, config in required_headers.items():\n",
    "            header_lower = header.lower()\n",
    "            \n",
    "            if header_lower not in headers:\n",
    "                if config['required']:\n",
    "                    findings.append({\n",
    "                        'header': header,\n",
    "                        'status': 'MISSING',\n",
    "                        'severity': 'Medium',\n",
    "                        'recommendation': f'Add {header} header'\n",
    "                    })\n",
    "            else:\n",
    "                value = headers[header_lower]\n",
    "                if 'expected' in config and value != config['expected']:\n",
    "                    findings.append({\n",
    "                        'header': header,\n",
    "                        'status': 'MISCONFIGURED',\n",
    "                        'value': value,\n",
    "                        'expected': config['expected'],\n",
    "                        'severity': 'Low'\n",
    "                    })\n",
    "                elif 'check' in config and not config['check'](value):\n",
    "                    findings.append({\n",
    "                        'header': header,\n",
    "                        'status': 'WEAK',\n",
    "                        'value': value,\n",
    "                        'severity': 'Low'\n",
    "                    })\n",
    "        \n",
    "        return findings\n",
    "    \n",
    "    def test_ssl_configuration(self):\n",
    "        \"\"\"\n",
    "        Test SSL/TLS configuration using sslscan or similar\n",
    "        \"\"\"\n",
    "        import ssl\n",
    "        import socket\n",
    "        \n",
    "        hostname = self.target.replace('https://', '').replace('http://', '').split('/')[0]\n",
    "        \n",
    "        try:\n",
    "            context = ssl.create_default_context()\n",
    "            with socket.create_connection((hostname, 443)) as sock:\n",
    "                with context.wrap_socket(sock, server_hostname=hostname) as ssock:\n",
    "                    cert = ssock.getpeercert()\n",
    "                    cipher = ssock.cipher()\n",
    "                    version = ssock.version()\n",
    "                    \n",
    "                    findings = []\n",
    "                    \n",
    "                    # Check SSL/TLS version\n",
    "                    if version in ['SSLv2', 'SSLv3', 'TLSv1', 'TLSv1.1']:\n",
    "                        findings.append({\n",
    "                            'issue': 'Deprecated TLS version',\n",
    "                            'current': version,\n",
    "                            'severity': 'High',\n",
    "                            'recommendation': 'Upgrade to TLS 1.2 or 1.3'\n",
    "                        })\n",
    "                    \n",
    "                    # Check certificate validity\n",
    "                    from datetime import datetime\n",
    "                    not_after = cert.get('notAfter')\n",
    "                    if not_after:\n",
    "                        expiry = datetime.strptime(not_after, '%b %d %H:%M:%S %Y %Z')\n",
    "                        if expiry < datetime.now():\n",
    "                            findings.append({\n",
    "                                'issue': 'Expired certificate',\n",
    "                                'expiry': str(expiry),\n",
    "                                'severity': 'Critical'\n",
    "                            })\n",
    "                    \n",
    "                    return {\n",
    "                        'version': version,\n",
    "                        'cipher': cipher,\n",
    "                        'findings': findings\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "\n",
    "# Usage\n",
    "# tester = ConfigurationTester(\"https://example.com\")\n",
    "# print(tester.test_security_headers())\n",
    "```\n",
    "\n",
    "### **40.1.4 Authentication Testing**\n",
    "\n",
    "```python\n",
    "# Authentication Security Testing\n",
    "class AuthenticationTester:\n",
    "    def __init__(self, login_url):\n",
    "        self.login_url = login_url\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def test_credential_stuffing_protection(self, usernames, passwords):\n",
    "        \"\"\"\n",
    "        Test for brute force and credential stuffing protection\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'rate_limiting': False,\n",
    "            'account_lockout': False,\n",
    "            'captcha_present': False,\n",
    "            'observations': []\n",
    "        }\n",
    "        \n",
    "        # Attempt multiple rapid logins\n",
    "        for i, (user, pwd) in enumerate(zip(usernames[:5], passwords[:5])):\n",
    "            start_time = time.time()\n",
    "            response = self.session.post(\n",
    "                self.login_url,\n",
    "                data={'username': user, 'password': pwd}\n",
    "            )\n",
    "            duration = time.time() - start_time\n",
    "            \n",
    "            # Check for rate limiting (slow response or specific message)\n",
    "            if duration > 2:  # Arbitrary threshold\n",
    "                results['rate_limiting'] = True\n",
    "                results['observations'].append(f\"Request {i+1} delayed: {duration:.2f}s\")\n",
    "            \n",
    "            # Check for account lockout messages\n",
    "            if 'locked' in response.text.lower() or 'attempts' in response.text.lower():\n",
    "                results['account_lockout'] = True\n",
    "            \n",
    "            # Check for CAPTCHA\n",
    "            if 'captcha' in response.text.lower():\n",
    "                results['captcha_present'] = True\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def test_password_policy(self):\n",
    "        \"\"\"\n",
    "        Test password complexity requirements\n",
    "        \"\"\"\n",
    "        test_passwords = [\n",
    "            ('short', 'Too short'),\n",
    "            ('password', 'Common dictionary word'),\n",
    "            ('Password1', 'Basic complexity'),\n",
    "            ('P@ssw0rd', 'Leet speak substitution'),\n",
    "            ('1234567890', 'Sequential numbers'),\n",
    "            ('aaaaaaaa', 'Repeated characters')\n",
    "        ]\n",
    "        \n",
    "        registration_url = self.login_url.replace('login', 'register')\n",
    "        results = []\n",
    "        \n",
    "        for pwd, description in test_passwords:\n",
    "            try:\n",
    "                response = self.session.post(\n",
    "                    registration_url,\n",
    "                    data={\n",
    "                        'username': f'testuser_{random.randint(1000,9999)}',\n",
    "                        'password': pwd,\n",
    "                        'confirm_password': pwd\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                results.append({\n",
    "                    'password': pwd,\n",
    "                    'description': description,\n",
    "                    'accepted': 'success' in response.text.lower() or response.status_code == 200,\n",
    "                    'error_message': response.text if 'error' in response.text.lower() else None\n",
    "                })\n",
    "            except Exception as e:\n",
    "                results.append({'password': pwd, 'error': str(e)})\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def test_session_management(self):\n",
    "        \"\"\"\n",
    "        Test session fixation and session hijacking protections\n",
    "        \"\"\"\n",
    "        # Step 1: Get pre-login session cookie\n",
    "        pre_login = self.session.get(self.login_url)\n",
    "        pre_login_cookie = self.session.cookies.get('sessionid')\n",
    "        \n",
    "        # Step 2: Login\n",
    "        login_response = self.session.post(\n",
    "            self.login_url,\n",
    "            data={'username': 'validuser', 'password': 'validpass'}\n",
    "        )\n",
    "        post_login_cookie = self.session.cookies.get('sessionid')\n",
    "        \n",
    "        findings = []\n",
    "        \n",
    "        # Check if session ID changed after login\n",
    "        if pre_login_cookie == post_login_cookie:\n",
    "            findings.append({\n",
    "                'issue': 'Session Fixation',\n",
    "                'severity': 'High',\n",
    "                'description': 'Session ID not regenerated after authentication'\n",
    "            })\n",
    "        \n",
    "        # Check cookie flags\n",
    "        if 'set-cookie' in login_response.headers:\n",
    "            cookie_header = login_response.headers['set-cookie'].lower()\n",
    "            \n",
    "            if 'httponly' not in cookie_header:\n",
    "                findings.append({\n",
    "                    'issue': 'Missing HttpOnly flag',\n",
    "                    'severity': 'Medium'\n",
    "                })\n",
    "            \n",
    "            if 'secure' not in cookie_header:\n",
    "                findings.append({\n",
    "                    'issue': 'Missing Secure flag',\n",
    "                    'severity': 'Medium'\n",
    "                })\n",
    "            \n",
    "            if 'samesite' not in cookie_header:\n",
    "                findings.append({\n",
    "                    'issue': 'Missing SameSite attribute',\n",
    "                    'severity': 'Low'\n",
    "                })\n",
    "        \n",
    "        return findings\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **40.2 Penetration Testing Execution Standard (PTES)**\n",
    "\n",
    "### **40.2.1 PTES Framework Overview**\n",
    "\n",
    "PTES defines a standard for penetration testing execution that ensures comprehensive and consistent security assessments across 7 phases:\n",
    "\n",
    "```\n",
    "PTES Phases:\n",
    "\n",
    "1. Pre-engagement Interactions\n",
    "   ├── Scope definition\n",
    "   ├── Rules of engagement\n",
    "   ├── Legal considerations\n",
    "   └── Communication channels\n",
    "\n",
    "2. Intelligence Gathering\n",
    "   ├── Open source intelligence (OSINT)\n",
    "   ├── Human intelligence (HUMINT)\n",
    "   └── Footprinting\n",
    "\n",
    "3. Threat Modeling\n",
    "   ├── Business asset analysis\n",
    "   ├── Threat agent identification\n",
    "   └── Attack surface mapping\n",
    "\n",
    "4. Vulnerability Analysis\n",
    "   ├── Automated scanning\n",
    "   ├── Manual verification\n",
    "   └── Exploit research\n",
    "\n",
    "5. Exploitation\n",
    "   ├── Proof of concept development\n",
    "   ├── Privilege escalation\n",
    "   └── Persistence establishment\n",
    "\n",
    "6. Post Exploitation\n",
    "   ├── Data exfiltration analysis\n",
    "   ├── Pivoting opportunities\n",
    "   └── Business impact assessment\n",
    "\n",
    "7. Reporting\n",
    "   ├── Technical findings\n",
    "   ├── Executive summary\n",
    "   └── Remediation roadmap\n",
    "```\n",
    "\n",
    "### **40.2.2 Pre-engagement and Scoping**\n",
    "\n",
    "```python\n",
    "# PTES Pre-engagement Documentation Generator\n",
    "class PTESPreEngagement:\n",
    "    def __init__(self, client_name, start_date, end_date):\n",
    "        self.client = client_name\n",
    "        self.start = start_date\n",
    "        self.end = end_date\n",
    "        self.scope = {}\n",
    "        self.rules = {}\n",
    "    \n",
    "    def define_scope(self, in_scope, out_of_scope, limitations):\n",
    "        \"\"\"\n",
    "        Define testing scope with explicit boundaries\n",
    "        \"\"\"\n",
    "        self.scope = {\n",
    "            'in_scope_assets': in_scope,  # IPs, domains, apps\n",
    "            'out_of_scope': out_of_scope,\n",
    "            'testing_limitations': limitations,\n",
    "            'testing_windows': 'Business hours only / 24x7',\n",
    "            'excluded_vulnerabilities': [\n",
    "                'Physical security testing',\n",
    "                'Social engineering without approval',\n",
    "                'DoS attacks',\n",
    "                'Data destruction'\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def generate_roe_document(self):\n",
    "        \"\"\"\n",
    "        Generate Rules of Engagement document\n",
    "        \"\"\"\n",
    "        roe = f\"\"\"\n",
    "        RULES OF ENGAGEMENT\n",
    "        ==================\n",
    "        \n",
    "        Client: {self.client}\n",
    "        Assessment Period: {self.start} to {self.end}\n",
    "        \n",
    "        1. AUTHORIZATION\n",
    "        This document serves as written authorization for security testing \n",
    "        of the defined scope. Any testing outside defined scope is prohibited.\n",
    "        \n",
    "        2. SCOPE\n",
    "        In-Scope Assets:\n",
    "        {chr(10).join(f\"  - {asset}\" for asset in self.scope.get('in_scope_assets', []))}\n",
    "        \n",
    "        Out-of-Scope:\n",
    "        {chr(10).join(f\"  - {item}\" for item in self.scope.get('out_of_scope', []))}\n",
    "        \n",
    "        3. TESTING CONSTRAINTS\n",
    "        - Testing Window: {self.scope.get('testing_windows')}\n",
    "        - Maximum impact: Non-destructive only\n",
    "        - Notification requirements: 24 hours for critical findings\n",
    "        \n",
    "        4. EMERGENCY CONTACTS\n",
    "        Primary: [Security Team Lead]\n",
    "        Secondary: [IT Operations]\n",
    "        Escalation: [CISO]\n",
    "        \n",
    "        5. DELIVERABLES\n",
    "        - Executive Summary\n",
    "        - Technical Findings Report\n",
    "        - Remediation Roadmap\n",
    "        - Raw scan data (optional)\n",
    "        \n",
    "        6. LEGAL CONSIDERATIONS\n",
    "        - Confidentiality: All data handled per NDA\n",
    "        - Data retention: 90 days post-delivery, then secure destruction\n",
    "        - Compliance: Testing aligned with industry regulations (PCI-DSS, HIPAA, etc.)\n",
    "        \n",
    "        Signed: _________________ Date: _________________\n",
    "        Client Representative\n",
    "        \"\"\"\n",
    "        return roe\n",
    "\n",
    "    def create_testing_matrix(self):\n",
    "        \"\"\"\n",
    "        Create testing methodology matrix per PTES\n",
    "        \"\"\"\n",
    "        matrix = {\n",
    "            'Information_Gathering': {\n",
    "                'passive': ['WHOIS', 'DNS enumeration', 'OSINT'],\n",
    "                'active': ['Port scanning', 'Service enumeration'],\n",
    "                'tools': ['theHarvester', 'Maltego', 'Nmap'],\n",
    "                'time_estimate': '8 hours'\n",
    "            },\n",
    "            'Vulnerability_Analysis': {\n",
    "                'automated': ['Nessus', 'OpenVAS', 'Nuclei'],\n",
    "                'manual': ['Configuration review', 'Version checking'],\n",
    "                'validation': ['False positive removal', 'Exploitability assessment'],\n",
    "                'time_estimate': '16 hours'\n",
    "            },\n",
    "            'Exploitation': {\n",
    "                'approach': 'Controlled exploitation with safety measures',\n",
    "                'tools': ['Metasploit', 'Manual exploits', 'Custom scripts'],\n",
    "                'constraints': ['No production data modification without approval'],\n",
    "                'time_estimate': '16 hours'\n",
    "            },\n",
    "            'Post_Exploitation': {\n",
    "                'activities': ['Privilege escalation testing', 'Lateral movement analysis'],\n",
    "                'data_handling': 'Screenshots and logs only, no sensitive data extraction',\n",
    "                'time_estimate': '8 hours'\n",
    "            }\n",
    "        }\n",
    "        return matrix\n",
    "```\n",
    "\n",
    "### **40.2.3 Threat Modeling**\n",
    "\n",
    "```python\n",
    "# Threat Modeling using STRIDE methodology\n",
    "class ThreatModeling:\n",
    "    \"\"\"\n",
    "    STRIDE Threat Classification:\n",
    "    - Spoofing\n",
    "    - Tampering\n",
    "    - Repudiation\n",
    "    - Information Disclosure\n",
    "    - Denial of Service\n",
    "    - Elevation of Privilege\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, application_name, data_flow_diagram=None):\n",
    "        self.app = application_name\n",
    "        self.dfd = data_flow_diagram  # Data Flow Diagram\n",
    "        self.threats = []\n",
    "    \n",
    "    def identify_threats(self, component_type, component_name, data_flow):\n",
    "        \"\"\"\n",
    "        Identify threats based on component type\n",
    "        \"\"\"\n",
    "        threats = []\n",
    "        \n",
    "        if component_type == 'process':\n",
    "            threats.extend([\n",
    "                {'type': 'Spoofing', 'description': f'Impersonation of {component_name}'},\n",
    "                {'type': 'Tampering', 'description': f'Code modification of {component_name}'},\n",
    "                {'type': 'Repudiation', 'description': f'Lack of audit logging in {component_name}'},\n",
    "                {'type': 'Elevation of Privilege', 'description': f'Unauthorized access to {component_name}'}\n",
    "            ])\n",
    "        \n",
    "        elif component_type == 'data_store':\n",
    "            threats.extend([\n",
    "                {'type': 'Tampering', 'description': f'Data modification in {component_name}'},\n",
    "                {'type': 'Information Disclosure', 'description': f'Unauthorized data access in {component_name}'},\n",
    "                {'type': 'Denial of Service', 'description': f'Resource exhaustion of {component_name}'}\n",
    "            ])\n",
    "        \n",
    "        elif component_type == 'data_flow':\n",
    "            threats.extend([\n",
    "                {'type': 'Tampering', 'description': f'Man-in-the-middle attack on {component_name}'},\n",
    "                {'type': 'Information Disclosure', 'description': f'Eavesdropping on {component_name}'},\n",
    "                {'type': 'Denial of Service', 'description': f'Traffic flooding of {component_name}'}\n",
    "            ])\n",
    "        \n",
    "        elif component_type == 'external_entity':\n",
    "            threats.extend([\n",
    "                {'type': 'Spoofing', 'description': f'Fake {component_name} connection'},\n",
    "                {'type': 'Repudiation', 'description': f'{component_name} denying actions'}\n",
    "            ])\n",
    "        \n",
    "        for threat in threats:\n",
    "            threat['component'] = component_name\n",
    "            threat['mitigation'] = self.suggest_mitigation(threat['type'], component_type)\n",
    "            self.threats.append(threat)\n",
    "        \n",
    "        return threats\n",
    "    \n",
    "    def suggest_mitigation(self, threat_type, component_type):\n",
    "        \"\"\"\n",
    "        Suggest mitigations based on threat type\n",
    "        \"\"\"\n",
    "        mitigations = {\n",
    "            'Spoofing': {\n",
    "                'process': 'Authentication, Digital signatures',\n",
    "                'external_entity': 'Certificate pinning, Mutual TLS',\n",
    "                'default': 'Strong authentication mechanisms'\n",
    "            },\n",
    "            'Tampering': {\n",
    "                'data_flow': 'TLS/SSL, Message authentication codes',\n",
    "                'data_store': 'Access controls, Integrity checks',\n",
    "                'process': 'Code signing, Input validation',\n",
    "                'default': 'Integrity verification'\n",
    "            },\n",
    "            'Repudiation': {\n",
    "                'process': 'Audit logging, Digital signatures, Timestamps',\n",
    "                'external_entity': 'Secure logging, Non-repudiation protocols',\n",
    "                'default': 'Comprehensive logging'\n",
    "            },\n",
    "            'Information Disclosure': {\n",
    "                'data_flow': 'Encryption, Access controls',\n",
    "                'data_store': 'Encryption at rest, Access controls, Data masking',\n",
    "                'process': 'Minimal privilege, Secure memory handling',\n",
    "                'default': 'Confidentiality controls'\n",
    "            },\n",
    "            'Denial of Service': {\n",
    "                'data_flow': 'Rate limiting, Traffic filtering',\n",
    "                'data_store': 'Resource quotas, Redundancy',\n",
    "                'process': 'Input validation, Resource management',\n",
    "                'default': 'Availability controls'\n",
    "            },\n",
    "            'Elevation of Privilege': {\n",
    "                'process': 'Authorization checks, Input validation, Sandboxing',\n",
    "                'default': 'Least privilege, Access controls'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if threat_type in mitigations:\n",
    "            if component_type in mitigations[threat_type]:\n",
    "                return mitigations[threat_type][component_type]\n",
    "            return mitigations[threat_type].get('default', 'Implement security controls')\n",
    "        \n",
    "        return 'Review and implement appropriate controls'\n",
    "    \n",
    "    def calculate_risk_score(self, threat, likelihood=3, impact=3):\n",
    "        \"\"\"\n",
    "        Calculate risk score: Likelihood (1-5) * Impact (1-5)\n",
    "        \"\"\"\n",
    "        risk_matrix = {\n",
    "            (1, 1): 'Low', (1, 2): 'Low', (1, 3): 'Low',\n",
    "            (2, 1): 'Low', (2, 2): 'Medium', (2, 3): 'Medium',\n",
    "            (3, 1): 'Low', (3, 2): 'Medium', (3, 3): 'High',\n",
    "            (4, 1): 'Medium', (4, 2): 'High', (4, 3): 'Critical',\n",
    "            (5, 1): 'Medium', (5, 2): 'High', (5, 3): 'Critical'\n",
    "        }\n",
    "        \n",
    "        score = likelihood * impact\n",
    "        severity = risk_matrix.get((likelihood, impact), 'Unknown')\n",
    "        \n",
    "        return {\n",
    "            'score': score,\n",
    "            'severity': severity,\n",
    "            'likelihood': likelihood,\n",
    "            'impact': impact\n",
    "        }\n",
    "    \n",
    "    def generate_threat_model_report(self):\n",
    "        \"\"\"\n",
    "        Generate comprehensive threat model document\n",
    "        \"\"\"\n",
    "        report = {\n",
    "            'application': self.app,\n",
    "            'methodology': 'STRIDE',\n",
    "            'total_threats': len(self.threats),\n",
    "            'threats_by_category': {},\n",
    "            'threats': self.threats\n",
    "        }\n",
    "        \n",
    "        # Categorize threats\n",
    "        for threat in self.threats:\n",
    "            category = threat['type']\n",
    "            if category not in report['threats_by_category']:\n",
    "                report['threats_by_category'][category] = 0\n",
    "            report['threats_by_category'][category] += 1\n",
    "        \n",
    "        return report\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **40.3 API Security Testing**\n",
    "\n",
    "### **40.3.1 REST API Security Testing**\n",
    "\n",
    "```python\n",
    "# Comprehensive API Security Testing\n",
    "class APISecurityTester:\n",
    "    def __init__(self, base_url, api_key=None):\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "        if api_key:\n",
    "            self.session.headers.update({'Authorization': f'Bearer {api_key}'})\n",
    "    \n",
    "    def test_authentication_bypass(self, endpoints):\n",
    "        \"\"\"\n",
    "        Test for authentication bypass vulnerabilities\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for endpoint in endpoints:\n",
    "            # Test 1: No authentication\n",
    "            response = requests.get(f\"{self.base_url}{endpoint}\")\n",
    "            if response.status_code != 401:\n",
    "                results.append({\n",
    "                    'endpoint': endpoint,\n",
    "                    'issue': 'Missing authentication',\n",
    "                    'severity': 'Critical',\n",
    "                    'status_code': response.status_code\n",
    "                })\n",
    "            \n",
    "            # Test 2: Null/Empty tokens\n",
    "            headers = {'Authorization': 'Bearer '}\n",
    "            response = requests.get(\n",
    "                f\"{self.base_url}{endpoint}\",\n",
    "                headers=headers\n",
    "            )\n",
    "            if response.status_code == 200:\n",
    "                results.append({\n",
    "                    'endpoint': endpoint,\n",
    "                    'issue': 'Empty token accepted',\n",
    "                    'severity': 'Critical'\n",
    "                })\n",
    "            \n",
    "            # Test 3: Token manipulation (JWT algorithm confusion)\n",
    "            if 'Authorization' in self.session.headers:\n",
    "                token = self.session.headers['Authorization'].replace('Bearer ', '')\n",
    "                if '.' in token:  # Likely JWT\n",
    "                    # Try algorithm confusion attack (none/None)\n",
    "                    parts = token.split('.')\n",
    "                    if len(parts) == 3:\n",
    "                        header = json.loads(base64.b64decode(parts[0] + '=='))\n",
    "                        header['alg'] = 'none'\n",
    "                        new_header = base64.b64encode(json.dumps(header).encode()).decode().rstrip('=')\n",
    "                        malicious_token = f\"{new_header}.{parts[1]}.{parts[2]}\"\n",
    "                        \n",
    "                        resp = requests.get(\n",
    "                            f\"{self.base_url}{endpoint}\",\n",
    "                            headers={'Authorization': f'Bearer {malicious_token}'}\n",
    "                        )\n",
    "                        if resp.status_code == 200:\n",
    "                            results.append({\n",
    "                                'endpoint': endpoint,\n",
    "                                'issue': 'JWT Algorithm Confusion (none)',\n",
    "                                'severity': 'Critical'\n",
    "                            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def test_authorization(self, user_endpoints, admin_endpoints):\n",
    "        \"\"\"\n",
    "        Test horizontal and vertical authorization controls\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # Horizontal IDOR testing\n",
    "        for endpoint in user_endpoints:\n",
    "            # Try accessing other users' resources\n",
    "            for id in [1, 2, 999]:\n",
    "                response = self.session.get(f\"{self.base_url}{endpoint}/{id}\")\n",
    "                if response.status_code == 200 and id != self.current_user_id():\n",
    "                    results.append({\n",
    "                        'type': 'IDOR',\n",
    "                        'endpoint': f\"{endpoint}/{id}\",\n",
    "                        'issue': 'Access to other user data',\n",
    "                        'severity': 'High'\n",
    "                    })\n",
    "        \n",
    "        # Vertical privilege escalation\n",
    "        for endpoint in admin_endpoints:\n",
    "            response = self.session.get(f\"{self.base_url}{endpoint}\")\n",
    "            if response.status_code == 200:\n",
    "                results.append({\n",
    "                    'type': 'Vertical Escalation',\n",
    "                    'endpoint': endpoint,\n",
    "                    'issue': 'User can access admin functionality',\n",
    "                    'severity': 'Critical'\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def test_input_validation(self, endpoints_with_params):\n",
    "        \"\"\"\n",
    "        Test for injection and validation vulnerabilities\n",
    "        \"\"\"\n",
    "        payloads = {\n",
    "            'sql_injection': [\"' OR '1'='1\", \"1 AND 1=1\", \"1 AND 1=2\"],\n",
    "            'xss': [\"<script>alert(1)</script>\", \"<img src=x onerror=alert(1)>\"],\n",
    "            'command_injection': [\"; id\", \"| whoami\", \"$(cat /etc/passwd)\"],\n",
    "            'path_traversal': [\"../../../etc/passwd\", \"..\\\\..\\\\..\\\\windows\\\\system32\\\\config\\\\sam\"],\n",
    "            'ssrf': [\"http://169.254.169.254/latest/meta-data/\", \"file:///etc/passwd\"]\n",
    "        }\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for endpoint, param in endpoints_with_params:\n",
    "            for attack_type, tests in payloads.items():\n",
    "                for payload in tests:\n",
    "                    data = {param: payload}\n",
    "                    response = self.session.post(f\"{self.base_url}{endpoint}\", json=data)\n",
    "                    \n",
    "                    # Check for indicators of vulnerability\n",
    "                    indicators = self.check_vulnerability_indicators(response, attack_type)\n",
    "                    if indicators:\n",
    "                        results.append({\n",
    "                            'endpoint': endpoint,\n",
    "                            'param': param,\n",
    "                            'attack_type': attack_type,\n",
    "                            'payload': payload,\n",
    "                            'indicators': indicators,\n",
    "                            'severity': 'High'\n",
    "                        })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def check_vulnerability_indicators(self, response, attack_type):\n",
    "        \"\"\"\n",
    "        Check response for signs of successful injection\n",
    "        \"\"\"\n",
    "        indicators = []\n",
    "        content = response.text.lower()\n",
    "        \n",
    "        if attack_type == 'sql_injection':\n",
    "            sql_errors = ['sql syntax', 'mysql_fetch', 'ora-', 'postgresql', 'sqlite3']\n",
    "            if any(err in content for err in sql_errors):\n",
    "                indicators.append('SQL error message detected')\n",
    "            if response.status_code == 500:\n",
    "                indicators.append('Server error (possible SQL error)')\n",
    "        \n",
    "        elif attack_type == 'command_injection':\n",
    "            unix_indicators = ['uid=', 'gid=', 'root:x:', 'bin/bash']\n",
    "            windows_indicators = ['windows ip configuration', 'volume serial number']\n",
    "            if any(ind in content for ind in unix_indicators + windows_indicators):\n",
    "                indicators.append('Command output detected')\n",
    "        \n",
    "        elif attack_type == 'xss':\n",
    "            if '<script>' in response.text and 'alert' in response.text:\n",
    "                indicators.append('XSS payload reflected without encoding')\n",
    "        \n",
    "        elif attack_type == 'ssrf':\n",
    "            if 'amazon' in content or 'ec2' in content or 'metadata' in content:\n",
    "                indicators.append('Cloud metadata accessible')\n",
    "        \n",
    "        return indicators\n",
    "    \n",
    "    def test_mass_assignment(self, endpoint, valid_payload):\n",
    "        \"\"\"\n",
    "        Test for mass assignment vulnerabilities (binding client data to model)\n",
    "        \"\"\"\n",
    "        # Add sensitive fields that shouldn't be user-modifiable\n",
    "        malicious_payload = valid_payload.copy()\n",
    "        malicious_payload.update({\n",
    "            'is_admin': True,\n",
    "            'role': 'admin',\n",
    "            'id': 1,\n",
    "            'created_at': '2020-01-01',\n",
    "            'password': 'hacked123',\n",
    "            'credit': 999999\n",
    "        })\n",
    "        \n",
    "        response = self.session.post(f\"{self.base_url}{endpoint}\", json=malicious_payload)\n",
    "        \n",
    "        # Check if sensitive fields were accepted\n",
    "        get_response = self.session.get(f\"{self.base_url}{endpoint}/profile\")\n",
    "        \n",
    "        findings = []\n",
    "        if 'is_admin' in get_response.text and '\"is_admin\": true' in get_response.text:\n",
    "            findings.append({\n",
    "                'issue': 'Mass Assignment - is_admin field accepted',\n",
    "                'severity': 'Critical'\n",
    "            })\n",
    "        \n",
    "        return findings\n",
    "    \n",
    "    def test_rate_limiting(self, endpoint, requests_count=100):\n",
    "        \"\"\"\n",
    "        Test for API rate limiting\n",
    "        \"\"\"\n",
    "        responses = []\n",
    "        for i in range(requests_count):\n",
    "            response = self.session.get(f\"{self.base_url}{endpoint}\")\n",
    "            responses.append(response.status_code)\n",
    "            \n",
    "            if response.status_code in [429, 503]:\n",
    "                return {\n",
    "                    'rate_limited': True,\n",
    "                    'threshold': i + 1,\n",
    "                    'reset_header': response.headers.get('Retry-After'),\n",
    "                    'status': 'Protected'\n",
    "                }\n",
    "        \n",
    "        unique_codes = set(responses)\n",
    "        if 200 in unique_codes and len(unique_codes) == 1:\n",
    "            return {\n",
    "                'rate_limited': False,\n",
    "                'total_requests': requests_count,\n",
    "                'status': 'VULNERABLE - No rate limiting detected',\n",
    "                'severity': 'Medium'\n",
    "            }\n",
    "        \n",
    "        return {'rate_limited': True, 'status': 'Protected'}\n",
    "    \n",
    "    def current_user_id(self):\n",
    "        \"\"\"Helper to get current user ID from token/session\"\"\"\n",
    "        # Implementation depends on API structure\n",
    "        return 1\n",
    "```\n",
    "\n",
    "### **40.3.2 GraphQL Security Testing**\n",
    "\n",
    "```python\n",
    "# GraphQL Specific Security Testing\n",
    "class GraphQLTester:\n",
    "    def __init__(self, endpoint):\n",
    "        self.endpoint = endpoint\n",
    "    \n",
    "    def introspection_query(self):\n",
    "        \"\"\"\n",
    "        Check if introspection is enabled (information disclosure)\n",
    "        \"\"\"\n",
    "        query = \"\"\"\n",
    "        query IntrospectionQuery {\n",
    "          __schema {\n",
    "            queryType { name }\n",
    "            mutationType { name }\n",
    "            subscriptionType { name }\n",
    "            types {\n",
    "              ...FullType\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "        fragment FullType on __Type {\n",
    "          name\n",
    "          kind\n",
    "          fields {\n",
    "            name\n",
    "            type { name }\n",
    "            args {\n",
    "              name\n",
    "              type { name }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        response = requests.post(\n",
    "            self.endpoint,\n",
    "            json={'query': query}\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200 and '__schema' in response.text:\n",
    "            return {\n",
    "                'vulnerability': 'Introspection Enabled',\n",
    "                'severity': 'Medium',\n",
    "                'description': 'Schema can be dumped revealing all types and fields',\n",
    "                'data': response.json()\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def test_query_depth(self, max_depth=10):\n",
    "        \"\"\"\n",
    "        Test for query depth limiting (DoS prevention)\n",
    "        \"\"\"\n",
    "        # Build nested query\n",
    "        nested_query = \"user {\"\n",
    "        for _ in range(max_depth):\n",
    "            nested_query += \" friends {\"\n",
    "        nested_query += \" name \" + \"}\" * (max_depth + 1)\n",
    "        \n",
    "        query = f\"{{ {nested_query} }}\"\n",
    "        \n",
    "        response = requests.post(\n",
    "            self.endpoint,\n",
    "            json={'query': query}\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return {\n",
    "                'vulnerability': 'No Query Depth Limit',\n",
    "                'severity': 'Medium',\n",
    "                'description': f'Query with depth {max_depth} was accepted, potential DoS'\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def test_batch_queries(self):\n",
    "        \"\"\"\n",
    "        Test for query batching (can bypass rate limiting)\n",
    "        \"\"\"\n",
    "        queries = [\n",
    "            {'query': '{ user(id: 1) { name } }'},\n",
    "            {'query': '{ user(id: 2) { name } }'},\n",
    "            {'query': '{ user(id: 3) { name } }'}\n",
    "        ]\n",
    "        \n",
    "        response = requests.post(\n",
    "            self.endpoint,\n",
    "            json=queries  # Send array instead of single object\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if isinstance(data, list) and len(data) == len(queries):\n",
    "                return {\n",
    "                    'vulnerability': 'Query Batching Enabled',\n",
    "                    'severity': 'Low',\n",
    "                    'description': 'Multiple queries accepted in single request, can bypass rate limits'\n",
    "                }\n",
    "        return None\n",
    "    \n",
    "    def test_field_suggestions(self):\n",
    "        \"\"\"\n",
    "        Check if field suggestions leak schema information\n",
    "        \"\"\"\n",
    "        query = \"{ usr { name } }\"  # Typo: usr instead of user\n",
    "        \n",
    "        response = requests.post(\n",
    "            self.endpoint,\n",
    "            json={'query': query}\n",
    "        )\n",
    "        \n",
    "        if 'did you mean' in response.text.lower() or 'user' in response.text:\n",
    "            return {\n",
    "                'vulnerability': 'Field Suggestions Enabled',\n",
    "                'severity': 'Info',\n",
    "                'description': 'Error messages reveal valid field names'\n",
    "            }\n",
    "        return None\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **40.4 Mobile Application Security Testing**\n",
    "\n",
    "### **40.4.1 Mobile Testing Methodology**\n",
    "\n",
    "```python\n",
    "# Mobile App Security Testing Framework\n",
    "class MobileSecurityTester:\n",
    "    \"\"\"\n",
    "    Mobile App Security Testing (MAST) methodology\n",
    "    Covers OWASP Mobile Top 10 and MASVS (Mobile Application Security Verification Standard)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, app_binary, platform='android'):\n",
    "        self.app = app_binary\n",
    "        self.platform = platform.lower()\n",
    "        self.findings = []\n",
    "    \n",
    "    def static_analysis(self):\n",
    "        \"\"\"\n",
    "        Static Application Security Testing (SAST) for mobile\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'hardcoded_secrets': self.find_hardcoded_secrets(),\n",
    "            'insecure_storage': self.check_insecure_storage(),\n",
    "            'code_obfuscation': self.check_obfuscation(),\n",
    "            'debug_flags': self.check_debug_flags(),\n",
    "            'backup_vulnerabilities': self.check_backup_issues()\n",
    "        }\n",
    "        return results\n",
    "    \n",
    "    def find_hardcoded_secrets(self):\n",
    "        \"\"\"\n",
    "        Search for hardcoded API keys, passwords, tokens in binary\n",
    "        \"\"\"\n",
    "        patterns = [\n",
    "            r'api[_-]?key\\s*[=:]\\s*[\"\\'][a-zA-Z0-9]{16,}[\"\\']',\n",
    "            r'password\\s*[=:]\\s*[\"\\'][^\"\\']+[\"\\']',\n",
    "            r'aws_access_key_id\\s*[=:]\\s*[\"\\']AKIA[0-9A-Z]{16}[\"\\']',\n",
    "            r'private[_-]?key',\n",
    "            r'secret[_-]?key'\n",
    "        ]\n",
    "        \n",
    "        findings = []\n",
    "        # Implementation would use strings command or apktool/jadx output\n",
    "        # Example with strings command:\n",
    "        try:\n",
    "            output = subprocess.check_output(['strings', self.app]).decode('utf-8', errors='ignore')\n",
    "            for pattern in patterns:\n",
    "                matches = re.findall(pattern, output, re.IGNORECASE)\n",
    "                if matches:\n",
    "                    findings.append({\n",
    "                        'pattern': pattern,\n",
    "                        'matches': matches[:5],  # Limit output\n",
    "                        'severity': 'High'\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            findings.append({'error': str(e)})\n",
    "        \n",
    "        return findings\n",
    "    \n",
    "    def check_insecure_storage(self):\n",
    "        \"\"\"\n",
    "        Check for insecure local data storage\n",
    "        \"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        # Check for SharedPreferences (Android) or UserDefaults (iOS)\n",
    "        if self.platform == 'android':\n",
    "            # Look for MODE_WORLD_READABLE or MODE_WORLD_WRITEABLE\n",
    "            if 'MODE_WORLD_READABLE' in open(self.app, 'rb').read().decode('utf-8', errors='ignore'):\n",
    "                issues.append('World-readable SharedPreferences detected')\n",
    "            \n",
    "            # Check for external storage usage\n",
    "            if 'getExternalStorageDirectory' in str(subprocess.check_output(['unzip', '-l', self.app])):\n",
    "                issues.append('External storage usage detected - potential data leakage')\n",
    "        \n",
    "        return issues\n",
    "    \n",
    "    def dynamic_analysis_setup(self):\n",
    "        \"\"\"\n",
    "        Setup for dynamic testing (Frida/Objection setup)\n",
    "        \"\"\"\n",
    "        setup_commands = {\n",
    "            'android': [\n",
    "                'adb devices',  # Verify device connection\n",
    "                'adb root',     # Root access\n",
    "                'frida-server &',  # Start Frida server\n",
    "                'objection --gadget com.example.app explore'  # Start Objection\n",
    "            ],\n",
    "            'ios': [\n",
    "                'ios-deploy --list',  # List devices\n",
    "                'frida -U -f com.example.app',  # Spawn app with Frida\n",
    "                'objection --gadget com.example.app explore'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        return setup_commands.get(self.platform, [])\n",
    "    \n",
    "    def test_ssl_pinning_bypass(self):\n",
    "        \"\"\"\n",
    "        SSL Pinning bypass techniques\n",
    "        \"\"\"\n",
    "        techniques = {\n",
    "            'android': [\n",
    "                'Frida script: android-ssl-pinning-disable',\n",
    "                'Objection: android sslpinning disable',\n",
    "                'Xposed module: SSLUnpinning',\n",
    "                'APK patching: Remove pinning logic from smali'\n",
    "            ],\n",
    "            'ios': [\n",
    "                'Frida script: ios-ssl-pinning-disable',\n",
    "                'Objection: ios sslpinning disable',\n",
    "                'SSL Kill Switch 2 (Cydia tweak)',\n",
    "                'Binary patching: nop out pinning checks'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'platform': self.platform,\n",
    "            'bypass_techniques': techniques.get(self.platform),\n",
    "            'test_script': self.generate_frida_ssl_script()\n",
    "        }\n",
    "    \n",
    "    def generate_frida_ssl_script(self):\n",
    "        \"\"\"\n",
    "        Generate Frida script for SSL pinning bypass\n",
    "        \"\"\"\n",
    "        if self.platform == 'android':\n",
    "            return \"\"\"\n",
    "            Java.perform(function() {\n",
    "                var array_list = Java.use(\"java.util.ArrayList\");\n",
    "                var TrustManagerImpl = Java.use(\"com.android.org.conscrypt.TrustManagerImpl\");\n",
    "                \n",
    "                TrustManagerImpl.checkTrustedRecursive.implementation = function() {\n",
    "                    return array_list.$new();\n",
    "                };\n",
    "            });\n",
    "            \"\"\"\n",
    "        else:\n",
    "            return \"\"\"\n",
    "            var SSL pinning bypass for iOS\n",
    "            \"\"\"\n",
    "    \n",
    "    def generate_mobsf_report(self):\n",
    "        \"\"\"\n",
    "        Generate report compatible with Mobile Security Framework\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'file_name': self.app,\n",
    "            'platform': self.platform,\n",
    "            'security_score': self.calculate_score(),\n",
    "            'findings': self.findings,\n",
    "            'compliance': {\n",
    "                'OWASP_MASVS': self.check_masvs_compliance(),\n",
    "                'OWASP_Mobile_Top_10': self.check_mobile_top10()\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def calculate_score(self):\n",
    "        \"\"\"Calculate security score based on findings\"\"\"\n",
    "        base_score = 100\n",
    "        for finding in self.findings:\n",
    "            if finding['severity'] == 'Critical':\n",
    "                base_score -= 20\n",
    "            elif finding['severity'] == 'High':\n",
    "                base_score -= 10\n",
    "            elif finding['severity'] == 'Medium':\n",
    "                base_score -= 5\n",
    "            else:\n",
    "                base_score -= 1\n",
    "        return max(0, base_score)\n",
    "    \n",
    "    def check_masvs_compliance(self):\n",
    "        \"\"\"Check against Mobile Application Security Verification Standard\"\"\"\n",
    "        # MASVS Levels: L1 (Standard), L2 (Defense in Depth), L3 (Resilient)\n",
    "        return {\n",
    "            'L1_Storage': 'Pass' if not self.find_hardcoded_secrets() else 'Fail',\n",
    "            'L1_Crypto': 'Pass',  # Would check crypto implementation\n",
    "            'L1_Auth': 'Pass',    # Would check auth mechanisms\n",
    "            'L1_Network': 'Pass' if self.test_ssl_pinning_bypass() else 'Fail'\n",
    "        }\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **40.5 Cloud Security Testing**\n",
    "\n",
    "### **40.5.1 AWS Security Assessment**\n",
    "\n",
    "```python\n",
    "# AWS Cloud Security Testing\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "class AWSSecurityTester:\n",
    "    def __init__(self, profile_name='default'):\n",
    "        self.session = boto3.Session(profile_name=profile_name)\n",
    "        self.findings = []\n",
    "    \n",
    "    def s3_security_audit(self):\n",
    "        \"\"\"\n",
    "        S3 Bucket Security Assessment\n",
    "        \"\"\"\n",
    "        s3 = self.session.client('s3')\n",
    "        findings = []\n",
    "        \n",
    "        try:\n",
    "            buckets = s3.list_buckets()['Buckets']\n",
    "            \n",
    "            for bucket in buckets:\n",
    "                bucket_name = bucket['Name']\n",
    "                issues = []\n",
    "                \n",
    "                # Check public access settings\n",
    "                try:\n",
    "                    public_access = s3.get_public_access_block(Bucket=bucket_name)\n",
    "                    config = public_access['PublicAccessBlockConfiguration']\n",
    "                    if not all(config.values()):\n",
    "                        issues.append('Public access block not fully enabled')\n",
    "                except ClientError:\n",
    "                    issues.append('No public access block configured')\n",
    "                \n",
    "                # Check bucket policy\n",
    "                try:\n",
    "                    policy = s3.get_bucket_policy(Bucket=bucket_name)\n",
    "                    if '\"Principal\": \"*\"' in policy['Policy']:\n",
    "                        issues.append('Bucket policy allows public access')\n",
    "                except ClientError as e:\n",
    "                    if 'NoSuchBucketPolicy' not in str(e):\n",
    "                        raise\n",
    "                \n",
    "                # Check bucket ACL\n",
    "                try:\n",
    "                    acl = s3.get_bucket_acl(Bucket=bucket_name)\n",
    "                    for grant in acl['Grants']:\n",
    "                        if grant['Grantee'].get('URI') == 'http://acs.amazonaws.com/groups/global/AllUsers':\n",
    "                            issues.append('Bucket ACL grants public access')\n",
    "                except ClientError:\n",
    "                    pass\n",
    "                \n",
    "                # Check encryption\n",
    "                try:\n",
    "                    encryption = s3.get_bucket_encryption(Bucket=bucket_name)\n",
    "                except ClientError as e:\n",
    "                    if 'ServerSideEncryptionConfigurationNotFoundError' in str(e):\n",
    "                        issues.append('Bucket encryption not enabled')\n",
    "                \n",
    "                # Check versioning\n",
    "                versioning = s3.get_bucket_versioning(Bucket=bucket_name)\n",
    "                if versioning.get('Status') != 'Enabled':\n",
    "                    issues.append('Versioning not enabled - ransomware risk')\n",
    "                \n",
    "                if issues:\n",
    "                    findings.append({\n",
    "                        'bucket': bucket_name,\n",
    "                        'issues': issues,\n",
    "                        'severity': 'High' if 'public' in str(issues).lower() else 'Medium'\n",
    "                    })\n",
    "        \n",
    "        except ClientError as e:\n",
    "            findings.append({'error': str(e)})\n",
    "        \n",
    "        return findings\n",
    "    \n",
    "    def iam_security_audit(self):\n",
    "        \"\"\"\n",
    "        IAM Security Assessment\n",
    "        \"\"\"\n",
    "        iam = self.session.client('iam')\n",
    "        findings = []\n",
    "        \n",
    "        # Check for old passwords/access keys\n",
    "        users = iam.list_users()['Users']\n",
    "        for user in users:\n",
    "            username = user['UserName']\n",
    "            \n",
    "            # Check password age\n",
    "            if 'PasswordLastUsed' in user:\n",
    "                last_used = user['PasswordLastUsed']\n",
    "                age_days = (datetime.now(last_used.tzinfo) - last_used).days\n",
    "                if age_days > 90:\n",
    "                    findings.append({\n",
    "                        'user': username,\n",
    "                        'issue': f'Password not changed in {age_days} days',\n",
    "                        'severity': 'Medium'\n",
    "                    })\n",
    "            \n",
    "            # Check access keys\n",
    "            keys = iam.list_access_keys(UserName=username)['AccessKeyMetadata']\n",
    "            for key in keys:\n",
    "                if key['Status'] == 'Active':\n",
    "                    key_age = (datetime.now(key['CreateDate'].tzinfo) - key['CreateDate']).days\n",
    "                    if key_age > 90:\n",
    "                        findings.append({\n",
    "                            'user': username,\n",
    "                            'issue': f'Access key {key[\"AccessKeyId\"][:5]}... is {key_age} days old',\n",
    "                            'severity': 'Medium'\n",
    "                        })\n",
    "        \n",
    "        # Check for MFA on root account\n",
    "        try:\n",
    "            summary = iam.get_account_summary()['SummaryMap']\n",
    "            if summary.get('AccountMFAEnabled') == 0:\n",
    "                findings.append({\n",
    "                    'resource': 'Root Account',\n",
    "                    'issue': 'MFA not enabled on root account',\n",
    "                    'severity': 'Critical'\n",
    "                })\n",
    "        except ClientError:\n",
    "            pass\n",
    "        \n",
    "        return findings\n",
    "    \n",
    "    def ec2_security_audit(self):\n",
    "        \"\"\"\n",
    "        EC2 Instance Security Assessment\n",
    "        \"\"\"\n",
    "        ec2 = self.session.client('ec2')\n",
    "        findings = []\n",
    "        \n",
    "        # Check security groups for open ports\n",
    "        security_groups = ec2.describe_security_groups()['SecurityGroups']\n",
    "        for sg in security_groups:\n",
    "            for rule in sg['IpPermissions']:\n",
    "                # Check for 0.0.0.0/0\n",
    "                for ip_range in rule.get('IpRanges', []):\n",
    "                    if ip_range.get('CidrIp') == '0.0.0.0/0':\n",
    "                        port_range = f\"{rule.get('FromPort', 'All')}-{rule.get('ToPort', 'All')}\"\n",
    "                        protocol = rule.get('IpProtocol')\n",
    "                        \n",
    "                        # Critical if SSH or RDP open\n",
    "                        severity = 'Critical' if port_range in ['22-22', '3389-3389'] else 'High'\n",
    "                        \n",
    "                        findings.append({\n",
    "                            'security_group': sg['GroupId'],\n",
    "                            'issue': f'Open to world: {protocol} {port_range}',\n",
    "                            'severity': severity\n",
    "                        })\n",
    "        \n",
    "        # Check for unencrypted volumes\n",
    "        volumes = ec2.describe_volumes()['Volumes']\n",
    "        for vol in volumes:\n",
    "            if not vol.get('Encrypted'):\n",
    "                findings.append({\n",
    "                    'volume': vol['VolumeId'],\n",
    "                    'issue': 'EBS volume not encrypted',\n",
    "                    'severity': 'Medium'\n",
    "                })\n",
    "        \n",
    "        return findings\n",
    "    \n",
    "    def generate_cloud_security_report(self):\n",
    "        \"\"\"\n",
    "        Generate comprehensive cloud security report\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'scan_date': datetime.now().isoformat(),\n",
    "            'aws_account': self.session.client('sts').get_caller_identity()['Account'],\n",
    "            'findings': {\n",
    "                's3': self.s3_security_audit(),\n",
    "                'iam': self.iam_security_audit(),\n",
    "                'ec2': self.ec2_security_audit()\n",
    "            },\n",
    "            'compliance': {\n",
    "                'cis_aws_foundations': self.check_cis_compliance(),\n",
    "                'pci_dss': self.check_pci_compliance()\n",
    "            }\n",
    "        }\n",
    "```\n",
    "\n",
    "### **40.5.2 Container Security Testing**\n",
    "\n",
    "```python\n",
    "# Docker/Kubernetes Security Testing\n",
    "class ContainerSecurityTester:\n",
    "    def __init__(self, image_name):\n",
    "        self.image = image_name\n",
    "    \n",
    "    def image_vulnerability_scan(self):\n",
    "        \"\"\"\n",
    "        Scan container image for vulnerabilities using Trivy\n",
    "        \"\"\"\n",
    "        cmd = ['trivy', 'image', '--format', 'json', self.image]\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "            data = json.loads(result.stdout)\n",
    "            \n",
    "            vulnerabilities = []\n",
    "            for result in data.get('Results', []):\n",
    "                for vuln in result.get('Vulnerabilities', []):\n",
    "                    vulnerabilities.append({\n",
    "                        'id': vuln.get('VulnerabilityID'),\n",
    "                        'package': vuln.get('PkgName'),\n",
    "                        'severity': vuln.get('Severity'),\n",
    "                        'title': vuln.get('Title'),\n",
    "                        'fixed_version': vuln.get('FixedVersion')\n",
    "                    })\n",
    "            \n",
    "            return vulnerabilities\n",
    "        except Exception as e:\n",
    "            return [{'error': str(e)}]\n",
    "    \n",
    "    def dockerfile_best_practices(self, dockerfile_path):\n",
    "        \"\"\"\n",
    "        Check Dockerfile for security best practices\n",
    "        \"\"\"\n",
    "        with open(dockerfile_path, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        findings = []\n",
    "        \n",
    "        # Check for latest tag\n",
    "        if ':latest' in content or 'FROM ' in content and ':' not in content:\n",
    "            findings.append({\n",
    "                'issue': 'Using \"latest\" tag',\n",
    "                'recommendation': 'Pin to specific version',\n",
    "                'severity': 'Medium'\n",
    "            })\n",
    "        \n",
    "        # Check for running as root\n",
    "        if 'USER ' not in content:\n",
    "            findings.append({\n",
    "                'issue': 'No USER instruction - running as root',\n",
    "                'recommendation': 'Add non-root user',\n",
    "                'severity': 'High'\n",
    "            })\n",
    "        \n",
    "        # Check for secrets in ENV\n",
    "        if re.search(r'ENV.*(password|secret|key|token)', content, re.IGNORECASE):\n",
    "            findings.append({\n",
    "                'issue': 'Potential hardcoded secrets in ENV',\n",
    "                'recommendation': 'Use build args or runtime secrets',\n",
    "                'severity': 'Critical'\n",
    "            })\n",
    "        \n",
    "        # Check for ADD vs COPY\n",
    "        if 'ADD ' in content and 'http' in content:\n",
    "            findings.append({\n",
    "                'issue': 'ADD with remote URL',\n",
    "                'recommendation': 'Use curl/wget with checksum verification',\n",
    "                'severity': 'Medium'\n",
    "            })\n",
    "        \n",
    "        return findings\n",
    "    \n",
    "    def kubernetes_manifest_check(self, manifest_path):\n",
    "        \"\"\"\n",
    "        Check Kubernetes manifests for security issues\n",
    "        \"\"\"\n",
    "        import yaml\n",
    "        \n",
    "        with open(manifest_path, 'r') as f:\n",
    "            manifest = yaml.safe_load(f)\n",
    "        \n",
    "        findings = []\n",
    "        \n",
    "        spec = manifest.get('spec', {})\n",
    "        containers = spec.get('containers', [])\n",
    "        \n",
    "        for container in containers:\n",
    "            # Check for privileged mode\n",
    "            security_context = container.get('securityContext', {})\n",
    "            if security_context.get('privileged'):\n",
    "                findings.append({\n",
    "                    'container': container.get('name'),\n",
    "                    'issue': 'Running in privileged mode',\n",
    "                    'severity': 'Critical'\n",
    "                })\n",
    "            \n",
    "            # Check for read-only root filesystem\n",
    "            if not security_context.get('readOnlyRootFilesystem'):\n",
    "                findings.append({\n",
    "                    'container': container.get('name'),\n",
    "                    'issue': 'Root filesystem not read-only',\n",
    "                    'severity': 'Medium'\n",
    "                })\n",
    "            \n",
    "            # Check resource limits\n",
    "            resources = container.get('resources', {})\n",
    "            if not resources.get('limits'):\n",
    "                findings.append({\n",
    "                    'container': container.get('name'),\n",
    "                    'issue': 'No resource limits set',\n",
    "                    'severity': 'Low'\n",
    "                })\n",
    "        \n",
    "        # Check for secrets in environment variables\n",
    "        env = container.get('env', [])\n",
    "        for var in env:\n",
    "            if 'value' in var and any(keyword in var.get('name', '').lower() \n",
    "                                     for keyword in ['password', 'secret', 'key', 'token']):\n",
    "                findings.append({\n",
    "                    'issue': f'Secret {var[\"name\"]} exposed in environment variable',\n",
    "                    'recommendation': 'Use Kubernetes Secrets',\n",
    "                    'severity': 'High'\n",
    "                })\n",
    "        \n",
    "        return findings\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **40.6 Bug Bounty Methodology**\n",
    "\n",
    "### **40.6.1 Reconnaissance and Asset Discovery**\n",
    "\n",
    "```python\n",
    "# Bug Bounty Automation Framework\n",
    "class BugBountyRecon:\n",
    "    def __init__(self, target_domain):\n",
    "        self.domain = target_domain\n",
    "        self.subdomains = set()\n",
    "        self.endpoints = set()\n",
    "        self.tech_stack = {}\n",
    "    \n",
    "    def comprehensive_recon(self):\n",
    "        \"\"\"\n",
    "        Comprehensive reconnaissance for bug bounty programs\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'subdomains': self.enumerate_subdomains(),\n",
    "            'endpoints': self.discover_endpoints(),\n",
    "            'js_analysis': self.analyze_javascript(),\n",
    "            'github_recon': self.github_reconnaissance(),\n",
    "            'cloud_assets': self.find_cloud_assets()\n",
    "        }\n",
    "        return results\n",
    "    \n",
    "    def enumerate_subdomains(self):\n",
    "        \"\"\"\n",
    "        Multi-source subdomain enumeration\n",
    "        \"\"\"\n",
    "        tools = {\n",
    "            'subfinder': f'subfinder -d {self.domain} -all -o subfinder.txt',\n",
    "            'amass': f'amass enum -passive -d {self.domain} -o amass.txt',\n",
    "            'assetfinder': f'assetfinder --subs-only {self.domain} > assetfinder.txt',\n",
    "            'chaos': f'chaos -d {self.domain} -o chaos.txt'\n",
    "        }\n",
    "        \n",
    "        # Run tools and aggregate results\n",
    "        for tool_name, command in tools.items():\n",
    "            try:\n",
    "                subprocess.run(command, shell=True, timeout=300)\n",
    "                with open(f'{tool_name}.txt', 'r') as f:\n",
    "                    self.subdomains.update(line.strip() for line in f)\n",
    "            except Exception as e:\n",
    "                print(f\"{tool_name} failed: {e}\")\n",
    "        \n",
    "        # Verify subdomains are alive\n",
    "        live_hosts = []\n",
    "        for sub in self.subdomains:\n",
    "            try:\n",
    "                response = requests.get(f'http://{sub}', timeout=5)\n",
    "                live_hosts.append({\n",
    "                    'subdomain': sub,\n",
    "                    'status': response.status_code,\n",
    "                    'title': self.get_page_title(response.text)\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return live_hosts\n",
    "    \n",
    "    def analyze_javascript(self):\n",
    "        \"\"\"\n",
    "        Extract endpoints and secrets from JavaScript files\n",
    "        \"\"\"\n",
    "        js_endpoints = set()\n",
    "        secrets = []\n",
    "        \n",
    "        # Find JS files\n",
    "        response = requests.get(f'https://{self.domain}')\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        scripts = soup.find_all('script', src=True)\n",
    "        \n",
    "        for script in scripts:\n",
    "            if script['src'].endswith('.js'):\n",
    "                js_url = script['src'] if script['src'].startswith('http') else f\"{self.domain}{script['src']}\"\n",
    "                \n",
    "                try:\n",
    "                    js_content = requests.get(js_url).text\n",
    "                    \n",
    "                    # Extract API endpoints\n",
    "                    api_patterns = re.findall(r'[\"\\'](\\/api\\/[a-zA-Z0-9\\/_-]+)[\"\\']', js_content)\n",
    "                    js_endpoints.update(api_patterns)\n",
    "                    \n",
    "                    # Extract secrets\n",
    "                    secret_patterns = [\n",
    "                        (r'api[_-]?key[\"\\']?\\s*:\\s*[\"\\']([a-zA-Z0-9]{16,})[\"\\']', 'API Key'),\n",
    "                        (r'secret[\"\\']?\\s*:\\s*[\"\\']([a-zA-Z0-9]{16,})[\"\\']', 'Secret'),\n",
    "                        (r'auth[_-]?token[\"\\']?\\s*:\\s*[\"\\']([a-zA-Z0-9-_\\.]+)[\"\\']', 'Auth Token')\n",
    "                    ]\n",
    "                    \n",
    "                    for pattern, secret_type in secret_patterns:\n",
    "                        matches = re.findall(pattern, js_content, re.IGNORECASE)\n",
    "                        for match in matches:\n",
    "                            secrets.append({\n",
    "                                'type': secret_type,\n",
    "                                'value': match[:10] + '...',\n",
    "                                'file': js_url\n",
    "                            })\n",
    "                    \n",
    "                    # Extract S3 buckets, GCP buckets\n",
    "                    buckets = re.findall(r'([a-z0-9-]+\\.s3\\.amazonaws\\.com)', js_content)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "        \n",
    "        return {\n",
    "            'endpoints': list(js_endpoints),\n",
    "            'secrets': secrets,\n",
    "            's3_buckets': list(set(buckets)) if 'buckets' in locals() else []\n",
    "        }\n",
    "    \n",
    "    def github_reconnaissance(self):\n",
    "        \"\"\"\n",
    "        Search GitHub for leaked credentials and code\n",
    "        \"\"\"\n",
    "        # Using GitHub API or tools like GitHound\n",
    "        queries = [\n",
    "            f'\"{self.domain}\" password',\n",
    "            f'\"{self.domain}\" api_key',\n",
    "            f'\"{self.domain}\" token',\n",
    "            f'\"{self.domain}\" database_password',\n",
    "            f'org:{self.domain.split(\".\")[0]} secret'\n",
    "        ]\n",
    "        \n",
    "        findings = []\n",
    "        # Implementation would use GitHub API with proper authentication\n",
    "        # to avoid rate limits\n",
    "        \n",
    "        return findings\n",
    "    \n",
    "    def get_page_title(self, html):\n",
    "        \"\"\"Helper to extract page title\"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            return soup.title.string if soup.title else 'No title'\n",
    "        except:\n",
    "            return 'Error parsing'\n",
    "```\n",
    "\n",
    "### **40.6.2 Vulnerability Triage and Reporting**\n",
    "\n",
    "```python\n",
    "class BugBountyReporter:\n",
    "    \"\"\"\n",
    "    Generate professional bug bounty reports\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vulnerability_data):\n",
    "        self.vuln = vulnerability_data\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"\n",
    "        Generate markdown report for bug bounty platforms\n",
    "        \"\"\"\n",
    "        template = \"\"\"\n",
    "# {title}\n",
    "\n",
    "## Summary\n",
    "{summary}\n",
    "\n",
    "## Severity\n",
    "{severity} ({cvss_score})\n",
    "\n",
    "## Steps to Reproduce\n",
    "{steps}\n",
    "\n",
    "## Impact\n",
    "{impact}\n",
    "\n",
    "## Proof of Concept\n",
    "{poc}\n",
    "\n",
    "## Remediation\n",
    "{remediation}\n",
    "\n",
    "## References\n",
    "{references}\n",
    "        \"\"\"\n",
    "        \n",
    "        return template.format(\n",
    "            title=self.vuln['title'],\n",
    "            summary=self.vuln['summary'],\n",
    "            severity=self.vuln['severity'],\n",
    "            cvss_score=self.vuln.get('cvss', 'N/A'),\n",
    "            steps=self.format_steps(self.vuln['steps']),\n",
    "            impact=self.vuln['impact'],\n",
    "            poc=self.vuln.get('poc', 'See attached screenshots'),\n",
    "            remediation=self.vuln['remediation'],\n",
    "            references=self.vuln.get('references', 'OWASP guidelines')\n",
    "        )\n",
    "    \n",
    "    def format_steps(self, steps):\n",
    "        \"\"\"Format reproduction steps as numbered list\"\"\"\n",
    "        return '\\n'.join(f'{i+1}. {step}' for i, step in enumerate(steps))\n",
    "    \n",
    "    def calculate_bounty_range(self):\n",
    "        \"\"\"\n",
    "        Suggest bounty range based on severity and impact\n",
    "        \"\"\"\n",
    "        severity_multipliers = {\n",
    "            'Critical': (5000, 10000),\n",
    "            'High': (1000, 5000),\n",
    "            'Medium': (300, 1000),\n",
    "            'Low': (100, 300),\n",
    "            'Informational': (0, 0)\n",
    "        }\n",
    "        \n",
    "        base = severity_multipliers.get(self.vuln['severity'], (0, 0))\n",
    "        \n",
    "        # Adjust for business impact\n",
    "        if 'customer data' in self.vuln['impact'].lower():\n",
    "            base = (base[0] * 1.5, base[1] * 1.5)\n",
    "        \n",
    "        return {\n",
    "            'suggested_range': f\"${int(base[0])} - ${int(base[1])}\",\n",
    "            'factors': ['Severity', 'Business impact', 'Exploitation difficulty']\n",
    "        }\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "In this comprehensive chapter on **Security Testing Techniques**, we covered the methodologies and frameworks that guide professional security assessments:\n",
    "\n",
    "**Key Methodologies:**\n",
    "\n",
    "1. **OWASP Testing Guide (40.1):** The industry-standard framework covering 12 categories from Information Gathering (DNS enumeration, fingerprinting, endpoint discovery) through Configuration Management (security headers, HTTP methods), Identity Management, Authentication (session management, password policies), Authorization (IDOR testing), Input Validation (SQLi, XSS, Command Injection), and Business Logic testing.\n",
    "\n",
    "2. **PTES - Penetration Testing Execution Standard (40.2):** A comprehensive 7-phase approach covering Pre-engagement (scoping, ROE, legal), Intelligence Gathering (OSINT, footprinting), Threat Modeling (STRIDE methodology), Vulnerability Analysis, Exploitation, Post-exploitation (pivoting, data analysis), and Reporting. We implemented Python tools for threat modeling using STRIDE and risk calculation.\n",
    "\n",
    "3. **API Security Testing (40.3):** Specialized techniques for REST APIs (authentication bypass, authorization testing, mass assignment, rate limiting) and GraphQL (introspection queries, depth limiting, batch query attacks). We built comprehensive testers for JWT vulnerabilities, IDOR detection, and injection attacks specific to API endpoints.\n",
    "\n",
    "4. **Mobile Security Testing (40.4):** MAST (Mobile Application Security Testing) methodology covering OWASP Mobile Top 10 and MASVS. We covered static analysis (hardcoded secrets, insecure storage), dynamic analysis setup (Frida/Objection), SSL pinning bypass techniques, and platform-specific testing for Android and iOS.\n",
    "\n",
    "5. **Cloud Security Testing (40.5):** AWS security assessment tools for S3 buckets (public access, encryption), IAM (MFA, key rotation), EC2 (security groups, encryption), and Container Security (Dockerfile best practices, Kubernetes manifest security, vulnerability scanning with Trivy).\n",
    "\n",
    "6. **Bug Bounty Methodology (40.6):** Reconnaissance automation (subdomain enumeration, JavaScript analysis, GitHub reconnaissance), vulnerability triage, and professional report generation with severity classification and bounty range estimation.\n",
    "\n",
    "**Industry Standards Compliance:**\n",
    "- **NIST SP 800-115:** Technical Guide to Information Security Testing\n",
    "- **OWASP MASVS:** Mobile Application Security Verification Standard\n",
    "- **CIS Benchmarks:** Cloud security configuration standards\n",
    "- **PCI-DSS:** Payment card industry security requirements\n",
    "\n",
    "---\n",
    "\n",
    "## **📖 Next Chapter: Chapter 41 - Test-Driven Development (TDD)**\n",
    "\n",
    "Now that you have mastered security testing methodologies, Chapter 41 will transition to **development methodologies that prevent vulnerabilities from being introduced in the first place**.\n",
    "\n",
    "In **Chapter 41**, you will learn:\n",
    "\n",
    "- **Test-Driven Development (TDD):** The Red-Green-Refactor cycle, writing tests before code, and how TDD naturally prevents security vulnerabilities by forcing developers to consider edge cases and invalid inputs.\n",
    "\n",
    "- **Unit Testing Fundamentals:** Writing effective unit tests, test isolation, mocking and stubbing, and achieving meaningful code coverage without chasing vanity metrics.\n",
    "\n",
    "- **TDD Security:** How to write security-focused unit tests (input validation tests, authentication logic tests, authorization boundary tests) that catch vulnerabilities at the earliest possible stage.\n",
    "\n",
    "- **Behavior-Driven Development (BDD):** Extending TDD with business-readable specifications using Gherkin syntax, and how BDD scenarios can capture security requirements in business terms.\n",
    "\n",
    "- **Secure Coding Practices:** Input validation, output encoding, secure authentication patterns, and defensive programming techniques integrated into the TDD workflow.\n",
    "\n",
    "- **Refactoring for Security:** How to safely refactor code to improve security posture without breaking functionality, using tests as safety nets.\n",
    "\n",
    "**Chapter 41 will teach you how to build security into the development process from day one, ensuring that quality and security are inherent in your codebase rather than retrofitted through testing alone.**\n",
    "\n",
    "**Continue to Chapter 41 to learn how to write code that is secure by design through Test-Driven Development!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
