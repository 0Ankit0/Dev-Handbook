{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 34: Performance Testing Tools**\n",
    "\n",
    "---\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "Selecting the right performance testing tool is critical to the success of your testing strategy. The tool must match your team's technical skills, integrate with your CI/CD pipeline, support your specific protocols (HTTP, gRPC, JDBC, etc.), and provide actionable reporting.\n",
    "\n",
    "This chapter covers the industry-standard toolsâ€”from the established Apache JMeter to modern cloud-native solutions like K6. Each tool is examined with practical examples, configuration guidance, and integration patterns to help you implement effective performance testing in your organization.\n",
    "\n",
    "---\n",
    "\n",
    "## **34.1 Apache JMeter**\n",
    "\n",
    "Apache JMeter is the de facto open-source standard for load testing. Written in Java, it supports a vast array of protocols including HTTP/HTTPS, SOAP, REST, FTP, JDBC, and message-oriented middleware (JMS).\n",
    "\n",
    "### **34.1.1 Architecture and Components**\n",
    "\n",
    "JMeter operates on a **Test Plan** hierarchy:\n",
    "\n",
    "```\n",
    "Test Plan (Root)\n",
    "â”œâ”€â”€ Thread Group (Virtual Users)\n",
    "â”‚   â”œâ”€â”€ Config Elements (CSV Data, HTTP Defaults)\n",
    "â”‚   â”œâ”€â”€ Logic Controllers (If, While, ForEach)\n",
    "â”‚   â”œâ”€â”€ Samplers (HTTP Request, JDBC Request)\n",
    "â”‚   â”œâ”€â”€ Pre-Processors (User Parameters)\n",
    "â”‚   â”œâ”€â”€ Post-Processors (Regular Expression Extractor)\n",
    "â”‚   â”œâ”€â”€ Assertions (Response Assertion)\n",
    "â”‚   â””â”€â”€ Listeners (View Results Tree, Aggregate Report)\n",
    "â””â”€â”€ Non-Test Elements (HTTP Proxy Server)\n",
    "```\n",
    "\n",
    "**Key Components:**\n",
    "\n",
    "- **Thread Group**: Defines the number of virtual users (threads), ramp-up period, and loop count\n",
    "- **Samplers**: Send requests to the target server (HTTP, FTP, JDBC, etc.)\n",
    "- **Logic Controllers**: Control execution flow (loops, conditions, randomization)\n",
    "- **Listeners**: Collect and display results (graphs, tables, trees)\n",
    "- **Assertions**: Verify responses meet criteria (contains text, response code, duration)\n",
    "\n",
    "### **34.1.2 Installation and Setup**\n",
    "\n",
    "```bash\n",
    "# Download and extract JMeter\n",
    "wget https://dlcdn.apache.org//jmeter/binaries/apache-jmeter-5.6.3.tgz\n",
    "tar -xzf apache-jmeter-5.6.3.tgz\n",
    "cd apache-jmeter-5.6.3/bin\n",
    "\n",
    "# Increase JVM heap for large tests (edit jmeter.bat or jmeter.sh)\n",
    "# Set HEAP=\"-Xms2g -Xmx8g -XX:MaxMetaspaceSize=512m\"\n",
    "\n",
    "# Launch GUI mode (for development)\n",
    "./jmeter.sh\n",
    "\n",
    "# Launch CLI mode (for execution - recommended for CI/CD)\n",
    "./jmeter.sh -n -t test-plan.jmx -l results.jtl -e -o dashboard\n",
    "```\n",
    "\n",
    "**CLI Arguments Explained:**\n",
    "- `-n`: Non-GUI mode (essential for CI/CD)\n",
    "- `-t`: Test plan file (.jmx)\n",
    "- `-l`: Log file for results (.jtl)\n",
    "- `-e`: Generate HTML report after test\n",
    "- `-o`: Output directory for HTML report\n",
    "\n",
    "### **34.1.3 Creating a Test Plan**\n",
    "\n",
    "**Example: REST API Load Test**\n",
    "\n",
    "```xml\n",
    "<!-- test-plan.jmx (XML structure simplified for clarity) -->\n",
    "<TestPlan guiclass=\"TestPlanGui\" testname=\"E-Commerce API Load Test\">\n",
    "  <stringProp name=\"TestPlan.user_defined_variables\">\n",
    "    <Arguments>\n",
    "      <stringProp name=\"base_url\">api.example.com</stringProp>\n",
    "      <stringProp name=\"protocol\">https</stringProp>\n",
    "    </Arguments>\n",
    "  </stringProp>\n",
    "  \n",
    "  <ThreadGroup testname=\"Concurrent Users\" guiclass=\"ThreadGroupGui\">\n",
    "    <!-- 1000 virtual users -->\n",
    "    <stringProp name=\"ThreadGroup.num_threads\">1000</stringProp>\n",
    "    <!-- Ramp up over 300 seconds (5 minutes) -->\n",
    "    <stringProp name=\"ThreadGroup.ramp_time\">300</stringProp>\n",
    "    <!-- Loop forever (or specify count) -->\n",
    "    <stringProp name=\"ThreadGroup.loops\">10</stringProp>\n",
    "    \n",
    "    <HTTPSamplerProxy testname=\"Login Request\" guiclass=\"HttpTestSampleGui\">\n",
    "      <stringProp name=\"HTTPSampler.domain\">${base_url}</stringProp>\n",
    "      <stringProp name=\"HTTPSampler.protocol\">${protocol}</stringProp>\n",
    "      <stringProp name=\"HTTPSampler.path\">/api/v1/auth/login</stringProp>\n",
    "      <stringProp name=\"HTTPSampler.method\">POST</stringProp>\n",
    "      <stringProp name=\"HTTPSampler.postBody\">\n",
    "        {\"username\": \"${username}\", \"password\": \"${password}\"}\n",
    "      </stringProp>\n",
    "      <stringProp name=\"HTTPSampler.postBodyContentType\">application/json</stringProp>\n",
    "    </HTTPSamplerProxy>\n",
    "    \n",
    "    <!-- Extract auth token for subsequent requests -->\n",
    "    <JSONPostProcessor testname=\"Extract Token\">\n",
    "      <stringProp name=\"JSONPostProcessor.referenceNames\">authToken</stringProp>\n",
    "      <stringProp name=\"JSONPostProcessor.jsonPathExprs\">$.token</stringProp>\n",
    "    </JSONPostProcessor>\n",
    "    \n",
    "    <HTTPSamplerProxy testname=\"Get User Profile\">\n",
    "      <stringProp name=\"HTTPSampler.path\">/api/v1/users/profile</stringProp>\n",
    "      <stringProp name=\"HTTPSampler.headerManager\">\n",
    "        <HeaderManager>\n",
    "          <collectionProp name=\"HeaderManager.headers\">\n",
    "            <elementProp>\n",
    "              <stringProp name=\"Header.name\">Authorization</stringProp>\n",
    "              <stringProp name=\"Header.value\">Bearer ${authToken}</stringProp>\n",
    "            </elementProp>\n",
    "          </collectionProp>\n",
    "        </HeaderManager>\n",
    "      </stringProp>\n",
    "    </HTTPSamplerProxy>\n",
    "    \n",
    "    <!-- Assertion: Response must contain user data -->\n",
    "    <ResponseAssertion testname=\"Verify Profile Response\">\n",
    "      <collectionProp name=\"Assertion.test_strings\">\n",
    "        <stringProp>user_id</stringProp>\n",
    "        <stringProp>email</stringProp>\n",
    "      </collectionProp>\n",
    "      <stringProp name=\"Assertion.test_field\">Assertion.response_data</stringProp>\n",
    "    </ResponseAssertion>\n",
    "  </ThreadGroup>\n",
    "</TestPlan>\n",
    "```\n",
    "\n",
    "### **34.1.4 Parameterization and Data-Driven Testing**\n",
    "\n",
    "```csv\n",
    "# users.csv - Test data for parameterization\n",
    "username,password,expected_status\n",
    "alice@example.com,secret123,200\n",
    "bob@example.com,password456,200\n",
    "invalid@example.com,wrongpass,401\n",
    "```\n",
    "\n",
    "**JMeter Configuration:**\n",
    "1. Add **CSV Data Set Config** element\n",
    "2. Configure:\n",
    "   - Filename: `users.csv`\n",
    "   - Variable Names: `username,password,expected_status`\n",
    "   - Recycle on EOF: `True` (loop back to start when file ends)\n",
    "   - Sharing Mode: `All threads` (each thread gets next row)\n",
    "\n",
    "### **34.1.5 Correlation (Dynamic Value Extraction)**\n",
    "\n",
    "Correlation is essential for stateful applications (sessions, tokens, dynamic IDs):\n",
    "\n",
    "```java\n",
    "// JSR223 PostProcessor (Groovy) for complex extraction\n",
    "// Extract CSRF token from HTML response using regex\n",
    "\n",
    "import java.util.regex.Pattern\n",
    "\n",
    "def response = prev.getResponseDataAsString()\n",
    "def pattern = ~/name=\"csrf_token\" value=\"([^\"]+)\"/\n",
    "def matcher = pattern.matcher(response)\n",
    "\n",
    "if (matcher.find()) {\n",
    "    vars.put(\"csrf_token\", matcher.group(1))\n",
    "    log.info(\"Extracted CSRF token: \" + matcher.group(1))\n",
    "} else {\n",
    "    prev.setSuccessful(false)\n",
    "    prev.setResponseMessage(\"CSRF token not found\")\n",
    "}\n",
    "```\n",
    "\n",
    "### **34.1.6 Distributed Testing (Master-Slave Architecture)**\n",
    "\n",
    "For loads exceeding a single machine's capacity:\n",
    "\n",
    "```bash\n",
    "# On Slave machines (load generators)\n",
    "./jmeter-server -Djava.rmi.server.hostname=192.168.1.10\n",
    "\n",
    "# On Master machine (controller)\n",
    "./jmeter.sh -n -t test-plan.jmx -R192.168.1.10,192.168.1.11,192.168.1.12 -l results.jtl\n",
    "\n",
    "# Or configure in jmeter.properties:\n",
    "# remote_hosts=192.168.1.10,192.168.1.11,192.168.1.12\n",
    "```\n",
    "\n",
    "**Best Practices for Distributed Testing:**\n",
    "- Ensure all slaves have identical JMeter versions and Java versions\n",
    "- Use absolute paths for CSV files (or place in `bin` directory)\n",
    "- Disable firewalls or open ports 1099, 4000-4002 between master and slaves\n",
    "- Monitor slave CPU/memory to avoid generator bottlenecks\n",
    "\n",
    "### **34.1.7 Best Practices for JMeter**\n",
    "\n",
    "1. **Always use CLI mode** for execution (GUI is for development only)\n",
    "2. **Disable listeners during execution** (consume memory; use them only for debugging)\n",
    "3. **Use CSV for parameterization** rather than User Defined Variables for large datasets\n",
    "4. **Implement think times** (Uniform Random Timer) to simulate realistic user behavior\n",
    "5. **Use assertions sparingly** (they consume resources; focus on critical validations)\n",
    "6. **Monitor JMeter's own resources** (if JMeter is at 100% CPU, results are invalid)\n",
    "7. **Split complex tests** into multiple thread groups or modularize with Test Fragments\n",
    "\n",
    "---\n",
    "\n",
    "## **34.2 Gatling**\n",
    "\n",
    "Gatling is a high-performance load testing tool built on Scala, Akka, and Netty. It's designed for high concurrency (thousands of users from a single machine) and provides excellent HTML reports.\n",
    "\n",
    "### **34.2.1 Architecture and DSL**\n",
    "\n",
    "Gatling uses a **Domain Specific Language (DSL)** for test scenarios:\n",
    "\n",
    "```scala\n",
    "// Scala: Gatling test scenario\n",
    "import io.gatling.core.Predef._\n",
    "import io.gatling.http.Predef._\n",
    "import scala.concurrent.duration._\n",
    "\n",
    "class EcommerceSimulation extends Simulation {\n",
    "  \n",
    "  // HTTP Protocol Configuration\n",
    "  val httpProtocol = http\n",
    "    .baseUrl(\"https://api.example.com\")\n",
    "    .acceptHeader(\"application/json\")\n",
    "    .contentTypeHeader(\"application/json\")\n",
    "    .header(\"X-API-Version\", \"v1\")\n",
    "  \n",
    "  // Scenario Definition\n",
    "  val scn = scenario(\"E-commerce User Journey\")\n",
    "    .exec(\n",
    "      http(\"Login\")\n",
    "        .post(\"/auth/login\")\n",
    "        .body(StringBody(\"\"\"{\"username\": \"user1\", \"password\": \"pass123\"}\"\"\"))\n",
    "        .check(status.is(200))\n",
    "        .check(jsonPath(\"$.token\").saveAs(\"authToken\"))\n",
    "    )\n",
    "    .pause(2, 5) // Think time: 2-5 seconds\n",
    "    \n",
    "    .exec(\n",
    "      http(\"Browse Products\")\n",
    "        .get(\"/products\")\n",
    "        .header(\"Authorization\", \"Bearer ${authToken}\")\n",
    "        .check(status.is(200))\n",
    "        .check(jsonPath(\"$.products[*].id\").findAll.saveAs(\"productIds\"))\n",
    "    )\n",
    "    .pause(1, 3)\n",
    "    \n",
    "    .exec(\n",
    "      http(\"Add to Cart\")\n",
    "        .post(\"/cart/items\")\n",
    "        .header(\"Authorization\", \"Bearer ${authToken}\")\n",
    "        .body(StringBody(\"\"\"{\"productId\": \"${productIds.random()}\", \"quantity\": 1}\"\"\"))\n",
    "        .check(status.is(201))\n",
    "    )\n",
    "  \n",
    "  // Load Profile\n",
    "  setUp(\n",
    "    scn.inject(\n",
    "      rampUsers(1000).during(60.seconds), // Ramp up 1000 users over 1 minute\n",
    "      constantUsersPerSec(50).during(300.seconds), // Maintain 50 users/sec for 5 minutes\n",
    "      rampUsersPerSec(50).to(200).during(120.seconds), // Spike test\n",
    "      nothingFor(10.seconds), // Pause\n",
    "      atOnceUsers(500) // Sudden spike\n",
    "    )\n",
    "  ).protocols(httpProtocol)\n",
    "   .assertions(\n",
    "     global.responseTime.percentile(95).lt(500), // P95 < 500ms\n",
    "     global.successfulRequests.percent.gt(99.9)  // 99.9% success rate\n",
    "   )\n",
    "}\n",
    "```\n",
    "\n",
    "### **34.2.2 Key Features**\n",
    "\n",
    "**Feeders (Data Parameterization):**\n",
    "```scala\n",
    "// CSV Feeder\n",
    "val csvFeeder = csv(\"users.csv\").random // or .queue, .shuffle, .circular\n",
    "\n",
    "val scn = scenario(\"Data Driven Test\")\n",
    "  .feed(csvFeeder)\n",
    "  .exec(\n",
    "    http(\"Login\")\n",
    "      .post(\"/login\")\n",
    "      .body(StringBody(\"\"\"{\"user\": \"${username}\", \"pass\": \"${password}\"}\"\"\"))\n",
    "  )\n",
    "```\n",
    "\n",
    "**Session Management:**\n",
    "```scala\n",
    "// Extracting and saving values to session\n",
    ".exec(\n",
    "  http(\"Get User\")\n",
    "    .get(\"/users/${userId}\")\n",
    "    .check(jsonPath(\"$.address.zipCode\").saveAs(\"zipCode\"))\n",
    ")\n",
    ".exec { session =>\n",
    "  // Custom logic with session data\n",
    "  println(\"User ZIP code: \" + session(\"zipCode\").as[String])\n",
    "  session\n",
    "}\n",
    "```\n",
    "\n",
    "**Checks and Assertions:**\n",
    "```scala\n",
    ".check(\n",
    "  status.is(200),\n",
    "  responseTimeInMillis.lte(500),\n",
    "  regex(\"\"\"orderId\": \"([^\"]+)\"\"\"\").saveAs(\"orderId\"),\n",
    "  substring(\"success\"),\n",
    "  jsonPath(\"$.status\").is(\"confirmed\")\n",
    ")\n",
    "```\n",
    "\n",
    "### **34.2.3 Execution and Reporting**\n",
    "\n",
    "```bash\n",
    "# Run simulation\n",
    "mvn gatling:test -Dgatling.simulationClass=EcommerceSimulation\n",
    "\n",
    "# Or using Gradle\n",
    "gradle gatlingRun\n",
    "\n",
    "# Results generated in: target/gatling/<simulation-name>-<timestamp>/\n",
    "# Index.html contains executive dashboard with:\n",
    "# - Response time percentiles over time\n",
    "# - Active users over time\n",
    "# - Requests per second\n",
    "# - Error rate\n",
    "# - Response time distribution\n",
    "```\n",
    "\n",
    "**Gatling Advantages:**\n",
    "- **Efficiency**: Handles thousands of concurrent users from single machine (async I/O)\n",
    "- **Readable DSL**: Code-as-configuration approach fits CI/CD pipelines\n",
    "- **Excellent Reports**: Built-in HTML reports with interactive graphs\n",
    "- **Akka-based**: Non-blocking architecture prevents thread contention\n",
    "\n",
    "---\n",
    "\n",
    "## **34.3 K6**\n",
    "\n",
    "K6 is a modern, developer-centric load testing tool built by Grafana Labs. Tests are written in JavaScript (ES6+) and it's designed specifically for CI/CD integration.\n",
    "\n",
    "### **34.3.1 Installation and Basic Script**\n",
    "\n",
    "```bash\n",
    "# Install K6 (macOS/Linux)\n",
    "brew install k6\n",
    "\n",
    "# Or Docker\n",
    "docker pull grafana/k6\n",
    "```\n",
    "\n",
    "```javascript\n",
    "// load-test.js\n",
    "import http from 'k6/http';\n",
    "import { check, sleep } from 'k6';\n",
    "import { Rate, Trend } from 'k6/metrics';\n",
    "\n",
    "// Custom metrics\n",
    "const errorRate = new Rate('errors');\n",
    "const apiLatency = new Trend('api_latency');\n",
    "\n",
    "// Test configuration\n",
    "export const options = {\n",
    "  stages: [\n",
    "    { duration: '2m', target: 100 },   // Ramp up\n",
    "    { duration: '5m', target: 100 },   // Steady state\n",
    "    { duration: '2m', target: 200 },   // Ramp up\n",
    "    { duration: '5m', target: 200 },   // Steady state\n",
    "    { duration: '2m', target: 0 },      // Ramp down\n",
    "  ],\n",
    "  thresholds: {\n",
    "    http_req_duration: ['p(95)<500'], // 95% of requests under 500ms\n",
    "    http_req_failed: ['rate<0.01'],    // Error rate under 1%\n",
    "    errors: ['rate<0.1'],              // Custom error metric\n",
    "  },\n",
    "  ext: {\n",
    "    loadimpact: {\n",
    "      projectID: 12345, // Cloud execution\n",
    "    },\n",
    "  },\n",
    "};\n",
    "\n",
    "export default function () {\n",
    "  // Login\n",
    "  const loginPayload = JSON.stringify({\n",
    "    username: `user_${__VU}`, // __VU = Virtual User ID\n",
    "    password: 'password123',\n",
    "  });\n",
    "  \n",
    "  const loginRes = http.post('https://api.example.com/auth/login', loginPayload, {\n",
    "    headers: { 'Content-Type': 'application/json' },\n",
    "  });\n",
    "  \n",
    "  check(loginRes, {\n",
    "    'login status is 200': (r) => r.status === 200,\n",
    "    'has auth token': (r) => r.json('token') !== '',\n",
    "  }) || errorRate.add(1);\n",
    "  \n",
    "  apiLatency.add(loginRes.timings.duration);\n",
    "  \n",
    "  const authToken = loginRes.json('token');\n",
    "  \n",
    "  // Subsequent requests with auth\n",
    "  const headers = {\n",
    "    'Authorization': `Bearer ${authToken}`,\n",
    "    'Content-Type': 'application/json',\n",
    "  };\n",
    "  \n",
    "  const res = http.get('https://api.example.com/dashboard', { headers });\n",
    "  \n",
    "  check(res, {\n",
    "    'dashboard loaded': (r) => r.status === 200,\n",
    "    'response time OK': (r) => r.timings.duration < 500,\n",
    "  });\n",
    "  \n",
    "  sleep(Math.random() * 3 + 2); // Random think time 2-5 seconds\n",
    "}\n",
    "\n",
    "// Setup/teardown\n",
    "export function setup() {\n",
    "  // Runs once before all iterations\n",
    "  const res = http.get('https://api.example.com/health');\n",
    "  return { status: res.status };\n",
    "}\n",
    "\n",
    "export function teardown(data) {\n",
    "  // Runs once after all iterations\n",
    "  console.log(`Test completed. Final status: ${data.status}`);\n",
    "}\n",
    "```\n",
    "\n",
    "### **34.3.2 Advanced K6 Features**\n",
    "\n",
    "**Modularization:**\n",
    "```javascript\n",
    "// helpers.js\n",
    "export function checkStatus(response, expectedStatus) {\n",
    "  return check(response, {\n",
    "    [`status is ${expectedStatus}`]: (r) => r.status === expectedStatus,\n",
    "  });\n",
    "}\n",
    "\n",
    "// main.js\n",
    "import { checkStatus } from './helpers.js';\n",
    "```\n",
    "\n",
    "**Data Parameterization:**\n",
    "```javascript\n",
    "import { SharedArray } from 'k6/data';\n",
    "import papaparse from 'https://jslib.k6.io/papaparse/5.1.1/index.js';\n",
    "\n",
    "const csvData = new SharedArray('users', function () {\n",
    "  // Load CSV only once, shared across VUs\n",
    "  return papaparse.parse(open('./users.csv'), { header: true }).data;\n",
    "});\n",
    "\n",
    "export default function () {\n",
    "  const user = csvData[Math.floor(Math.random() * csvData.length)];\n",
    "  http.post('/login', JSON.stringify(user));\n",
    "}\n",
    "```\n",
    "\n",
    "**WebSocket Testing:**\n",
    "```javascript\n",
    "import ws from 'k6/ws';\n",
    "\n",
    "export default function () {\n",
    "  const url = 'wss://api.example.com/socket';\n",
    "  const res = ws.connect(url, null, function (socket) {\n",
    "    socket.on('open', () => {\n",
    "      socket.send(JSON.stringify({ type: 'subscribe', channel: 'updates' }));\n",
    "    });\n",
    "    \n",
    "    socket.on('message', (msg) => {\n",
    "      check(msg, { 'message received': (m) => m !== '' });\n",
    "    });\n",
    "    \n",
    "    socket.setTimeout(function () {\n",
    "      socket.close();\n",
    "    }, 30000);\n",
    "  });\n",
    "}\n",
    "```\n",
    "\n",
    "### **34.3.3 Cloud Execution and CI/CD**\n",
    "\n",
    "K6 Cloud (managed) or K6 Operator (Kubernetes) for distributed execution:\n",
    "\n",
    "```yaml\n",
    "# .github/workflows/performance.yml\n",
    "name: Performance Tests\n",
    "\n",
    "on: [push]\n",
    "\n",
    "jobs:\n",
    "  k6_test:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Run K6 tests\n",
    "        uses: grafana/k6-action@v0.2.0\n",
    "        with:\n",
    "          filename: load-test.js\n",
    "          flags: --out influxdb=http://influxdb:8086/k6\n",
    "        env:\n",
    "          API_HOST: ${{ secrets.API_HOST }}\n",
    "```\n",
    "\n",
    "**K6 Advantages:**\n",
    "- **JavaScript**: Familiar to web developers; no JVM or complex setup\n",
    "- **Cloud-native**: Built for containers and Kubernetes\n",
    "- **Integrations**: Native Grafana dashboards, InfluxDB/TimescaleDB output\n",
    "- **Developer experience**: CLI output with emojis and real-time metrics\n",
    "\n",
    "---\n",
    "\n",
    "## **34.4 Locust**\n",
    "\n",
    "Locust is a Python-based load testing tool that allows you to define user behavior in Python code. It's particularly suited for testing web applications with complex user flows.\n",
    "\n",
    "### **34.4.1 Python-Based Test Scripts**\n",
    "\n",
    "```python\n",
    "# locustfile.py\n",
    "from locust import HttpUser, task, between, events\n",
    "import random\n",
    "import json\n",
    "\n",
    "class WebsiteUser(HttpUser):\n",
    "    \"\"\"\n",
    "    Simulates user behavior on e-commerce site\n",
    "    \"\"\"\n",
    "    wait_time = between(1, 5)  # Wait 1-5 seconds between tasks\n",
    "    weight = 1  # Relative weight of this user class\n",
    "    \n",
    "    def on_start(self):\n",
    "        \"\"\"Called when a user starts\"\"\"\n",
    "        self.login()\n",
    "    \n",
    "    def login(self):\n",
    "        response = self.client.post(\"/auth/login\", json={\n",
    "            \"username\": f\"user_{self.user_id}\",\n",
    "            \"password\": \"test123\"\n",
    "        })\n",
    "        self.token = response.json()[\"token\"]\n",
    "        self.client.headers.update({\"Authorization\": f\"Bearer {self.token}\"})\n",
    "    \n",
    "    @task(10)  # Weight: 10x more likely than task with weight 1\n",
    "    def view_products(self):\n",
    "        \"\"\"Browse product catalog\"\"\"\n",
    "        self.client.get(\"/api/products\")\n",
    "    \n",
    "    @task(5)\n",
    "    def view_product_detail(self):\n",
    "        \"\"\"View specific product\"\"\"\n",
    "        product_id = random.randint(1, 1000)\n",
    "        self.client.get(f\"/api/products/{product_id}\", \n",
    "                       name=\"/api/products/[id]\")\n",
    "    \n",
    "    @task(2)\n",
    "    def add_to_cart(self):\n",
    "        \"\"\"Add item to cart\"\"\"\n",
    "        product_id = random.randint(1, 1000)\n",
    "        self.client.post(\"/api/cart/items\", json={\n",
    "            \"product_id\": product_id,\n",
    "            \"quantity\": random.randint(1, 5)\n",
    "        })\n",
    "    \n",
    "    @task(1)\n",
    "    def checkout(self):\n",
    "        \"\"\"Complete purchase\"\"\"\n",
    "        with self.client.post(\"/api/orders\", json={\n",
    "            \"items\": [{\"product_id\": 1, \"quantity\": 1}],\n",
    "            \"payment_method\": \"credit_card\"\n",
    "        }, catch_response=True) as response:\n",
    "            \n",
    "            if response.status_code == 201:\n",
    "                response.success()\n",
    "            elif response.status_code == 422:\n",
    "                # Validation error - might be expected\n",
    "                response.failure(\"Validation failed: \" + response.text)\n",
    "            else:\n",
    "                response.failure(\"Unexpected status code\")\n",
    "\n",
    "class MobileUser(HttpUser):\n",
    "    \"\"\"Simulates mobile app traffic patterns\"\"\"\n",
    "    wait_time = between(0.5, 2)  # Mobile users are faster\n",
    "    weight = 2  # Twice as many mobile users as web users\n",
    "    \n",
    "    @task\n",
    "    def api_call(self):\n",
    "        self.client.get(\"/api/v2/mobile/feed\")\n",
    "\n",
    "# Event hooks\n",
    "@events.test_stop.add_listener\n",
    "def on_test_stop(environment, **kwargs):\n",
    "    print(\"Test finished\")\n",
    "    stats = environment.runner.stats\n",
    "    \n",
    "    # Custom reporting\n",
    "    with open('results.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'total_requests': stats.total.num_requests,\n",
    "            'failures': stats.total.num_failures,\n",
    "            'avg_response_time': stats.total.avg_response_time,\n",
    "        }, f)\n",
    "```\n",
    "\n",
    "### **34.4.2 Distributed Execution**\n",
    "\n",
    "Locust uses a master-worker architecture:\n",
    "\n",
    "```bash\n",
    "# Master node\n",
    "locust -f locustfile.py --master --web-port 8089\n",
    "\n",
    "# Worker nodes (run on multiple machines)\n",
    "locust -f locustfile.py --worker --master-host=192.168.1.10\n",
    "\n",
    "# Headless execution (CI/CD)\n",
    "locust -f locustfile.py --headless -u 1000 -r 100 --run-time 10m --html report.html\n",
    "```\n",
    "\n",
    "**Locust Advantages:**\n",
    "- **Python**: Full programming power (conditionals, loops, complex logic)\n",
    "- **Web UI**: Real-time monitoring during test execution\n",
    "- **Extensible**: Easy to integrate with Python libraries (numpy, pandas for data analysis)\n",
    "- **Readable**: Python code is self-documenting\n",
    "\n",
    "---\n",
    "\n",
    "## **34.5 Enterprise Tools**\n",
    "\n",
    "For large enterprises with complex requirements:\n",
    "\n",
    "### **34.5.1 Micro Focus LoadRunner**\n",
    "- **Protocols**: Supports 50+ protocols including legacy systems (Citrix, SAP, Oracle Forms)\n",
    "- **Features**: IP spoofing, bandwidth throttling, sophisticated correlation\n",
    "- **Scripting**: C, Java, JavaScript, or record/playback\n",
    "- **Analysis**: Advanced root cause analysis with drill-down capabilities\n",
    "\n",
    "### **34.5.2 NeoLoad (Tricentis)**\n",
    "- **Codeless**: Visual design for non-programmers\n",
    "- **Integration**: Strong CI/CD integrations, SAP-specific support\n",
    "- **Cloud**: Built-in cloud load generation\n",
    "- **Collaboration**: Web-based sharing and design\n",
    "\n",
    "### **34.5.3 BlazeMeter (Broadcom)**\n",
    "- **Cloud-based**: SaaS solution, no infrastructure management\n",
    "- **JMeter-compatible**: Runs JMeter scripts in the cloud\n",
    "- **Scalability**: Millions of concurrent users from global locations\n",
    "\n",
    "---\n",
    "\n",
    "## **34.6 Tool Selection Guide**\n",
    "\n",
    "| Criteria | JMeter | Gatling | K6 | Locust |\n",
    "|----------|--------|---------|-----|---------|\n",
    "| **Language** | XML/GUI, Groovy, Java | Scala DSL | JavaScript | Python |\n",
    "| **Learning Curve** | Medium | High (Scala) | Low | Low |\n",
    "| **Resource Efficiency** | Moderate | High (Async I/O) | High | Moderate (GIL limitations) |\n",
    "| **CI/CD Integration** | Good | Excellent | Excellent | Good |\n",
    "| **Reporting** | Basic (Extensible) | Excellent | Good | Basic |\n",
    "| **Protocol Support** | Extensive (50+) | HTTP/WebSocket | HTTP/WebSocket/gRPC | HTTP primarily |\n",
    "| **Distributed Testing** | Master-Slave | Built-in | Cloud/Operator | Master-Worker |\n",
    "| **Best For** | Complex protocols, GUI preference | High-scale web, Scala teams | DevOps, JavaScript shops | Python teams, complex logic |\n",
    "\n",
    "**Decision Framework:**\n",
    "1. **Team Skills**: Choose K6 for JS developers, Locust for Python developers, Gatling for Scala/Java teams\n",
    "2. **Scale**: Gatling/K6 for >10k users per machine; JMeter for complex protocols\n",
    "3. **Budget**: Open source (all four) vs. Enterprise (LoadRunner, NeoLoad) for specialized support\n",
    "4. **Protocols**: JMeter for legacy/non-HTTP; others for modern web/APIs\n",
    "\n",
    "---\n",
    "\n",
    "## **34.7 CI/CD Integration Patterns**\n",
    "\n",
    "### **34.7.1 Performance Gates**\n",
    "\n",
    "```groovy\n",
    "// Jenkins pipeline with performance gates\n",
    "pipeline {\n",
    "    agent any\n",
    "    stages {\n",
    "        stage('Build') {\n",
    "            steps { sh 'mvn clean package' }\n",
    "        }\n",
    "        stage('Functional Tests') {\n",
    "            steps { sh 'mvn test' }\n",
    "        }\n",
    "        stage('Performance Tests') {\n",
    "            steps {\n",
    "                sh 'jmeter -n -t load-test.jmx -l results.jtl'\n",
    "            }\n",
    "            post {\n",
    "                always {\n",
    "                    // Parse JTL file for thresholds\n",
    "                    perfReport sourceDataFiles: 'results.jtl',\n",
    "                              errorUnstableThreshold: 5,\n",
    "                              responseTimeUnstableRelativeThreshold: 150\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        stage('Decision') {\n",
    "            steps {\n",
    "                script {\n",
    "                    // Fail build if P95 > 2s\n",
    "                    def p95 = sh(script: \"python3 parse_results.py results.jtl\", returnStdout: true).trim()\n",
    "                    if (p95.toInteger() > 2000) {\n",
    "                        error(\"Performance regression detected: P95 = ${p95}ms\")\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### **34.7.2 Nightly Performance Regression**\n",
    "\n",
    "```yaml\n",
    "# .github/workflows/nightly-perf.yml\n",
    "name: Nightly Performance Regression\n",
    "\n",
    "on:\n",
    "  schedule:\n",
    "    - cron: '0 2 * * *' # 2 AM daily\n",
    "\n",
    "jobs:\n",
    "  performance:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Run K6 baseline test\n",
    "        run: |\n",
    "          k6 run --out json=results.json load-test.js\n",
    "          \n",
    "      - name: Compare to baseline\n",
    "        run: |\n",
    "          python compare_baseline.py results.json baseline.json\n",
    "          \n",
    "      - name: Upload results\n",
    "        uses: actions/upload-artifact@v3\n",
    "        with:\n",
    "          name: performance-results\n",
    "          path: results.json\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "### **Key Takeaways:**\n",
    "\n",
    "**Apache JMeter (34.1):**\n",
    "- **Industry standard** with extensive protocol support beyond HTTP (JDBC, JMS, FTP)\n",
    "- **GUI for development**, CLI for execution (`-n` non-GUI mode)\n",
    "- **Distributed testing** via master-slave architecture for large-scale tests\n",
    "- **Best for**: Teams needing GUI-based test building, complex protocol support, or extensive plugin ecosystem\n",
    "\n",
    "**Gatling (34.2):**\n",
    "- **High performance** (Scala/Akka-based) allowing thousands of users from single machine\n",
    "- **Code-as-configuration** approach with readable DSL\n",
    "- **Excellent HTML reports** with detailed percentiles and trends\n",
    "- **Best for**: High-scale web testing, Scala/Java teams, beautiful reporting requirements\n",
    "\n",
    "**K6 (34.3):**\n",
    "- **Developer-friendly** JavaScript/ES6 syntax\n",
    "- **Cloud-native** design with Kubernetes operator and Grafana integration\n",
    "- **Thresholds in code** enabling CI/CD performance gates\n",
    "- **Best for**: API testing, DevOps integration, teams preferring JavaScript, cloud-based execution\n",
    "\n",
    "**Locust (34.4):**\n",
    "- **Python-based** allowing complex logic and custom integrations\n",
    "- **Web UI** for real-time monitoring during test execution\n",
    "- **Programmable** user behavior with Python's full capabilities\n",
    "- **Best for**: Python teams, complex user workflows requiring conditional logic, educational purposes\n",
    "\n",
    "**Enterprise Tools (34.5):**\n",
    "- **LoadRunner**: Legacy protocol support, enterprise support, sophisticated analysis\n",
    "- **NeoLoad**: Codeless approach, SAP integration, collaboration features\n",
    "- **BlazeMeter**: Cloud-based JMeter execution, global load generation\n",
    "\n",
    "**CI/CD Integration (34.7):**\n",
    "- **Performance as Code**: Store test scripts in version control\n",
    "- **Automated Gates**: Fail builds when P95 exceeds thresholds or error rates spike\n",
    "- **Baseline Comparison**: Compare current results against historical baselines to detect regressions\n",
    "- **Nightly Runs**: Schedule comprehensive performance tests outside business hours\n",
    "\n",
    "**Tool Selection Criteria:**\n",
    "1. **Protocol diversity** â†’ JMeter\n",
    "2. **Developer experience/Modern stack** â†’ K6 or Gatling\n",
    "3. **Programming flexibility** â†’ Locust (Python) or Gatling (Scala)\n",
    "4. **Enterprise legacy systems** â†’ LoadRunner\n",
    "5. **Budget constraints** â†’ Any open-source option (JMeter, Gatling, K6, Locust)\n",
    "\n",
    "**Common Anti-Patterns to Avoid:**\n",
    "- Running performance tests from your laptop (network bottlenecks, resource contention)\n",
    "- Testing against production without safeguards (use staging or isolated environments)\n",
    "- Ignoring think times (unrealistic results)\n",
    "- Using only one data point (run multiple iterations for statistical significance)\n",
    "- Testing without monitoring (can't diagnose bottlenecks without system metrics)\n",
    "\n",
    "---\n",
    "\n",
    "## **ðŸ“– Next Chapter: Chapter 35 - Performance Test Execution**\n",
    "\n",
    "Now that you understand the tools available for performance testing, **Chapter 35** will guide you through the **practical execution** of performance testsâ€”from environment preparation to result analysis.\n",
    "\n",
    "In **Chapter 35**, you will master:\n",
    "\n",
    "- **Test Environment Setup**: Creating production-like test environments, data preparation, and monitoring configuration\n",
    "- **Test Execution Best Practices**: Warm-up periods, gradual ramp-up strategies, and real-time monitoring during tests\n",
    "- **Bottleneck Identification**: Analyzing CPU, memory, database, and network constraints using APM tools and logs\n",
    "- **Result Analysis**: Interpreting percentile distributions, identifying performance regressions, and root cause analysis\n",
    "- **Performance Tuning**: Common optimization techniques (caching, indexing, connection pooling, async processing)\n",
    "- **Reporting**: Creating executive dashboards and technical deep-dives for different stakeholders\n",
    "- **Production Monitoring**: Synthetic monitoring and real user monitoring (RUM) to validate test results in production\n",
    "\n",
    "This chapter will provide the **operational expertise** to run successful performance tests and translate raw metrics into actionable engineering decisions.\n",
    "\n",
    "**Continue to Chapter 35 to learn how to execute performance tests and turn results into optimized systems!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
