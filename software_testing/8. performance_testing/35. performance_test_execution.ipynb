{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 35: Performance Test Execution**\n",
    "\n",
    "---\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "Having the right tools and understanding the theory of performance testing is only half the battle. The execution phase\u2014how you prepare the environment, run the tests, monitor the systems, and analyze results\u2014determines whether your performance testing provides actionable insights or misleading data.\n",
    "\n",
    "A poorly executed performance test is worse than no test at all. It can give false confidence (\"the system passed\") when critical issues lurk undetected, or create false alarms that waste engineering time chasing ghosts. This chapter covers the operational discipline required to execute performance tests that accurately reflect production reality and guide optimization efforts.\n",
    "\n",
    "---\n",
    "\n",
    "## **35.1 Test Environment Setup**\n",
    "\n",
    "### **35.1.1 Production-Like Environment Requirements**\n",
    "\n",
    "Performance test results are only valid if the test environment mirrors production characteristics. Even minor differences can invalidate results.\n",
    "\n",
    "**Critical Environment Parities:**\n",
    "\n",
    "| Component | Production | Test Environment | Risk of Deviation |\n",
    "|-----------|-----------|------------------|-------------------|\n",
    "| **Hardware** | 32-core, 128GB RAM | 16-core, 64GB RAM | Linear scaling assumptions fail |\n",
    "| **Network** | 10Gbps, <1ms latency | 1Gbps, 10ms latency | Timeouts, throughput limits |\n",
    "| **Database** | 500M rows, SSD | 10K rows, HDD | Query plans differ, I/O bottlenecks hidden |\n",
    "| **Middleware** | 8-node cluster | Single instance | Connection limits, load balancing untested |\n",
    "| **OS/Kernel** | RHEL 8, tuned | Ubuntu default | TCP buffer sizes, file descriptor limits |\n",
    "\n",
    "**Environment Checklist:**\n",
    "\n",
    "```python\n",
    "# Environment validation script\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "class EnvironmentValidator:\n",
    "    \"\"\"\n",
    "    Validates test environment parity with production\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, production_specs):\n",
    "        self.prod = production_specs\n",
    "        self.issues = []\n",
    "    \n",
    "    def validate_compute_resources(self):\n",
    "        \"\"\"Check CPU and Memory\"\"\"\n",
    "        # CPU cores\n",
    "        cpu_count = subprocess.getoutput('nproc')\n",
    "        if int(cpu_count) < self.prod['cpu_cores']:\n",
    "            self.issues.append(\n",
    "                f\"CPU cores: Test has {cpu_count}, \"\n",
    "                f\"Production has {self.prod['cpu_cores']}\"\n",
    "            )\n",
    "        \n",
    "        # Memory\n",
    "        mem_info = subprocess.getoutput(\"cat /proc/meminfo | grep MemTotal\")\n",
    "        mem_kb = int(mem_info.split()[1])\n",
    "        mem_gb = mem_kb / (1024 * 1024)\n",
    "        \n",
    "        if mem_gb < self.prod['memory_gb'] * 0.8:  # Allow 20% variance\n",
    "            self.issues.append(\n",
    "                f\"Memory: Test has {mem_gb:.1f}GB, \"\n",
    "                f\"Production has {self.prod['memory_gb']}GB\"\n",
    "            )\n",
    "    \n",
    "    def validate_network(self):\n",
    "        \"\"\"Check network bandwidth and latency\"\"\"\n",
    "        import speedtest\n",
    "        st = speedtest.Speedtest()\n",
    "        \n",
    "        download_mbps = st.download() / 1_000_000\n",
    "        upload_mbps = st.upload() / 1_000_000\n",
    "        \n",
    "        if download_mbps < self.prod['network_gbps'] * 1000 * 0.5:\n",
    "            self.issues.append(\n",
    "                f\"Network bandwidth may be insufficient: \"\n",
    "                f\"{download_mbps:.0f}Mbps available\"\n",
    "            )\n",
    "    \n",
    "    def validate_database(self):\n",
    "        \"\"\"Check database size and configuration\"\"\"\n",
    "        # Check if database has realistic data volume\n",
    "        query = \"SELECT pg_size_pretty(pg_database_size('test_db'))\"\n",
    "        size = self.execute_sql(query)\n",
    "        \n",
    "        if 'GB' not in size and 'TB' not in size:\n",
    "            self.issues.append(\n",
    "                f\"Database size {size} may be too small for realistic testing\"\n",
    "            )\n",
    "        \n",
    "        # Check connection pool configuration\n",
    "        pool_size = self.execute_sql(\"SHOW max_connections\")\n",
    "        if int(pool_size) < self.prod['max_connections']:\n",
    "            self.issues.append(\n",
    "                f\"DB connections: {pool_size} vs {self.prod['max_connections']}\"\n",
    "            )\n",
    "    \n",
    "    def generate_report(self):\n",
    "        if not self.issues:\n",
    "            return \"Environment validation PASSED\"\n",
    "        \n",
    "        report = \"Environment validation WARNINGS:\\n\"\n",
    "        for issue in self.issues:\n",
    "            report += f\"- {issue}\\n\"\n",
    "        report += \"\\nRecommendations: Scale test environment or adjust expectations\"\n",
    "        return report\n",
    "\n",
    "# Usage\n",
    "validator = EnvironmentValidator({\n",
    "    'cpu_cores': 32,\n",
    "    'memory_gb': 128,\n",
    "    'network_gbps': 10,\n",
    "    'max_connections': 500\n",
    "})\n",
    "validator.validate_compute_resources()\n",
    "print(validator.generate_report())\n",
    "```\n",
    "\n",
    "### **35.1.2 Test Data Preparation**\n",
    "\n",
    "**Data Volume Requirements:**\n",
    "- **Database**: Should contain at least 80% of production data volume\n",
    "- **Data Distribution**: Match production data distribution (histograms, cardinality)\n",
    "- **Cache Warming**: Pre-populate caches to avoid \"cold cache\" anomalies\n",
    "\n",
    "```sql\n",
    "-- Database size verification\n",
    "SELECT \n",
    "    schemaname,\n",
    "    tablename,\n",
    "    pg_size_pretty(pg_total_relation_size(tablename::regclass)) as size,\n",
    "    n_live_tup as row_count\n",
    "FROM pg_stat_user_tables \n",
    "WHERE schemaname = 'public'\n",
    "ORDER BY pg_total_relation_size(tablename::regclass) DESC;\n",
    "\n",
    "-- Check data distribution matches production\n",
    "SELECT \n",
    "    date_trunc('day', created_at) as day,\n",
    "    count(*) as records\n",
    "FROM orders\n",
    "WHERE created_at > now() - interval '30 days'\n",
    "GROUP BY 1\n",
    "ORDER BY 1;\n",
    "```\n",
    "\n",
    "**Data Masking for Performance Testing:**\n",
    "When using production data subsets, ensure sensitive data is masked while preserving data characteristics (cardinality, distribution).\n",
    "\n",
    "```python\n",
    "# Masking utility that preserves performance characteristics\n",
    "import hashlib\n",
    "import faker\n",
    "\n",
    "class PerformanceDataMasker:\n",
    "    \"\"\"\n",
    "    Masks PII while preserving data characteristics for realistic query plans\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.fake = faker.Faker()\n",
    "    \n",
    "    def mask_email_preserving_domain(self, email):\n",
    "        \"\"\"Keep domain distribution for query optimization\"\"\"\n",
    "        if '@' not in email:\n",
    "            return self.fake.email()\n",
    "        domain = email.split('@')[1]\n",
    "        return f\"user_{hashlib.md5(email.encode()).hexdigest()[:8]}@{domain}\"\n",
    "    \n",
    "    def mask_credit_card_preserving_bin(self, card_number):\n",
    "        \"\"\"Preserve BIN (first 6 digits) for routing logic tests\"\"\"\n",
    "        bin_number = str(card_number)[:6]\n",
    "        random_suffix = hashlib.md5(str(card_number).encode()).hexdigest()[:10]\n",
    "        return f\"{bin_number}******{random_suffix}\"\n",
    "    \n",
    "    def generate_consistent_fake_data(self, table_name, row_count):\n",
    "        \"\"\"\n",
    "        Generate synthetic data with same cardinality as production\n",
    "        \"\"\"\n",
    "        if table_name == 'users':\n",
    "            return [\n",
    "                {\n",
    "                    'id': i,\n",
    "                    'email': self.fake.email(),\n",
    "                    'created_at': self.fake.date_between('-2y', 'now'),\n",
    "                    'status': random.choice(['active', 'inactive', 'suspended'])\n",
    "                }\n",
    "                for i in range(row_count)\n",
    "            ]\n",
    "```\n",
    "\n",
    "### **35.1.3 Monitoring Setup**\n",
    "\n",
    "Before running tests, establish comprehensive monitoring. You cannot optimize what you cannot measure.\n",
    "\n",
    "**The Three Pillars of Observability:**\n",
    "\n",
    "```\n",
    "Performance Monitoring Stack:\n",
    "\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    Application Layer                        \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n",
    "\u2502  \u2502   APM Tools  \u2502  \u2502   Logs       \u2502  \u2502   Metrics    \u2502    \u2502\n",
    "\u2502  \u2502  (New Relic, \u2502  \u2502  (ELK Stack, \u2502  \u2502 (Prometheus,\u2502    \u2502\n",
    "\u2502  \u2502   Datadog,   \u2502  \u2502   Splunk)    \u2502  \u2502  Grafana)   \u2502    \u2502\n",
    "\u2502  \u2502   Dynatrace) \u2502  \u2502              \u2502  \u2502             \u2502    \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                              \u2502\n",
    "                              \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    Infrastructure Layer                      \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n",
    "\u2502  \u2502   Server     \u2502  \u2502   Network    \u2502  \u2502   Database   \u2502    \u2502\n",
    "\u2502  \u2502   (CPU,Mem)  \u2502  \u2502  (Latency,   \u2502  \u2502  (Slow Query \u2502    \u2502\n",
    "\u2502  \u2502   Disk I/O   \u2502  \u2502   Throughput)\u2502  \u2502   Log, Locks)\u2502    \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**Essential Metrics to Monitor:**\n",
    "\n",
    "```yaml\n",
    "# Monitoring configuration checklist\n",
    "Application_Metrics:\n",
    "  - Response_time_percentiles: [p50, p95, p99]\n",
    "  - Throughput: requests_per_second\n",
    "  - Error_rates: [4xx_rate, 5xx_rate, timeout_rate]\n",
    "  - Thread_pool: [active, queued, rejected]\n",
    "  - GC_metrics: [frequency, pause_duration]  # For JVM apps\n",
    "\n",
    "Database_Metrics:\n",
    "  - Query_performance: slow_query_log_threshold_100ms\n",
    "  - Connection_pool: [active, idle, wait_queue]\n",
    "  - Lock_metrics: [deadlocks, lock_waits]\n",
    "  - Cache_hit_ratio: buffer_pool_read_efficiency\n",
    "  - Disk_I/O: reads_per_sec, writes_per_sec\n",
    "\n",
    "Infrastructure_Metrics:\n",
    "  - CPU: [user, system, iowait]  # iowait > 20% indicates disk bottleneck\n",
    "  - Memory: [used, cached, available, swap_usage]\n",
    "  - Network: [bytes_in, bytes_out, retransmits]\n",
    "  - Disk: [utilization_percent, queue_depth, await]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **35.2 Test Execution Best Practices**\n",
    "\n",
    "### **35.2.1 The Performance Test Lifecycle**\n",
    "\n",
    "```\n",
    "Proper Test Execution Flow:\n",
    "\n",
    "1. ENVIRONMENT VALIDATION\n",
    "   \u2514\u2500 Verify hardware, data, monitoring are ready\n",
    "   \n",
    "2. BASELINE TEST\n",
    "   \u2514\u2500 Single user, single iteration\n",
    "   \u2514\u2500 Establishes \"best case\" response time\n",
    "   \n",
    "3. WARM-UP PHASE\n",
    "   \u2514\u2500 Gradual load to populate caches\n",
    "   \u2514\u2500 JIT compilation (JVM), connection pool initialization\n",
    "   \n",
    "4. RAMP-UP PHASE\n",
    "   \u2514\u2500 Gradual increase to target load\n",
    "   \u2514\u2500 Prevents thundering herd\n",
    "   \n",
    "5. STEADY STATE\n",
    "   \u2514\u2500 Sustained target load\n",
    "   \u2514\u2500 Duration: 2x the longest business transaction\n",
    "   \n",
    "6. RAMP-DOWN\n",
    "   \u2514\u2500 Gradual decrease\n",
    "   \u2514\u2500 Tests resource deallocation\n",
    "   \n",
    "7. COOL-DOWN & ANALYSIS\n",
    "   \u2514\u2500 System returns to baseline\n",
    "   \u2514\u2500 Memory leak detection\n",
    "```\n",
    "\n",
    "### **35.2.2 Warm-Up Periods**\n",
    "\n",
    "Cold systems perform differently than warm systems. Always include a warm-up period:\n",
    "\n",
    "```python\n",
    "# Warm-up implementation in test script\n",
    "class PerformanceTestWithWarmup:\n",
    "    def __init__(self):\n",
    "        self.warmup_duration = 300  # 5 minutes\n",
    "        self.target_users = 1000\n",
    "        \n",
    "    def execute(self):\n",
    "        # Phase 1: Warm-up\n",
    "        print(\"Starting warm-up phase...\")\n",
    "        self.run_load(\n",
    "            users=10,  # Light load\n",
    "            duration=self.warmup_duration,\n",
    "            label=\"warmup\"\n",
    "        )\n",
    "        \n",
    "        # Verify system is warm\n",
    "        metrics = self.collect_metrics()\n",
    "        if metrics['error_rate'] > 0.01:\n",
    "            raise Exception(\"System unstable after warm-up\")\n",
    "        \n",
    "        # Phase 2: Actual test\n",
    "        print(\"Starting main test...\")\n",
    "        results = self.run_load(\n",
    "            users=self.target_users,\n",
    "            duration=3600,\n",
    "            label=\"main_test\"\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def run_load(self, users, duration, label):\n",
    "        # Implementation of load generation\n",
    "        pass\n",
    "```\n",
    "\n",
    "**Why Warm-Up Matters:**\n",
    "- **JVM**: JIT compilation optimizes hot paths after ~10,000 iterations\n",
    "- **Database**: Query plan cache, buffer pool population\n",
    "- **Connection Pools**: Initial connection establishment overhead\n",
    "- **Caches**: Application caches populate with real data\n",
    "\n",
    "### **35.2.3 Gradual Ramp-Up Strategies**\n",
    "\n",
    "Avoid starting tests with full target load immediately. This creates unrealistic \"thundering herd\" problems.\n",
    "\n",
    "**Recommended Ramp-Up Formula:**\n",
    "```\n",
    "Ramp-Up Time = Target Users / User Addition Rate\n",
    "\n",
    "Where:\n",
    "- User Addition Rate = 10-20% of target users per minute\n",
    "- Example: 1000 users at 10%/min = 100 users/min = 10-minute ramp-up\n",
    "```\n",
    "\n",
    "```python\n",
    "# Implementing smooth ramp-up\n",
    "def calculate_ramp_schedule(target_users, ramp_duration_minutes):\n",
    "    \"\"\"\n",
    "    Generate user addition schedule for smooth ramp-up\n",
    "    \"\"\"\n",
    "    schedule = []\n",
    "    steps = ramp_duration_minutes\n",
    "    users_per_step = target_users / steps\n",
    "    \n",
    "    for minute in range(1, steps + 1):\n",
    "        cumulative_users = int(minute * users_per_step)\n",
    "        schedule.append({\n",
    "            'time': minute,\n",
    "            'active_users': cumulative_users,\n",
    "            'users_to_add': int(users_per_step)\n",
    "        })\n",
    "    \n",
    "    return schedule\n",
    "\n",
    "# Example output for 1000 users over 10 minutes:\n",
    "# Minute 1: 100 users\n",
    "# Minute 2: 200 users\n",
    "# ...\n",
    "# Minute 10: 1000 users\n",
    "```\n",
    "\n",
    "### **35.2.4 Real-Time Monitoring During Tests**\n",
    "\n",
    "Monitor key indicators during execution to abort tests if the system is failing catastrophically (saving time):\n",
    "\n",
    "```python\n",
    "class RealTimeMonitor:\n",
    "    \"\"\"\n",
    "    Monitors test health during execution and can trigger early abort\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, abort_thresholds):\n",
    "        self.thresholds = abort_thresholds\n",
    "        self.metrics_history = []\n",
    "        \n",
    "    def check_health(self, current_metrics):\n",
    "        \"\"\"\n",
    "        Returns (should_continue, reason)\n",
    "        \"\"\"\n",
    "        self.metrics_history.append(current_metrics)\n",
    "        \n",
    "        # Check error rate\n",
    "        if current_metrics['error_rate'] > self.thresholds['max_error_rate']:\n",
    "            return False, f\"Error rate {current_metrics['error_rate']} exceeds threshold\"\n",
    "        \n",
    "        # Check response time degradation\n",
    "        if len(self.metrics_history) > 6:  # Last 6 data points\n",
    "            recent_p95 = [m['p95'] for m in self.metrics_history[-6:]]\n",
    "            if all(t > self.thresholds['max_p95'] for t in recent_p95):\n",
    "                return False, f\"Persistent P95 > {self.thresholds['max_p95']}ms\"\n",
    "        \n",
    "        # Check for sudden throughput drop (possible deadlock)\n",
    "        if len(self.metrics_history) > 3:\n",
    "            current_tps = current_metrics['throughput']\n",
    "            previous_tps = self.metrics_history[-2]['throughput']\n",
    "            if current_tps < previous_tps * 0.5:\n",
    "                return False, f\"Throughput dropped 50%: {previous_tps} -> {current_tps}\"\n",
    "        \n",
    "        return True, \"Healthy\"\n",
    "\n",
    "# Usage in test loop\n",
    "monitor = RealTimeMonitor({\n",
    "    'max_error_rate': 0.10,  # Abort if >10% errors\n",
    "    'max_p95': 5000,         # Abort if P95 > 5s sustained\n",
    "    'min_throughput': 100    # Minimum acceptable TPS\n",
    "})\n",
    "\n",
    "while test_running:\n",
    "    metrics = collect_current_metrics()\n",
    "    should_continue, reason = monitor.check_health(metrics)\n",
    "    \n",
    "    if not should_continue:\n",
    "        print(f\"ABORTING TEST: {reason}\")\n",
    "        gracefully_shutdown_test()\n",
    "        break\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **35.3 Bottleneck Identification**\n",
    "\n",
    "### **35.3.1 The Performance Tuning Cycle**\n",
    "\n",
    "```\n",
    "Identify Bottleneck \u2192 Hypothesis \u2192 Implement Fix \u2192 Validate \u2192 Repeat\n",
    "\n",
    "Common Bottleneck Pattern:\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    User Request                               \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                              \u2502\n",
    "                              \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n",
    "\u2502  \u2502   Web Server \u2502  \u2502  Application \u2502  \u2502   Database   \u2502      \u2502\n",
    "\u2502  \u2502   (Nginx)    \u2502  \u2502    (Java)    \u2502  \u2502  (Postgres)  \u2502      \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n",
    "\u2502        \u2502                  \u2502                  \u2502              \u2502\n",
    "\u2502        \u25bc                  \u25bc                  \u25bc              \u2502\n",
    "\u2502   CPU/Mem/IO         GC/Threads/Heap    Connections/IOPS     \u2502\n",
    "\u2502   [Bottleneck?]      [Bottleneck?]       [Bottleneck?]       \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### **35.3.2 CPU-Bound vs. I/O-Bound Identification**\n",
    "\n",
    "Use `vmstat` or similar tools to identify the constraint:\n",
    "\n",
    "```bash\n",
    "# Linux: vmstat 1 (samples every second)\n",
    "# Output interpretation:\n",
    "# - us (user CPU) > 80%: CPU bound (need faster code or more cores)\n",
    "# - wa (wait I/O) > 20%: Disk I/O bound (need SSD, caching, or query optimization)\n",
    "# - si/so (swap in/out) > 0: Memory bound (need more RAM)\n",
    "\n",
    "$ vmstat 1\n",
    "procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n",
    " r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n",
    " 2  0      0 234567  12345 456789    0    0    10    20   10   80 15  5 80  0  0\n",
    " 5  0      0 234500  12345 456800    0    0     0     0   95  200 85 10  0  5  0  # CPU bound (us=85)\n",
    " 2  0      0 234500  12345 456800    0    0  5000   100   50  100 10  5  0 85  0  # I/O bound (wa=85)\n",
    "```\n",
    "\n",
    "**Python Analysis Script:**\n",
    "\n",
    "```python\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "class BottleneckAnalyzer:\n",
    "    def analyze_system_state(self):\n",
    "        cpu_percent = psutil.cpu_percent(interval=1)\n",
    "        cpu_times = psutil.cpu_times_percent(interval=1)\n",
    "        \n",
    "        memory = psutil.virtual_memory()\n",
    "        disk_io = psutil.disk_io_counters()\n",
    "        net_io = psutil.net_io_counters()\n",
    "        \n",
    "        analysis = {\n",
    "            'cpu_total': cpu_percent,\n",
    "            'cpu_user': cpu_times.user,\n",
    "            'cpu_system': cpu_times.system,\n",
    "            'cpu_iowait': getattr(cpu_times, 'iowait', 0),\n",
    "            'memory_percent': memory.percent,\n",
    "            'memory_available_gb': memory.available / (1024**3),\n",
    "            'disk_read_mb': disk_io.read_bytes / (1024**2),\n",
    "            'disk_write_mb': disk_io.write_bytes / (1024**2),\n",
    "        }\n",
    "        \n",
    "        # Determine bottleneck type\n",
    "        if analysis['cpu_iowait'] > 20:\n",
    "            analysis['bottleneck'] = 'IO_BOUND'\n",
    "            analysis['recommendation'] = 'Optimize disk access: caching, indexing, SSD upgrade'\n",
    "        elif analysis['cpu_total'] > 85:\n",
    "            analysis['bottleneck'] = 'CPU_BOUND'\n",
    "            analysis['recommendation'] = 'Optimize code: profiling, algorithmic improvements, scaling'\n",
    "        elif analysis['memory_percent'] > 90:\n",
    "            analysis['bottleneck'] = 'MEMORY_BOUND'\n",
    "            analysis['recommendation'] = 'Reduce memory usage: caching limits, pagination, heap tuning'\n",
    "        else:\n",
    "            analysis['bottleneck'] = 'UNKNOWN'\n",
    "            analysis['recommendation'] = 'Check application logs, database slow queries'\n",
    "        \n",
    "        return analysis\n",
    "```\n",
    "\n",
    "### **35.3.3 Database Bottleneck Analysis**\n",
    "\n",
    "**Slow Query Identification:**\n",
    "```sql\n",
    "-- PostgreSQL: Find slow queries during test\n",
    "SELECT \n",
    "    query,\n",
    "    calls,\n",
    "    total_time / 1000 as total_seconds,\n",
    "    mean_time as avg_ms,\n",
    "    max_time as max_ms,\n",
    "    rows / calls as avg_rows\n",
    "FROM pg_stat_statements\n",
    "WHERE mean_time > 100  -- Queries taking >100ms on average\n",
    "ORDER BY total_time DESC\n",
    "LIMIT 10;\n",
    "\n",
    "-- Check for missing indexes\n",
    "SELECT \n",
    "    schemaname,\n",
    "    tablename,\n",
    "    seq_scan,\n",
    "    seq_tup_read,\n",
    "    idx_scan,\n",
    "    n_tup_ins,\n",
    "    n_tup_upd\n",
    "FROM pg_stat_user_tables\n",
    "WHERE seq_scan > 0\n",
    "ORDER BY seq_tup_read DESC;\n",
    "```\n",
    "\n",
    "**Connection Pool Exhaustion:**\n",
    "```python\n",
    "# Detect connection pool saturation\n",
    "def check_connection_pool_health(db_stats):\n",
    "    active = db_stats['active_connections']\n",
    "    max_conn = db_stats['max_connections']\n",
    "    waiting = db_stats['waiting_connections']\n",
    "    \n",
    "    utilization = (active / max_conn) * 100\n",
    "    \n",
    "    if utilization > 80:\n",
    "        return {\n",
    "            'status': 'CRITICAL',\n",
    "            'issue': 'Connection pool near exhaustion',\n",
    "            'action': 'Increase pool size or implement connection pooling (PgBouncer)'\n",
    "        }\n",
    "    \n",
    "    if waiting > 10:\n",
    "        return {\n",
    "            'status': 'WARNING',\n",
    "            'issue': 'Connections waiting in queue',\n",
    "            'action': 'Optimize query time or increase pool'\n",
    "        }\n",
    "    \n",
    "    return {'status': 'HEALTHY'}\n",
    "```\n",
    "\n",
    "### **35.3.4 Memory Leak Detection**\n",
    "\n",
    "During endurance tests, monitor for memory growth that doesn't plateau:\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MemoryLeakDetector:\n",
    "    def __init__(self):\n",
    "        self.measurements = []\n",
    "    \n",
    "    def record_memory(self, timestamp, memory_mb):\n",
    "        self.measurements.append((timestamp, memory_mb))\n",
    "    \n",
    "    def analyze_trend(self):\n",
    "        \"\"\"\n",
    "        Uses linear regression to detect upward trend\n",
    "        \"\"\"\n",
    "        if len(self.measurements) < 10:\n",
    "            return {'status': 'INSUFFICIENT_DATA'}\n",
    "        \n",
    "        # Simple trend analysis: compare first half to second half\n",
    "        mid = len(self.measurements) // 2\n",
    "        first_half = [m[1] for m in self.measurements[:mid]]\n",
    "        second_half = [m[1] for m in self.measurements[mid:]]\n",
    "        \n",
    "        first_avg = sum(first_half) / len(first_half)\n",
    "        second_avg = sum(second_half) / len(second_half)\n",
    "        \n",
    "        growth_percent = ((second_avg - first_avg) / first_avg) * 100\n",
    "        \n",
    "        if growth_percent > 20:\n",
    "            return {\n",
    "                'status': 'LEAK_DETECTED',\n",
    "                'growth_percent': growth_percent,\n",
    "                'recommendation': 'Generate heap dump and analyze with Eclipse MAT or similar'\n",
    "            }\n",
    "        elif growth_percent > 5:\n",
    "            return {\n",
    "                'status': 'SUSPECT',\n",
    "                'growth_percent': growth_percent,\n",
    "                'recommendation': 'Continue monitoring, possible slow leak'\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'status': 'STABLE',\n",
    "                'growth_percent': growth_percent\n",
    "            }\n",
    "    \n",
    "    def plot_memory(self):\n",
    "        times = [m[0] for m in self.measurements]\n",
    "        memory = [m[1] for m in self.measurements]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(times, memory, 'b-', label='Memory Usage')\n",
    "        plt.axhline(y=memory[0], color='r', linestyle='--', label='Baseline')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Memory (MB)')\n",
    "        plt.title('Memory Usage During Endurance Test')\n",
    "        plt.legend()\n",
    "        plt.savefig('memory_trend.png')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **35.4 Result Analysis**\n",
    "\n",
    "### **35.4.1 Statistical Analysis of Results**\n",
    "\n",
    "Don't rely on averages. Use percentiles and standard deviation to understand distribution.\n",
    "\n",
    "```python\n",
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "class PerformanceAnalyzer:\n",
    "    def analyze_results(self, response_times):\n",
    "        \"\"\"\n",
    "        Comprehensive statistical analysis\n",
    "        \"\"\"\n",
    "        sorted_times = sorted(response_times)\n",
    "        n = len(sorted_times)\n",
    "        \n",
    "        # Calculate percentiles\n",
    "        percentiles = {\n",
    "            'p50': np.percentile(sorted_times, 50),\n",
    "            'p75': np.percentile(sorted_times, 75),\n",
    "            'p90': np.percentile(sorted_times, 90),\n",
    "            'p95': np.percentile(sorted_times, 95),\n",
    "            'p99': np.percentile(sorted_times, 99),\n",
    "            'p999': np.percentile(sorted_times, 99.9)\n",
    "        }\n",
    "        \n",
    "        # Standard deviation and variance\n",
    "        std_dev = statistics.stdev(sorted_times)\n",
    "        mean = statistics.mean(sorted_times)\n",
    "        cv = (std_dev / mean) * 100  # Coefficient of variation\n",
    "        \n",
    "        analysis = {\n",
    "            'count': n,\n",
    "            'mean': mean,\n",
    "            'min': min(sorted_times),\n",
    "            'max': max(sorted_times),\n",
    "            'std_dev': std_dev,\n",
    "            'cv_percent': cv,\n",
    "            'percentiles': percentiles\n",
    "        }\n",
    "        \n",
    "        # Interpretation\n",
    "        if cv > 30:\n",
    "            analysis['consistency'] = 'HIGH_VARIANCE'\n",
    "            analysis['recommendation'] = 'Response times are inconsistent. Check for GC pauses or resource contention.'\n",
    "        elif cv > 10:\n",
    "            analysis['consistency'] = 'MODERATE_VARIANCE'\n",
    "        else:\n",
    "            analysis['consistency'] = 'LOW_VARIANCE'\n",
    "            analysis['recommendation'] = 'System performance is consistent'\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def compare_to_baseline(self, current_results, baseline_results):\n",
    "        \"\"\"\n",
    "        Detect performance regressions\n",
    "        \"\"\"\n",
    "        degradation_threshold = 1.20  # 20% regression\n",
    "        \n",
    "        current_p95 = current_results['percentiles']['p95']\n",
    "        baseline_p95 = baseline_results['percentiles']['p95']\n",
    "        \n",
    "        change_percent = ((current_p95 - baseline_p95) / baseline_p95) * 100\n",
    "        \n",
    "        comparison = {\n",
    "            'baseline_p95': baseline_p95,\n",
    "            'current_p95': current_p95,\n",
    "            'change_percent': change_percent,\n",
    "            'regression': change_percent > 20,\n",
    "            'status': 'REGRESSION' if change_percent > 20 else 'ACCEPTABLE'\n",
    "        }\n",
    "        \n",
    "        return comparison\n",
    "```\n",
    "\n",
    "### **35.4.2 Latency Distribution Visualization**\n",
    "\n",
    "Understanding the shape of your latency distribution helps identify issues:\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_latency_distribution(response_times):\n",
    "    \"\"\"\n",
    "    Create histogram with percentile markers\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(response_times, bins=50, edgecolor='black', alpha=0.7)\n",
    "    plt.axvline(np.percentile(response_times, 95), color='r', linestyle='--', \n",
    "                label='P95')\n",
    "    plt.axvline(np.percentile(response_times, 99), color='orange', linestyle='--', \n",
    "                label='P99')\n",
    "    plt.xlabel('Response Time (ms)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Response Time Distribution')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Percentile chart\n",
    "    plt.subplot(1, 2, 2)\n",
    "    percentiles = [50, 75, 90, 95, 99, 99.9]\n",
    "    values = [np.percentile(response_times, p) for p in percentiles]\n",
    "    \n",
    "    plt.plot(percentiles, values, 'bo-', linewidth=2, markersize=8)\n",
    "    plt.xlabel('Percentile')\n",
    "    plt.ylabel('Response Time (ms)')\n",
    "    plt.title('Latency Percentiles')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('latency_analysis.png')\n",
    "    \n",
    "    # Detect \"hockey stick\" (sudden latency increase at high percentiles)\n",
    "    p95 = values[3]\n",
    "    p99 = values[4]\n",
    "    if p99 > p95 * 2:\n",
    "        print(\"WARNING: Latency hockey stick detected at P99\")\n",
    "        print(\"Indication of tail latency issues (GC, locks, timeouts)\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **35.5 Performance Tuning Techniques**\n",
    "\n",
    "### **35.5.1 Caching Strategies**\n",
    "\n",
    "```python\n",
    "# Implementing multi-layer caching\n",
    "import functools\n",
    "import redis\n",
    "from cachetools import TTLCache\n",
    "\n",
    "class PerformanceOptimizedService:\n",
    "    def __init__(self):\n",
    "        self.local_cache = TTLCache(maxsize=1000, ttl=60)  # L1: In-memory\n",
    "        self.redis_client = redis.Redis()                  # L2: Distributed\n",
    "    \n",
    "    def get_user_profile(self, user_id):\n",
    "        \"\"\"\n",
    "        Multi-tier caching strategy\n",
    "        \"\"\"\n",
    "        # L1: Check local memory (fastest, < 1ms)\n",
    "        if user_id in self.local_cache:\n",
    "            return self.local_cache[user_id]\n",
    "        \n",
    "        # L2: Check Redis (< 5ms)\n",
    "        cached = self.redis_client.get(f\"user:{user_id}\")\n",
    "        if cached:\n",
    "            user = json.loads(cached)\n",
    "            self.local_cache[user_id] = user  # Promote to L1\n",
    "            return user\n",
    "        \n",
    "        # L3: Database (slowest, 10-50ms)\n",
    "        user = self.db.query(User).get(user_id)\n",
    "        \n",
    "        # Populate caches\n",
    "        self.redis_client.setex(f\"user:{user_id}\", 300, json.dumps(user))\n",
    "        self.local_cache[user_id] = user\n",
    "        \n",
    "        return user\n",
    "    \n",
    "    @functools.lru_cache(maxsize=128)\n",
    "    def calculate_expensive_metric(self, param):\n",
    "        \"\"\"\n",
    "        Function-level caching for CPU-intensive operations\n",
    "        \"\"\"\n",
    "        # Expensive calculation\n",
    "        return result\n",
    "```\n",
    "\n",
    "### **35.5.2 Database Optimization**\n",
    "\n",
    "**Connection Pooling:**\n",
    "```yaml\n",
    "# HikariCP configuration (JVM)\n",
    "hikari:\n",
    "  minimum-idle: 10\n",
    "  maximum-pool-size: 50\n",
    "  connection-timeout: 30000\n",
    "  idle-timeout: 600000\n",
    "  max-lifetime: 1800000\n",
    "  leak-detection-threshold: 60000  # Detect connection leaks\n",
    "```\n",
    "\n",
    "**Query Optimization:**\n",
    "```sql\n",
    "-- Add covering index for frequently queried columns\n",
    "CREATE INDEX CONCURRENTLY idx_orders_user_date_status \n",
    "ON orders(user_id, created_at, status) \n",
    "INCLUDE (total_amount);  -- Covering index avoids table lookup\n",
    "\n",
    "-- Analyze query plan\n",
    "EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON)\n",
    "SELECT * FROM orders \n",
    "WHERE user_id = 123 \n",
    "AND created_at > '2026-01-01';\n",
    "```\n",
    "\n",
    "### **35.5.3 Async Processing**\n",
    "\n",
    "Move blocking operations to background:\n",
    "\n",
    "```python\n",
    "# Asynchronous processing with Celery\n",
    "from celery import Celery\n",
    "\n",
    "app = Celery('tasks', broker='redis://localhost:6379')\n",
    "\n",
    "@app.task\n",
    "def process_order_async(order_id):\n",
    "    \"\"\"\n",
    "    Offload heavy processing from request thread\n",
    "    \"\"\"\n",
    "    order = Order.query.get(order_id)\n",
    "    # Heavy processing: inventory check, payment processing, email sending\n",
    "    process_payment(order)\n",
    "    update_inventory(order)\n",
    "    send_confirmation_email(order)\n",
    "\n",
    "# In web endpoint\n",
    "@app.route('/orders', methods=['POST'])\n",
    "def create_order():\n",
    "    order = create_order_in_db(request.json)\n",
    "    # Queue async task, return immediately\n",
    "    process_order_async.delay(order.id)\n",
    "    return {'order_id': order.id, 'status': 'processing'}, 202\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **35.6 Reporting**\n",
    "\n",
    "### **35.6.1 Executive Dashboard**\n",
    "\n",
    "High-level view for stakeholders:\n",
    "\n",
    "```yaml\n",
    "Executive_Summary:\n",
    "  Test_Date: \"2026-02-15\"\n",
    "  Application: \"E-Commerce Platform v2.3\"\n",
    "  Test_Duration: \"4 hours\"\n",
    "  \n",
    "  Key_Findings:\n",
    "    Status: \"PASSED\"  # or \"FAILED\", \"CONDITIONAL\"\n",
    "    Max_Supported_Users: 15000\n",
    "    Peak_Response_Time_P95: \"450ms\"\n",
    "    Error_Rate: \"0.02%\"\n",
    "    Infrastructure_Cost_Per_1K_Users: \"$0.45\"\n",
    "  \n",
    "  Recommendations:\n",
    "    - \"System supports projected Black Friday load (12K users)\"\n",
    "    - \"Consider CDN for static assets to improve P95 by 20%\"\n",
    "    - \"Database connection pool should be increased before next scaling event\"\n",
    "  \n",
    "  Risk_Assessment: \"LOW\"\n",
    "```\n",
    "\n",
    "### **35.6.2 Technical Deep Dive**\n",
    "\n",
    "Detailed analysis for engineering teams:\n",
    "\n",
    "```python\n",
    "def generate_technical_report(results):\n",
    "    report = {\n",
    "        'bottlenecks_identified': [\n",
    "            {\n",
    "                'component': 'Database',\n",
    "                'issue': 'Sequential scan on orders table for date range queries',\n",
    "                'evidence': 'Query time 1200ms, Seq Scan in EXPLAIN plan',\n",
    "                'remediation': 'Add composite index on (created_at, status)',\n",
    "                'estimated_improvement': '80% reduction in query time'\n",
    "            },\n",
    "            {\n",
    "                'component': 'JVM',\n",
    "                'issue': 'GC pauses causing P99 spikes',\n",
    "                'evidence': 'GC logs show 200ms+ STW pauses every 30s',\n",
    "                'remediation': 'Switch to G1GC, increase heap to 8GB',\n",
    "                'estimated_improvement': 'P99 latency < 500ms'\n",
    "            }\n",
    "        ],\n",
    "        'resource_utilization': {\n",
    "            'cpu_peak': '85%',\n",
    "            'memory_peak': '12GB / 16GB',\n",
    "            'disk_io_peak': '450 IOPS',\n",
    "            'network_peak': '850 Mbps'\n",
    "        },\n",
    "        'scalability_analysis': {\n",
    "            'linear_scaling': 'Observed up to 8000 users',\n",
    "            'saturation_point': '10000 users (CPU bound)',\n",
    "            'efficiency_at_peak': '78%'\n",
    "        }\n",
    "    }\n",
    "    return report\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **35.7 Production Monitoring**\n",
    "\n",
    "### **35.7.1 Synthetic Monitoring**\n",
    "\n",
    "Continuous automated testing in production:\n",
    "\n",
    "```python\n",
    "# Synthetic monitoring script (runs every 5 minutes from multiple locations)\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def synthetic_check():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            'https://api.example.com/health',\n",
    "            timeout=10,\n",
    "            headers={'User-Agent': 'SyntheticMonitor/1.0'}\n",
    "        )\n",
    "        latency = (time.time() - start) * 1000\n",
    "        \n",
    "        check_result = {\n",
    "            'timestamp': time.time(),\n",
    "            'available': response.status_code == 200,\n",
    "            'latency_ms': latency,\n",
    "            'status_code': response.status_code,\n",
    "            'location': 'us-east-1'\n",
    "        }\n",
    "        \n",
    "        if latency > 1000:\n",
    "            alert_team(f\"High latency detected: {latency}ms\")\n",
    "        \n",
    "        return check_result\n",
    "        \n",
    "    except requests.exceptions.Timeout:\n",
    "        alert_team(\"CRITICAL: Health check timeout\")\n",
    "        return {'available': False, 'error': 'timeout'}\n",
    "```\n",
    "\n",
    "### **35.7.2 Real User Monitoring (RUM)**\n",
    "\n",
    "```javascript\n",
    "// JavaScript snippet for RUM (Real User Monitoring)\n",
    "window.addEventListener('load', function() {\n",
    "    const timing = performance.timing;\n",
    "    \n",
    "    const metrics = {\n",
    "        // DNS lookup time\n",
    "        dns: timing.domainLookupEnd - timing.domainLookupStart,\n",
    "        \n",
    "        // TCP connection time\n",
    "        tcp: timing.connectEnd - timing.connectStart,\n",
    "        \n",
    "        // Time to First Byte (TTFB)\n",
    "        ttfb: timing.responseStart - timing.requestStart,\n",
    "        \n",
    "        // DOM processing\n",
    "        domProcessing: timing.domComplete - timing.domLoading,\n",
    "        \n",
    "        // Total page load\n",
    "        totalLoad: timing.loadEventEnd - timing.navigationStart\n",
    "    };\n",
    "    \n",
    "    // Send to analytics\n",
    "    fetch('/rum-metrics', {\n",
    "        method: 'POST',\n",
    "        body: JSON.stringify(metrics),\n",
    "        headers: {'Content-Type': 'application/json'}\n",
    "    });\n",
    "});\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "### **Key Takeaways:**\n",
    "\n",
    "**Environment Setup (35.1):**\n",
    "- **Production parity** is non-negotiable: hardware, data volume, and network latency must mirror production\n",
    "- **Data masking** must preserve cardinality and distribution to ensure query plans match production\n",
    "- **Comprehensive monitoring** (APM, infrastructure, logs) must be in place before testing begins\n",
    "\n",
    "**Execution Best Practices (35.2):**\n",
    "- **Warm-up phases** are essential (5-10 minutes) to populate caches and allow JVM optimization\n",
    "- **Gradual ramp-up** prevents thundering herd problems; use 10-20% of target load per minute\n",
    "- **Real-time health checks** can abort tests early if catastrophic failure occurs, saving time\n",
    "\n",
    "**Bottleneck Identification (35.3):**\n",
    "- **CPU vs. I/O**: Use `vmstat` to distinguish (high 'us' = CPU bound, high 'wa' = I/O bound)\n",
    "- **Database**: Check slow query logs, missing indexes, and connection pool saturation (>80% utilization is concerning)\n",
    "- **Memory leaks**: Detect via trend analysis in endurance tests (>10% growth over test duration indicates leak)\n",
    "\n",
    "**Result Analysis (35.4):**\n",
    "- **Percentiles matter**: Focus on P95 and P99, not averages; watch for \"hockey stick\" patterns indicating tail latency\n",
    "- **Coefficient of Variation**: CV > 30% indicates high variance and potential instability\n",
    "- **Baseline comparison**: Fail builds on >20% regression from baseline P95\n",
    "\n",
    "**Performance Tuning (35.5):**\n",
    "- **Caching hierarchy**: L1 (in-memory) \u2192 L2 (Redis) \u2192 L3 (Database); each layer 10x slower than previous\n",
    "- **Connection pooling**: Size pools at (core_count * 2) + effective_spindle_count for databases\n",
    "- **Async processing**: Move non-critical path operations to background queues\n",
    "\n",
    "**Reporting (35.6):**\n",
    "- **Executive reports**: Pass/fail status, max capacity, risk assessment\n",
    "- **Technical reports**: Specific bottlenecks, query plans, GC logs, remediation steps\n",
    "\n",
    "**Production Monitoring (35.7):**\n",
    "- **Synthetic monitoring**: Proactive uptime checks from multiple geographic locations\n",
    "- **RUM**: Real user metrics provide ground truth but require large sample sizes for statistical significance\n",
    "\n",
    "**Critical Success Factors:**\n",
    "1. **Test data realism**: Empty databases lie; test with production-like data volumes\n",
    "2. **Isolation**: Ensure tests don't interfere with each other or production systems\n",
    "3. **Monitoring**: You cannot optimize what you cannot measure; instrument everything\n",
    "4. **Iterative tuning**: Fix one bottleneck at a time, then re-test (bottlenecks shift after fixes)\n",
    "5. **Documentation**: Record environment configurations, test scenarios, and results for comparison\n",
    "\n",
    "---\n",
    "\n",
    "## **\ud83d\udcd6 Next Chapter: Chapter 36 - Performance Test Analysis**\n",
    "\n",
    "Now that you understand how to execute performance tests and identify bottlenecks, **Chapter 36** will dive deeper into the **analytical techniques** used to interpret complex performance data and make optimization decisions.\n",
    "\n",
    "In **Chapter 36**, you will master:\n",
    "\n",
    "- **Statistical Analysis**: Understanding variance, standard deviation, confidence intervals, and identifying statistically significant changes\n",
    "- **Latency Modeling**: Little's Law, queueing theory basics, and predicting behavior at different loads\n",
    "- **Comparative Analysis**: A/B testing for performance, canary analysis, and blue-green deployment validation\n",
    "- **Capacity Planning**: Forecasting when you'll need to scale based on growth projections\n",
    "- **Cost-Performance Optimization**: Balancing cloud infrastructure costs against performance requirements\n",
    "- **Advanced Visualization**: Heatmaps, flame graphs, and latency histograms for deep-dive analysis\n",
    "- **Performance Regression Root Cause Analysis**: Techniques for bisecting commits to find performance degradation sources\n",
    "\n",
    "This chapter will provide the **analytical rigor** needed to move from basic performance testing to **performance engineering**, enabling you to predict system behavior and optimize costs while maintaining SLAs.\n",
    "\n",
    "**Continue to Chapter 36 to become a performance analysis expert!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='34. performance_testing_tools.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='36. performance_test_analysis.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}