{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 54: Chaos Engineering\n",
    "\n",
    "---\n",
    "\n",
    "## 54.1 Introduction to Chaos Engineering\n",
    "\n",
    "Chaos Engineering is the discipline of experimenting on a distributed system to build confidence in its capability to withstand turbulent conditions in production. It involves intentionally injecting failures, latency, or other disruptions to observe how the system behaves and identify weaknesses before they cause user-facing outages.\n",
    "\n",
    "### 54.1.1 Why Chaos Engineering?\n",
    "\n",
    "Modern software systems are complex, distributed, and interdependent. Failures can arise from:\n",
    "- Network latency or packet loss\n",
    "- Server crashes or resource exhaustion\n",
    "- Dependency unavailability (databases, APIs)\n",
    "- Configuration errors\n",
    "- Unexpected traffic spikes\n",
    "\n",
    "Traditional testing (unit, integration, end-to-end) verifies expected behavior under controlled conditions. Chaos Engineering tests the system's ability to survive unexpected real-world conditions.\n",
    "\n",
    "### 54.1.2 The Goal: Build Resilient Systems\n",
    "\n",
    "The goal is not to break things randomly, but to **learn** about system behavior and **improve** resilience. By proactively simulating failures, teams can:\n",
    "- Discover blind spots in monitoring and alerting\n",
    "- Validate fallback mechanisms\n",
    "- Test disaster recovery procedures\n",
    "- Build confidence in system robustness\n",
    "\n",
    "---\n",
    "\n",
    "## 54.2 Principles of Chaos\n",
    "\n",
    "The principles of Chaos Engineering, as defined by the Principles of Chaos (principlesofchaos.org), are:\n",
    "\n",
    "### 54.2.1 Build a Hypothesis Around Steady State\n",
    "\n",
    "Define what \"normal\" looks like for your system. This could be:\n",
    "- Response times under a threshold\n",
    "- Error rate below a certain percentage\n",
    "- Throughput (requests per second)\n",
    "- Resource utilization (CPU, memory)\n",
    "\n",
    "### 54.2.2 Vary Real-World Events\n",
    "\n",
    "Inject failures that mimic real-world conditions:\n",
    "- Service crashes\n",
    "- Network latency or packet loss\n",
    "- Resource exhaustion (CPU, memory, disk)\n",
    "- Time shifts (clock skew)\n",
    "- Dependency failures (database down, 3rd-party API unavailable)\n",
    "\n",
    "### 54.2.3 Run Experiments in Production\n",
    "\n",
    "Chaos experiments should be run in production (or production-like environments) to get realistic results. Start small and expand.\n",
    "\n",
    "### 54.2.4 Automate Experiments to Run Continuously\n",
    "\n",
    "Integrate chaos experiments into your CI/CD pipeline or run them as scheduled jobs. This ensures that resilience is continuously validated as the system evolves.\n",
    "\n",
    "### 54.2.5 Minimize Blast Radius\n",
    "\n",
    "Start with small experiments that affect a limited subset of traffic or a single instance. Observe the impact before scaling up. Use techniques like feature flags or canary deployments to limit exposure.\n",
    "\n",
    "---\n",
    "\n",
    "## 54.3 Chaos Testing Tools\n",
    "\n",
    "Several tools help implement chaos experiments:\n",
    "\n",
    "| Tool | Description |\n",
    "|------|-------------|\n",
    "| **Chaos Monkey** | Part of Netflix's Simian Army; randomly terminates instances in production. |\n",
    "| **Gremlin** | Commercial chaos engineering platform with a wide range of attack types. |\n",
    "| **Litmus** | Open-source chaos engineering tool for Kubernetes. |\n",
    "| **Chaos Mesh** | Kubernetes-native chaos platform. |\n",
    "| **PowerfulSeal** | Open-source tool for Kubernetes that kills pods and nodes. |\n",
    "| **AWS Fault Injection Simulator** | Managed chaos service on AWS. |\n",
    "| **Azure Chaos Studio** | Managed chaos service on Azure. |\n",
    "| **Chaos Toolkit** | Open-source framework for defining and running chaos experiments as code. |\n",
    "\n",
    "---\n",
    "\n",
    "## 54.4 Gremlin\n",
    "\n",
    "Gremlin is a leading chaos engineering platform that provides a safe, controlled way to run experiments. It offers a variety of attack types and integrates with major cloud providers and Kubernetes.\n",
    "\n",
    "### 54.4.1 Key Features\n",
    "\n",
    "- **Attacks:** CPU, memory, IO, packet loss, latency, DNS failure, blackhole, shutdown, etc.\n",
    "- **Scenarios:** Combine multiple attacks in sequence.\n",
    "- **Targeting:** Choose specific hosts, containers, or Kubernetes resources.\n",
    "- **Safety:** Halt experiments automatically if certain conditions are met.\n",
    "- **Integrations:** Slack, PagerDuty, Datadog, etc.\n",
    "\n",
    "### 54.4.2 Gremlin Attack Types\n",
    "\n",
    "| Attack | Description |\n",
    "|--------|-------------|\n",
    "| **CPU** | Consume CPU cores to simulate a runaway process. |\n",
    "| **Memory** | Consume RAM to trigger OOM killer. |\n",
    "| **IO** | Stress disk I/O to simulate slow storage. |\n",
    "| **Packet Loss** | Drop network packets to test retries and timeouts. |\n",
    "| **Latency** | Add delay to network requests. |\n",
    "| **DNS** | Fail DNS resolution to test fallbacks. |\n",
    "| **Blackhole** | Drop all traffic to/from a host. |\n",
    "| **Shutdown** | Gracefully or forcefully shut down a service. |\n",
    "\n",
    "### 54.4.3 Gremlin Example\n",
    "\n",
    "```bash\n",
    "# Install Gremlin agent on a host\n",
    "curl -sSL https://get.gremlin.com | sudo bash\n",
    "sudo gremlin config --client-id $CLIENT_ID --client-secret $CLIENT_SECRET\n",
    "\n",
    "# Run a CPU attack for 60 seconds\n",
    "gremlin attack cpu --length 60 --cores 1\n",
    "```\n",
    "\n",
    "### 54.4.4 Gremlin with Kubernetes\n",
    "\n",
    "```bash\n",
    "# Deploy Gremlin as a DaemonSet\n",
    "kubectl apply -f https://k8s.gremlin.com/resources/gremlin-namespace.yaml\n",
    "kubectl apply -f https://k8s.gremlin.com/resources/gremlin-secret.yaml  # with your keys\n",
    "kubectl apply -f https://k8s.gremlin.com/resources/gremlin-daemonset.yaml\n",
    "\n",
    "# Run a pod kill attack\n",
    "gremlin attack pod --target pod-name my-pod --kill\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 54.5 Chaos Monkey\n",
    "\n",
    "Chaos Monkey is the original chaos tool, created by Netflix. It randomly terminates instances in production to ensure that the system can survive instance failures without user impact.\n",
    "\n",
    "### 54.5.1 How Chaos Monkey Works\n",
    "\n",
    "- Chaos Monkey runs on a schedule (e.g., once per day).\n",
    "- It selects a random instance from a configured pool.\n",
    "- It terminates that instance.\n",
    "- Monitoring should detect the failure and trigger auto-healing (e.g., a new instance spins up).\n",
    "- If the system can handle the termination without user-visible errors, the experiment passes.\n",
    "\n",
    "### 54.5.2 Spinnaker Integration\n",
    "\n",
    "Netflix's Chaos Monkey is part of the Spinnaker continuous delivery platform. It's configured via a YAML file:\n",
    "\n",
    "```yaml\n",
    "# chaos-monkey-config.yml\n",
    "enabled: true\n",
    "lethalityEnabled: true\n",
    "meanDaysBetweenAttacks: 2\n",
    "minTimeBetweenAttacksInMilliseconds: 60000\n",
    "exceptionList:\n",
    "  - \"my-critical-service\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 54.6 Implementing Chaos Tests\n",
    "\n",
    "### 54.6.1 Chaos Experiment Lifecycle\n",
    "\n",
    "1. **Define steady state** â€“ measurable metrics that indicate normal operation.\n",
    "2. **Form a hypothesis** â€“ e.g., \"If one instance fails, the system continues serving requests with <1% error rate.\"\n",
    "3. **Design the experiment** â€“ choose attack type, scope, duration.\n",
    "4. **Run the experiment** â€“ start small, observe.\n",
    "5. **Analyze results** â€“ compare metrics against steady state.\n",
    "6. **Remediate** â€“ fix weaknesses, then run again.\n",
    "\n",
    "### 54.6.2 Example: Testing Database Failover\n",
    "\n",
    "**Hypothesis:** When the primary database goes down, the application automatically fails over to the replica within 30 seconds with <5% error rate.\n",
    "\n",
    "**Experiment:**\n",
    "1. Start a load test against the application.\n",
    "2. Using Gremlin, execute a `shutdown` attack on the primary database instance.\n",
    "3. Monitor application error rate and response time.\n",
    "4. Observe if failover occurs and how long it takes.\n",
    "5. Analyze logs to see if alerts fired correctly.\n",
    "\n",
    "**Tools:** Gremlin, load generator (e.g., JMeter), monitoring (Prometheus, Grafana).\n",
    "\n",
    "### 54.6.3 Example: Testing Network Latency\n",
    "\n",
    "**Hypothesis:** Adding 500ms latency between services will cause requests to time out, but the circuit breaker opens and fallback data is served.\n",
    "\n",
    "**Experiment:**\n",
    "1. Using Gremlin's `latency` attack on a specific service pod.\n",
    "2. Observe downstream service behavior.\n",
    "3. Check if circuit breaker trips and fallback is served.\n",
    "4. After attack stops, verify system recovers.\n",
    "\n",
    "### 54.6.4 Example: Chaos Toolkit\n",
    "\n",
    "Chaos Toolkit allows defining experiments as code.\n",
    "\n",
    "```yaml\n",
    "# experiment.yaml\n",
    "version: 1.0.0\n",
    "title: \"Kill a pod and verify recovery\"\n",
    "description: \"Kill one pod and ensure the service continues\"\n",
    "configuration:\n",
    "  target_pod: \"my-app-pod\"\n",
    "  namespace: \"default\"\n",
    "steady-state-hypothesis:\n",
    "  title: \"Service is healthy\"\n",
    "  probes:\n",
    "    - name: \"service-responds\"\n",
    "      type: probe\n",
    "      tolerance: 200\n",
    "      provider:\n",
    "        type: http\n",
    "        url: \"http://my-service/health\"\n",
    "        timeout: 5\n",
    "method:\n",
    "  - name: \"kill-pod\"\n",
    "    type: action\n",
    "    provider:\n",
    "      type: python\n",
    "      module: chaosk8s.pod.actions\n",
    "      func: terminate_pods\n",
    "      arguments:\n",
    "        name_pattern: \"my-app-pod\"\n",
    "        namespace: \"default\"\n",
    "        rand: true\n",
    "    pauses:\n",
    "      after: 10\n",
    "  - name: \"verify-recovery\"\n",
    "    type: probe\n",
    "    provider:\n",
    "      type: http\n",
    "      url: \"http://my-service/health\"\n",
    "      timeout: 5\n",
    "    tolerance: 200\n",
    "rollbacks:\n",
    "  - name: \"ensure-pod-running\"\n",
    "    type: action\n",
    "    provider:\n",
    "      type: python\n",
    "      module: chaosk8s.pod.actions\n",
    "      func: scale_resource\n",
    "      arguments:\n",
    "        name: \"my-app\"\n",
    "        namespace: \"default\"\n",
    "        replicas: 3\n",
    "```\n",
    "\n",
    "Run with:\n",
    "\n",
    "```bash\n",
    "chaos run experiment.yaml\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 54.7 Best Practices\n",
    "\n",
    "### 54.7.1 Start Small\n",
    "\n",
    "- Run experiments in staging first.\n",
    "- Use minimal blast radius (e.g., 1% of traffic, one pod).\n",
    "- Gradually increase scope as confidence grows.\n",
    "\n",
    "### 54.7.2 Automate Safely\n",
    "\n",
    "- Integrate with CI/CD to run experiments after deployments.\n",
    "- Implement automatic rollback or halt if error rate spikes.\n",
    "- Use feature flags to disable experiments during critical periods.\n",
    "\n",
    "### 54.7.3 Monitor Everything\n",
    "\n",
    "- Ensure you have comprehensive monitoring (metrics, logs, traces) before starting chaos experiments.\n",
    "- Define clear steady-state metrics and alert thresholds.\n",
    "\n",
    "### 54.7.4 Blameless Culture\n",
    "\n",
    "Chaos experiments may reveal failures. Treat them as learning opportunities, not as reasons to blame teams.\n",
    "\n",
    "### 54.7.5 Involve the Whole Team\n",
    "\n",
    "Developers, SREs, and product managers should participate in designing and reviewing experiments.\n",
    "\n",
    "### 54.7.6 Document Findings\n",
    "\n",
    "Keep a record of experiments, results, and remediation actions. This builds institutional knowledge.\n",
    "\n",
    "### 54.7.7 Game Days\n",
    "\n",
    "Conduct scheduled \"game days\" where the team runs chaos experiments together to practice incident response.\n",
    "\n",
    "---\n",
    "\n",
    "## 54.8 Common Challenges and Solutions\n",
    "\n",
    "| Challenge | Solution |\n",
    "|-----------|----------|\n",
    "| **Fear of breaking production** | Start with staging; use blast radius controls; run during low traffic. |\n",
    "| **Lack of observability** | Invest in monitoring first; experiments without observability are blind. |\n",
    "| **Resistance from teams** | Educate on benefits; start with small, low-risk experiments. |\n",
    "| **Complex environments** | Use Kubernetes-native tools (Chaos Mesh, Litmus) that understand orchestration. |\n",
    "| **False positives** | Ensure steady state definition is accurate; review experiment design. |\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary\n",
    "\n",
    "In this chapter, we introduced **Chaos Engineering**:\n",
    "\n",
    "- **What it is** â€“ experimenting on systems to uncover weaknesses.\n",
    "- **Principles** â€“ steady state hypothesis, vary real-world events, run in production, automate.\n",
    "- **Tools** â€“ Gremlin, Chaos Monkey, Chaos Toolkit, Litmus, Chaos Mesh.\n",
    "- **Implementing experiments** â€“ lifecycle, examples for database failover and latency.\n",
    "- **Best practices** â€“ start small, automate safely, monitor, blameless culture.\n",
    "- **Challenges and solutions** â€“ addressing fear, lack of observability, resistance.\n",
    "\n",
    "**Key Insight:** Chaos Engineering shifts testing from \"does it work?\" to \"will it survive?\" By proactively injecting failures, you build systems that are resilient and trustworthy.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“– Next Chapter: Chapter 55 - Service Virtualization\n",
    "\n",
    "Now that you know how to test resilience, Chapter 55 explores **Service Virtualization**â€”creating virtual versions of dependencies to enable testing without relying on real services."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
