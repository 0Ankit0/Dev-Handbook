{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c8da13",
   "metadata": {},
   "source": [
    "# **Chapter 4: Estimation and Sizing**\n",
    "\n",
    "---\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Explain why software estimation is inherently difficult and prone to systematic errors\n",
    "- Apply multiple estimation techniques including T-Shirt Sizing, Planning Poker, and Three-Point Estimation\n",
    "- Use story points effectively and understand when to use relative vs. absolute estimation\n",
    "- Calculate and interpret velocity, throughput, and cycle time metrics\n",
    "- Build appropriate buffers into estimates without padding\n",
    "- Use probabilistic forecasting techniques like Monte Carlo simulation\n",
    "- Monitor and refine estimates throughout the project lifecycle\n",
    "\n",
    "---\n",
    "\n",
    "## **Real-World Case Study: The $50 Million Miscalculation**\n",
    "\n",
    "In 2019, a major healthcare organization embarked on a project to modernize their patient records system. The initial estimate from the vendor: **$15 million over 18 months**.\n",
    "\n",
    "The project seemed straightforward:\n",
    "- Migrate data from legacy mainframe to modern cloud platform\n",
    "- Build web interface for doctors and nurses\n",
    "- Integrate with existing billing and scheduling systems\n",
    "- Ensure HIPAA compliance\n",
    "\n",
    "**Month 6**: The project was 20% over budget. The team discovered the legacy data was far messier than anticipated\u201430 years of inconsistent formats, duplicate records, and missing fields.\n",
    "\n",
    "**Month 12**: The project was 50% over budget. Integration with the billing system required custom middleware that wasn't in the original scope. The web interface needed to support 15 different user roles, each with different permissions.\n",
    "\n",
    "**Month 18**: The project was 100% over budget ($30 million) and only 60% complete. The team had to rebuild the database schema three times. Security audits revealed gaps that required significant rework.\n",
    "\n",
    "**Month 24**: The project was finally \"complete\" at **$50 million**\u2014more than 3x the original estimate\u2014and 6 months late. The system worked, but users complained it was slower than the old mainframe. Adoption was only 40%.\n",
    "\n",
    "**What Went Wrong:**\n",
    "\n",
    "1. **The Planning Fallacy**: The team estimated based on best-case scenarios, ignoring historical data about similar projects.\n",
    "\n",
    "2. **Anchoring Bias**: The initial $15 million estimate anchored all subsequent discussions, making it difficult to adjust upward even as reality diverged.\n",
    "\n",
    "3. **Unknown Unknowns**: The team didn't know what they didn't know about the legacy data quality, integration complexity, and security requirements.\n",
    "\n",
    "4. **Commitment Escalation**: As costs rose, the organization felt compelled to continue rather than cut losses, throwing good money after bad.\n",
    "\n",
    "5. **No Probabilistic Thinking**: The estimate was presented as a single number ($15M) rather than a range with confidence levels.\n",
    "\n",
    "**The Lesson:**\n",
    "\n",
    "Estimation is not about predicting the future with certainty\u2014it's about understanding uncertainty and making informed decisions under uncertainty. The goal isn't perfect accuracy; it's useful accuracy that enables good decisions.\n",
    "\n",
    "---\n",
    "\n",
    "## **4.1 Why Estimation Fails (The Planning Fallacy)**\n",
    "\n",
    "### **The Planning Fallacy**\n",
    "\n",
    "The Planning Fallacy, identified by psychologists Daniel Kahneman and Amos Tversky, is the tendency to underestimate the time, costs, and risks of future actions while overestimating the benefits.\n",
    "\n",
    "**Why We Fall for It:**\n",
    "\n",
    "```\n",
    "Causes of the Planning Fallacy:\n",
    "\n",
    "1. Optimism Bias:\n",
    "   \u251c\u2500 We focus on best-case scenarios\n",
    "   \u251c\u2500 We ignore potential problems\n",
    "   \u251c\u2500 We overestimate our capabilities\n",
    "   \u2514\u2500 We underestimate complexity\n",
    "\n",
    "2. Anchoring:\n",
    "   \u251c\u2500 First estimate anchors all subsequent estimates\n",
    "   \u251c\u2500 Hard to adjust away from initial number\n",
    "   \u251c\u2500 Even arbitrary anchors influence us\n",
    "   \u2514\u2500 Creates false precision\n",
    "\n",
    "3. Inside View:\n",
    "   \u251c\u2500 Focus on specific details of current project\n",
    "   \u251c\u2500 Ignore historical data from similar projects\n",
    "   \u251c\u2500 Assume this time will be different\n",
    "   \u2514\u2500 Overweight unique aspects\n",
    "\n",
    "4. Sunk Cost Fallacy:\n",
    "   \u251c\u2500 Continue with failing estimates\n",
    "   \u251c\u2500 Throw good money after bad\n",
    "   \u251c\u2500 Reluctant to admit mistakes\n",
    "   \u2514\u2500 Escalate commitment\n",
    "\n",
    "5. Social Pressure:\n",
    "   \u251c\u2500 Pressure to provide optimistic estimates\n",
    "   \u251c\u2500 Fear of appearing pessimistic\n",
    "   \u251c\u2500 Desire to please stakeholders\n",
    "   \u2514\u2500 Competition for resources\n",
    "```\n",
    "\n",
    "**Overcoming the Planning Fallacy:**\n",
    "\n",
    "```\n",
    "Strategies to Overcome Planning Fallacy:\n",
    "\n",
    "1. Reference Class Forecasting:\n",
    "   \u251c\u2500 Look at similar past projects\n",
    "   \u251c\u2500 Use historical data for estimates\n",
    "   \u251c\u2500 Adjust for specific differences\n",
    "   \u2514\u2500 Base estimates on reality, not optimism\n",
    "\n",
    "2. Outside View:\n",
    "   \u251c\u2500 Ask: \"How long do similar projects take?\"\n",
    "   \u251c\u2500 Consult experts with relevant experience\n",
    "   \u251c\u2500 Use industry benchmarks\n",
    "   \u2514\u2500 Avoid focusing only on unique aspects\n",
    "\n",
    "3. Probabilistic Estimation:\n",
    "   \u251c\u2500 Provide ranges, not single numbers\n",
    "   \u251c\u2500 Include confidence levels\n",
    "   \u251c\u2500 Use three-point estimation\n",
    "   \u2514\u2500 Acknowledge uncertainty\n",
    "\n",
    "4. Pre-Mortem Analysis:\n",
    "   \u251c\u2500 Imagine project failed\n",
    "   \u251c\u2500 Ask: \"What went wrong?\"\n",
    "   \u251c\u2500 Identify potential problems\n",
    "   \u2514\u2500 Plan mitigations\n",
    "\n",
    "5. Independent Estimation:\n",
    "   \u251c\u2500 Have multiple people estimate\n",
    "   \u251c\u2500 Use anonymous estimation\n",
    "   \u251c\u2500 Average or median estimates\n",
    "   \u2514\u2500 Reduce individual bias\n",
    "\n",
    "6. Buffer Management:\n",
    "   \u251c\u2500 Add appropriate buffers\n",
    "   \u251c\u2500 Don't pad estimates\n",
    "   \u251c\u2500 Use evidence-based buffers\n",
    "   \u2514\u2500 Manage buffers explicitly\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Reference Class Forecasting**\n",
    "\n",
    "Reference class forecasting is a method of predicting the future by looking at similar past situations (the \"reference class\").\n",
    "\n",
    "**The Process:**\n",
    "\n",
    "```\n",
    "Reference Class Forecasting Steps:\n",
    "\n",
    "1. Identify the Reference Class:\n",
    "   \u251c\u2500 Find similar past projects\n",
    "   \u251c\u2500 Look for projects with similar:\n",
    "   \u2502  \u251c\u2500 Technology\n",
    "   \u2502  \u251c\u2500 Team size\n",
    "   \u2502  \u251c\u2500 Complexity\n",
    "   \u2502  \u2514\u2500 Domain\n",
    "   \u2514\u2500 Aim for 5-10 similar projects\n",
    "\n",
    "2. Establish the Distribution:\n",
    "   \u251c\u2500 Collect actual outcomes\n",
    "   \u251c\u2500 Calculate statistics:\n",
    "   \u2502  \u251c\u2500 Mean (average)\n",
    "   \u2502  \u251c\u2500 Median (middle value)\n",
    "   \u2502  \u251c\u2500 Standard deviation (variability)\n",
    "   \u2502  \u2514\u2500 Percentiles (10th, 25th, 75th, 90th)\n",
    "   \u2514\u2500 Create distribution curve\n",
    "\n",
    "3. Adjust for Specifics:\n",
    "   \u251c\u2500 Identify differences from reference class\n",
    "   \u251c\u2500 Adjust estimate up or down based on:\n",
    "   \u2502  \u251c\u2500 Team experience\n",
    "   \u2502  \u251c\u2500 Technology familiarity\n",
    "   \u2502  \u251c\u2500 Requirements clarity\n",
    "   \u2502  \u2514\u2500 External dependencies\n",
    "   \u2514\u2500 Document adjustments\n",
    "\n",
    "4. Provide Range:\n",
    "   \u251c\u2500 Don't give single number\n",
    "   \u251c\u2500 Provide range with confidence:\n",
    "   \u2502  \u251c\u2500 Optimistic (10th percentile)\n",
    "   \u2502  \u251c\u2500 Most likely (50th percentile)\n",
    "   \u2502  \u2514\u2500 Pessimistic (90th percentile)\n",
    "   \u2514\u2500 Include confidence level\n",
    "```\n",
    "\n",
    "**Example Reference Class Forecasting:**\n",
    "\n",
    "```yaml\n",
    "reference_class_forecasting:\n",
    "  project: \"E-Commerce Platform Development\"\n",
    "  forecast_date: \"2025-03-15\"\n",
    "  forecaster: \"Project Manager\"\n",
    "  \n",
    "  reference_class:\n",
    "    description: \"Similar e-commerce platform projects\"\n",
    "    projects:\n",
    "      - project_name: \"RetailCo Platform\"\n",
    "        completion_date: \"2023-06\"\n",
    "        actual_duration: \"10 months\"\n",
    "        actual_cost: \"$850K\"\n",
    "        team_size: 8\n",
    "        technology: \"React, Node.js, PostgreSQL\"\n",
    "        complexity: \"Medium\"\n",
    "        notes: \"Similar scope, slightly larger team\"\n",
    "        \n",
    "      - project_name: \"ShopNow App\"\n",
    "        completion_date: \"2023-09\"\n",
    "        actual_duration: \"12 months\"\n",
    "        actual_cost: \"$1.2M\"\n",
    "        team_size: 10\n",
    "        technology: \"Angular, Java, Oracle\"\n",
    "        complexity: \"High\"\n",
    "        notes: \"More complex, larger team, different tech\"\n",
    "        \n",
    "      - project_name: \"QuickBuy Platform\"\n",
    "        completion_date: \"2024-01\"\n",
    "        actual_duration: \"7 months\"\n",
    "        actual_cost: \"$600K\"\n",
    "        team_size: 6\n",
    "        technology: \"Vue, Python, PostgreSQL\"\n",
    "        complexity: \"Low\"\n",
    "        notes: \"Simpler scope, smaller team\"\n",
    "        \n",
    "      - project_name: \"MegaStore Online\"\n",
    "        completion_date: \"2024-03\"\n",
    "        actual_duration: \"9 months\"\n",
    "        actual_cost: \"$750K\"\n",
    "        team_size: 8\n",
    "        technology: \"React, Node.js, MongoDB\"\n",
    "        complexity: \"Medium\"\n",
    "        notes: \"Very similar to our project\"\n",
    "        \n",
    "      - project_name: \"LocalShop Digital\"\n",
    "        completion_date: \"2024-06\"\n",
    "        actual_duration: \"8 months\"\n",
    "        actual_cost: \"$700K\"\n",
    "        team_size: 7\n",
    "        technology: \"React, Node.js, PostgreSQL\"\n",
    "        complexity: \"Medium\"\n",
    "        notes: \"Similar tech stack, slightly smaller\"\n",
    "    \n",
    "    statistics:\n",
    "      duration:\n",
    "        mean: \"9.2 months\"\n",
    "        median: \"8.5 months\"\n",
    "        min: \"7 months\"\n",
    "        max: \"12 months\"\n",
    "        std_dev: \"1.8 months\"\n",
    "        percentile_10: \"7.2 months\"\n",
    "        percentile_25: \"7.8 months\"\n",
    "        percentile_75: \"10.5 months\"\n",
    "        percentile_90: \"11.5 months\"\n",
    "        \n",
    "      cost:\n",
    "        mean: \"$783K\"\n",
    "        median: \"$725K\"\n",
    "        min: \"$600K\"\n",
    "        max: \"$1.2M\"\n",
    "        std_dev: \"$215K\"\n",
    "        percentile_10: \"$620K\"\n",
    "        percentile_25: \"$675K\"\n",
    "        percentile_75: \"$800K\"\n",
    "        percentile_90: \"$1.1M\"\n",
    "  \n",
    "  current_project_adjustments:\n",
    "    description: \"Adjustments for specific project characteristics\"\n",
    "    \n",
    "    factors:\n",
    "      - factor: \"Team Experience\"\n",
    "        reference_class: \"Mixed experience\"\n",
    "        current_project: \"Experienced team (3+ years together)\"\n",
    "        adjustment: \"-10% duration\"\n",
    "        rationale: \"Experienced team works faster\"\n",
    "        \n",
    "      - factor: \"Technology Familiarity\"\n",
    "        reference_class: \"Mixed technologies\"\n",
    "        current_project: \"Team has used React/Node.js extensively\"\n",
    "        adjustment: \"-15% duration\"\n",
    "        rationale: \"No learning curve for technology\"\n",
    "        \n",
    "      - factor: \"Requirements Clarity\"\n",
    "        reference_class: \"Evolving requirements\"\n",
    "        current_project: \"Well-defined requirements with stakeholder buy-in\"\n",
    "        adjustment: \"-10% duration\"\n",
    "        rationale: \"Less rework due to changing requirements\"\n",
    "        \n",
    "      - factor: \"Integration Complexity\"\n",
    "        reference_class: \"Standard integrations\"\n",
    "        current_project: \"Complex legacy system integration\"\n",
    "        adjustment: \"+20% duration\"\n",
    "        rationale: \"Integration complexity underestimated in reference class\"\n",
    "        \n",
    "      - factor: \"Regulatory Requirements\"\n",
    "        reference_class: \"Standard compliance\"\n",
    "        current_project: \"HIPAA and PCI DSS compliance required\"\n",
    "        adjustment: \"+10% duration\"\n",
    "        rationale: \"Additional security and compliance work\"\n",
    "    \n",
    "    net_adjustment: \"-5% duration\"\n",
    "    adjusted_statistics:\n",
    "      duration:\n",
    "        mean: \"8.7 months\"\n",
    "        median: \"8.1 months\"\n",
    "        percentile_10: \"6.8 months\"\n",
    "        percentile_25: \"7.4 months\"\n",
    "        percentile_75: \"10.0 months\"\n",
    "        percentile_90: \"10.9 months\"\n",
    "        \n",
    "      cost:\n",
    "        mean: \"$744K\"\n",
    "        median: \"$689K\"\n",
    "        percentile_10: \"$589K\"\n",
    "        percentile_25: \"$641K\"\n",
    "        percentile_75: \"$760K\"\n",
    "        percentile_90: \"$1.0M\"\n",
    "  \n",
    "  final_forecast:\n",
    "    optimistic:\n",
    "      duration: \"7 months\"\n",
    "      cost: \"$650K\"\n",
    "      confidence: \"10th percentile\"\n",
    "      scenario: \"Everything goes smoothly, no major issues\"\n",
    "      \n",
    "    most_likely:\n",
    "      duration: \"8 months\"\n",
    "      cost: \"$750K\"\n",
    "      confidence: \"50th percentile\"\n",
    "      scenario: \"Typical project with expected challenges\"\n",
    "      \n",
    "    pessimistic:\n",
    "      duration: \"11 months\"\n",
    "      cost: \"$1.0M\"\n",
    "      confidence: \"90th percentile\"\n",
    "      scenario: \"Significant challenges and delays\"\n",
    "    \n",
    "    recommended_estimate:\n",
    "      duration: \"8-9 months\"\n",
    "      cost: \"$750K-$850K\"\n",
    "      buffer: \"15% contingency\"\n",
    "      approach: \"Use most likely with buffer for uncertainty\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4.2 Estimation Techniques**\n",
    "\n",
    "### **T-Shirt Sizing**\n",
    "\n",
    "T-Shirt Sizing is a relative estimation technique where items are categorized by size: XS, S, M, L, XL, XXL.\n",
    "\n",
    "**How T-Shirt Sizing Works:**\n",
    "\n",
    "```\n",
    "T-Shirt Sizing Process:\n",
    "\n",
    "1. Define Reference Stories:\n",
    "   \u251c\u2500 Select a few well-understood stories\n",
    "   \u251c\u2500 Assign them sizes (e.g., S, M, L)\n",
    "   \u251c\u2500 Use these as reference points\n",
    "   \u2514\u2500 Ensure team understands the reference\n",
    "\n",
    "2. Compare New Items:\n",
    "   \u251c\u2500 Take a new item to estimate\n",
    "   \u251c\u2500 Compare to reference stories\n",
    "   \u251c\u2500 Ask: \"Is this bigger or smaller than [reference]?\"\n",
    "   \u2514\u2500 Assign appropriate size\n",
    "\n",
    "3. Group by Size:\n",
    "   \u251c\u2500 Create buckets for each size\n",
    "   \u251c\u2500 Place items in appropriate buckets\n",
    "   \u251c\u2500 Review for consistency\n",
    "   \u2514\u2500 Adjust as needed\n",
    "\n",
    "4. Convert to Capacity:\n",
    "   \u251c\u2500 Determine how many of each size fit in iteration\n",
    "   \u251c\u2500 Track actual vs. estimated capacity\n",
    "   \u251c\u2500 Adjust capacity assumptions\n",
    "   \u2514\u2500 Use for sprint planning\n",
    "```\n",
    "\n",
    "**T-Shirt Size Definitions:**\n",
    "\n",
    "| Size | Relative Effort | Typical Duration | Complexity |\n",
    "|------|----------------|------------------|------------|\n",
    "| **XS** | 0.5x | 1-2 days | Trivial |\n",
    "| **S** | 1x | 3-5 days | Simple |\n",
    "| **M** | 2x | 1-2 weeks | Moderate |\n",
    "| **L** | 4x | 3-4 weeks | Complex |\n",
    "| **XL** | 8x | 1-2 months | Very complex |\n",
    "| **XXL** | 16x+ | 2+ months | Epic |\n",
    "\n",
    "**Example T-Shirt Sizing Session:**\n",
    "\n",
    "```yaml\n",
    "t_shirt_sizing_session:\n",
    "  project: \"E-Commerce Platform\"\n",
    "  session_date: \"2025-03-20\"\n",
    "  participants:\n",
    "    - \"Product Owner\"\n",
    "    - \"Tech Lead\"\n",
    "    - \"Senior Developer\"\n",
    "    - \"UX Designer\"\n",
    "    - \"QA Engineer\"\n",
    "  \n",
    "  reference_stories:\n",
    "    - story_id: \"REF-001\"\n",
    "      title: \"Simple Button Component\"\n",
    "      description: \"Create a reusable button component with basic styling\"\n",
    "      size: \"XS\"\n",
    "      actual_effort: \"1 day\"\n",
    "      \n",
    "    - story_id: \"REF-002\"\n",
    "      title: \"User Login Form\"\n",
    "      description: \"Create login form with email and password fields\"\n",
    "      size: \"S\"\n",
    "      actual_effort: \"3 days\"\n",
    "      \n",
    "    - story_id: \"REF-003\"\n",
    "      title: \"Product Catalog Page\"\n",
    "      description: \"Create product listing with filtering and pagination\"\n",
    "      size: \"M\"\n",
    "      actual_effort: \"10 days\"\n",
    "      \n",
    "    - story_id: \"REF-004\"\n",
    "      title: \"Shopping Cart System\"\n",
    "      description: \"Full cart functionality with add, remove, update, checkout\"\n",
    "      size: \"L\"\n",
    "      actual_effort: \"20 days\"\n",
    "  \n",
    "  stories_to_size:\n",
    "    - story_id: \"US-001\"\n",
    "      title: \"User Registration\"\n",
    "      description: \"Allow users to register with email and password\"\n",
    "      \n",
    "      team_discussion: |\n",
    "        Product Owner: \"This needs email validation, password requirements, and confirmation email.\"\n",
    "        Tech Lead: \"Similar to login form but with more validation. Database write, email service integration.\"\n",
    "        UX Designer: \"Registration form with validation feedback, confirmation page.\"\n",
    "        QA Engineer: \"Need to test validation rules, email sending, confirmation flow.\"\n",
    "      \n",
    "      comparison_to_reference: \"More complex than login form (REF-002) due to email confirmation\"\n",
    "      proposed_size: \"M\"\n",
    "      rationale: \"Includes form, validation, database, email integration, confirmation flow\"\n",
    "      consensus: \"M\"\n",
    "      \n",
    "    - story_id: \"US-002\"\n",
    "      title: \"Product Search\"\n",
    "      description: \"Allow users to search products by name and description\"\n",
    "      \n",
    "      team_discussion: |\n",
    "        Product Owner: \"Basic text search, results listing, highlighting matches.\"\n",
    "        Tech Lead: \"Database full-text search or Elasticsearch integration. Search indexing.\"\n",
    "        UX Designer: \"Search bar, results page, filters for search results.\"\n",
    "        QA Engineer: \"Test search accuracy, performance, edge cases.\"\n",
    "      \n",
    "      comparison_to_reference: \"Similar complexity to product catalog (REF-003) but focused on search\"\n",
    "      proposed_size: \"M\"\n",
    "      rationale: \"Search implementation, indexing, results display, performance optimization\"\n",
    "      consensus: \"M\"\n",
    "      \n",
    "    - story_id: \"US-003\"\n",
    "      title: \"Add to Cart\"\n",
    "      description: \"Allow users to add products to shopping cart\"\n",
    "      \n",
    "      team_discussion: |\n",
    "        Product Owner: \"Add button, cart update, quantity management.\"\n",
    "        Tech Lead: \"Cart state management, local storage or database, cart API.\"\n",
    "        UX Designer: \"Add button, cart icon with count, cart preview.\"\n",
    "        QA Engineer: \"Test add functionality, cart persistence, quantity limits.\"\n",
    "      \n",
    "      comparison_to_reference: \"Simpler than full cart system (REF-004), just add functionality\"\n",
    "      proposed_size: \"S\"\n",
    "      rationale: \"Focused scope - just add to cart, not full cart management\"\n",
    "      consensus: \"S\"\n",
    "      \n",
    "    - story_id: \"US-004\"\n",
    "      title: \"Payment Integration\"\n",
    "      description: \"Integrate with payment gateway for processing\"\n",
    "      \n",
    "      team_discussion: |\n",
    "        Product Owner: \"Credit card processing, PayPal, secure handling.\"\n",
    "        Tech Lead: \"Payment gateway API integration, PCI compliance, error handling, webhooks.\"\n",
    "        UX Designer: \"Payment form, loading states, error messages, confirmation.\"\n",
    "        QA Engineer: \"Test payment flows, error scenarios, security testing.\"\n",
    "      \n",
    "      comparison_to_reference: \"More complex than any reference story, involves external integration\"\n",
    "      proposed_size: \"L\"\n",
    "      rationale: \"External API integration, security requirements, error handling, compliance\"\n",
    "      consensus: \"L\"\n",
    "  \n",
    "  capacity_planning:\n",
    "    iteration_length: \"2 weeks\"\n",
    "    team_capacity:\n",
    "      developers: 4\n",
    "      velocity_per_sprint: \"20 story points\"\n",
    "      t_shirt_capacity:\n",
    "        XS: \"8 items\"\n",
    "        S: \"4 items\"\n",
    "        M: \"2 items\"\n",
    "        L: \"1 item\"\n",
    "        XL: \"0.5 items (every 2 sprints)\"\n",
    "    \n",
    "    sprint_planning:\n",
    "      sprint_1:\n",
    "        capacity: \"20 points\"\n",
    "        planned_items:\n",
    "          - \"US-003 (Add to Cart) - S - 3 points\"\n",
    "          - \"US-001 (User Registration) - M - 5 points\"\n",
    "          - \"Other stories...\"\n",
    "        total_planned: \"20 points\"\n",
    "        \n",
    "      sprint_2:\n",
    "        capacity: \"20 points\"\n",
    "        planned_items:\n",
    "          - \"US-002 (Product Search) - M - 5 points\"\n",
    "          - \"US-004 (Payment Integration) - L - 8 points\"\n",
    "          - \"Other stories...\"\n",
    "        total_planned: \"20 points\"\n",
    "  \n",
    "  tracking:\n",
    "    velocity_tracking:\n",
    "      sprint_1:\n",
    "        planned: 20\n",
    "        completed: 18\n",
    "        velocity: 18\n",
    "        \n",
    "      sprint_2:\n",
    "        planned: 20\n",
    "        completed: 22\n",
    "        velocity: 22\n",
    "        \n",
    "      average_velocity: 20\n",
    "    \n",
    "    size_accuracy:\n",
    "      XS: \"90% accurate\"\n",
    "      S: \"85% accurate\"\n",
    "      M: \"75% accurate\"\n",
    "      L: \"60% accurate\"\n",
    "      XL: \"40% accurate\"\n",
    "    \n",
    "    lessons_learned:\n",
    "      - \"L and XL stories consistently underestimated\"\n",
    "      - \"Need to break down large stories further\"\n",
    "      - \"External integrations (Payment) need extra buffer\"\n",
    "      - \"Team velocity stabilizing after 3 sprints\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4.2 Estimation Techniques**\n",
    "\n",
    "### **Planning Poker**\n",
    "\n",
    "Planning Poker is a consensus-based estimation technique used by Agile teams to estimate the effort required for user stories.\n",
    "\n",
    "**How Planning Poker Works:**\n",
    "\n",
    "```\n",
    "Planning Poker Process:\n",
    "\n",
    "1. Preparation:\n",
    "   \u251c\u2500 Product Owner explains the user story\n",
    "   \u251c\u2500 Team asks clarifying questions\n",
    "   \u251c\u2500 Acceptance criteria are reviewed\n",
    "   \u2514\u2500 Team ensures shared understanding\n",
    "\n",
    "2. Individual Estimation:\n",
    "   \u251c\u2500 Each team member selects a card (story points)\n",
    "   \u251c\u2500 Cards are kept private (no influence)\n",
    "   \u251c\u2500 Team members think independently\n",
    "   \u2514\u2500 No discussion during selection\n",
    "\n",
    "3. Reveal:\n",
    "   \u251c\u2500 All cards revealed simultaneously\n",
    "   \u251c\u2500 Differences in estimates are visible\n",
    "   \u2514\u2500 Range of estimates becomes clear\n",
    "\n",
    "4. Discussion:\n",
    "   \u251c\u2500 High and low estimators explain reasoning\n",
    "   \u251c\u2500 Assumptions are surfaced\n",
    "   \u251c\u2500 Risks are identified\n",
    "   \u2514\u2500 Shared understanding improves\n",
    "\n",
    "5. Re-estimation:\n",
    "   \u251c\u2500 Team votes again\n",
    "   \u251c\u2500 Process repeats until consensus\n",
    "   \u2514\u2500 Typically converges in 2-3 rounds\n",
    "\n",
    "6. Record:\n",
    "   \u251c\u2500 Final estimate recorded\n",
    "   \u251c\u2500 Assumptions documented\n",
    "   \u2514\u2500 Risks noted\n",
    "```\n",
    "\n",
    "**Planning Poker Cards:**\n",
    "\n",
    "Standard Planning Poker uses a modified Fibonacci sequence:\n",
    "\n",
    "```\n",
    "Planning Poker Sequence:\n",
    "0, \u00bd, 1, 2, 3, 5, 8, 13, 20, 40, 100, ?, \u221e\n",
    "\n",
    "Why Fibonacci?\n",
    "\u251c\u2500 Reflects uncertainty at larger sizes\n",
    "\u251c\u2500 Easier to distinguish between 5 and 8 than 7 and 8\n",
    "\u251c\u2500 Prevents false precision in large estimates\n",
    "\u2514\u2500 Encourages breaking down large items\n",
    "\n",
    "Special Cards:\n",
    "\u251c\u2500 0: Already done or trivial\n",
    "\u251c\u2500 \u00bd: Very small task\n",
    "\u251c\u2500 ?: Don't understand, need clarification\n",
    "\u2514\u2500 \u221e: Too large, needs to be broken down\n",
    "```\n",
    "\n",
    "**Example Planning Poker Session:**\n",
    "\n",
    "```yaml\n",
    "planning_poker_session:\n",
    "  project: \"E-Commerce Platform\"\n",
    "  session_date: \"2025-03-20\"\n",
    "  iteration: \"Sprint 1 Planning\"\n",
    "  participants:\n",
    "    - name: \"Sarah\"\n",
    "      role: \"Product Owner\"\n",
    "    - name: \"Mike\"\n",
    "      role: \"Tech Lead\"\n",
    "    - name: \"Emily\"\n",
    "      role: \"Senior Developer\"\n",
    "    - name: \"David\"\n",
    "      role: \"Developer\"\n",
    "    - name: \"Lisa\"\n",
    "      role: \"QA Engineer\"\n",
    "  \n",
    "  stories:\n",
    "    - story_id: \"US-001\"\n",
    "      title: \"User Registration\"\n",
    "      description: \"Allow users to register with email and password\"\n",
    "      \n",
    "      round_1:\n",
    "        sarah: \"?\"  # Product Owner doesn't estimate\n",
    "        mike: \"5\"\n",
    "        emily: \"8\"\n",
    "        david: \"5\"\n",
    "        lisa: \"8\"\n",
    "        range: \"5-8\"\n",
    "        average: \"6.5\"\n",
    "        \n",
    "        discussion:\n",
    "          mike: \"I think it's a 5. Form validation, database write, email confirmation.\"\n",
    "          emily: \"I said 8 because of the email service integration and confirmation flow complexity.\"\n",
    "          david: \"I agree with Mike, the email integration is standard.\"\n",
    "          lisa: \"From testing perspective, we need to test validation rules, email sending, confirmation flow. That's significant testing effort.\"\n",
    "      \n",
    "      round_2:\n",
    "        sarah: \"?\"\n",
    "        mike: \"5\"\n",
    "        emily: \"5\"\n",
    "        david: \"5\"\n",
    "        lisa: \"5\"\n",
    "        consensus: \"5\"\n",
    "        result: \"5 story points\"\n",
    "        \n",
    "        notes: \"Team agreed on 5 after discussing email integration complexity\"\n",
    "      \n",
    "    - story_id: \"US-002\"\n",
    "      title: \"Product Search\"\n",
    "      description: \"Allow users to search products by name\"\n",
    "      \n",
    "      round_1:\n",
    "        sarah: \"?\"\n",
    "        mike: \"8\"\n",
    "        emily: \"13\"\n",
    "        david: \"8\"\n",
    "        lisa: \"8\"\n",
    "        range: \"8-13\"\n",
    "        \n",
    "        discussion:\n",
    "          mike: \"8 points. Database search, results display.\"\n",
    "          emily: \"I think 13. We need to consider search indexing, performance optimization, relevance ranking.\"\n",
    "          david: \"If we use database full-text search, it's simpler. If we need Elasticsearch, it's more complex.\"\n",
    "          lisa: \"Testing search functionality requires various test cases - exact match, partial match, no results, performance.\"\n",
    "      \n",
    "      round_2:\n",
    "        sarah: \"?\"\n",
    "        mike: \"8\"\n",
    "        emily: \"8\"\n",
    "        david: \"8\"\n",
    "        lisa: \"8\"\n",
    "        consensus: \"8\"\n",
    "        result: \"8 story points\"\n",
    "        \n",
    "        notes: \"Team agreed to use database full-text search initially, can upgrade to Elasticsearch later if needed\"\n",
    "      \n",
    "    - story_id: \"US-003\"\n",
    "      title: \"Payment Integration\"\n",
    "      description: \"Integrate with payment gateway\"\n",
    "      \n",
    "      round_1:\n",
    "        sarah: \"?\"\n",
    "        mike: \"13\"\n",
    "        emily: \"20\"\n",
    "        david: \"13\"\n",
    "        lisa: \"20\"\n",
    "        range: \"13-20\"\n",
    "        \n",
    "        discussion:\n",
    "          mike: \"13 points. API integration, error handling, webhook processing.\"\n",
    "          emily: \"I think 20. Payment integration is complex - PCI compliance, security, error handling, retry logic, reconciliation.\"\n",
    "          david: \"Agree with Mike on 13 if we use Stripe or similar. They handle a lot of the complexity.\"\n",
    "          lisa: \"Testing payment flows is critical - we need to test success, failure, edge cases, security. That's significant effort.\"\n",
    "      \n",
    "      round_2:\n",
    "        sarah: \"?\"\n",
    "        mike: \"13\"\n",
    "        emily: \"13\"\n",
    "        david: \"13\"\n",
    "        lisa: \"13\"\n",
    "        consensus: \"13\"\n",
    "        result: \"13 story points\"\n",
    "        \n",
    "        notes: \"Team agreed on 13, will use Stripe to reduce complexity, extensive testing required\"\n",
    "      \n",
    "    - story_id: \"US-004\"\n",
    "      title: \"Complete E-Commerce Platform\"\n",
    "      description: \"Build entire platform with all features\"\n",
    "      \n",
    "      round_1:\n",
    "        sarah: \"?\"\n",
    "        mike: \"\u221e\"\n",
    "        emily: \"\u221e\"\n",
    "        david: \"\u221e\"\n",
    "        lisa: \"\u221e\"\n",
    "        consensus: \"\u221e\"\n",
    "        \n",
    "        discussion:\n",
    "          mike: \"This is way too big. We can't estimate this as one item.\"\n",
    "          emily: \"Agree. This needs to be broken down into epics and stories.\"\n",
    "          david: \"We should split this into major components - auth, catalog, cart, checkout, etc.\"\n",
    "          lisa: \"From testing perspective, this would be impossible to test as one unit.\"\n",
    "      \n",
    "      result: \"Too large - needs to be broken down\"\n",
    "      action: \"Split into epics: User Management, Product Catalog, Shopping Cart, Checkout, Order Management\"\n",
    "  \n",
    "  session_summary:\n",
    "    total_stories: 4\n",
    "    estimated: 3\n",
    "    too_large: 1\n",
    "    total_story_points: 26\n",
    "    average_story_points: 8.7\n",
    "    \n",
    "    team_velocity: \"20 points per sprint\"\n",
    "    estimated_sprints: \"1.3 sprints for these stories\"\n",
    "    \n",
    "    key_insights:\n",
    "      - \"Payment integration (13 points) is the largest story\"\n",
    "      - \"Team converged quickly on estimates after discussion\"\n",
    "      - \"One story was too large and needs decomposition\"\n",
    "      - \"Team using database search for now, can upgrade later\"\n",
    "    \n",
    "    next_steps:\n",
    "      - \"Break down US-004 into manageable epics\"\n",
    "      - \"Plan stories for Sprint 1 based on 20-point capacity\"\n",
    "      - \"Schedule spike for payment integration research\"\n",
    "      - \"Set up database full-text search proof-of-concept\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Three-Point Estimation**\n",
    "\n",
    "Three-point estimation uses three estimates to account for uncertainty: optimistic (O), most likely (M), and pessimistic (P).\n",
    "\n",
    "**The Three Estimates:**\n",
    "\n",
    "```\n",
    "Three-Point Estimation:\n",
    "\n",
    "Optimistic (O):\n",
    "\u251c\u2500 Best-case scenario\n",
    "\u251c\u2500 Everything goes right\n",
    "\u251c\u2500 No unexpected issues\n",
    "\u251c\u2500 10th percentile (10% of outcomes better)\n",
    "\u2514\u2500 \"If we're lucky...\"\n",
    "\n",
    "Most Likely (M):\n",
    "\u251c\u2500 Realistic scenario\n",
    "\u251c\u2500 Normal conditions\n",
    "\u251c\u2500 Some minor issues\n",
    "\u251c\u2500 50th percentile (median)\n",
    "\u2514\u2500 \"Most likely...\"\n",
    "\n",
    "Pessimistic (P):\n",
    "\u251c\u2500 Worst-case scenario\n",
    "\u251c\u2500 Many things go wrong\n",
    "\u251c\u2500 Significant issues\n",
    "\u251c\u2500 90th percentile (90% of outcomes better)\n",
    "\u2514\u2500 \"If everything goes wrong...\"\n",
    "```\n",
    "\n",
    "**Calculation Methods:**\n",
    "\n",
    "```\n",
    "Expected Value (Triangular Distribution):\n",
    "E = (O + M + P) \u00f7 3\n",
    "\n",
    "Expected Value (Beta Distribution / PERT):\n",
    "E = (O + 4M + P) \u00f7 6\n",
    "\n",
    "Standard Deviation (Uncertainty):\n",
    "SD = (P - O) \u00f7 6\n",
    "\n",
    "Confidence Intervals:\n",
    "\u251c\u2500 68% confidence: E \u00b1 1 SD\n",
    "\u251c\u2500 95% confidence: E \u00b1 2 SD\n",
    "\u2514\u2500 99.7% confidence: E \u00b1 3 SD\n",
    "```\n",
    "\n",
    "**Example Three-Point Estimation:**\n",
    "\n",
    "```yaml\n",
    "three_point_estimation:\n",
    "  project: \"E-Commerce Platform\"\n",
    "  estimation_date: \"2025-03-20\"\n",
    "  estimator: \"Development Team\"\n",
    "  \n",
    "  stories:\n",
    "    - story_id: \"US-001\"\n",
    "      title: \"User Registration\"\n",
    "      \n",
    "      estimates:\n",
    "        optimistic: \"3 days\"\n",
    "        optimistic_assumptions:\n",
    "          - \"No email service issues\"\n",
    "          - \"Simple validation rules\"\n",
    "          - \"No UI complications\"\n",
    "          \n",
    "        most_likely: \"5 days\"\n",
    "        most_likely_assumptions:\n",
    "          - \"Some email configuration needed\"\n",
    "          - \"Standard validation requirements\"\n",
    "          - \"Minor UI adjustments\"\n",
    "          \n",
    "        pessimistic: \"10 days\"\n",
    "        pessimistic_assumptions:\n",
    "          - \"Email service integration issues\"\n",
    "          - \"Complex validation requirements\"\n",
    "          - \"Significant UI rework\"\n",
    "          - \"Security review findings\"\n",
    "      \n",
    "      calculations:\n",
    "        triangular_distribution: \"6 days\"  # (3 + 5 + 10) / 3\n",
    "        pert_distribution: \"5.5 days\"     # (3 + 4*5 + 10) / 6\n",
    "        standard_deviation: \"1.2 days\"   # (10 - 3) / 6\n",
    "        \n",
    "        confidence_intervals:\n",
    "          \"68%\": \"5.5 \u00b1 1.2 days (4.3 - 6.7 days)\"\n",
    "          \"95%\": \"5.5 \u00b1 2.4 days (3.1 - 7.9 days)\"\n",
    "      \n",
    "      recommended_estimate: \"5-6 days\"\n",
    "      buffer: \"20%\"\n",
    "      final_estimate: \"6-7 days\"\n",
    "      \n",
    "    - story_id: \"US-031\"\n",
    "      title: \"Payment Integration\"\n",
    "      \n",
    "      estimates:\n",
    "        optimistic: \"5 days\"\n",
    "        optimistic_assumptions:\n",
    "          - \"Payment gateway well-documented\"\n",
    "          - \"No compliance issues\"\n",
    "          - \"Simple integration\"\n",
    "          \n",
    "        most_likely: \"10 days\"\n",
    "        most_likely_assumptions:\n",
    "          - \"Some API quirks\"\n",
    "          - \"Standard compliance requirements\"\n",
    "          - \"Moderate complexity\"\n",
    "          \n",
    "        pessimistic: \"20 days\"\n",
    "        pessimistic_assumptions:\n",
    "          - \"Poor documentation\"\n",
    "          - \"Complex compliance requirements\"\n",
    "          - \"Integration issues\"\n",
    "          - \"Security audit findings\"\n",
    "      \n",
    "      calculations:\n",
    "        triangular_distribution: \"11.7 days\"\n",
    "        pert_distribution: \"10.8 days\"\n",
    "        standard_deviation: \"2.5 days\"\n",
    "        \n",
    "        confidence_intervals:\n",
    "          \"68%\": \"10.8 \u00b1 2.5 days (8.3 - 13.3 days)\"\n",
    "          \"95%\": \"10.8 \u00b1 5.0 days (5.8 - 15.8 days)\"\n",
    "      \n",
    "      recommended_estimate: \"10-12 days\"\n",
    "      buffer: \"25%\"\n",
    "      final_estimate: \"12-15 days\"\n",
    "  \n",
    "  summary:\n",
    "    total_stories: 2\n",
    "    total_optimistic: \"8 days\"\n",
    "    total_most_likely: \"15 days\"\n",
    "    total_pessimistic: \"30 days\"\n",
    "    \n",
    "    pert_total: \"16.3 days\"\n",
    "    with_buffer: \"20 days\"\n",
    "    \n",
    "    confidence: \"80% confidence: 16-20 days\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Monte Carlo Simulation**\n",
    "\n",
    "Monte Carlo simulation uses random sampling to model the probability of different outcomes in a process that cannot easily be predicted due to the intervention of random variables.\n",
    "\n",
    "**How Monte Carlo Simulation Works for Project Estimation:**\n",
    "\n",
    "```\n",
    "Monte Carlo Simulation Process:\n",
    "\n",
    "1. Define Variables:\n",
    "   \u251c\u2500 Identify uncertain variables (task durations, costs)\n",
    "   \u251c\u2500 Define probability distributions for each\n",
    "   \u251c\u2500 Specify ranges (min, max, likely)\n",
    "   \u2514\u2500 Choose distribution type (triangular, normal, etc.)\n",
    "\n",
    "2. Run Simulations:\n",
    "   \u251c\u2500 Run thousands of iterations (e.g., 10,000)\n",
    "   \u251c\u2500 For each iteration:\n",
    "   \u2502  \u251c\u2500 Randomly sample each variable from its distribution\n",
    "   \u2502  \u251c\u2500 Calculate total duration/cost\n",
    "   \u2502  \u2514\u2500 Record result\n",
    "   \u2514\u2500 Build distribution of possible outcomes\n",
    "\n",
    "3. Analyze Results:\n",
    "   \u251c\u2500 Calculate statistics (mean, median, percentiles)\n",
    "   \u251c\u2500 Identify confidence levels (50%, 80%, 90%, 95%)\n",
    "   \u251c\u2500 Determine probability of meeting deadlines\n",
    "   \u2514\u2500 Identify critical path risks\n",
    "\n",
    "4. Make Decisions:\n",
    "   \u251c\u2500 Choose confidence level for commitment\n",
    "   \u251c\u2500 Identify buffer needs\n",
    "   \u251c\u2500 Plan contingencies\n",
    "   \u2514\u2500 Communicate uncertainty ranges\n",
    "```\n",
    "\n",
    "**Code Snippet: Monte Carlo Simulation for Project Completion**\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Monte Carlo Simulation for Project Estimation\n",
    "Simulates project completion dates based on task duration uncertainty\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Task:\n",
    "    \"\"\"Represents a project task with uncertain duration.\"\"\"\n",
    "    name: str\n",
    "    optimistic: float  # days\n",
    "    most_likely: float  # days\n",
    "    pessimistic: float  # days\n",
    "    dependencies: List[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.dependencies is None:\n",
    "            self.dependencies = []\n",
    "    \n",
    "    def triangular_sample(self) -> float:\n",
    "        \"\"\"\n",
    "        Generate random duration using triangular distribution.\n",
    "        \n",
    "        Returns:\n",
    "            Random duration in days\n",
    "        \"\"\"\n",
    "        return np.random.triangular(\n",
    "            self.optimistic,\n",
    "            self.most_likely,\n",
    "            self.pessimistic\n",
    "        )\n",
    "    \n",
    "    def pert_sample(self) -> float:\n",
    "        \"\"\"\n",
    "        Generate random duration using PERT (Beta) distribution.\n",
    "        \n",
    "        Returns:\n",
    "            Random duration in days\n",
    "        \"\"\"\n",
    "        # PERT uses weighted average: (O + 4M + P) / 6\n",
    "        mean = (self.optimistic + 4 * self.most_likely + self.pessimistic) / 6\n",
    "        # Standard deviation: (P - O) / 6\n",
    "        std_dev = (self.pessimistic - self.optimistic) / 6\n",
    "        \n",
    "        # Use normal distribution as approximation\n",
    "        return max(self.optimistic, np.random.normal(mean, std_dev))\n",
    "\n",
    "\n",
    "class MonteCarloSimulator:\n",
    "    \"\"\"Performs Monte Carlo simulation for project estimation.\"\"\"\n",
    "    \n",
    "    def __init__(self, tasks: List[Task], start_date: datetime = None):\n",
    "        \"\"\"\n",
    "        Initialize simulator with project tasks.\n",
    "        \n",
    "        Args:\n",
    "            tasks: List of Task objects\n",
    "            start_date: Project start date (defaults to today)\n",
    "        \"\"\"\n",
    "        self.tasks = {task.name: task for task in tasks}\n",
    "        self.start_date = start_date or datetime.now()\n",
    "        self.results = []\n",
    "    \n",
    "    def _calculate_critical_path(self, simulation_results: Dict[str, float]) -> float:\n",
    "        \"\"\"\n",
    "        Calculate project duration based on task dependencies.\n",
    "        Simplified: assumes sequential execution with dependencies.\n",
    "        \n",
    "        Args:\n",
    "            simulation_results: Dictionary of task names to durations\n",
    "        \n",
    "        Returns:\n",
    "            Total project duration in days\n",
    "        \"\"\"\n",
    "        # Build dependency graph\n",
    "        completion_times = {}\n",
    "        \n",
    "        # Calculate completion time for each task\n",
    "        for task_name, task in self.tasks.items():\n",
    "            # Get dependencies completion times\n",
    "            dep_times = [\n",
    "                completion_times.get(dep, 0) \n",
    "                for dep in task.dependencies\n",
    "            ]\n",
    "            \n",
    "            # Start time is max of dependencies completion\n",
    "            start_time = max(dep_times) if dep_times else 0\n",
    "            \n",
    "            # Completion time is start + duration\n",
    "            completion_times[task_name] = start_time + simulation_results[task_name]\n",
    "        \n",
    "        # Project duration is max completion time\n",
    "        return max(completion_times.values())\n",
    "    \n",
    "    def run_simulation(self, iterations: int = 10000, distribution: str = \"triangular\") -> Dict:\n",
    "        \"\"\"\n",
    "        Run Monte Carlo simulation.\n",
    "        \n",
    "        Args:\n",
    "            iterations: Number of simulation runs\n",
    "            distribution: 'triangular' or 'pert'\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with simulation results and statistics\n",
    "        \"\"\"\n",
    "        self.results = []\n",
    "        \n",
    "        for _ in range(iterations):\n",
    "            # Generate random durations for all tasks\n",
    "            task_durations = {}\n",
    "            for task_name, task in self.tasks.items():\n",
    "                if distribution == \"pert\":\n",
    "                    task_durations[task_name] = task.pert_sample()\n",
    "                else:\n",
    "                    task_durations[task_name] = task.triangular_sample()\n",
    "            \n",
    "            # Calculate project duration\n",
    "            project_duration = self._calculate_critical_path(task_durations)\n",
    "            self.results.append(project_duration)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        results_array = np.array(self.results)\n",
    "        \n",
    "        stats = {\n",
    "            \"iterations\": iterations,\n",
    "            \"distribution\": distribution,\n",
    "            \"mean\": np.mean(results_array),\n",
    "            \"median\": np.median(results_array),\n",
    "            \"std_dev\": np.std(results_array),\n",
    "            \"min\": np.min(results_array),\n",
    "            \"max\": np.max(results_array),\n",
    "            \"percentile_10\": np.percentile(results_array, 10),\n",
    "            \"percentile_25\": np.percentile(results_array, 25),\n",
    "            \"percentile_50\": np.percentile(results_array, 50),\n",
    "            \"percentile_75\": np.percentile(results_array, 75),\n",
    "            \"percentile_80\": np.percentile(results_array, 80),\n",
    "            \"percentile_90\": np.percentile(results_array, 90),\n",
    "            \"percentile_95\": np.percentile(results_array, 95),\n",
    "            \"percentile_99\": np.percentile(results_array, 99),\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def plot_distribution(self, stats: Dict, filename: str = \"monte_carlo_distribution.png\"):\n",
    "        \"\"\"\n",
    "        Plot the distribution of simulation results.\n",
    "        \n",
    "        Args:\n",
    "            stats: Statistics dictionary from run_simulation\n",
    "            filename: Output filename for plot\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Histogram\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.hist(self.results, bins=50, edgecolor='black', alpha=0.7)\n",
    "        plt.axvline(stats[\"mean\"], color='red', linestyle='--', label=f'Mean: {stats[\"mean\"]:.1f}')\n",
    "        plt.axvline(stats[\"percentile_50\"], color='green', linestyle='--', label=f'Median: {stats[\"percentile_50\"]:.1f}')\n",
    "        plt.axvline(stats[\"percentile_80\"], color='orange', linestyle='--', label=f'80%: {stats[\"percentile_80\"]:.1f}')\n",
    "        plt.xlabel('Project Duration (days)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Monte Carlo Simulation: Project Duration Distribution')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Cumulative Distribution\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sorted_results = np.sort(self.results)\n",
    "        cumulative = np.arange(1, len(sorted_results) + 1) / len(sorted_results) * 100\n",
    "        plt.plot(sorted_results, cumulative, linewidth=2)\n",
    "        plt.axhline(50, color='green', linestyle='--', alpha=0.5, label='50% confidence')\n",
    "        plt.axhline(80, color='orange', linestyle='--', alpha=0.5, label='80% confidence')\n",
    "        plt.axhline(90, color='red', linestyle='--', alpha=0.5, label='90% confidence')\n",
    "        plt.xlabel('Project Duration (days)')\n",
    "        plt.ylabel('Cumulative Probability (%)')\n",
    "        plt.title('Cumulative Distribution Function')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename)\n",
    "        print(f\"Distribution plot saved to {filename}\")\n",
    "    \n",
    "    def generate_report(self, stats: Dict, start_date: datetime = None) -> str:\n",
    "        \"\"\"\n",
    "        Generate a comprehensive Monte Carlo simulation report.\n",
    "        \n",
    "        Args:\n",
    "            stats: Statistics dictionary from run_simulation\n",
    "            start_date: Project start date\n",
    "        \n",
    "        Returns:\n",
    "            Formatted report string\n",
    "        \"\"\"\n",
    "        if start_date is None:\n",
    "            start_date = self.start_date\n",
    "        \n",
    "        lines = []\n",
    "        lines.append(\"Monte Carlo Simulation Report\")\n",
    "        lines.append(\"=\" * 70)\n",
    "        lines.append(f\"Simulation Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "        lines.append(f\"Iterations: {stats['iterations']:,}\")\n",
    "        lines.append(f\"Distribution: {stats['distribution'].title()}\")\n",
    "        lines.append(\"\")\n",
    "        \n",
    "        # Statistics\n",
    "        lines.append(\"Statistical Summary:\")\n",
    "        lines.append(\"-\" * 70)\n",
    "        lines.append(f\"Mean (Average):        {stats['mean']:.1f} days\")\n",
    "        lines.append(f\"Median (50th %ile):     {stats['median']:.1f} days\")\n",
    "        lines.append(f\"Standard Deviation:      {stats['std_dev']:.1f} days\")\n",
    "        lines.append(f\"Minimum:               {stats['min']:.1f} days\")\n",
    "        lines.append(f\"Maximum:               {stats['max']:.1f} days\")\n",
    "        lines.append(\"\")\n",
    "        \n",
    "        # Percentiles\n",
    "        lines.append(\"Completion Probability by Date:\")\n",
    "        lines.append(\"-\" * 70)\n",
    "        \n",
    "        percentiles = [10, 25, 50, 75, 80, 90, 95, 99]\n",
    "        for p in percentiles:\n",
    "            days = stats[f'percentile_{p}']\n",
    "            completion_date = start_date + timedelta(days=days)\n",
    "            lines.append(f\"{p:2d}th percentile: {days:6.1f} days ({completion_date.strftime('%Y-%m-%d')})\")\n",
    "        \n",
    "        lines.append(\"\")\n",
    "        \n",
    "        # Confidence Levels\n",
    "        lines.append(\"Key Confidence Levels:\")\n",
    "        lines.append(\"-\" * 70)\n",
    "        \n",
    "        conf_50_date = start_date + timedelta(days=stats['percentile_50'])\n",
    "        conf_80_date = start_date + timedelta(days=stats['percentile_80'])\n",
    "        conf_90_date = start_date + timedelta(days=stats['percentile_90'])\n",
    "        \n",
    "        lines.append(f\"50% confidence: Complete by {conf_50_date.strftime('%Y-%m-%d')} ({stats['percentile_50']:.1f} days)\")\n",
    "        lines.append(f\"80% confidence: Complete by {conf_80_date.strftime('%Y-%m-%d')} ({stats['percentile_80']:.1f} days)\")\n",
    "        lines.append(f\"90% confidence: Complete by {conf_90_date.strftime('%Y-%m-%d')} ({stats['percentile_90']:.1f} days)\")\n",
    "        lines.append(\"\")\n",
    "        \n",
    "        # Recommendations\n",
    "        lines.append(\"Recommendations:\")\n",
    "        lines.append(\"-\" * 70)\n",
    "        lines.append(f\"1. Use 80% confidence level for planning: {conf_80_date.strftime('%Y-%m-%d')}\")\n",
    "        lines.append(f\"2. Communicate range: {stats['percentile_25']:.0f}-{stats['percentile_75']:.0f} days (50% confidence)\")\n",
    "        lines.append(f\"3. Risk buffer: Add {(stats['percentile_90'] - stats['percentile_50']):.0f} days for high-confidence delivery\")\n",
    "        lines.append(\"4. Monitor actual progress against simulation and adjust\")\n",
    "        lines.append(\"5. Update simulation monthly with actual data\")\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define project tasks\n",
    "    tasks = [\n",
    "        Task(\n",
    "            name=\"Requirements\",\n",
    "            optimistic=10,\n",
    "            most_likely=15,\n",
    "            pessimistic=25,\n",
    "            dependencies=[]\n",
    "        ),\n",
    "        Task(\n",
    "            name=\"Architecture\",\n",
    "            optimistic=5,\n",
    "            most_likely=10,\n",
    "            pessimistic=20,\n",
    "            dependencies=[\"Requirements\"]\n",
    "        ),\n",
    "        Task(\n",
    "            name=\"Development\",\n",
    "            optimistic=60,\n",
    "            most_likely=90,\n",
    "            pessimistic=150,\n",
    "            dependencies=[\"Architecture\"]\n",
    "        ),\n",
    "        Task(\n",
    "            name=\"Testing\",\n",
    "            optimistic=20,\n",
    "            most_likely=30,\n",
    "            pessimistic=50,\n",
    "            dependencies=[\"Development\"]\n",
    "        ),\n",
    "        Task(\n",
    "            name=\"Deployment\",\n",
    "            optimistic=5,\n",
    "            most_likely=10,\n",
    "            pessimistic=20,\n",
    "            dependencies=[\"Testing\"]\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    # Run simulation\n",
    "    simulator = MonteCarloSimulator(tasks, start_date=datetime(2025, 3, 15))\n",
    "    stats = simulator.run_simulation(iterations=10000, distribution=\"triangular\")\n",
    "    \n",
    "    # Generate report\n",
    "    print(simulator.generate_report(stats))\n",
    "    \n",
    "    # Plot distribution\n",
    "    simulator.plot_distribution(stats)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4.3 Velocity, Throughput, and Cycle Time**\n",
    "\n",
    "### **Velocity**\n",
    "\n",
    "Velocity is a measure of the amount of work a team can tackle during a single sprint. It's typically measured in story points per sprint.\n",
    "\n",
    "**Understanding Velocity:**\n",
    "\n",
    "```\n",
    "Velocity Concepts:\n",
    "\n",
    "Definition:\n",
    "\u251c\u2500 Amount of work completed per iteration\n",
    "\u251c\u2500 Measured in story points (or other units)\n",
    "\u251c\u2500 Based on actual completed work\n",
    "\u2514\u2500 Historical measure, not a target\n",
    "\n",
    "Calculation:\n",
    "Velocity = Sum of story points completed in sprint\n",
    "\n",
    "Example:\n",
    "Sprint 1: Completed stories worth 3 + 5 + 2 + 8 = 18 points\n",
    "Sprint 2: Completed stories worth 5 + 5 + 8 + 3 = 21 points\n",
    "Sprint 3: Completed stories worth 5 + 3 + 5 + 5 = 18 points\n",
    "\n",
    "Average Velocity = (18 + 21 + 18) / 3 = 19 points per sprint\n",
    "```\n",
    "\n",
    "**Using Velocity for Planning:**\n",
    "\n",
    "```\n",
    "Velocity-Based Planning:\n",
    "\n",
    "1. Calculate Average Velocity:\n",
    "   \u251c\u2500 Use last 3-5 sprints\n",
    "   \u251c\u2500 Remove outliers if necessary\n",
    "   \u251c\u2500 Calculate rolling average\n",
    "   \u2514\u2500 Update regularly\n",
    "\n",
    "2. Determine Capacity:\n",
    "   \u251c\u2500 Adjust for team changes\n",
    "   \u251c\u2500 Account for holidays/time off\n",
    "   \u251c\u2500 Consider sprint length changes\n",
    "   \u2514\u2500 Calculate available capacity\n",
    "\n",
    "3. Select Stories:\n",
    "   \u251c\u2500 Pull stories up to velocity limit\n",
    "   \u251c\u2500 Consider story dependencies\n",
    "   \u251c\u2500 Balance types of work\n",
    "   \u2514\u2500 Leave buffer for uncertainty\n",
    "\n",
    "4. Monitor and Adjust:\n",
    "   \u251c\u2500 Track actual vs. planned\n",
    "   \u251c\u2500 Update velocity after each sprint\n",
    "   \u251c\u2500 Adjust planning based on trends\n",
    "   \u2514\u2500 Communicate changes\n",
    "```\n",
    "\n",
    "**Code Snippet: Velocity Tracker**\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Velocity Tracker\n",
    "Tracks team velocity over time and provides forecasting\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Dict, Optional\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import statistics\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Sprint:\n",
    "    \"\"\"Represents a sprint with velocity data.\"\"\"\n",
    "    sprint_number: int\n",
    "    start_date: datetime\n",
    "    end_date: datetime\n",
    "    planned_points: int\n",
    "    completed_points: int\n",
    "    stories_completed: int\n",
    "    stories_planned: int\n",
    "    notes: str = \"\"\n",
    "    \n",
    "    @property\n",
    "    def velocity(self) -> int:\n",
    "        \"\"\"Calculate velocity (completed points).\"\"\"\n",
    "        return self.completed_points\n",
    "    \n",
    "    @property\n",
    "    def completion_rate(self) -> float:\n",
    "        \"\"\"Calculate completion rate.\"\"\"\n",
    "        if self.planned_points == 0:\n",
    "            return 0.0\n",
    "        return (self.completed_points / self.planned_points) * 100\n",
    "\n",
    "\n",
    "class VelocityTracker:\n",
    "    \"\"\"Tracks velocity and provides forecasting.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize velocity tracker.\"\"\"\n",
    "        self.sprints: List[Sprint] = []\n",
    "    \n",
    "    def add_sprint(self, sprint: Sprint):\n",
    "        \"\"\"\n",
    "        Add a sprint to the tracker.\n",
    "        \n",
    "        Args:\n",
    "            sprint: Sprint data\n",
    "        \"\"\"\n",
    "        self.sprints.append(sprint)\n",
    "    \n",
    "    def get_average_velocity(self, num_sprints: int = 3) -> float:\n",
    "        \"\"\"\n",
    "        Calculate average velocity over last N sprints.\n",
    "        \n",
    "        Args:\n",
    "            num_sprints: Number of sprints to average (default 3)\n",
    "        \n",
    "        Returns:\n",
    "            Average velocity\n",
    "        \"\"\"\n",
    "        if not self.sprints:\n",
    "            return 0.0\n",
    "        \n",
    "        recent_sprints = self.sprints[-num_sprints:]\n",
    "        velocities = [s.velocity for s in recent_sprints]\n",
    "        \n",
    "        return statistics.mean(velocities)\n",
    "    \n",
    "    def get_velocity_trend(self) -> str:\n",
    "        \"\"\"\n",
    "        Determine if velocity is trending up, down, or stable.\n",
    "        \n",
    "        Returns:\n",
    "            Trend description\n",
    "        \"\"\"\n",
    "        if len(self.sprints) < 3:\n",
    "            return \"Insufficient data\"\n",
    "        \n",
    "        # Compare first half to second half\n",
    "        mid = len(self.sprints) // 2\n",
    "        first_half = self.sprints[:mid]\n",
    "        second_half = self.sprints[mid:]\n",
    "        \n",
    "        first_avg = statistics.mean([s.velocity for s in first_half])\n",
    "        second_avg = statistics.mean([s.velocity for s in second_half])\n",
    "        \n",
    "        diff_pct = ((second_avg - first_avg) / first_avg) * 100 if first_avg > 0 else 0\n",
    "        \n",
    "        if diff_pct > 10:\n",
    "            return f\"Improving (+{diff_pct:.1f}%)\"\n",
    "        elif diff_pct < -10:\n",
    "            return f\"Declining ({diff_pct:.1f}%)\"\n",
    "        else:\n",
    "            return f\"Stable ({diff_pct:+.1f}%)\"\n",
    "    \n",
    "    def forecast_completion(self, remaining_points: int, confidence_level: float = 0.8) -> Dict:\n",
    "        \"\"\"\n",
    "        Forecast when remaining work will be completed.\n",
    "        \n",
    "        Args:\n",
    "            remaining_points: Story points remaining\n",
    "            confidence_level: Confidence level for forecast (0.0-1.0)\n",
    "        \n",
    "        Returns:\n",
    "            Forecast dictionary with dates and confidence\n",
    "        \"\"\"\n",
    "        if not self.sprints or remaining_points <= 0:\n",
    "            return {}\n",
    "        \n",
    "        # Get velocity distribution from historical sprints\n",
    "        velocities = [s.velocity for s in self.sprints]\n",
    "        \n",
    "        # Simulate future sprints\n",
    "        num_simulations = 10000\n",
    "        sprints_needed = []\n",
    "        \n",
    "        for _ in range(num_simulations):\n",
    "            points_remaining = remaining_points\n",
    "            sprints = 0\n",
    "            \n",
    "            while points_remaining > 0:\n",
    "                # Randomly sample from historical velocities\n",
    "                velocity = np.random.choice(velocities)\n",
    "                points_remaining -= velocity\n",
    "                sprints += 1\n",
    "            \n",
    "            sprints_needed.append(sprints)\n",
    "        \n",
    "        sprints_array = np.array(sprints_needed)\n",
    "        \n",
    "        # Calculate percentiles\n",
    "        percentiles = [50, 60, 70, 80, 90, 95, 99]\n",
    "        forecast = {}\n",
    "        \n",
    "        for p in percentiles:\n",
    "            num_sprints = int(np.percentile(sprints_array, p))\n",
    "            end_date = self._calculate_end_date(num_sprints)\n",
    "            forecast[f\"{p}th\"] = {\n",
    "                \"sprints\": num_sprints,\n",
    "                \"end_date\": end_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"confidence\": f\"{p}%\"\n",
    "            }\n",
    "        \n",
    "        # Determine sprints needed for requested confidence\n",
    "        target_sprints = int(np.percentile(sprints_array, confidence_level * 100))\n",
    "        target_date = self._calculate_end_date(target_sprints)\n",
    "        \n",
    "        return {\n",
    "            \"remaining_points\": remaining_points,\n",
    "            \"target_confidence\": f\"{confidence_level*100:.0f}%\",\n",
    "            \"forecasted_sprints\": target_sprints,\n",
    "            \"forecasted_end_date\": target_date.strftime(\"%Y-%m-%d\"),\n",
    "            \"percentile_forecasts\": forecast,\n",
    "            \"velocity_statistics\": {\n",
    "                \"mean\": np.mean(velocities),\n",
    "                \"median\": np.median(velocities),\n",
    "                \"min\": np.min(velocities),\n",
    "                \"max\": np.max(velocities)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _calculate_end_date(self, num_sprints: int) -> datetime:\n",
    "        \"\"\"Calculate end date based on number of sprints.\"\"\"\n",
    "        # Assume 2-week sprints\n",
    "        days = num_sprints * 14\n",
    "        \n",
    "        # Add weekends and holidays (simplified)\n",
    "        # In reality, you'd use a calendar library\n",
    "        if self.sprints:\n",
    "            last_sprint_end = self.sprints[-1].end_date\n",
    "            return last_sprint_end + timedelta(days=days)\n",
    "        else:\n",
    "            return datetime.now() + timedelta(days=days)\n",
    "    \n",
    "    def generate_report(self) -> str:\n",
    "        \"\"\"\n",
    "        Generate comprehensive velocity report.\n",
    "        \n",
    "        Returns:\n",
    "            Formatted report string\n",
    "        \"\"\"\n",
    "        lines = []\n",
    "        lines.append(\"Velocity Tracking Report\")\n",
    "        lines.append(\"=\" * 70)\n",
    "        lines.append(f\"Report Date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "        lines.append(f\"Total Sprints: {len(self.sprints)}\")\n",
    "        lines.append(\"\")\n",
    "        \n",
    "        # Sprint History\n",
    "        if self.sprints:\n",
    "            lines.append(\"Sprint History:\")\n",
    "            lines.append(\"-\" * 70)\n",
    "            lines.append(f\"{'Sprint':<8} {'Planned':<10} {'Completed':<10} {'Rate':<8} {'Trend':<10}\")\n",
    "            lines.append(\"-\" * 70)\n",
    "            \n",
    "            for sprint in self.sprints:\n",
    "                trend = self.get_velocity_trend() if sprint == self.sprints[-1] else \"\"\n",
    "                lines.append(\n",
    "                    f\"{sprint.sprint_number:<8} \"\n",
    "                    f\"{sprint.planned_points:<10} \"\n",
    "                    f\"{sprint.completed_points:<10} \"\n",
    "                    f\"{sprint.completion_rate:.1f}%{'':<3} \"\n",
    "                    f\"{trend:<10}\"\n",
    "                )\n",
    "            lines.append(\"\")\n",
    "        \n",
    "        # Velocity Statistics\n",
    "        if len(self.sprints) >= 3:\n",
    "            lines.append(\"Velocity Statistics (Last 3 Sprints):\")\n",
    "            lines.append(\"-\" * 70)\n",
    "            avg_velocity = self.get_average_velocity(3)\n",
    "            lines.append(f\"Average Velocity: {avg_velocity:.1f} story points per sprint\")\n",
    "            lines.append(f\"Velocity Trend: {self.get_velocity_trend()}\")\n",
    "            lines.append(\"\")\n",
    "        \n",
    "        # Forecast\n",
    "        if len(self.sprints) > 0:\n",
    "            lines.append(\"Forecast Example:\")\n",
    "            lines.append(\"-\" * 70)\n",
    "            forecast = self.forecast_completion(remaining_points=100, confidence_level=0.8)\n",
    "            if forecast:\n",
    "                lines.append(f\"Remaining Work: {forecast['remaining_points']} story points\")\n",
    "                lines.append(f\"Target Confidence: {forecast['target_confidence']}\")\n",
    "                lines.append(f\"Forecasted Sprints: {forecast['forecasted_sprints']}\")\n",
    "                lines.append(f\"Forecasted End Date: {forecast['forecasted_end_date']}\")\n",
    "                lines.append(\"\")\n",
    "                lines.append(\"Confidence Intervals:\")\n",
    "                for key, value in forecast['percentile_forecasts'].items():\n",
    "                    lines.append(f\"  {value['confidence']}: {value['sprints']} sprints by {value['end_date']}\")\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create velocity tracker\n",
    "    tracker = VelocityTracker()\n",
    "    \n",
    "    # Add historical sprints\n",
    "    sprints = [\n",
    "        Sprint(1, datetime(2025, 1, 6), datetime(2025, 1, 17), 20, 18, 4, 5),\n",
    "        Sprint(2, datetime(2025, 1, 20), datetime(2025, 1, 31), 22, 21, 5, 5),\n",
    "        Sprint(3, datetime(2025, 2, 3), datetime(2025, 2, 14), 20, 19, 4, 5),\n",
    "        Sprint(4, datetime(2025, 2, 17), datetime(2025, 2, 28), 24, 22, 5, 6),\n",
    "    ]\n",
    "    \n",
    "    for sprint in sprints:\n",
    "        tracker.add_sprint(sprint)\n",
    "    \n",
    "    # Generate report\n",
    "    print(tracker.generate_report())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Throughput and Cycle Time**\n",
    "\n",
    "While velocity measures output per iteration, throughput and cycle time provide additional perspectives on team performance.\n",
    "\n",
    "**Throughput:**\n",
    "\n",
    "```\n",
    "Throughput:\n",
    "\u251c\u2500 Definition: Number of work items completed per unit of time\n",
    "\u251c\u2500 Unit: Items per week/day/sprint\n",
    "\u251c\u2500 Focus: Flow of work through system\n",
    "\u251c\u2500 Best for: Kanban teams, continuous flow\n",
    "\u2514\u2500 Calculation: Count of items completed / time period\n",
    "\n",
    "Example:\n",
    "Week 1: 5 stories completed\n",
    "Week 2: 7 stories completed\n",
    "Week 3: 6 stories completed\n",
    "Week 4: 8 stories completed\n",
    "\n",
    "Average Throughput = (5 + 7 + 6 + 8) / 4 = 6.5 stories per week\n",
    "```\n",
    "\n",
    "**Cycle Time:**\n",
    "\n",
    "```\n",
    "Cycle Time:\n",
    "\u251c\u2500 Definition: Time from when work starts to when it's delivered\n",
    "\u251c\u2500 Unit: Days/hours\n",
    "\u251c\u2500 Focus: Speed of delivery\n",
    "\u251c\u2500 Best for: Identifying bottlenecks, flow optimization\n",
    "\u2514\u2500 Calculation: End date - Start date\n",
    "\n",
    "Example:\n",
    "Story 1: Started Jan 6, Completed Jan 10 = 4 days\n",
    "Story 2: Started Jan 7, Completed Jan 12 = 5 days\n",
    "Story 3: Started Jan 8, Completed Jan 11 = 3 days\n",
    "\n",
    "Average Cycle Time = (4 + 5 + 3) / 3 = 4 days\n",
    "```\n",
    "\n",
    "**Little's Law:**\n",
    "\n",
    "```\n",
    "Little's Law:\n",
    "Work in Progress (WIP) = Throughput \u00d7 Cycle Time\n",
    "\n",
    "Or rearranged:\n",
    "Cycle Time = WIP / Throughput\n",
    "\n",
    "Implications:\n",
    "\u251c\u2500 Reducing WIP reduces Cycle Time\n",
    "\u251c\u2500 Increasing Throughput reduces Cycle Time\n",
    "\u251c\u2500 High WIP leads to longer delivery times\n",
    "\u2514\u2500 Limiting WIP improves flow\n",
    "\n",
    "Example:\n",
    "If Throughput = 5 stories/week\n",
    "And WIP = 10 stories\n",
    "Then Cycle Time = 10 / 5 = 2 weeks\n",
    "```\n",
    "\n",
    "**Code Snippet: Throughput and Cycle Time Tracker**\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Throughput and Cycle Time Tracker\n",
    "Tracks flow metrics for Kanban and Scrum teams\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Dict, Optional\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "import statistics\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class WorkItem:\n",
    "    \"\"\"Represents a work item with flow dates.\"\"\"\n",
    "    item_id: str\n",
    "    title: str\n",
    "    story_points: Optional[int] = None\n",
    "    created_date: Optional[datetime] = None\n",
    "    started_date: Optional[datetime] = None\n",
    "    completed_date: Optional[datetime] = None\n",
    "    status: str = \"Backlog\"\n",
    "    \n",
    "    @property\n",
    "    def cycle_time(self) -> Optional[float]:\n",
    "        \"\"\"Calculate cycle time in days.\"\"\"\n",
    "        if self.started_date and self.completed_date:\n",
    "            delta = self.completed_date - self.started_date\n",
    "            return delta.total_seconds() / (24 * 3600)\n",
    "        return None\n",
    "    \n",
    "    @property\n",
    "    def lead_time(self) -> Optional[float]:\n",
    "        \"\"\"Calculate lead time in days.\"\"\"\n",
    "        if self.created_date and self.completed_date:\n",
    "            delta = self.completed_date - self.created_date\n",
    "            return delta.total_seconds() / (24 * 3600)\n",
    "        return None\n",
    "    \n",
    "    @property\n",
    "    def wait_time(self) -> Optional[float]:\n",
    "        \"\"\"Calculate time spent waiting (before started).\"\"\"\n",
    "        if self.created_date and self.started_date:\n",
    "            delta = self.started_date - self.created_date\n",
    "            return delta.total_seconds() / (24 * 3600)\n",
    "        return None\n",
    "\n",
    "\n",
    "class FlowMetricsTracker:\n",
    "    \"\"\"Tracks throughput, cycle time, and other flow metrics.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize flow metrics tracker.\"\"\"\n",
    "        self.items: List[WorkItem] = []\n",
    "    \n",
    "    def add_item(self, item: WorkItem):\n",
    "        \"\"\"\n",
    "        Add a work item to the tracker.\n",
    "        \n",
    "        Args:\n",
    "            item: WorkItem to add\n",
    "        \"\"\"\n",
    "        self.items.append(item)\n",
    "    \n",
    "    def get_throughput(self, start_date: datetime, end_date: datetime, unit: str = \"week\") -> float:\n",
    "        \"\"\"\n",
    "        Calculate throughput for a date range.\n",
    "        \n",
    "        Args:\n",
    "            start_date: Start of range\n",
    "            end_date: End of range\n",
    "            unit: 'day', 'week', or 'sprint'\n",
    "        \n",
    "        Returns:\n",
    "            Throughput (items per unit)\n",
    "        \"\"\"\n",
    "        # Filter items completed in range\n",
    "        completed = [\n",
    "            item for item in self.items\n",
    "            if item.completed_date\n",
    "            and start_date <= item.completed_date <= end_date\n",
    "        ]\n",
    "        \n",
    "        count = len(completed)\n",
    "        days = (end_date - start_date).days\n",
    "        \n",
    "        if unit == \"day\":\n",
    "            return count / days if days > 0 else 0\n",
    "        elif unit == \"week\":\n",
    "            weeks = days / 7\n",
    "            return count / weeks if weeks > 0 else 0\n",
    "        elif unit == \"sprint\":\n",
    "            sprints = days / 14  # Assume 2-week sprints\n",
    "            return count / sprints if sprints > 0 else 0\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def get_cycle_time_stats(self, start_date: Optional[datetime] = None, \n",
    "                            end_date: Optional[datetime] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate cycle time statistics.\n",
    "        \n",
    "        Args:\n",
    "            start_date: Filter items completed after this date\n",
    "            end_date: Filter items completed before this date\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with cycle time statistics\n",
    "        \"\"\"\n",
    "        # Filter items\n",
    "        items = self.items\n",
    "        if start_date:\n",
    "            items = [i for i in items if i.completed_date and i.completed_date >= start_date]\n",
    "        if end_date:\n",
    "            items = [i for i in items if i.completed_date and i.completed_date <= end_date]\n",
    "        \n",
    "        # Get cycle times\n",
    "        cycle_times = [i.cycle_time for i in items if i.cycle_time is not None]\n",
    "        \n",
    "        if not cycle_times:\n",
    "            return {}\n",
    "        \n",
    "        return {\n",
    "            \"count\": len(cycle_times),\n",
    "            \"mean\": statistics.mean(cycle_times),\n",
    "            \"median\": statistics.median(cycle_times),\n",
    "            \"min\": min(cycle_times),\n",
    "            \"max\": max(cycle_times),\n",
    "            \"std_dev\": statistics.stdev(cycle_times) if len(cycle_times) > 1 else 0,\n",
    "            \"percentile_85\": np.percentile(cycle_times, 85) if cycle_times else 0,\n",
    "            \"percentile_95\": np.percentile(cycle_times, 95) if cycle_times else 0,\n",
    "        }\n",
    "    \n",
    "    def calculate_wip(self, date: datetime) -> int:\n",
    "        \"\"\"\n",
    "        Calculate Work in Progress at a specific date.\n",
    "        \n",
    "        Args:\n",
    "            date: Date to check\n",
    "        \n",
    "        Returns:\n",
    "            Number of items in progress\n",
    "        \"\"\"\n",
    "        wip = 0\n",
    "        for item in self.items:\n",
    "            if item.started_date and item.started_date <= date:\n",
    "                if not item.completed_date or item.completed_date > date:\n",
    "                    wip += 1\n",
    "        return wip\n",
    "    \n",
    "    def apply_littles_law(self, throughput: float, cycle_time: float) -> float:\n",
    "        \"\"\"\n",
    "        Apply Little's Law to calculate expected WIP.\n",
    "        \n",
    "        Args:\n",
    "            throughput: Items per unit time\n",
    "            cycle_time: Time per item\n",
    "        \n",
    "        Returns:\n",
    "            Expected WIP\n",
    "        \"\"\"\n",
    "        return throughput * cycle_time\n",
    "    \n",
    "    def generate_report(self) -> str:\n",
    "        \"\"\"\n",
    "        Generate comprehensive flow metrics report.\n",
    "        \n",
    "        Returns:\n",
    "            Formatted report string\n",
    "        \"\"\"\n",
    "        lines = []\n",
    "        lines.append(\"Flow Metrics Report\")\n",
    "        lines.append(\"=\" * 70)\n",
    "        lines.append(f\"Report Date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "        lines.append(f\"Total Items: {len(self.items)}\")\n",
    "        lines.append(\"\")\n",
    "        \n",
    "        # Throughput\n",
    "        if len(self.items) >= 2:\n",
    "            dates = [i.completed_date for i in self.items if i.completed_date]\n",
    "            if len(dates) >= 2:\n",
    "                min_date = min(dates)\n",
    "                max_date = max(dates)\n",
    "                throughput = self.get_throughput(min_date, max_date, \"week\")\n",
    "                \n",
    "                lines.append(\"Throughput:\")\n",
    "                lines.append(\"-\" * 70)\n",
    "                lines.append(f\"Period: {min_date.strftime('%Y-%m-%d')} to {max_date.strftime('%Y-%m-%d')}\")\n",
    "                lines.append(f\"Throughput: {throughput:.2f} items per week\")\n",
    "                lines.append(\"\")\n",
    "        \n",
    "        # Cycle Time\n",
    "        cycle_stats = self.get_cycle_time_stats()\n",
    "        if cycle_stats:\n",
    "            lines.append(\"Cycle Time Statistics:\")\n",
    "            lines.append(\"-\" * 70)\n",
    "            lines.append(f\"Count: {cycle_stats['count']} items\")\n",
    "            lines.append(f\"Mean: {cycle_stats['mean']:.1f} days\")\n",
    "            lines.append(f\"Median: {cycle_stats['median']:.1f} days\")\n",
    "            lines.append(f\"Min: {cycle_stats['min']:.1f} days\")\n",
    "            lines.append(f\"Max: {cycle_stats['max']:.1f} days\")\n",
    "            lines.append(f\"85th percentile: {cycle_stats['percentile_85']:.1f} days\")\n",
    "            lines.append(f\"95th percentile: {cycle_stats['percentile_95']:.1f} days\")\n",
    "            lines.append(\"\")\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create tracker\n",
    "    tracker = FlowMetricsTracker()\n",
    "    \n",
    "    # Add sample items\n",
    "    items = [\n",
    "        WorkItem(\"ITEM-001\", \"Login\", 3, datetime(2025, 1, 6), datetime(2025, 1, 6), datetime(2025, 1, 10)),\n",
    "        WorkItem(\"ITEM-002\", \"Register\", 5, datetime(2025, 1, 6), datetime(2025, 1, 7), datetime(2025, 1, 14)),\n",
    "        WorkItem(\"ITEM-003\", \"Search\", 3, datetime(2025, 1, 13), datetime(2025, 1, 13), datetime(2025, 1, 16)),\n",
    "        WorkItem(\"ITEM-004\", \"Cart\", 5, datetime(2025, 1, 15), datetime(2025, 1, 15), datetime(2025, 1, 22)),\n",
    "        WorkItem(\"ITEM-005\", \"Checkout\", 8, datetime(2025, 1, 20), datetime(2025, 1, 21), datetime(2025, 2, 3)),\n",
    "    ]\n",
    "    \n",
    "    for item in items:\n",
    "        tracker.add_item(item)\n",
    "    \n",
    "    # Generate report\n",
    "    print(tracker.generate_report())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4.4 Buffer Management**\n",
    "\n",
    "### **Why Buffers Are Necessary**\n",
    "\n",
    "Buffers (or contingencies) are necessary because:\n",
    "- Estimates are uncertain\n",
    "- Unexpected issues arise\n",
    "- Scope changes occur\n",
    "- Dependencies cause delays\n",
    "\n",
    "**Types of Buffers:**\n",
    "\n",
    "```\n",
    "Buffer Types:\n",
    "\n",
    "1. Feature Buffer:\n",
    "   \u251c\u2500 Include low-priority features that can be dropped\n",
    "   \u251c\u2500 Scope buffer for high-priority items\n",
    "   \u2514\u2500 Protects schedule and quality\n",
    "\n",
    "2. Schedule Buffer:\n",
    "   \u251c\u2500 Extra time added to critical path\n",
    "   \u251c\u2500 Protects project end date\n",
    "   \u251c\u2500 Usually 15-25% of project duration\n",
    "   \u2514\u2500 Managed explicitly, not hidden in tasks\n",
    "\n",
    "3. Resource Buffer:\n",
    "   \u251c\u2500 Extra capacity for critical resources\n",
    "   \u251c\u2500 Protects against resource unavailability\n",
    "   \u251c\u2500 May include backup personnel\n",
    "   \u2514\u2500 Cross-training for flexibility\n",
    "\n",
    "4. Budget Buffer:\n",
    "   \u251c\u2500 Extra funds for unexpected costs\n",
    "   \u251c\u2500 Usually 10-20% of budget\n",
    "   \u251c\u2500 Requires approval to use\n",
    "   \u2514\u2500 Protects against cost overruns\n",
    "\n",
    "5. Quality Buffer:\n",
    "   \u251c\u2500 Extra time for testing and bug fixing\n",
    "   \u251c\u2500 Protects against quality issues\n",
    "   \u251c\u2500 Not a substitute for good practices\n",
    "   \u2514\u2500 Contingency for unexpected defects\n",
    "```\n",
    "\n",
    "**Buffer Calculation Methods:**\n",
    "\n",
    "```\n",
    "Buffer Calculation:\n",
    "\n",
    "Method 1: Percentage of Total\n",
    "Buffer = Total Estimate \u00d7 Buffer Percentage\n",
    "Example: 100 days \u00d7 20% = 20 days buffer\n",
    "\n",
    "Method 2: Square Root of Sum of Squares (Critical Chain)\n",
    "Buffer = \u221a(\u03a3(Task Variance))\n",
    "Where Variance = (Pessimistic - Optimistic)\u00b2 / 36\n",
    "\n",
    "Method 3: Aggregation of Local Buffers\n",
    "Buffer = Sum of individual task buffers\n",
    "(Not recommended - buffers get used up)\n",
    "\n",
    "Method 4: Risk-Based\n",
    "Buffer = Sum of (Risk Probability \u00d7 Risk Impact)\n",
    "For all identified risks\n",
    "\n",
    "Method 5: Historical Data\n",
    "Buffer = Average overrun from similar past projects\n",
    "Based on reference class forecasting\n",
    "```\n",
    "\n",
    "**Code Snippet: Buffer Calculator**\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Buffer Calculator\n",
    "Calculates various types of project buffers\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "from typing import List, Dict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TaskEstimate:\n",
    "    \"\"\"Task with three-point estimate.\"\"\"\n",
    "    name: str\n",
    "    optimistic: float\n",
    "    most_likely: float\n",
    "    pessimistic: float\n",
    "    \n",
    "    @property\n",
    "    def expected_duration(self) -> float:\n",
    "        \"\"\"Calculate PERT expected duration.\"\"\"\n",
    "        return (self.optimistic + 4 * self.most_likely + self.pessimistic) / 6\n",
    "    \n",
    "    @property\n",
    "    def variance(self) -> float:\n",
    "        \"\"\"Calculate variance.\"\"\"\n",
    "        return ((self.pessimistic - self.optimistic) / 6) ** 2\n",
    "    \n",
    "    @property\n",
    "    def standard_deviation(self) -> float:\n",
    "        \"\"\"Calculate standard deviation.\"\"\"\n",
    "        return math.sqrt(self.variance)\n",
    "\n",
    "\n",
    "class BufferCalculator:\n",
    "    \"\"\"Calculates various types of project buffers.\"\"\"\n",
    "    \n",
    "    def __init__(self, tasks: List[TaskEstimate]):\n",
    "        \"\"\"\n",
    "        Initialize with project tasks.\n",
    "        \n",
    "        Args:\n",
    "            tasks: List of TaskEstimate objects\n",
    "        \"\"\"\n",
    "        self.tasks = tasks\n",
    "    \n",
    "    def calculate_percentage_buffer(self, percentage: float = 0.20) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate simple percentage buffer.\n",
    "        \n",
    "        Args:\n",
    "            percentage: Buffer percentage (default 20%)\n",
    "        \n",
    "        Returns:\n",
    "            Buffer calculation details\n",
    "        \"\"\"\n",
    "        total_duration = sum(task.expected_duration for task in self.tasks)\n",
    "        buffer = total_duration * percentage\n",
    "        total_with_buffer = total_duration + buffer\n",
    "        \n",
    "        return {\n",
    "            \"method\": \"Percentage Buffer\",\n",
    "            \"total_duration\": total_duration,\n",
    "            \"buffer_percentage\": percentage,\n",
    "            \"buffer_duration\": buffer,\n",
    "            \"total_with_buffer\": total_with_buffer,\n",
    "            \"rationale\": f\"Simple {percentage*100}% buffer based on total duration\"\n",
    "        }\n",
    "    \n",
    "    def calculate_critical_chain_buffer(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate Critical Chain Project Management (CCPM) buffer.\n",
    "        Uses square root of sum of squares method.\n",
    "        \n",
    "        Returns:\n",
    "            Buffer calculation details\n",
    "        \"\"\"\n",
    "        # Calculate total variance\n",
    "        total_variance = sum(task.variance for task in self.tasks)\n",
    "        \n",
    "        # Buffer is square root of total variance\n",
    "        buffer = math.sqrt(total_variance)\n",
    "        \n",
    "        # Total duration (using 50% estimates, not aggressive)\n",
    "        total_duration = sum(task.expected_duration for task in self.tasks)\n",
    "        \n",
    "        # Critical chain uses 50% task estimates + buffer\n",
    "        # (vs traditional which uses 90% estimates)\n",
    "        critical_chain_duration = total_duration + buffer\n",
    "        \n",
    "        return {\n",
    "            \"method\": \"Critical Chain (CCPM)\",\n",
    "            \"task_estimates\": \"50% confidence (aggressive)\",\n",
    "            \"total_variance\": total_variance,\n",
    "            \"buffer_calculation\": \"\u221a(\u03a3 variances)\",\n",
    "            \"buffer_duration\": buffer,\n",
    "            \"buffer_percentage\": (buffer / total_duration) * 100,\n",
    "            \"critical_chain_duration\": critical_chain_duration,\n",
    "            \"rationale\": \"Statistical buffer based on aggregation of task uncertainties\"\n",
    "        }\n",
    "    \n",
    "    def calculate_risk_based_buffer(self, risks: List[Dict]) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate buffer based on identified risks.\n",
    "        \n",
    "        Args:\n",
    "            risks: List of risk dictionaries with probability and impact\n",
    "        \n",
    "        Returns:\n",
    "            Buffer calculation details\n",
    "        \"\"\"\n",
    "        total_risk_impact = 0\n",
    "        \n",
    "        for risk in risks:\n",
    "            probability = risk.get(\"probability\", 0)  # 0-1\n",
    "            impact = risk.get(\"impact\", 0)  # days\n",
    "            expected_impact = probability * impact\n",
    "            total_risk_impact += expected_impact\n",
    "        \n",
    "        # Total duration\n",
    "        total_duration = sum(task.expected_duration for task in self.tasks)\n",
    "        \n",
    "        total_with_buffer = total_duration + total_risk_impact\n",
    "        \n",
    "        return {\n",
    "            \"method\": \"Risk-Based Buffer\",\n",
    "            \"number_of_risks\": len(risks),\n",
    "            \"total_expected_impact\": total_risk_impact,\n",
    "            \"buffer_percentage\": (total_risk_impact / total_duration) * 100 if total_duration > 0 else 0,\n",
    "            \"total_with_buffer\": total_with_buffer,\n",
    "            \"rationale\": \"Buffer based on expected value of identified risks\",\n",
    "            \"risk_details\": risks\n",
    "        }\n",
    "    \n",
    "    def compare_methods(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Compare all buffer calculation methods.\n",
    "        \n",
    "        Returns:\n",
    "            Comparison of methods\n",
    "        \"\"\"\n",
    "        methods = []\n",
    "        \n",
    "        # Percentage method\n",
    "        methods.append(self.calculate_percentage_buffer(0.15))  # 15%\n",
    "        methods.append(self.calculate_percentage_buffer(0.20))  # 20%\n",
    "        methods.append(self.calculate_percentage_buffer(0.25))  # 25%\n",
    "        \n",
    "        # Critical chain\n",
    "        methods.append(self.calculate_critical_chain_buffer())\n",
    "        \n",
    "        # Risk-based (example risks)\n",
    "        example_risks = [\n",
    "            {\"name\": \"Integration Complexity\", \"probability\": 0.6, \"impact\": 10},\n",
    "            {\"name\": \"Resource Unavailability\", \"probability\": 0.3, \"impact\": 5},\n",
    "            {\"name\": \"Requirements Changes\", \"probability\": 0.7, \"impact\": 8},\n",
    "        ]\n",
    "        methods.append(self.calculate_risk_based_buffer(example_risks))\n",
    "        \n",
    "        return {\n",
    "            \"comparison_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "            \"base_duration\": sum(task.expected_duration for task in self.tasks),\n",
    "            \"methods\": methods\n",
    "        }\n",
    "    \n",
    "    def generate_report(self) -> str:\n",
    "        \"\"\"\n",
    "        Generate comprehensive buffer report.\n",
    "        \n",
    "        Returns:\n",
    "            Formatted report string\n",
    "        \"\"\"\n",
    "        lines = []\n",
    "        lines.append(\"Project Buffer Analysis\")\n",
    "        lines.append(\"=\" * 70)\n",
    "        lines.append(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "        lines.append(\"\")\n",
    "        \n",
    "        # Task Summary\n",
    "        lines.append(\"Task Estimates:\")\n",
    "        lines.append(\"-\" * 70)\n",
    "        total = 0\n",
    "        for task in self.tasks:\n",
    "            expected = task.expected_duration\n",
    "            total += expected\n",
    "            lines.append(\n",
    "                f\"{task.name:<30} \"\n",
    "                f\"O:{task.optimistic:>4.1f} \"\n",
    "                f\"M:{task.most_likely:>4.1f} \"\n",
    "                f\"P:{task.pessimistic:>4.1f} \"\n",
    "                f\"E:{expected:>5.1f}\"\n",
    "            )\n",
    "        lines.append(\"-\" * 70)\n",
    "        lines.append(f\"{'Total Expected Duration':<30} {total:>5.1f} days\")\n",
    "        lines.append(\"\")\n",
    "        \n",
    "        # Buffer Methods\n",
    "        comparison = self.compare_methods()\n",
    "        lines.append(\"Buffer Calculations:\")\n",
    "        lines.append(\"-\" * 70)\n",
    "        \n",
    "        for method in comparison[\"methods\"]:\n",
    "            lines.append(f\"\\n{method['method']}:\")\n",
    "            lines.append(f\"  Buffer: {method['buffer_duration']:.1f} days\")\n",
    "            lines.append(f\"  Buffer %: {method['buffer_percentage']:.1f}%\")\n",
    "            lines.append(f\"  Total: {method['total_with_buffer']:.1f} days\")\n",
    "            lines.append(f\"  Rationale: {method['rationale']}\")\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define project tasks\n",
    "    tasks = [\n",
    "        TaskEstimate(\"Requirements\", 5, 10, 20),\n",
    "        TaskEstimate(\"Design\", 3, 7, 15),\n",
    "        TaskEstimate(\"Development\", 30, 60, 120),\n",
    "        TaskEstimate(\"Testing\", 10, 20, 40),\n",
    "        TaskEstimate(\"Deployment\", 2, 5, 10),\n",
    "    ]\n",
    "    \n",
    "    # Create calculator\n",
    "    calculator = BufferCalculator(tasks)\n",
    "    \n",
    "    # Generate report\n",
    "    print(calculator.generate_report())\n",
    "    \n",
    "    # Run Monte Carlo simulation\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"Monte Carlo Simulation\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Create simulator\n",
    "    simulator = MonteCarloSimulator(\n",
    "        [Task(t.name, t.optimistic, t.most_likely, t.pessimistic) for t in tasks],\n",
    "        start_date=datetime(2025, 3, 15)\n",
    "    )\n",
    "    \n",
    "    # Run simulation\n",
    "    stats = simulator.run_simulation(iterations=10000)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Iterations: {stats['iterations']:,}\")\n",
    "    print(f\"Mean Duration: {stats['mean']:.1f} days\")\n",
    "    print(f\"Median Duration: {stats['median']:.1f} days\")\n",
    "    print(f\"Standard Deviation: {stats['std_dev']:.1f} days\")\n",
    "    print(\"\")\n",
    "    print(\"Confidence Levels:\")\n",
    "    print(f\"  50% confidence: {stats['percentile_50']:.0f} days by {(datetime(2025, 3, 15) + timedelta(days=stats['percentile_50'])).strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  80% confidence: {stats['percentile_80']:.0f} days by {(datetime(2025, 3, 15) + timedelta(days=stats['percentile_80'])).strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  90% confidence: {stats['percentile_90']:.0f} days by {(datetime(2025, 3, 15) + timedelta(days=stats['percentile_90'])).strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  95% confidence: {stats['percentile_95']:.0f} days by {(datetime(2025, 3, 15) + timedelta(days=stats['percentile_95'])).strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # Plot distribution\n",
    "    simulator.plot_distribution(stats)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "In this chapter, we've explored the challenging but essential practice of software estimation. Let's recap the key points:\n",
    "\n",
    "### **Key Takeaways:**\n",
    "\n",
    "1. **Why Estimation Fails**:\n",
    "   - The Planning Fallacy causes systematic underestimation\n",
    "   - Optimism bias, anchoring, and inside view distort estimates\n",
    "   - Unknown unknowns create unavoidable uncertainty\n",
    "   - Reference class forecasting helps overcome these biases\n",
    "\n",
    "2. **Estimation Techniques**:\n",
    "   - **T-Shirt Sizing**: Quick relative sizing (XS, S, M, L, XL)\n",
    "   - **Planning Poker**: Consensus-based estimation using story points\n",
    "   - **Three-Point Estimation**: Optimistic, most likely, pessimistic with PERT calculations\n",
    "   - **Monte Carlo Simulation**: Probabilistic forecasting using random sampling\n",
    "\n",
    "3. **Velocity, Throughput, and Cycle Time**:\n",
    "   - **Velocity**: Story points per sprint (Scrum)\n",
    "   - **Throughput**: Items completed per time period (Kanban)\n",
    "   - **Cycle Time**: Time from start to finish\n",
    "   - **Little's Law**: WIP = Throughput \u00d7 Cycle Time\n",
    "\n",
    "4. **Buffer Management**:\n",
    "   - **Percentage Buffer**: Simple percentage of total estimate\n",
    "   - **Critical Chain**: Square root of sum of squares of variances\n",
    "   - **Risk-Based**: Expected value of identified risks\n",
    "   - **Evidence-Based**: Historical data on overruns\n",
    "\n",
    "### **Industry Guidelines Referenced:**\n",
    "\n",
    "- **PMBOK**: Three-point estimation, PERT analysis\n",
    "- **Agile Practice Guide**: Velocity, story points, planning poker\n",
    "- **Kanban**: Throughput, cycle time, WIP limits\n",
    "- **Critical Chain Project Management**: Buffer management\n",
    "- **SAFe**: WSJF, probabilistic forecasting\n",
    "\n",
    "---\n",
    "\n",
    "## **Review Questions**\n",
    "\n",
    "1. **What is the Planning Fallacy, and how does it affect software estimates?** Provide three strategies to overcome it.\n",
    "\n",
    "2. **Compare T-Shirt Sizing, Planning Poker, and Three-Point Estimation.** When would you use each technique?\n",
    "\n",
    "3. **Your team has a velocity of 20 story points per sprint. You have 100 points remaining.** How many sprints will it take to complete? Why might this simple calculation be wrong?\n",
    "\n",
    "4. **What is the difference between cycle time and lead time?** How can you use Little's Law to improve flow?\n",
    "\n",
    "5. **Calculate the Critical Chain buffer for a project with the following task variances:** 4, 9, 16, 25, 36.\n",
    "\n",
    "6. **Why is Monte Carlo simulation more useful than single-point estimates for project forecasting?** What insights does it provide that simple averages don't?\n",
    "\n",
    "---\n",
    "\n",
    "## **Practical Exercise: Project Estimation**\n",
    "\n",
    "**Scenario**: You're planning a 6-month project to build a mobile banking app. The app needs to support account viewing, transfers, bill payments, and check deposits.\n",
    "\n",
    "**Your Task**:\n",
    "1. **Create a Work Breakdown Structure**:\n",
    "   - Break the project into 8-10 major tasks\n",
    "   - Provide three-point estimates for each task\n",
    "\n",
    "2. **Calculate Project Estimates**:\n",
    "   - Calculate expected duration using PERT\n",
    "   - Calculate standard deviation\n",
    "   - Determine 80% confidence interval\n",
    "\n",
    "3. **Run Monte Carlo Simulation**:\n",
    "   - Use the provided code to run 10,000 iterations\n",
    "   - Determine the 50th, 80th, and 90th percentile completion dates\n",
    "   - Create a recommendation for project commitment\n",
    "\n",
    "4. **Calculate Buffers**:\n",
    "   - Calculate 20% percentage buffer\n",
    "   - Calculate Critical Chain buffer\n",
    "   - Compare and recommend which to use\n",
    "\n",
    "**Deliverable**: Create an estimation report that includes your WBS, three-point estimates, PERT calculations, Monte Carlo results, and buffer recommendations. Include a recommendation for the project end date with appropriate confidence levels.\n",
    "\n",
    "---\n",
    "\n",
    "## **Further Reading and Resources**\n",
    "\n",
    "**Books:**\n",
    "- \"Software Estimation: Demystifying the Black Art\" by Steve McConnell\n",
    "- \"Agile Estimating and Planning\" by Mike Cohn\n",
    "- \"The Principles of Product Development Flow\" by Donald Reinertsen\n",
    "- \"Critical Chain\" by Eliyahu Goldratt\n",
    "\n",
    "**Standards and Frameworks:**\n",
    "- PMBOK Guide (Estimation techniques)\n",
    "- Agile Practice Guide (Velocity, story points)\n",
    "- SAFe (WSJF, Lean economics)\n",
    "- Kanban (Throughput, cycle time)\n",
    "\n",
    "**Online Resources:**\n",
    "- Mountain Goat Software (Mike Cohn's resources)\n",
    "- Focused Objective (Troy Magennis' forecasting tools)\n",
    "- Actionable Agile (Cycle time analytics)\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 4**\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter 5 Preview**\n",
    "\n",
    "In **Chapter 5: Technical Architecture Planning**, we'll explore how to make architectural decisions that support project success. You'll learn how to:\n",
    "\n",
    "- Create Architecture Decision Records (ADRs) to document technical choices\n",
    "- Identify and quantify technical debt before it becomes unmanageable\n",
    "- Plan for scalability using horizontal and vertical scaling strategies\n",
    "- Implement security by design using shift-left security practices\n",
    "- Balance architectural purity with delivery speed\n",
    "\n",
    "Architecture decisions made early in a project can have massive long-term implications. This chapter will give you the tools to make those decisions thoughtfully and document them clearly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='../1. Foundations/3. requirements_engineering.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='5. technical_architecture_planning.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}