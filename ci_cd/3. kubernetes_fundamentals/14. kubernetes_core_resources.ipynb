{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14: Kubernetes Core Resources\n",
    "\n",
    "Having established your development environment and mastered basic kubectl operations in Chapter 13, we now examine the fundamental building blocks of Kubernetes applications. This chapter explores the core API resources that transform container images from your registry (Chapter 11) into running, networked, and managed workloads orchestrated by the control plane (Chapter 12).\n",
    "\n",
    "These resources form the declarative vocabulary through which you communicate application requirements to Kubernetes. Understanding their nuances—from Pod lifecycle hooks to Deployment strategy nuances—separates operational Kubernetes proficiency from basic container running.\n",
    "\n",
    "## 14.1 Pods\n",
    "\n",
    "The Pod is the smallest deployable unit in Kubernetes. Unlike Docker containers which run individually, Kubernetes wraps containers into Pods, providing shared execution contexts including networking, storage, and metadata.\n",
    "\n",
    "### Pod Fundamentals\n",
    "\n",
    "A Pod represents a single instance of a running process in your cluster. It can contain one or more containers that share:\n",
    "- **Network namespace**: Single IP address, shared localhost interface\n",
    "- **Storage volumes**: Shared filesystem mounts\n",
    "- **IPC namespace**: Inter-process communication capabilities\n",
    "- **UTS namespace**: Shared hostname\n",
    "\n",
    "**Single vs. Multi-Container Pods:**\n",
    "While Pods can run multiple containers, adhere to the \"one main process per container\" philosophy. Use multi-container Pods only for tightly coupled auxiliary processes (sidecars, adapters, proxies) that must share the same lifecycle and filesystem.\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: single-container-pod\n",
    "  namespace: default\n",
    "  labels:\n",
    "    app: web\n",
    "    version: v1.0\n",
    "spec:\n",
    "  containers:\n",
    "  - name: nginx\n",
    "    image: nginx:1.25-alpine\n",
    "    ports:\n",
    "    - containerPort: 80\n",
    "      protocol: TCP\n",
    "    resources:\n",
    "      requests:\n",
    "        memory: \"64Mi\"\n",
    "        cpu: \"100m\"\n",
    "      limits:\n",
    "        memory: \"128Mi\"\n",
    "        cpu: \"200m\"\n",
    "```\n",
    "\n",
    "### 14.1.1 Pod Lifecycle\n",
    "\n",
    "Pods follow a defined lifecycle from creation through termination, progressing through distinct phases.\n",
    "\n",
    "**Pod Phases:**\n",
    "- **Pending**: Accepted by cluster, container images not yet pulled/started\n",
    "- **Running**: At least one container executing (or completed for restartPolicy: Never)\n",
    "- **Succeeded**: All containers terminated successfully (exit 0), not restarting\n",
    "- **Failed**: All containers terminated, at least one failed (non-zero exit)\n",
    "- **Unknown**: State cannot be determined (typically node communication lost)\n",
    "\n",
    "**Container States:**\n",
    "Within each Pod, individual containers maintain states:\n",
    "- **Waiting**: Image pulling, volume mounting, or waiting for dependencies\n",
    "- **Running**: Executing without issues\n",
    "- **Terminated**: Completed execution or failed, includes exit code and reason\n",
    "\n",
    "**Lifecycle Hooks:**\n",
    "Execute commands at specific lifecycle events:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "spec:\n",
    "  containers:\n",
    "  - name: lifecycle-demo\n",
    "    image: nginx:alpine\n",
    "    lifecycle:\n",
    "      postStart:\n",
    "        exec:\n",
    "          command: [\"/bin/sh\", \"-c\", \"echo 'Container started' >> /var/log/nginx/start.log\"]\n",
    "      preStop:\n",
    "        exec:\n",
    "          command: [\"/bin/sh\", \"-c\", \"nginx -s quit; sleep 10\"]  # Graceful shutdown\n",
    "```\n",
    "\n",
    "**Restart Policies:**\n",
    "Control behavior when containers fail:\n",
    "- **Always** (default): Restart regardless of exit code (suitable for long-running services)\n",
    "- **OnFailure**: Restart only on non-zero exit codes (suitable for batch jobs)\n",
    "- **Never**: Do not restart; Pod remains in Failed phase (suitable for one-time tasks)\n",
    "\n",
    "```yaml\n",
    "spec:\n",
    "  restartPolicy: OnFailure  # For batch workloads\n",
    "```\n",
    "\n",
    "### 14.1.2 Pod Specifications\n",
    "\n",
    "The PodSpec defines runtime behavior, resource allocation, and security contexts.\n",
    "\n",
    "**Security Contexts:**\n",
    "Run containers with specific security constraints:\n",
    "\n",
    "```yaml\n",
    "spec:\n",
    "  securityContext:\n",
    "    runAsNonRoot: true\n",
    "    runAsUser: 1000\n",
    "    runAsGroup: 3000\n",
    "    fsGroup: 2000\n",
    "    seccompProfile:\n",
    "      type: RuntimeDefault\n",
    "  containers:\n",
    "  - name: secure-app\n",
    "    image: myapp:latest\n",
    "    securityContext:\n",
    "      allowPrivilegeEscalation: false\n",
    "      readOnlyRootFilesystem: true\n",
    "      capabilities:\n",
    "        drop:\n",
    "        - ALL\n",
    "        add:\n",
    "        - NET_BIND_SERVICE  # Only if binding low ports required\n",
    "```\n",
    "\n",
    "**DNS Policy:**\n",
    "Control DNS resolution behavior:\n",
    "\n",
    "```yaml\n",
    "spec:\n",
    "  dnsPolicy: ClusterFirst  # Default: cluster DNS for cluster domains, upstream otherwise\n",
    "  # Alternative: ClusterFirstWithHostNet (for host networking)\n",
    "  # Alternative: Default (inherit from node)\n",
    "  dnsConfig:\n",
    "    nameservers:\n",
    "      - 8.8.8.8\n",
    "    searches:\n",
    "      - mycompany.local\n",
    "    options:\n",
    "      - name: ndots\n",
    "        value: \"2\"\n",
    "```\n",
    "\n",
    "**Scheduling Constraints:**\n",
    "Direct Pod placement:\n",
    "\n",
    "```yaml\n",
    "spec:\n",
    "  nodeSelector:\n",
    "    disktype: ssd\n",
    "  affinity:\n",
    "    nodeAffinity:\n",
    "      requiredDuringSchedulingIgnoredDuringExecution:\n",
    "        nodeSelectorTerms:\n",
    "        - matchExpressions:\n",
    "          - key: kubernetes.io/arch\n",
    "            operator: In\n",
    "            values: [\"amd64\"]\n",
    "    podAntiAffinity:\n",
    "      preferredDuringSchedulingIgnoredDuringExecution:\n",
    "      - weight: 100\n",
    "        podAffinityTerm:\n",
    "          labelSelector:\n",
    "            matchExpressions:\n",
    "            - key: app\n",
    "              operator: In\n",
    "              values: [\"web\"]\n",
    "          topologyKey: kubernetes.io/hostname\n",
    "  tolerations:\n",
    "  - key: \"dedicated\"\n",
    "    operator: \"Equal\"\n",
    "    value: \"web\"\n",
    "    effect: \"NoSchedule\"\n",
    "```\n",
    "\n",
    "### 14.1.3 Init Containers\n",
    "\n",
    "Init containers run before application containers start, completing initialization tasks such as database migrations, configuration generation, or permission fixes.\n",
    "\n",
    "**Characteristics:**\n",
    "- Run sequentially in defined order\n",
    "- Must complete successfully (exit 0) before main containers start\n",
    "- Have separate resource limits from application containers\n",
    "- Do not support lifecycle hooks, liveness/readiness probes, or restart policies\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: init-demo\n",
    "spec:\n",
    "  initContainers:\n",
    "  - name: init-migrate\n",
    "    image: myapp:latest\n",
    "    command: ['python', 'manage.py', 'migrate']\n",
    "    env:\n",
    "    - name: DATABASE_URL\n",
    "      valueFrom:\n",
    "        secretKeyRef:\n",
    "          name: db-credentials\n",
    "          key: url\n",
    "    volumeMounts:\n",
    "    - name: data\n",
    "      mountPath: /data\n",
    "  - name: init-permissions\n",
    "    image: busybox:1.36\n",
    "    command: ['sh', '-c', 'chmod 700 /data && chown 1000:1000 /data']\n",
    "    volumeMounts:\n",
    "    - name: data\n",
    "      mountPath: /data\n",
    "  containers:\n",
    "  - name: app\n",
    "    image: myapp:latest\n",
    "    ports:\n",
    "    - containerPort: 8080\n",
    "    volumeMounts:\n",
    "    - name: data\n",
    "      mountPath: /data\n",
    "  volumes:\n",
    "  - name: data\n",
    "    emptyDir: {}\n",
    "```\n",
    "\n",
    "**Sidecar Pattern:**\n",
    "While init containers handle initialization, sidecars (additional containers in the Pod) handle ongoing auxiliary functions:\n",
    "\n",
    "```yaml\n",
    "spec:\n",
    "  containers:\n",
    "  - name: main-app\n",
    "    image: myapp:latest\n",
    "  - name: nginx-sidecar\n",
    "    image: nginx:alpine\n",
    "    volumeMounts:\n",
    "    - name: shared-logs\n",
    "      mountPath: /var/log/nginx\n",
    "  - name: log-aggregator\n",
    "    image: fluentd:latest\n",
    "    volumeMounts:\n",
    "    - name: shared-logs\n",
    "      mountPath: /var/log/app\n",
    "  volumes:\n",
    "  - name: shared-logs\n",
    "    emptyDir: {}\n",
    "```\n",
    "\n",
    "### 14.1.4 Resource Requests and Limits\n",
    "\n",
    "Resource specifications ensure fair scheduling and prevent noisy neighbor problems.\n",
    "\n",
    "**Resource Types:**\n",
    "- **CPU**: Measured in millicores (m) or cores. `100m` = 0.1 CPU cores\n",
    "- **Memory**: Measured in bytes (Ki, Mi, Gi) or raw bytes\n",
    "- **Ephemeral Storage**: Container writable layer and emptyDir volumes (Kubernetes 1.21+)\n",
    "\n",
    "**Best Practices:**\n",
    "\n",
    "```yaml\n",
    "spec:\n",
    "  containers:\n",
    "  - name: web\n",
    "    image: nginx:alpine\n",
    "    resources:\n",
    "      requests:\n",
    "        memory: \"128Mi\"    # Guaranteed minimum; used for scheduling\n",
    "        cpu: \"100m\"        # 0.1 cores; used for scheduling\n",
    "        ephemeral-storage: \"1Gi\"\n",
    "      limits:\n",
    "        memory: \"256Mi\"    # Hard limit; OOMKill if exceeded\n",
    "        cpu: \"500m\"        # Throttled if exceeded, not killed\n",
    "        ephemeral-storage: \"2Gi\"\n",
    "```\n",
    "\n",
    "**Quality of Service (QoS) Classes:**\n",
    "Kubernetes assigns QoS classes based on resource specifications:\n",
    "- **Guaranteed**: Requests = Limits for all resources (highest priority, least likely evicted)\n",
    "- **Burstable**: Requests < Limits for at least one resource (default for specified resources)\n",
    "- **BestEffort**: No requests or limits specified (lowest priority, first evicted)\n",
    "\n",
    "**Vertical Pod Autoscaler (VPA) Recommendation:**\n",
    "For initial sizing, use VPA in recommendation mode:\n",
    "```yaml\n",
    "apiVersion: autoscaling.k8s.io/v1\n",
    "kind: VerticalPodAutoscaler\n",
    "metadata:\n",
    "  name: web-vpa\n",
    "spec:\n",
    "  targetRef:\n",
    "    apiVersion: apps/v1\n",
    "    kind: Deployment\n",
    "    name: web\n",
    "  updatePolicy:\n",
    "    updateMode: \"Off\"  # Recommend only, don't auto-update\n",
    "```\n",
    "\n",
    "## 14.2 Deployments\n",
    "\n",
    "Deployments provide declarative updates for Pods and ReplicaSets, managing the lifecycle of stateless applications. They handle rolling updates, rollback capabilities, and scaling operations.\n",
    "\n",
    "### 14.2.1 ReplicaSets\n",
    "\n",
    "A ReplicaSet ensures a specified number of Pod replicas run at any given time. While you rarely create ReplicaSets directly (Deployments manage them), understanding their function clarifies Deployment behavior.\n",
    "\n",
    "**ReplicaSet Function:**\n",
    "- Maintains stable set of replica Pods\n",
    "- Uses label selectors to identify managed Pods\n",
    "- Creates/deletes Pods to match desired replica count\n",
    "- Supports equality-based selectors (not set-based)\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: ReplicaSet\n",
    "metadata:\n",
    "  name: frontend\n",
    "  labels:\n",
    "    app: guestbook\n",
    "    tier: frontend\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      tier: frontend\n",
    "    matchExpressions:\n",
    "      - {key: tier, operator: In, values: [frontend]}\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        tier: frontend\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: php-redis\n",
    "        image: gcr.io/google_samples/gb-frontend:v3\n",
    "```\n",
    "\n",
    "**Warning:** Do not manage ReplicaSets directly. Use Deployments which manage ReplicaSets, providing update strategies and rollback capabilities.\n",
    "\n",
    "### 14.2.2 Rolling Updates\n",
    "\n",
    "Deployments manage application updates through configurable strategies that replace old Pods with new ones gradually.\n",
    "\n",
    "**RollingUpdate Strategy:**\n",
    "The default strategy replaces Pods incrementally to ensure zero downtime.\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: nginx-deployment\n",
    "  labels:\n",
    "    app: nginx\n",
    "spec:\n",
    "  replicas: 10\n",
    "  strategy:\n",
    "    type: RollingUpdate\n",
    "    rollingUpdate:\n",
    "      maxSurge: 25%        # Maximum pods above desired count during update (absolute number or %)\n",
    "      maxUnavailable: 25%  # Maximum pods unavailable during update\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: nginx\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: nginx\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: nginx\n",
    "        image: nginx:1.25\n",
    "        ports:\n",
    "        - containerPort: 80\n",
    "```\n",
    "\n",
    "**Update Mechanics:**\n",
    "1. Deployment creates new ReplicaSet with updated Pod template\n",
    "2. Scales up new ReplicaSet by `maxSurge` while scaling down old by `maxUnavailable`\n",
    "3. Continues until all replicas run new version\n",
    "4. Old ReplicaSet retained (replicas=0) for rollback capability\n",
    "\n",
    "**Monitoring Updates:**\n",
    "```bash\n",
    "# Watch rollout status\n",
    "kubectl rollout status deployment/nginx-deployment\n",
    "\n",
    "# View ReplicaSets (shows old and new)\n",
    "kubectl get rs -l app=nginx\n",
    "\n",
    "# View rollout history\n",
    "kubectl rollout history deployment/nginx-deployment\n",
    "```\n",
    "\n",
    "### 14.2.3 Rollbacks\n",
    "\n",
    "Deployments retain revision history, enabling reversion to previous stable states when updates fail.\n",
    "\n",
    "**Rollback Commands:**\n",
    "```bash\n",
    "# Check revision history\n",
    "kubectl rollout history deployment/nginx-deployment\n",
    "\n",
    "# Rollback to previous version\n",
    "kubectl rollout undo deployment/nginx-deployment\n",
    "\n",
    "# Rollback to specific revision\n",
    "kubectl rollout undo deployment/nginx-deployment --to-revision=2\n",
    "\n",
    "# Pause rollout for investigation\n",
    "kubectl rollout pause deployment/nginx-deployment\n",
    "\n",
    "# Resume rollout\n",
    "kubectl rollout resume deployment/nginx-deployment\n",
    "```\n",
    "\n",
    "**Revision History Limits:**\n",
    "Control history retention to manage etcd storage:\n",
    "\n",
    "```yaml\n",
    "spec:\n",
    "  revisionHistoryLimit: 10  # Default is 10; old ReplicaSets cleaned up beyond this\n",
    "```\n",
    "\n",
    "### 14.2.4 Deployment Strategies\n",
    "\n",
    "Beyond RollingUpdate, Kubernetes supports Recreate strategy and custom progressive delivery patterns.\n",
    "\n",
    "**Recreate Strategy:**\n",
    "Terminate all old Pods before creating new ones (causes downtime but avoids running two versions simultaneously).\n",
    "\n",
    "```yaml\n",
    "spec:\n",
    "  strategy:\n",
    "    type: Recreate  # Use when application cannot tolerate mixed versions\n",
    "```\n",
    "\n",
    "**Blue/Green Deployment (Manual):**\n",
    "Maintain two environments, switching service selectors:\n",
    "\n",
    "```yaml\n",
    "# Blue deployment (current)\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: app-blue\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: myapp\n",
    "      version: blue\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: myapp\n",
    "        version: blue\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: app\n",
    "        image: myapp:v1\n",
    "\n",
    "---\n",
    "# Service pointing to blue\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: myapp\n",
    "spec:\n",
    "  selector:\n",
    "    app: myapp\n",
    "    version: blue  # Switch to green when ready\n",
    "  ports:\n",
    "  - port: 80\n",
    "```\n",
    "\n",
    "**Canary Deployment (Advanced):**\n",
    "Use separate Deployments with traffic splitting (requires Service Mesh or Ingress controller):\n",
    "\n",
    "```yaml\n",
    "# Primary (90% traffic)\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: app-primary\n",
    "spec:\n",
    "  replicas: 9\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: myapp\n",
    "      track: stable\n",
    "---\n",
    "# Canary (10% traffic)\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: app-canary\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: myapp\n",
    "      track: canary\n",
    "```\n",
    "\n",
    "## 14.3 Services\n",
    "\n",
    "Services provide stable networking endpoints for Pods, abstracting away the ephemeral nature of individual containers. Since Pods are created and destroyed dynamically, their IP addresses change; Services provide a constant IP and DNS name that routes to healthy Pods.\n",
    "\n",
    "### Service Types Overview\n",
    "\n",
    "Kubernetes supports four primary Service types, each suited to different exposure requirements.\n",
    "\n",
    "### 14.3.1 ClusterIP\n",
    "\n",
    "ClusterIP is the default Service type, exposing the Service on an internal IP accessible only within the cluster. This is ideal for internal microservice communication.\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: backend-api\n",
    "  namespace: production\n",
    "spec:\n",
    "  type: ClusterIP\n",
    "  selector:\n",
    "    app: backend\n",
    "    tier: api\n",
    "  ports:\n",
    "  - protocol: TCP\n",
    "    port: 8080        # Service port exposed within cluster\n",
    "    targetPort: 8080  # Container port to forward to\n",
    "    name: http\n",
    "  - protocol: TCP\n",
    "    port: 8443\n",
    "    targetPort: 8443\n",
    "    name: https\n",
    "  sessionAffinity: None  # or ClientIP for sticky sessions\n",
    "```\n",
    "\n",
    "**DNS Resolution:**\n",
    "ClusterIP Services receive DNS entries automatically:\n",
    "- Short name: `backend-api` (same namespace)\n",
    "- FQDN: `backend-api.production.svc.cluster.local`\n",
    "\n",
    "**Headless Services (Preliminary):**\n",
    "When clusterIP: None, DNS returns Pod IPs directly (useful for StatefulSets):\n",
    "```yaml\n",
    "spec:\n",
    "  clusterIP: None  # Headless\n",
    "  selector:\n",
    "    app: db\n",
    "```\n",
    "\n",
    "### 14.3.2 NodePort\n",
    "\n",
    "NodePort exposes the Service on each Node's IP at a static port (30000-32767 by default), allowing external access without a cloud load balancer.\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: web-nodeport\n",
    "spec:\n",
    "  type: NodePort\n",
    "  selector:\n",
    "    app: web\n",
    "  ports:\n",
    "  - port: 80\n",
    "    targetPort: 8080\n",
    "    nodePort: 30080  # Optional: auto-allocated if unspecified\n",
    "    name: http\n",
    "```\n",
    "\n",
    "**Access Pattern:**\n",
    "`curl http://<Node-IP>:30080`\n",
    "\n",
    "**Considerations:**\n",
    "- Port range limited (30000-32767 by default; configurable via `--service-node-port-range`)\n",
    "- Exposes nodes directly; security groups must allow NodePort range\n",
    "- Traffic routes through kube-proxy (iptables/IPVS) adding slight latency\n",
    "- Not recommended for production external exposure; use LoadBalancer or Ingress instead\n",
    "\n",
    "### 14.3.3 LoadBalancer\n",
    "\n",
    "LoadBalancer exposes the Service externally using a cloud provider's load balancer (AWS ELB, Azure Load Balancer, GCP Forwarding Rule).\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: web-lb\n",
    "  annotations:\n",
    "    service.beta.kubernetes.io/aws-load-balancer-type: \"nlb\"  # Network LB\n",
    "    service.beta.kubernetes.io/aws-load-balancer-scheme: \"internet-facing\"\n",
    "spec:\n",
    "  type: LoadBalancer\n",
    "  selector:\n",
    "    app: web\n",
    "  ports:\n",
    "  - port: 80\n",
    "    targetPort: 8080\n",
    "  externalTrafficPolicy: Local  # Preserve client source IP; no kube-proxy hop\n",
    "  healthCheckNodePort: 30000     # Required when externalTrafficPolicy=Local\n",
    "```\n",
    "\n",
    "**External Traffic Policy:**\n",
    "- **Cluster** (default): Routes to any node, then kube-proxy forwards to Pod (may cross nodes, masks client IP)\n",
    "- **Local**: Routes only to nodes running Service endpoints (preserves client IP, no extra hop, but uneven distribution if node pods differ)\n",
    "\n",
    "**MetalLB (On-Premises):**\n",
    "For bare-metal clusters without cloud providers, MetalLB provides LoadBalancer functionality:\n",
    "```yaml\n",
    "apiVersion: metallb.io/v1beta1\n",
    "kind: IPAddressPool\n",
    "metadata:\n",
    "  name: production\n",
    "spec:\n",
    "  addresses:\n",
    "  - 192.168.1.240-192.168.1.250\n",
    "---\n",
    "apiVersion: metallb.io/v1beta1\n",
    "kind: L2Advertisement\n",
    "metadata:\n",
    "  name: production\n",
    "spec:\n",
    "  ipAddressPools:\n",
    "  - production\n",
    "```\n",
    "\n",
    "### 14.3.4 Headless Services\n",
    "\n",
    "Headless Services (clusterIP: None) do not allocate a virtual IP. Instead, they return the IPs of the backing Pods directly via DNS, useful for direct Pod-to-Pod communication and StatefulSets.\n",
    "\n",
    "**Use Cases:**\n",
    "- StatefulSets requiring stable network identity (database clusters)\n",
    "- Client-side load balancing when applications must discover individual Pods\n",
    "- Direct Pod communication without kube-proxy intermediation\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: db-headless\n",
    "spec:\n",
    "  clusterIP: None  # Headless\n",
    "  selector:\n",
    "    app: db\n",
    "  ports:\n",
    "  - port: 5432\n",
    "    name: postgres\n",
    "```\n",
    "\n",
    "**DNS Behavior:**\n",
    "Headless Services return A records for each Pod IP:\n",
    "```bash\n",
    "nslookup db-headless\n",
    "# Returns:\n",
    "# db-headless.default.svc.cluster.local.  IN A 10.244.1.5\n",
    "# db-headless.default.svc.cluster.local.  IN A 10.244.2.8\n",
    "```\n",
    "\n",
    "**StatefulSet Integration:**\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: StatefulSet\n",
    "metadata:\n",
    "  name: postgres\n",
    "spec:\n",
    "  serviceName: \"db-headless\"  # Governs network identity\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: db\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: db\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: postgres\n",
    "        image: postgres:15\n",
    "```\n",
    "\n",
    "**Pod Identity:**\n",
    "StatefulSets with Headless Services create predictable DNS names:\n",
    "- `postgres-0.db-headless.default.svc.cluster.local`\n",
    "- `postgres-1.db-headless.default.svc.cluster.local`\n",
    "- `postgres-2.db-headless.default.svc.cluster.local`\n",
    "\n",
    "## 14.4 ConfigMaps\n",
    "\n",
    "ConfigMaps decouple configuration artifacts from image content, allowing you to change application configuration without rebuilding containers. They store non-sensitive data such as config files, command-line arguments, or environment variables.\n",
    "\n",
    "**Creation Methods:**\n",
    "\n",
    "**From Literal Values:**\n",
    "```bash\n",
    "kubectl create configmap app-config \\\n",
    "  --from-literal=LOG_LEVEL=info \\\n",
    "  --from-literal=MAX_CONNECTIONS=100\n",
    "```\n",
    "\n",
    "**From Files:**\n",
    "```bash\n",
    "kubectl create configmap nginx-config \\\n",
    "  --from-file=nginx.conf=./configs/nginx.conf \\\n",
    "  --from-file=ssl.conf=./configs/ssl.conf\n",
    "```\n",
    "\n",
    "**From Directory:**\n",
    "```bash\n",
    "kubectl create configmap app-configs \\\n",
    "  --from-file=./configs/\n",
    "```\n",
    "\n",
    "**YAML Definition:**\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: app-config\n",
    "  namespace: production\n",
    "data:\n",
    "  # Key-value pairs\n",
    "  database.host: \"postgres.production.svc.cluster.local\"\n",
    "  database.port: \"5432\"\n",
    "  features.caching: \"enabled\"\n",
    "  \n",
    "  # File-like content\n",
    "  app.properties: |\n",
    "    log.level=INFO\n",
    "    log.format=json\n",
    "    max.threads=50\n",
    "    \n",
    "  # JSON configuration\n",
    "  settings.json: |\n",
    "    {\n",
    "      \"timeout\": 30,\n",
    "      \"retries\": 3,\n",
    "      \"backoff\": \"exponential\"\n",
    "    }\n",
    "```\n",
    "\n",
    "**Consumption in Pods:**\n",
    "\n",
    "**Environment Variables:**\n",
    "```yaml\n",
    "spec:\n",
    "  containers:\n",
    "  - name: app\n",
    "    image: myapp:latest\n",
    "    env:\n",
    "    # Single value\n",
    "    - name: DATABASE_HOST\n",
    "      valueFrom:\n",
    "        configMapKeyRef:\n",
    "          name: app-config\n",
    "          key: database.host\n",
    "    # All keys as env vars (prefix optional)\n",
    "    envFrom:\n",
    "    - configMapRef:\n",
    "        name: app-config\n",
    "        prefix: CONFIG_\n",
    "```\n",
    "\n",
    "**Volume Mounts:**\n",
    "```yaml\n",
    "spec:\n",
    "  containers:\n",
    "  - name: app\n",
    "    image: nginx:alpine\n",
    "    volumeMounts:\n",
    "    - name: config-vol\n",
    "      mountPath: /etc/nginx/conf.d\n",
    "      readOnly: true\n",
    "  volumes:\n",
    "  - name: config-vol\n",
    "    configMap:\n",
    "      name: nginx-config\n",
    "      items:  # Optional: select specific keys\n",
    "      - key: nginx.conf\n",
    "        path: default.conf\n",
    "      - key: ssl.conf\n",
    "        path: ssl.conf\n",
    "      defaultMode: 0444  # File permissions\n",
    "```\n",
    "\n",
    "**Immutable ConfigMaps:**\n",
    "Mark ConfigMaps as immutable to improve performance and prevent accidental changes:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: immutable-config\n",
    "immutable: true  # Cannot be updated without recreation\n",
    "data:\n",
    "  config.key: value\n",
    "```\n",
    "\n",
    "**Limitations:**\n",
    "- Maximum size: 1MiB (etcd limit)\n",
    "- No built-in versioning; changes propagate immediately to mounted volumes (kubelet syncs periodically)\n",
    "- Not suitable for sensitive data (use Secrets instead)\n",
    "\n",
    "## 14.5 Secrets\n",
    "\n",
    "Secrets store sensitive data such as passwords, OAuth tokens, SSH keys, and TLS certificates. While similar to ConfigMaps, Secrets are base64 encoded (not encrypted by default) and designed for confidential data.\n",
    "\n",
    "**Types of Secrets:**\n",
    "\n",
    "**Opaque (Generic):**\n",
    "Default type for arbitrary key-value data.\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: db-credentials\n",
    "type: Opaque\n",
    "stringData:  # stringData automatically base64 encodes; prefer over data\n",
    "  username: admin\n",
    "  password: P@ssw0rd123!\n",
    "  host: postgres.production.svc.cluster.local\n",
    "data:  # base64 encoded manually if using data field\n",
    "  legacy: YWRtaW4=  # echo -n 'admin' | base64\n",
    "```\n",
    "\n",
    "**TLS Certificates:**\n",
    "```bash\n",
    "kubectl create secret tls tls-cert \\\n",
    "  --cert=path/to/cert.crt \\\n",
    "  --key=path/to/key.key\n",
    "```\n",
    "\n",
    "**Docker Registry:**\n",
    "```bash\n",
    "kubectl create secret docker-registry regcred \\\n",
    "  --docker-server=registry.company.com \\\n",
    "  --docker-username=developer \\\n",
    "  --docker-password=token123 \\\n",
    "  --docker-email=dev@company.com\n",
    "```\n",
    "\n",
    "**Basic Authentication:**\n",
    "```bash\n",
    "kubectl create secret generic basic-auth \\\n",
    "  --from-literal=username=admin \\\n",
    "  --from-literal=password=secret\n",
    "```\n",
    "\n",
    "**Consumption:**\n",
    "\n",
    "**Environment Variables (Risky):**\n",
    "```yaml\n",
    "spec:\n",
    "  containers:\n",
    "  - name: app\n",
    "    image: myapp:latest\n",
    "    env:\n",
    "    - name: DB_PASSWORD\n",
    "      valueFrom:\n",
    "        secretKeyRef:\n",
    "          name: db-credentials\n",
    "          key: password\n",
    "          optional: false  # Pod fails to start if secret missing\n",
    "```\n",
    "\n",
    "**Volume Mounts (Preferred for Security):**\n",
    "Secrets mounted as volumes are stored in tmpfs (RAM), never touching node disk:\n",
    "\n",
    "```yaml\n",
    "spec:\n",
    "  containers:\n",
    "  - name: app\n",
    "    image: myapp:latest\n",
    "    volumeMounts:\n",
    "    - name: secret-vol\n",
    "      mountPath: /etc/secrets\n",
    "      readOnly: true\n",
    "  volumes:\n",
    "  - name: secret-vol\n",
    "    secret:\n",
    "      secretName: db-credentials\n",
    "      items:\n",
    "      - key: password\n",
    "        path: db-password.txt\n",
    "        mode: 0400  # Restrictive permissions\n",
    "```\n",
    "\n",
    "**Security Considerations:**\n",
    "\n",
    "1. **Encryption at Rest:**\n",
    "   Enable etcd encryption for Secrets (disabled by default):\n",
    "   ```yaml\n",
    "   apiVersion: apiserver.config.k8s.io/v1\n",
    "   kind: EncryptionConfiguration\n",
    "   resources:\n",
    "   - resources:\n",
    "     - secrets\n",
    "     providers:\n",
    "     - aescbc:\n",
    "         keys:\n",
    "         - name: key1\n",
    "           secret: <base64-encoded-32-byte-key>\n",
    "     - identity: {}  # Fallback for unencrypted resources\n",
    "   ```\n",
    "\n",
    "2. **RBAC Restriction:**\n",
    "   ```yaml\n",
    "   apiVersion: rbac.authorization.k8s.io/v1\n",
    "   kind: Role\n",
    "   metadata:\n",
    "     name: secret-reader\n",
    "   rules:\n",
    "   - apiGroups: [\"\"]\n",
    "     resources: [\"secrets\"]\n",
    "     verbs: [\"get\", \"list\"]\n",
    "     resourceNames: [\"specific-secret\"]  # Limit to specific secrets\n",
    "   ```\n",
    "\n",
    "3. **External Secret Operators:**\n",
    "   For production, use external secret management (HashiCorp Vault, AWS Secrets Manager) with operators like External Secrets Operator or Vault Agent Injector rather than storing sensitive data in etcd.\n",
    "\n",
    "## 14.6 Namespaces\n",
    "\n",
    "While introduced in Chapter 13, Namespaces warrant deeper examination as resource objects themselves, particularly regarding resource quotas and limits.\n",
    "\n",
    "**Resource Quotas:**\n",
    "Limit aggregate resource consumption per namespace:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: ResourceQuota\n",
    "metadata:\n",
    "  name: compute-quota\n",
    "  namespace: development\n",
    "spec:\n",
    "  hard:\n",
    "    requests.cpu: \"20\"\n",
    "    requests.memory: 40Gi\n",
    "    limits.cpu: \"40\"\n",
    "    limits.memory: 80Gi\n",
    "    pods: \"50\"\n",
    "    services: \"20\"\n",
    "    persistentvolumeclaims: \"10\"\n",
    "```\n",
    "\n",
    "**Limit Ranges:**\n",
    "Default and enforce container resource specifications:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: LimitRange\n",
    "metadata:\n",
    "  name: default-limits\n",
    "  namespace: development\n",
    "spec:\n",
    "  limits:\n",
    "  - default:\n",
    "      cpu: \"500m\"\n",
    "      memory: \"512Mi\"\n",
    "    defaultRequest:\n",
    "      cpu: \"100m\"\n",
    "      memory: \"128Mi\"\n",
    "    type: Container\n",
    "  - max:\n",
    "      cpu: \"2\"\n",
    "      memory: 2Gi\n",
    "    min:\n",
    "      cpu: \"50m\"\n",
    "      memory: \"64Mi\"\n",
    "    type: Container\n",
    "```\n",
    "\n",
    "**Network Policies:**\n",
    "Namespace-scoped firewall rules (requires CNI support):\n",
    "\n",
    "```yaml\n",
    "apiVersion: networking.k8s.io/v1\n",
    "kind: NetworkPolicy\n",
    "metadata:\n",
    "  name: api-allow\n",
    "  namespace: production\n",
    "spec:\n",
    "  podSelector:\n",
    "    matchLabels:\n",
    "      app: api\n",
    "  policyTypes:\n",
    "  - Ingress\n",
    "  - Egress\n",
    "  ingress:\n",
    "  - from:\n",
    "    - namespaceSelector:\n",
    "        matchLabels:\n",
    "          name: frontend\n",
    "    - podSelector:\n",
    "        matchLabels:\n",
    "          app: web\n",
    "    ports:\n",
    "    - protocol: TCP\n",
    "      port: 8080\n",
    "  egress:\n",
    "  - to:\n",
    "    - namespaceSelector:\n",
    "        matchLabels:\n",
    "          name: database\n",
    "    ports:\n",
    "    - protocol: TCP\n",
    "      port: 5432\n",
    "```\n",
    "\n",
    "## 14.7 Labels and Selectors\n",
    "\n",
    "Labels are key-value pairs attached to objects for identification and grouping. Selectors query these labels to filter resources, forming the loose coupling mechanism between Services and Pods, or Deployments and ReplicaSets.\n",
    "\n",
    "**Label Syntax:**\n",
    "- Keys: Optional prefix (DNS subdomain) + name, up to 63 characters\n",
    "- Values: Up to 63 characters, alphanumeric with `-`, `_`, `.`\n",
    "\n",
    "**Common Label Conventions:**\n",
    "```yaml\n",
    "metadata:\n",
    "  labels:\n",
    "    app.kubernetes.io/name: mysql\n",
    "    app.kubernetes.io/instance: wordpress-abcx\n",
    "    app.kubernetes.io/version: \"5.7.21\"\n",
    "    app.kubernetes.io/component: database\n",
    "    app.kubernetes.io/part-of: wordpress\n",
    "    app.kubernetes.io/managed-by: helm\n",
    "    environment: production\n",
    "    tier: backend\n",
    "```\n",
    "\n",
    "**Selector Types:**\n",
    "\n",
    "**Equality-Based:**\n",
    "```yaml\n",
    "selector:\n",
    "  matchLabels:\n",
    "    app: nginx\n",
    "    environment: production\n",
    "```\n",
    "\n",
    "**Set-Based (Supported in Deployments, Services use equality):**\n",
    "```yaml\n",
    "selector:\n",
    "  matchExpressions:\n",
    "  - key: tier\n",
    "    operator: In\n",
    "    values: [frontend, backend]\n",
    "  - key: environment\n",
    "    operator: NotIn\n",
    "    values: [development]\n",
    "  - key: version\n",
    "    operator: Exists  # Key exists, any value\n",
    "```\n",
    "\n",
    "**CLI Usage:**\n",
    "```bash\n",
    "# Select by label\n",
    "kubectl get pods -l app=nginx,environment=production\n",
    "\n",
    "# Set-based in CLI\n",
    "kubectl get pods -l 'environment notin (development,staging)'\n",
    "\n",
    "# Remove label\n",
    "kubectl label pods my-pod app-\n",
    "\n",
    "# Add/overwrite label\n",
    "kubectl label pods my-pod version=2.0 --overwrite\n",
    "```\n",
    "\n",
    "**Service Selector Matching:**\n",
    "Services route traffic to Pods with matching labels, regardless of how Pods were created:\n",
    "```yaml\n",
    "# Service selects Pods with these labels\n",
    "selector:\n",
    "  app: web\n",
    "  version: v2\n",
    "```\n",
    "\n",
    "## 14.8 Annotations\n",
    "\n",
    "Unlike labels used for querying and selection, annotations store non-identifying metadata for external tooling, automation, or administrative purposes.\n",
    "\n",
    "**Use Cases:**\n",
    "- Build/release tracking (git commit SHA, build ID)\n",
    "- Configuration for ingress controllers (rewrite targets, SSL redirects)\n",
    "- Audit timestamps and owner information\n",
    "- Phone/pager contact for on-call rotation\n",
    "- Image policy requirements\n",
    "\n",
    "**Syntax:**\n",
    "```yaml\n",
    "metadata:\n",
    "  annotations:\n",
    "    deployment.kubernetes.io/revision: \"3\"\n",
    "    kubectl.kubernetes.io/last-applied-configuration: |\n",
    "      {\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\"...}\n",
    "    prometheus.io/scrape: \"true\"\n",
    "    prometheus.io/port: \"8080\"\n",
    "    prometheus.io/path: \"/metrics\"\n",
    "    nginx.ingress.kubernetes.io/rewrite-target: /\n",
    "    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n",
    "    vault.hashicorp.com/agent-inject: \"true\"\n",
    "    vault.hashicorp.com/role: \"app\"\n",
    "    company.com/build-id: \"20231102.3\"\n",
    "    company.com/owner: \"platform-team@company.com\"\n",
    "```\n",
    "\n",
    "**Size Limit:**\n",
    "Annotations total 256KB per object (including system annotations).\n",
    "\n",
    "**Accessing Annotations:**\n",
    "```bash\n",
    "# View annotations\n",
    "kubectl get deployment myapp -o jsonpath='{.metadata.annotations}'\n",
    "\n",
    "# Add annotation\n",
    "kubectl annotate deployment myapp company.com/release-date=\"2023-11-02\"\n",
    "\n",
    "# Remove annotation\n",
    "kubectl annotate deployment myapp company.com/release-date-\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary and Preview\n",
    "\n",
    "In this chapter, we examined Kubernetes' fundamental resource types that transform container images into managed, networked applications. We explored Pods as the atomic deployment unit, detailing lifecycle phases, init containers for initialization sequences, and resource specifications ensuring cluster stability. Deployments emerged as the primary workload controller, managing ReplicaSets to maintain desired state while enabling sophisticated update strategies including rolling updates with configurable surge/unavailability parameters and instant rollback capabilities. Services provided stable networking abstractions across ClusterIP for internal communication, NodePort for direct node access, LoadBalancer for cloud integration, and Headless Services for direct Pod discovery. ConfigMaps and Secrets decoupled configuration from application code, with Secrets providing additional security considerations for sensitive data. Finally, Labels and Selectors established the loose coupling mechanism enabling Services to discover dynamic Pod sets, while Annotations stored metadata for tooling and automation.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Always use Deployments rather than managing Pods or ReplicaSets directly to gain self-healing, scaling, and update capabilities.\n",
    "- Specify resource requests and limits for every container to ensure predictable scheduling and prevent resource starvation.\n",
    "- Use ClusterIP Services for internal communication; expose via Ingress rather than NodePort for production external access.\n",
    "- Mount Secrets as volumes rather than environment variables to prevent exposure in process lists and core dumps.\n",
    "- Implement Immutable ConfigMaps when configuration rarely changes to improve performance and prevent drift.\n",
    "- Label resources consistently using the recommended kubernetes.io prefixes for tooling compatibility.\n",
    "\n",
    "**Next Chapter Preview:**\n",
    "Chapter 15: Kubernetes Networking explores the sophisticated networking layer enabling Pod-to-Pod communication across nodes, Service discovery mechanisms, Ingress controllers for HTTP/HTTPS routing, and NetworkPolicies for micro-segmentation. You will understand CNI plugins (Calico, Cilium, Flannel), DNS resolution within the cluster, TLS termination patterns, and how the flat network model implements the Kubernetes requirement that all Pods communicate without NAT, forming the communication fabric upon which your Deployments and Services operate."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
