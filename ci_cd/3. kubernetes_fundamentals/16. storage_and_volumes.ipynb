{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 16: Storage and Volumes\n",
    "\n",
    "While Kubernetes excels at orchestrating stateless applications, modern systems inevitably require durable storage for databases, message queues, content repositories, and session data. Chapter 15 established the communication fabric; this chapter addresses data persistence across the container lifecycle. We distinguish between ephemeral storage (tied to Pod lifetimes) and persistent storage (surviving Pod rescheduling), examining the abstractions Kubernetes provides to decouple storage consumption from storage implementation.\n",
    "\n",
    "Understanding PersistentVolumes, StorageClasses, and StatefulSets is essential for running production databases and stateful services in Kubernetes, moving beyond the stateless microservices patterns toward enterprise-grade data management.\n",
    "\n",
    "## 16.1 Volume Types\n",
    "\n",
    "Kubernetes supports multiple volume types, each suited to specific use cases ranging from temporary scratch space to high-performance persistent network storage.\n",
    "\n",
    "### Ephemeral vs. Persistent\n",
    "\n",
    "**Ephemeral Volumes:**\n",
    "- Lifecycle bound to Pod existence\n",
    "- Destroyed when Pod is deleted\n",
    "- Suitable for temporary data, caching, scratch space\n",
    "- Types: `emptyDir`, `configMap`, `secret`, `downwardAPI`\n",
    "\n",
    "**Persistent Volumes:**\n",
    "- Exist beyond Pod lifecycle\n",
    "- Survive node failures and Pod rescheduling\n",
    "- Require backend storage (cloud disks, NFS, SAN)\n",
    "- Types: Implemented via PersistentVolume abstraction\n",
    "\n",
    "### emptyDir\n",
    "\n",
    "The simplest volume type, created when a Pod is assigned to a node and exists as long as the Pod runs on that node.\n",
    "\n",
    "**Characteristics:**\n",
    "- Initially empty\n",
    "- Shared between containers in the same Pod\n",
    "- Stored on node disk (or RAM with `medium: Memory`)\n",
    "- Deleted when Pod leaves the node (not just restarted)\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: scratch-space\n",
    "spec:\n",
    "  containers:\n",
    "  - name: processor\n",
    "    image: busybox\n",
    "    command: ['sh', '-c', 'while true; do echo $(date) >> /scratch/log.txt; sleep 5; done']\n",
    "    volumeMounts:\n",
    "    - name: shared-data\n",
    "      mountPath: /scratch\n",
    "  - name: reader\n",
    "    image: busybox\n",
    "    command: ['sh', '-c', 'tail -f /scratch/log.txt']\n",
    "    volumeMounts:\n",
    "    - name: shared-data\n",
    "      mountPath: /scratch\n",
    "  volumes:\n",
    "  - name: shared-data\n",
    "    emptyDir:\n",
    "      medium: Memory  # Optional: tmpfs (RAM-backed), faster but counts against memory limit\n",
    "      sizeLimit: 500Mi  # Enforced eviction when exceeded\n",
    "```\n",
    "\n",
    "**Use Cases:**\n",
    "- Shared temporary workspace for multi-container Pods\n",
    "- Caching layers that rebuild on restart\n",
    "- Sorting/scratch space for data processing\n",
    "\n",
    "**Caution:** `emptyDir` with `medium: Memory` consumes node RAM and is included in container memory limits. Exceeding `sizeLimit` triggers Pod eviction.\n",
    "\n",
    "### hostPath\n",
    "\n",
    "Mounts a file or directory from the host node's filesystem into the Pod.\n",
    "\n",
    "**Security Warning:** hostPath exposes host filesystem, creating security risks and breaking Pod portability. Use only for:\n",
    "- Accessing Docker internals (socket, cgroup)\n",
    "- Node-level logging agents\n",
    "- Storage drivers requiring host access\n",
    "- Single-node development (Minikube)\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: node-logger\n",
    "spec:\n",
    "  containers:\n",
    "  - name: logger\n",
    "    image: fluentd\n",
    "    volumeMounts:\n",
    "    - name: host-logs\n",
    "      mountPath: /var/log/host\n",
    "      readOnly: true  # Always use readOnly when possible\n",
    "  volumes:\n",
    "  - name: host-logs\n",
    "    hostPath:\n",
    "      path: /var/log\n",
    "      type: Directory  # Must exist or Pod fails to start\n",
    "      # Alternatives: DirectoryOrCreate, File, FileOrCreate, Socket, CharDevice, BlockDevice\n",
    "```\n",
    "\n",
    "**Restrictions:**\n",
    "- Read-only recommended to prevent container escape\n",
    "- Path must exist on node (unless using `*OrCreate` types)\n",
    "- Not portable across nodes with different filesystem layouts\n",
    "\n",
    "### projected\n",
    "\n",
    "Projects multiple volume sources into a single directory, useful for combining ConfigMaps, Secrets, and downwardAPI:\n",
    "\n",
    "```yaml\n",
    "volumes:\n",
    "- name: projected-config\n",
    "  projected:\n",
    "    sources:\n",
    "    - secret:\n",
    "        name: db-credentials\n",
    "        items:\n",
    "        - key: username\n",
    "          path: db/user.txt\n",
    "    - configMap:\n",
    "        name: app-config\n",
    "        items:\n",
    "        - key: settings.json\n",
    "          path: config/settings.json\n",
    "    - downwardAPI:\n",
    "        items:\n",
    "        - path: labels.json\n",
    "          fieldRef:\n",
    "            fieldPath: metadata.labels\n",
    "    defaultMode: 0440\n",
    "```\n",
    "\n",
    "## 16.2 Persistent Volumes (PV)\n",
    "\n",
    "PersistentVolumes represent storage resources provisioned by administrators or dynamic provisioners. They exist as cluster-level resources independent of individual Pods, decoupling storage lifecycle from application lifecycle.\n",
    "\n",
    "### PV Lifecycle\n",
    "\n",
    "**Provisioning:**\n",
    "- **Static**: Administrator creates PVs in advance\n",
    "- **Dynamic**: StorageClass creates PVs on demand (preferred)\n",
    "\n",
    "**Binding:**\n",
    "- PVC requests bind to available PVs matching criteria\n",
    "- One-to-one relationship (PV to PVC)\n",
    "- Binding is exclusive; released PVs must be reclaimed\n",
    "\n",
    "**Using:**\n",
    "- PV mounted as volume in Pod\n",
    "- Specified via PVC reference in Pod spec\n",
    "\n",
    "**Reclaiming:**\n",
    "- **Retain**: Manual reclamation required (data preserved)\n",
    "- **Delete**: PV and underlying storage deleted (default for dynamic provisioning)\n",
    "- **Recycle**: Deprecated; basic scrub (rm -rf /thevolume/*)\n",
    "\n",
    "### PV Specification\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: PersistentVolume\n",
    "metadata:\n",
    "  name: pv-nfs-001\n",
    "  labels:\n",
    "    type: nfs\n",
    "    tier: production\n",
    "spec:\n",
    "  capacity:\n",
    "    storage: 100Gi\n",
    "  volumeMode: Filesystem  # or Block for raw block devices\n",
    "  accessModes:\n",
    "    - ReadWriteOnce      # RWO: Single node read-write\n",
    "    # - ReadOnlyMany     # ROX: Multiple nodes read-only\n",
    "    # - ReadWriteMany    # RWX: Multiple nodes read-write (requires NFS, CephFS, etc.)\n",
    "    # - ReadWriteOncePod # RWOP: Single Pod read-write (Kubernetes 1.22+)\n",
    "  persistentVolumeReclaimPolicy: Retain\n",
    "  storageClassName: nfs-slow\n",
    "  mountOptions:\n",
    "    - hard\n",
    "    - nfsvers=4.1\n",
    "  nfs:\n",
    "    server: nfs.company.internal\n",
    "    path: /exports/data-001\n",
    "```\n",
    "\n",
    "**Access Modes Explained:**\n",
    "\n",
    "| Mode | Abbreviation | Use Case | Supported By |\n",
    "|------|--------------|----------|--------------|\n",
    "| ReadWriteOnce | RWO | Single Pod read-write (most databases) | GCE PD, EBS, iSCSI, NFS |\n",
    "| ReadOnlyMany | ROX | Multiple Pods read-only (shared config) | NFS, CephFS, Azure File |\n",
    "| ReadWriteMany | RWX | Multiple Pods read-write (shared storage) | NFS, CephFS, GlusterFS, Azure File |\n",
    "| ReadWriteOncePod | RWOP | Single Pod exclusive access (newer, safer) | Most block storage |\n",
    "\n",
    "**Volume Modes:**\n",
    "- **Filesystem**: Mounts into directory (default)\n",
    "- **Block**: Raw block device for databases needing direct I/O (bypassing filesystem overhead)\n",
    "\n",
    "### NFS Example\n",
    "\n",
    "Network File System provides shared storage accessible from multiple nodes:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: PersistentVolume\n",
    "metadata:\n",
    "  name: pv-shared-assets\n",
    "spec:\n",
    "  capacity:\n",
    "    storage: 500Gi\n",
    "  accessModes:\n",
    "    - ReadWriteMany\n",
    "  nfs:\n",
    "    server: 10.0.0.50\n",
    "    path: /var/nfs/shared-assets\n",
    "  mountOptions:\n",
    "    - vers=4.1\n",
    "    - nconnect=16  # Multiple connections for better throughput\n",
    "    - noatime      # Disable access time updates for performance\n",
    "```\n",
    "\n",
    "### Cloud Provider Examples\n",
    "\n",
    "**AWS EBS (Block Storage):**\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: PersistentVolume\n",
    "metadata:\n",
    "  name: pv-aws-ebs\n",
    "spec:\n",
    "  capacity:\n",
    "    storage: 100Gi\n",
    "  accessModes:\n",
    "    - ReadWriteOnce\n",
    "  awsElasticBlockStore:\n",
    "    volumeID: vol-0a1234567890abcdef0\n",
    "    fsType: ext4\n",
    "    # Optional: IOPS and throughput for gp3/io1/io2\n",
    "```\n",
    "\n",
    "**GCP Persistent Disk:**\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: PersistentVolume\n",
    "metadata:\n",
    "  name: pv-gcp-pd\n",
    "spec:\n",
    "  gcePersistentDisk:\n",
    "    pdName: my-data-disk\n",
    "    fsType: ext4\n",
    "```\n",
    "\n",
    "**Azure Disk:**\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: PersistentVolume\n",
    "metadata:\n",
    "  name: pv-azure-disk\n",
    "spec:\n",
    "  azureDisk:\n",
    "    diskName: mydisk.vhd\n",
    "    diskURI: https://myaccount.blob.core.windows.net/vhds/mydisk.vhd\n",
    "    cachingMode: ReadOnly\n",
    "    fsType: ext4\n",
    "    readOnly: false\n",
    "```\n",
    "\n",
    "## 16.3 Persistent Volume Claims (PVC)\n",
    "\n",
    "PersistentVolumeClaims are user requests for storage. Developers consume storage through PVCs without knowing underlying infrastructure details, enabling portability across environments.\n",
    "\n",
    "### PVC Specification\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  name: postgres-data\n",
    "  namespace: database\n",
    "spec:\n",
    "  accessModes:\n",
    "    - ReadWriteOnce\n",
    "  volumeMode: Filesystem\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 50Gi\n",
    "  storageClassName: fast-ssd  # Optional: triggers dynamic provisioning\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      tier: production\n",
    "    matchExpressions:\n",
    "      - {key: type, operator: In, values: [ssd, nvme]}\n",
    "```\n",
    "\n",
    "**Key Fields:**\n",
    "- **accessModes**: Must match PV capabilities (subset of PV modes)\n",
    "- **storageClassName**: Links to StorageClass for dynamic provisioning; empty string for static binding\n",
    "- **resources.requests.storage**: Minimum capacity required\n",
    "- **selector**: Optional label matching for specific PVs\n",
    "\n",
    "### Binding Process\n",
    "\n",
    "1. User creates PVC requesting 50Gi, RWO, StorageClass \"fast-ssd\"\n",
    "2. Control plane searches for matching PVs or triggers StorageClass provisioner\n",
    "3. If static: Binds to available PV meeting criteria\n",
    "4. If dynamic: Creates new PV of requested size, then binds\n",
    "5. PVC status changes to \"Bound\"\n",
    "6. Pod references PVC by name in volume mounts\n",
    "\n",
    "### Using PVCs in Pods\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: postgres-0\n",
    "spec:\n",
    "  containers:\n",
    "  - name: postgres\n",
    "    image: postgres:15\n",
    "    volumeMounts:\n",
    "    - name: data\n",
    "      mountPath: /var/lib/postgresql/data\n",
    "      subPath: postgres  # Mounts specific subdirectory, prevents volume root clutter\n",
    "  volumes:\n",
    "  - name: data\n",
    "    persistentVolumeClaim:\n",
    "      claimName: postgres-data\n",
    "      readOnly: false\n",
    "```\n",
    "\n",
    "**subPath Usage:**\n",
    "- Mounts specific subdirectory rather than volume root\n",
    "- Prevents database files from mixing with lost+found or other system directories\n",
    "- Enables multiple databases to share one PV (not recommended for production)\n",
    "\n",
    "### Expanding PVCs\n",
    "\n",
    "Kubernetes supports online volume expansion for many storage classes:\n",
    "\n",
    "```yaml\n",
    "# Edit PVC to increase size\n",
    "kubectl patch pvc postgres-data -p '{\"spec\":{\"resources\":{\"requests\":{\"storage\":\"100Gi\"}}}}'\n",
    "\n",
    "# Verify expansion\n",
    "kubectl get pvc postgres-data -o jsonpath='{.status.capacity.storage}'\n",
    "```\n",
    "\n",
    "**Requirements:**\n",
    "- StorageClass must have `allowVolumeExpansion: true`\n",
    "- Cloud provider/CSI driver must support expansion\n",
    "- File system may require manual expansion inside Pod (xfs_growfs, resize2fs)\n",
    "\n",
    "## 16.4 Storage Classes\n",
    "\n",
    "StorageClasses provide abstraction over storage types, enabling dynamic provisioning without pre-created PVs. They define \"classes\" of storage (fast SSD, archival, replicated, etc.) with different performance and cost characteristics.\n",
    "\n",
    "### StorageClass Definition\n",
    "\n",
    "```yaml\n",
    "apiVersion: storage.k8s.io/v1\n",
    "kind: StorageClass\n",
    "metadata:\n",
    "  name: fast-ssd\n",
    "  annotations:\n",
    "    storageclass.kubernetes.io/is-default-class: \"true\"  # Used when PVC omits storageClassName\n",
    "provisioner: kubernetes.io/gce-pd  # CSI driver or in-tree provisioner\n",
    "parameters:\n",
    "  type: pd-ssd  # SSD persistent disk\n",
    "  replication-type: regional  # Replicated across zones\n",
    "  zones: us-central1-a,us-central1-b\n",
    "volumeBindingMode: WaitForFirstConsumer  # Delay provisioning until Pod scheduled\n",
    "allowVolumeExpansion: true\n",
    "mountOptions:\n",
    "  - debug\n",
    "  - noatime\n",
    "reclaimPolicy: Delete  # Delete underlying disk when PVC deleted\n",
    "```\n",
    "\n",
    "**Common Provisioners:**\n",
    "\n",
    "| Provisioner | Platform | Parameters |\n",
    "|-------------|----------|------------|\n",
    "| kubernetes.io/aws-ebs | AWS | type (gp2/gp3/io1/io2), iops, encrypted, kmsKeyId |\n",
    "| kubernetes.io/gce-pd | GCP | type (pd-standard/pd-ssd/pd-balanced), replication-type |\n",
    "| kubernetes.io/azure-disk | Azure | storageaccounttype (Standard_LRS/Premium_LRS), kind (Shared/Dedicated) |\n",
    "| kubernetes.io/cinder | OpenStack | availability, type |\n",
    "| csi.driver.name | Generic CSI | Driver-specific parameters |\n",
    "| nfs-client | NFS subdir | archiveOnDelete, pathPattern |\n",
    "\n",
    "### Volume Binding Modes\n",
    "\n",
    "**Immediate (Default):**\n",
    "- Provisions PV immediately when PVC created\n",
    "- May create volume in zone different from Pod requirements\n",
    "- Can cause scheduling failures if volume and Pod zones mismatch\n",
    "\n",
    "**WaitForFirstConsumer:**\n",
    "- Delays provisioning until Pod using PVC is created and scheduled\n",
    "- Ensures volume created in same zone as Pod\n",
    "- Recommended for multi-zone clusters\n",
    "\n",
    "```yaml\n",
    "volumeBindingMode: WaitForFirstConsumer\n",
    "```\n",
    "\n",
    "### Default StorageClass\n",
    "\n",
    "Mark one StorageClass as default for PVCs that don't specify one:\n",
    "\n",
    "```yaml\n",
    "metadata:\n",
    "  annotations:\n",
    "    storageclass.kubernetes.io/is-default-class: \"true\"\n",
    "```\n",
    "\n",
    "**Checking Default:**\n",
    "```bash\n",
    "kubectl get storageclass\n",
    "# NAME                 PROVISIONER           RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\n",
    "# fast-ssd (default)   kubernetes.io/gce-pd   Delete          WaitForFirstConsumer   true                  30d\n",
    "# standard             kubernetes.io/gce-pd   Delete          Immediate              false                 30d\n",
    "```\n",
    "\n",
    "## 16.5 Dynamic Provisioning\n",
    "\n",
    "Dynamic provisioning eliminates manual PV creation. When a PVC requests a StorageClass, the provisioner automatically creates the underlying storage asset and corresponding PV object.\n",
    "\n",
    "### Provisioning Flow\n",
    "\n",
    "1. User creates PVC referencing StorageClass \"fast-ssd\"\n",
    "2. Kubernetes API server recognizes StorageClass provisioner (e.g., GCE PD CSI driver)\n",
    "3. Provisioner creates cloud resource (GCP SSD disk)\n",
    "4. Provisioner creates PV object with volume details\n",
    "5. PVC binds to new PV\n",
    "6. Pod mounts PVC\n",
    "\n",
    "### CSI Drivers\n",
    "\n",
    "Container Storage Interface (CSI) is the modern standard for storage plugins, replacing in-tree provisioners.\n",
    "\n",
    "**Benefits:**\n",
    "- Out-of-tree development (no core Kubernetes releases needed)\n",
    "- Storage vendor maintains driver independently\n",
    "- Advanced features (snapshots, cloning, expansion) via standardized API\n",
    "\n",
    "**Common CSI Drivers:**\n",
    "- AWS EBS CSI driver\n",
    "- GCP Compute Persistent Disk CSI driver\n",
    "- Azure Disk/File CSI driver\n",
    "- NFS CSI driver\n",
    "- Ceph CSI (RBD and CephFS)\n",
    "- Portworx CSI\n",
    "- VMware vSphere CSI\n",
    "\n",
    "### Installation Example (AWS EBS CSI)\n",
    "\n",
    "```bash\n",
    "# Install CSI driver via Helm\n",
    "helm repo add aws-ebs-csi-driver https://kubernetes-sigs.github.io/aws-ebs-csi-driver\n",
    "helm install aws-ebs-csi-driver aws-ebs-csi-driver/aws-ebs-csi-driver \\\n",
    "  --namespace kube-system \\\n",
    "  --set enableVolumeSnapshot=true \\\n",
    "  --set controller.serviceAccount.annotations.\"eks\\.amazonaws\\.com/role-arn\"=arn:aws:iam::ACCOUNT:role/EBS-CSI-Driver-Role\n",
    "\n",
    "# Create StorageClass using CSI\n",
    "cat <<EOF | kubectl apply -f -\n",
    "apiVersion: storage.k8s.io/v1\n",
    "kind: StorageClass\n",
    "metadata:\n",
    "  name: ebs-sc\n",
    "provisioner: ebs.csi.aws.com\n",
    "volumeBindingMode: WaitForFirstConsumer\n",
    "parameters:\n",
    "  type: gp3\n",
    "  encrypted: \"true\"\n",
    "  kmsKeyId: alias/aws/ebs\n",
    "  iops: \"10000\"\n",
    "  throughput: \"500\"\n",
    "EOF\n",
    "```\n",
    "\n",
    "### Volume Snapshots (CSI)\n",
    "\n",
    "CSI enables point-in-time snapshots for backup and cloning:\n",
    "\n",
    "```yaml\n",
    "apiVersion: snapshot.storage.k8s.io/v1\n",
    "kind: VolumeSnapshotClass\n",
    "metadata:\n",
    "  name: csi-snapclass\n",
    "driver: ebs.csi.aws.com\n",
    "deletionPolicy: Retain  # Keep snapshot when VolumeSnapshot deleted\n",
    "parameters:\n",
    "  tags: \"key1=value1,key2=value2\"\n",
    "---\n",
    "apiVersion: snapshot.storage.k8s.io/v1\n",
    "kind: VolumeSnapshot\n",
    "metadata:\n",
    "  name: postgres-snapshot\n",
    "  namespace: database\n",
    "spec:\n",
    "  volumeSnapshotClassName: csi-snapclass\n",
    "  source:\n",
    "    persistentVolumeClaimName: postgres-data\n",
    "```\n",
    "\n",
    "## 16.6 StatefulSets\n",
    "\n",
    "StatefulSets manage deployment and scaling of stateful applications requiring:\n",
    "- Stable, unique network identifiers\n",
    "- Stable, persistent storage\n",
    "- Ordered, graceful deployment and scaling\n",
    "- Ordered, automated rolling updates\n",
    "\n",
    "### StatefulSet vs Deployment\n",
    "\n",
    "| Feature | Deployment | StatefulSet |\n",
    "|---------|------------|-------------|\n",
    "| Pod Naming | Random hash suffixes | Ordinal index (0, 1, 2...) |\n",
    "| Storage | Shared PVC (ReadWriteMany) or ephemeral | Unique PVC per Pod (volumeClaimTemplates) |\n",
    "| Ordering | Parallel creation/deletion | Sequential, ordered |\n",
    "| Network | Random IPs | Stable DNS: `<pod-name>.<service-name>` |\n",
    "| Scaling | Random deletion | Reverse ordinal termination |\n",
    "\n",
    "### StatefulSet Specification\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: StatefulSet\n",
    "metadata:\n",
    "  name: postgres\n",
    "  namespace: database\n",
    "spec:\n",
    "  serviceName: postgres-headless  # Headless service for stable network ID\n",
    "  replicas: 3\n",
    "  podManagementPolicy: OrderedReady  # Parallel alternative available\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: postgres\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: postgres\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: postgres\n",
    "        image: postgres:15\n",
    "        ports:\n",
    "        - containerPort: 5432\n",
    "          name: postgres\n",
    "        env:\n",
    "        - name: PGDATA\n",
    "          value: /var/lib/postgresql/data/pgdata\n",
    "        - name: POSTGRES_USER\n",
    "          valueFrom:\n",
    "            secretKeyRef:\n",
    "              name: postgres-auth\n",
    "              key: username\n",
    "        - name: POSTGRES_PASSWORD\n",
    "          valueFrom:\n",
    "            secretKeyRef:\n",
    "              name: postgres-auth\n",
    "              key: password\n",
    "        volumeMounts:\n",
    "        - name: data\n",
    "          mountPath: /var/lib/postgresql/data\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"2Gi\"\n",
    "            cpu: \"1000m\"\n",
    "          limits:\n",
    "            memory: \"4Gi\"\n",
    "            cpu: \"2000m\"\n",
    "  volumeClaimTemplates:  # Creates PVC per replica\n",
    "  - metadata:\n",
    "      name: data\n",
    "    spec:\n",
    "      accessModes: [\"ReadWriteOnce\"]\n",
    "      storageClassName: fast-ssd\n",
    "      resources:\n",
    "        requests:\n",
    "          storage: 100Gi\n",
    "```\n",
    "\n",
    "**Generated Resources:**\n",
    "- Pods: postgres-0, postgres-1, postgres-2\n",
    "- PVCs: data-postgres-0, data-postgres-1, data-postgres-2\n",
    "- DNS: postgres-0.postgres-headless.database.svc.cluster.local\n",
    "\n",
    "### Headless Service Requirement\n",
    "\n",
    "StatefulSets require a Headless Service for network identity:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: postgres-headless\n",
    "  namespace: database\n",
    "spec:\n",
    "  clusterIP: None  # Headless\n",
    "  selector:\n",
    "    app: postgres\n",
    "  ports:\n",
    "  - port: 5432\n",
    "    name: postgres\n",
    "```\n",
    "\n",
    "**Discovery:**\n",
    "Each Pod gets a stable DNS entry:\n",
    "- `postgres-0.postgres-headless.database.svc.cluster.local`\n",
    "- `postgres-1.postgres-headless.database.svc.cluster.local`\n",
    "\n",
    "### Scaling Behavior\n",
    "\n",
    "**Scaling Up:**\n",
    "1. postgres-3 created and must be Running/Ready before postgres-4 created\n",
    "2. PVC data-postgres-3 provisioned automatically\n",
    "3. Pod mounts new PVC (empty if new, or existing data if scaled down and back up)\n",
    "\n",
    "**Scaling Down:**\n",
    "1. postgres-2 terminated first (highest ordinal)\n",
    "2. PVC data-postgres-2 **not deleted** (data preserved)\n",
    "3. If scaled back up, postgres-2 reclaims same PVC with previous data\n",
    "\n",
    "**Manual Intervention:**\n",
    "To delete PVC after scale-down:\n",
    "```bash\n",
    "kubectl delete pvc data-postgres-2\n",
    "# Warning: Irreversible data loss\n",
    "```\n",
    "\n",
    "## 16.7 Database Persistence Strategies\n",
    "\n",
    "Running databases in Kubernetes requires careful consideration of storage performance, backup, and high availability.\n",
    "\n",
    "### Strategy 1: Single Pod with PV (Development)\n",
    "\n",
    "Simplest approach suitable for development or non-critical workloads:\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment  # Note: Deployment, not StatefulSet\n",
    "metadata:\n",
    "  name: postgres-dev\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: postgres-dev\n",
    "  template:\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: postgres\n",
    "        image: postgres:15\n",
    "        volumeMounts:\n",
    "        - name: data\n",
    "          mountPath: /var/lib/postgresql/data\n",
    "      volumes:\n",
    "      - name: data\n",
    "        persistentVolumeClaim:\n",
    "          claimName: postgres-dev-pvc\n",
    "```\n",
    "\n",
    "**Limitations:**\n",
    "- No high availability (downtime during node maintenance)\n",
    "- Potential data corruption if Pod crashes during write\n",
    "- Manual failover required\n",
    "\n",
    "### Strategy 2: StatefulSet with Replication (Production)\n",
    "\n",
    "For PostgreSQL, use StatefulSet with streaming replication or Patroni for HA:\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: StatefulSet\n",
    "metadata:\n",
    "  name: postgres-primary\n",
    "spec:\n",
    "  serviceName: postgres\n",
    "  replicas: 1  # Single writer; read replicas separate\n",
    "  template:\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: postgres\n",
    "        image: bitnami/postgresql-repmgr:15\n",
    "        env:\n",
    "        - name: POSTGRESQL_POSTGRES_PASSWORD\n",
    "          valueFrom:\n",
    "            secretKeyRef:\n",
    "              name: postgres\n",
    "              key: password\n",
    "        - name: POSTGRESQL_USERNAME\n",
    "          value: app_user\n",
    "        - name: POSTGRESQL_PASSWORD\n",
    "          valueFrom:\n",
    "            secretKeyRef:\n",
    "              name: postgres\n",
    "              key: user-password\n",
    "        - name: POSTGRESQL_DATABASE\n",
    "          value: app_db\n",
    "        - name: REPMGR_PRIMARY_HOST\n",
    "          value: postgres-0.postgres\n",
    "        - name: REPMGR_PRIMARY_PORT\n",
    "          value: \"5432\"\n",
    "        - name: REPMGR_PARTNER_NODES\n",
    "          value: \"postgres-0.postgres:5432,postgres-1.postgres:5432\"\n",
    "        volumeMounts:\n",
    "        - name: data\n",
    "          mountPath: /bitnami/postgresql\n",
    "  volumeClaimTemplates:\n",
    "  - metadata:\n",
    "      name: data\n",
    "    spec:\n",
    "      accessModes: [\"ReadWriteOnce\"]\n",
    "      storageClassName: fast-ssd\n",
    "      resources:\n",
    "        requests:\n",
    "          storage: 500Gi\n",
    "```\n",
    "\n",
    "### Strategy 3: Cloud Managed Databases\n",
    "\n",
    "For production, consider ExternalName Services pointing to managed databases:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: postgres-production\n",
    "  namespace: production\n",
    "spec:\n",
    "  type: ExternalName\n",
    "  externalName: prod-db.abc123.us-east-1.rds.amazonaws.com\n",
    "  ports:\n",
    "  - port: 5432\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- Automated backups and patching\n",
    "- Multi-AZ replication\n",
    "- Managed failover\n",
    "- Performance insights\n",
    "\n",
    "### Performance Optimization\n",
    "\n",
    "**Storage Configuration:**\n",
    "```yaml\n",
    "volumeClaimTemplates:\n",
    "- metadata:\n",
    "    name: data\n",
    "  spec:\n",
    "    storageClassName: io2-block-storage  # AWS io2 for critical databases\n",
    "    resources:\n",
    "      requests:\n",
    "        storage: 100Gi\n",
    "    volumeMode: Block  # Raw block for databases\n",
    "---\n",
    "# Mount as block device in Pod\n",
    "volumeMounts:\n",
    "- name: data\n",
    "  mountPath: /var/lib/mysql\n",
    "volumes:\n",
    "- name: data\n",
    "  persistentVolumeClaim:\n",
    "    claimName: data-mysql-0\n",
    "```\n",
    "\n",
    "**Database-Specific Settings:**\n",
    "- PostgreSQL: Use `volumeMode: Filesystem` with `fsync` optimizations\n",
    "- MySQL: Consider `volumeMode: Block` for InnoDB\n",
    "- MongoDB: WiredTiger cache size tuning relative to memory limits\n",
    "\n",
    "## 16.8 Backup and Restore\n",
    "\n",
    "Data protection strategies for persistent volumes range from CSI snapshots to application-consistent backups.\n",
    "\n",
    "### Method 1: CSI Snapshots\n",
    "\n",
    "Leverage storage-level snapshots for point-in-time recovery:\n",
    "\n",
    "```yaml\n",
    "apiVersion: snapshot.storage.k8s.io/v1\n",
    "kind: VolumeSnapshot\n",
    "metadata:\n",
    "  name: postgres-backup-$(date +%s)\n",
    "  namespace: database\n",
    "spec:\n",
    "  volumeSnapshotClassName: csi-snapclass\n",
    "  source:\n",
    "    persistentVolumeClaimName: postgres-data\n",
    "---\n",
    "# Restore from snapshot\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  name: postgres-data-restored\n",
    "spec:\n",
    "  dataSource:\n",
    "    name: postgres-backup-1234567890\n",
    "    kind: VolumeSnapshot\n",
    "    apiGroup: snapshot.storage.k8s.io\n",
    "  accessModes:\n",
    "    - ReadWriteOnce\n",
    "  storageClassName: fast-ssd\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 100Gi\n",
    "```\n",
    "\n",
    "**Limitations:**\n",
    "- Crash-consistent (not application-consistent)\n",
    "- Database may be mid-transaction\n",
    "- Suitable for file systems, risky for active databases without coordination\n",
    "\n",
    "### Method 2: Application-Level Backups\n",
    "\n",
    "Use database-native tools for consistent backups:\n",
    "\n",
    "**PostgreSQL with pg_dump:**\n",
    "```yaml\n",
    "apiVersion: batch/v1\n",
    "kind: CronJob\n",
    "metadata:\n",
    "  name: postgres-backup\n",
    "spec:\n",
    "  schedule: \"0 2 * * *\"  # Daily at 2 AM\n",
    "  concurrencyPolicy: Forbid\n",
    "  jobTemplate:\n",
    "    spec:\n",
    "      template:\n",
    "        spec:\n",
    "          containers:\n",
    "          - name: backup\n",
    "            image: postgres:15\n",
    "            command:\n",
    "            - /bin/sh\n",
    "            - -c\n",
    "            - |\n",
    "              pg_dump -h postgres -U admin app_db | \\\n",
    "              gzip > /backups/postgres-$(date +%Y%m%d-%H%M%S).sql.gz\n",
    "            env:\n",
    "            - name: PGPASSWORD\n",
    "              valueFrom:\n",
    "                secretKeyRef:\n",
    "                  name: postgres-auth\n",
    "                  key: password\n",
    "            volumeMounts:\n",
    "            - name: backups\n",
    "              mountPath: /backups\n",
    "          volumes:\n",
    "          - name: backups\n",
    "            persistentVolumeClaim:\n",
    "              claimName: backup-storage\n",
    "          restartPolicy: OnFailure\n",
    "```\n",
    "\n",
    "**Velero (Cluster Backup):**\n",
    "Velero backs up Kubernetes resources and persistent volumes to cloud storage:\n",
    "\n",
    "```bash\n",
    "# Install Velero\n",
    "velero install \\\n",
    "  --provider aws \\\n",
    "  --bucket my-backups \\\n",
    "  --secret-file ./credentials \\\n",
    "  --backup-location-config region=us-east-1 \\\n",
    "  --snapshot-location-config region=us-east-1 \\\n",
    "  --plugins velero/velero-plugin-for-aws:v1.7.0\n",
    "\n",
    "# Create backup\n",
    "velero backup create database-backup \\\n",
    "  --include-namespaces database \\\n",
    "  --include-resources persistentvolumeclaims,persistentvolumes,statefulsets,pods \\\n",
    "  --ttl 720h0m0s\n",
    "\n",
    "# Restore\n",
    "velero restore create --from-backup database-backup\n",
    "```\n",
    "\n",
    "### Backup Verification\n",
    "\n",
    "Regularly test restore procedures:\n",
    "\n",
    "```bash\n",
    "# Restore to staging namespace\n",
    "velero restore create --from-backup database-backup \\\n",
    "  --namespace-mappings database:database-restore-test\n",
    "\n",
    "# Verify data integrity\n",
    "kubectl exec -it -n database-restore-test postgres-0 -- psql -c \"SELECT count(*) FROM critical_table;\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary and Preview\n",
    "\n",
    "In this chapter, we explored Kubernetes storage abstractions essential for stateful workloads. We distinguished ephemeral volumes (emptyDir, hostPath) suitable for temporary data from PersistentVolumes providing durable storage beyond Pod lifetimes. PersistentVolumeClaims enable developers to consume storage without infrastructure knowledge, while StorageClasses automate dynamic provisioning across cloud providers and on-premises storage. We examined StatefulSets as the primary workload controller for stateful applications, providing stable network identities and unique persistent storage per replica. Database persistence strategies ranged from simple single-Pod deployments for development to replicated StatefulSets with cloud-managed database integration for production. Finally, we established backup methodologies including CSI snapshots for crash-consistent recovery and application-level backups (pg_dump, Velero) for transaction-consistent data protection.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Always use PersistentVolumeClaims rather than directly referencing PersistentVolumes to maintain workload portability.\n",
    "- Choose StorageClasses with `volumeBindingMode: WaitForFirstConsumer` for multi-zone clusters to ensure volume and Pod zone alignment.\n",
    "- Use StatefulSets with volumeClaimTemplates for databases requiring stable storage identity; Deployments with PVCs suffice for single-instance caches.\n",
    "- Never delete StatefulSet PVCs when scaling down unless explicitly intending data destruction.\n",
    "- Implement application-consistent backups using native database tools or Velero rather than relying solely on CSI snapshots for critical data.\n",
    "\n",
    "**Next Chapter Preview:**\n",
    "Chapter 17: Advanced Kubernetes Concepts extends beyond basic workloads to explore DaemonSets for node-level services, Jobs and CronJobs for batch processing, Horizontal Pod Autoscaler (HPA) for dynamic scaling based on metrics, Vertical Pod Autoscaler (VPA) for right-sizing resources, Pod Disruption Budgets for graceful maintenance, and Resource Quotas for multi-tenant governance. These resources complete your operational toolkit for production Kubernetes management, enabling efficient resource utilization, automated scaling, and resilient batch processing alongside the stateful services established in this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='15. kubernetes_networking.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='17. advanced_kubernetes_concepts.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}