{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 22: Testing in CI\n",
    "\n",
    "While Chapter 21 established how container images are constructed, testing in CI validates that those images contain functional, secure, and performant code. Testing in automated pipelines differs fundamentally from local development: tests must execute reproducibly in ephemeral environments, complete within strict time constraints, and provide actionable feedback without human intervention.\n",
    "\n",
    "This chapter examines the testing pyramid as implemented in CI/CD—from isolated unit tests through integration tests with real dependencies to end-to-end validation of complete systems. We explore strategies for maintaining test reliability, managing test data, and generating coverage reports that gate deployment quality, ensuring that only verified artifacts progress toward production.\n",
    "\n",
    "## 22.1 Unit Testing\n",
    "\n",
    "Unit tests validate individual components in isolation, forming the foundation of the testing pyramid. In CI, unit tests must execute rapidly (typically under 10 minutes for the entire suite) and without external dependencies to provide immediate feedback on code changes.\n",
    "\n",
    "### Containerized Unit Testing\n",
    "\n",
    "Execute unit tests within the same container environment used for production builds to ensure consistency:\n",
    "\n",
    "```dockerfile\n",
    "# Dockerfile.test - Multi-stage for testing\n",
    "FROM node:20-alpine AS test\n",
    "WORKDIR /app\n",
    "\n",
    "# Install dependencies (including devDependencies)\n",
    "COPY package*.json ./\n",
    "RUN npm ci\n",
    "\n",
    "# Copy source\n",
    "COPY . .\n",
    "\n",
    "# Default command runs unit tests\n",
    "CMD [\"npm\", \"run\", \"test:unit\"]\n",
    "```\n",
    "\n",
    "**CI Integration:**\n",
    "```yaml\n",
    "# GitHub Actions - Unit test stage\n",
    "jobs:\n",
    "  unit-tests:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "      \n",
    "      - name: Build test image\n",
    "        run: docker build -f Dockerfile.test -t myapp:test .\n",
    "      \n",
    "      - name: Run unit tests\n",
    "        run: docker run --rm myapp:test\n",
    "        \n",
    "      - name: Copy coverage from container (if needed)\n",
    "        run: |\n",
    "          docker create --name test-container myapp:test\n",
    "          docker cp test-container:/app/coverage ./coverage\n",
    "          docker rm test-container\n",
    "          \n",
    "      - name: Upload coverage\n",
    "        uses: codecov/codecov-action@v3\n",
    "        with:\n",
    "          files: ./coverage/lcov.info\n",
    "```\n",
    "\n",
    "### Test Isolation and Determinism\n",
    "\n",
    "CI environments must ensure tests produce identical results across runs:\n",
    "\n",
    "**Environment Variable Control:**\n",
    "```yaml\n",
    "# Freeze random seeds, timezones, and locales\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "    env:\n",
    "      TZ: UTC\n",
    "      LANG: C.UTF-8\n",
    "      NODE_ENV: test\n",
    "      CI: true\n",
    "      RANDOM_SEED: 12345  # For deterministic randomness in tests\n",
    "```\n",
    "\n",
    "**Database Isolation (Unit Tests with In-Memory DBs):**\n",
    "```javascript\n",
    "// Jest configuration for isolated tests\n",
    "module.exports = {\n",
    "  testEnvironment: 'node',\n",
    "  setupFilesAfterEnv: ['<rootDir>/jest.setup.js'],\n",
    "  coverageThreshold: {\n",
    "    global: {\n",
    "      branches: 80,\n",
    "      functions: 80,\n",
    "      lines: 80,\n",
    "      statements: 80\n",
    "    }\n",
    "  },\n",
    "  // Parallel execution\n",
    "  maxWorkers: '50%',\n",
    "  // Retry flaky tests once in CI\n",
    "  retry: process.env.CI ? 1 : 0\n",
    "};\n",
    "```\n",
    "\n",
    "### Coverage Reporting\n",
    "\n",
    "Enforce coverage thresholds to prevent quality regression:\n",
    "\n",
    "```yaml\n",
    "# GitLab CI with coverage visualization\n",
    "unit_tests:\n",
    "  stage: test\n",
    "  image: node:20-alpine\n",
    "  coverage: '/All files[^|]*\\|[^|]*\\s+([\\d\\.]+)/'\n",
    "  script:\n",
    "    - npm ci\n",
    "    - npm run test:unit -- --coverage --coverageReporters=text-summary\n",
    "  artifacts:\n",
    "    reports:\n",
    "      coverage_report:\n",
    "        coverage_format: cobertura\n",
    "        path: coverage/cobertura-coverage.xml\n",
    "      junit: junit.xml\n",
    "    paths:\n",
    "      - coverage/\n",
    "  only:\n",
    "    - merge_requests\n",
    "    - main\n",
    "```\n",
    "\n",
    "**Coverage Gates:**\n",
    "```yaml\n",
    "# Fail pipeline if coverage drops\n",
    "- name: Check coverage threshold\n",
    "  run: |\n",
    "    COVERAGE=$(cat coverage/coverage-summary.json | jq '.total.lines.pct')\n",
    "    if (( $(echo \"$COVERAGE < 80\" | bc -l) )); then\n",
    "      echo \"Coverage $COVERAGE% is below threshold of 80%\"\n",
    "      exit 1\n",
    "    fi\n",
    "```\n",
    "\n",
    "## 22.2 Integration Testing\n",
    "\n",
    "Integration tests verify component interactions with real dependencies (databases, message queues, external APIs). Unlike unit tests, they require infrastructure orchestration within CI pipelines.\n",
    "\n",
    "### Service Containers\n",
    "\n",
    "CI platforms provide \"service containers\"—sidecar containers that run alongside the test job:\n",
    "\n",
    "```yaml\n",
    "# GitHub Actions with service containers\n",
    "jobs:\n",
    "  integration-tests:\n",
    "    runs-on: ubuntu-latest\n",
    "    \n",
    "    services:\n",
    "      postgres:\n",
    "        image: postgres:15-alpine\n",
    "        env:\n",
    "          POSTGRES_PASSWORD: postgres\n",
    "          POSTGRES_DB: testdb\n",
    "        options: >-\n",
    "          --health-cmd pg_isready\n",
    "          --health-interval 10s\n",
    "          --health-timeout 5s\n",
    "          --health-retries 5\n",
    "        ports:\n",
    "          - 5432:5432\n",
    "          \n",
    "      redis:\n",
    "        image: redis:7-alpine\n",
    "        options: >-\n",
    "          --health-cmd \"redis-cli ping\"\n",
    "          --health-interval 10s\n",
    "          --health-timeout 5s\n",
    "          --health-retries 5\n",
    "        ports:\n",
    "          - 6379:6379\n",
    "\n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "      \n",
    "      - name: Run integration tests\n",
    "        env:\n",
    "          DATABASE_URL: postgres://postgres:postgres@localhost:5432/testdb\n",
    "          REDIS_URL: redis://localhost:6379\n",
    "        run: |\n",
    "          npm ci\n",
    "          npm run test:integration\n",
    "```\n",
    "\n",
    "**GitLab CI Services:**\n",
    "```yaml\n",
    "integration_tests:\n",
    "  stage: test\n",
    "  image: node:20\n",
    "  services:\n",
    "    - name: postgres:15-alpine\n",
    "      alias: postgres\n",
    "    - name: redis:7-alpine\n",
    "      alias: redis\n",
    "  variables:\n",
    "    POSTGRES_DB: testdb\n",
    "    POSTGRES_USER: postgres\n",
    "    POSTGRES_PASSWORD: postgres\n",
    "    DATABASE_URL: postgres://postgres:postgres@postgres/testdb\n",
    "  script:\n",
    "    - npm run test:integration\n",
    "```\n",
    "\n",
    "### Testcontainers\n",
    "\n",
    "Testcontainers provides programmatic container management for integration tests, ensuring consistent test environments across local development and CI:\n",
    "\n",
    "```java\n",
    "// Java/JUnit 5 example with Testcontainers\n",
    "@SpringBootTest\n",
    "@Testcontainers\n",
    "public class DatabaseIntegrationTest {\n",
    "    \n",
    "    @Container\n",
    "    static PostgreSQLContainer<?> postgres = new PostgreSQLContainer<>(\"postgres:15-alpine\")\n",
    "        .withDatabaseName(\"testdb\")\n",
    "        .withUsername(\"test\")\n",
    "        .withPassword(\"test\");\n",
    "    \n",
    "    @DynamicPropertySource\n",
    "    static void configureProperties(DynamicPropertyRegistry registry) {\n",
    "        registry.add(\"spring.datasource.url\", postgres::getJdbcUrl);\n",
    "        registry.add(\"spring.datasource.username\", postgres::getUsername);\n",
    "        registry.add(\"spring.datasource.password\", postgres::getPassword);\n",
    "    }\n",
    "    \n",
    "    @Test\n",
    "    void shouldSaveAndRetrieveUser() {\n",
    "        // Test uses real PostgreSQL instance\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Node.js with Testcontainers:**\n",
    "```javascript\n",
    "// JavaScript example\n",
    "const { PostgreSqlContainer } = require(\"@testcontainers/postgresql\");\n",
    "const { Client } = require(\"pg\");\n",
    "\n",
    "describe(\"Database Integration\", () => {\n",
    "  let container;\n",
    "  let client;\n",
    "\n",
    "  beforeAll(async () => {\n",
    "    container = await new PostgreSqlContainer(\"postgres:15-alpine\")\n",
    "      .withDatabase(\"testdb\")\n",
    "      .withUsername(\"test\")\n",
    "      .withPassword(\"test\")\n",
    "      .start();\n",
    "    \n",
    "    client = new Client({\n",
    "      connectionString: container.getConnectionUri(),\n",
    "    });\n",
    "    await client.connect();\n",
    "  });\n",
    "\n",
    "  afterAll(async () => {\n",
    "    await client.end();\n",
    "    await container.stop();\n",
    "  });\n",
    "\n",
    "  test(\"should insert and query data\", async () => {\n",
    "    await client.query(\"CREATE TABLE users (id SERIAL, name VARCHAR(255))\");\n",
    "    await client.query(\"INSERT INTO users (name) VALUES ('John')\");\n",
    "    const result = await client.query(\"SELECT * FROM users\");\n",
    "    expect(result.rows).toHaveLength(1);\n",
    "  });\n",
    "});\n",
    "```\n",
    "\n",
    "**CI Considerations for Testcontainers:**\n",
    "- Requires Docker socket access (privileged mode or Docker-in-Docker)\n",
    "- Cleanup is automatic (containers stopped after test suite)\n",
    "- Supports Ryuk resource reaper for cleanup after crashes\n",
    "\n",
    "### Database Migration Testing\n",
    "\n",
    "Validate schema changes don't break existing data:\n",
    "\n",
    "```yaml\n",
    "# Test migration path from previous version\n",
    "migration_test:\n",
    "  stage: test\n",
    "  image: node:20\n",
    "  services:\n",
    "    - postgres:15-alpine\n",
    "  script:\n",
    "    # 1. Setup database at previous version\n",
    "    - git checkout HEAD~1\n",
    "    - npm ci\n",
    "    - npm run db:migrate\n",
    "    \n",
    "    # 2. Insert test data representing production state\n",
    "    - npm run db:seed:test-data\n",
    "    \n",
    "    # 3. Apply new migrations\n",
    "    - git checkout $CI_COMMIT_SHA\n",
    "    - npm ci\n",
    "    - npm run db:migrate\n",
    "    \n",
    "    # 4. Verify application still works\n",
    "    - npm run test:integration\n",
    "```\n",
    "\n",
    "## 22.3 End-to-End Testing\n",
    "\n",
    "End-to-end (E2E) tests validate complete user workflows through the application stack. While valuable, they are slower and more brittle than unit or integration tests, requiring careful management in CI.\n",
    "\n",
    "### Browser Testing with Playwright\n",
    "\n",
    "Playwright provides cross-browser testing with automatic waiting and tracing:\n",
    "\n",
    "```yaml\n",
    "# GitHub Actions with Playwright\n",
    "e2e_tests:\n",
    "  runs-on: ubuntu-latest\n",
    "  steps:\n",
    "    - uses: actions/checkout@v4\n",
    "    \n",
    "    - name: Setup Node\n",
    "      uses: actions/setup-node@v4\n",
    "      with:\n",
    "        node-version: '20'\n",
    "    \n",
    "    - name: Install dependencies\n",
    "      run: npm ci\n",
    "    \n",
    "    - name: Install Playwright browsers\n",
    "      run: npx playwright install --with-deps\n",
    "    \n",
    "    - name: Start application\n",
    "      run: |\n",
    "        docker-compose -f docker-compose.test.yml up -d\n",
    "        npx wait-on http://localhost:3000 --timeout 60000\n",
    "    \n",
    "    - name: Run E2E tests\n",
    "      run: npx playwright test\n",
    "      \n",
    "    - name: Upload test results\n",
    "      if: always()\n",
    "      uses: actions/upload-artifact@v3\n",
    "      with:\n",
    "        name: playwright-report\n",
    "        path: |\n",
    "          playwright-report/\n",
    "          test-results/\n",
    "    \n",
    "    - name: Cleanup\n",
    "      if: always()\n",
    "      run: docker-compose -f docker-compose.test.yml down -v\n",
    "```\n",
    "\n",
    "**Playwright Configuration for CI:**\n",
    "```javascript\n",
    "// playwright.config.js\n",
    "module.exports = {\n",
    "  testDir: './e2e',\n",
    "  fullyParallel: true,\n",
    "  forbidOnly: !!process.env.CI,  // Fail if .only left in code\n",
    "  retries: process.env.CI ? 2 : 0,  // Retry flaky tests in CI\n",
    "  workers: process.env.CI ? 1 : undefined,  // Single worker in CI for stability\n",
    "  reporter: [\n",
    "    ['html'],\n",
    "    ['junit', { outputFile: 'junit-results.xml' }]\n",
    "  ],\n",
    "  use: {\n",
    "    baseURL: 'http://localhost:3000',\n",
    "    trace: 'on-first-retry',  // Capture trace on first retry\n",
    "    screenshot: 'only-on-failure',\n",
    "    video: 'retain-on-failure',\n",
    "  },\n",
    "  projects: [\n",
    "    {\n",
    "      name: 'chromium',\n",
    "      use: { ...devices['Desktop Chrome'] },\n",
    "    },\n",
    "    // Only test one browser in CI for speed, all browsers locally\n",
    "    process.env.CI ? null : {\n",
    "      name: 'firefox',\n",
    "      use: { ...devices['Desktop Firefox'] },\n",
    "    },\n",
    "  ].filter(Boolean),\n",
    "};\n",
    "```\n",
    "\n",
    "### Cypress in CI\n",
    "\n",
    "Cypress provides real-time reloading and debugging capabilities:\n",
    "\n",
    "```yaml\n",
    "# Cypress in Docker\n",
    "cypress_tests:\n",
    "  stage: test\n",
    "  image: cypress/included:cypress-13.0.0-node-20.5.0-chrome-114.1.2.1-1-ff-114.0.2-edge-114.0.1823.51-1\n",
    "  services:\n",
    "    - name: $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n",
    "      alias: app\n",
    "  variables:\n",
    "    CYPRESS_baseUrl: http://app:3000\n",
    "  script:\n",
    "    - cypress run --browser chrome --headless\n",
    "  artifacts:\n",
    "    when: always\n",
    "    paths:\n",
    "      - cypress/videos/\n",
    "      - cypress/screenshots/\n",
    "    reports:\n",
    "      junit: cypress/results/junit.xml\n",
    "```\n",
    "\n",
    "**Parallelization with Cypress Dashboard:**\n",
    "```yaml\n",
    "# Split tests across multiple machines\n",
    "cypress:\n",
    "  parallel: 4  # Run 4 parallel instances\n",
    "  script:\n",
    "    - cypress run --record --parallel --key $CYPRESS_RECORD_KEY\n",
    "```\n",
    "\n",
    "### API Testing\n",
    "\n",
    "Test REST/GraphQL endpoints in isolation:\n",
    "\n",
    "```yaml\n",
    "# Postman/Newman integration\n",
    "api_tests:\n",
    "  stage: test\n",
    "  image: postman/newman:alpine\n",
    "  services:\n",
    "    - $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n",
    "  script:\n",
    "    - newman run collection.json \n",
    "        --environment ci-environment.json\n",
    "        --reporters cli,junit\n",
    "        --reporter-junit-export newman-results.xml\n",
    "  artifacts:\n",
    "    reports:\n",
    "      junit: newman-results.xml\n",
    "```\n",
    "\n",
    "## 22.4 Test Containers Pattern\n",
    "\n",
    "Testcontainers (mentioned in 22.2) deserves deeper examination as the modern standard for integration testing with real dependencies.\n",
    "\n",
    "### Architecture and Benefits\n",
    "\n",
    "**Consistency:** Tests use the same container images as production databases, eliminating \"works on my machine\" issues.\n",
    "\n",
    "**Isolation:** Each test suite receives fresh, isolated database instances, preventing test pollution.\n",
    "\n",
    "**Cleanup:** Automatic resource cleanup via Ryuk sidecar container, even if tests crash.\n",
    "\n",
    "### Advanced Patterns\n",
    "\n",
    "**Custom Wait Strategies:**\n",
    "```java\n",
    "// Wait for specific log message or HTTP endpoint\n",
    "@Container\n",
    "static GenericContainer<?> myService = new GenericContainer<>(\"myapp:latest\")\n",
    "    .withExposedPorts(8080)\n",
    "    .waitingFor(\n",
    "        Wait.forHttp(\"/health\")\n",
    "            .forStatusCode(200)\n",
    "            .withStartupTimeout(Duration.ofSeconds(60))\n",
    "    );\n",
    "```\n",
    "\n",
    "**Docker Compose Integration:**\n",
    "```java\n",
    "// Test full stack with docker-compose\n",
    "@Container\n",
    "static DockerComposeContainer<?> environment = \n",
    "    new DockerComposeContainer<>(new File(\"docker-compose.test.yml\"))\n",
    "        .withExposedService(\"web\", 8080)\n",
    "        .withExposedService(\"database\", 5432)\n",
    "        .waitingFor(\"web\", Wait.forListeningPort());\n",
    "```\n",
    "\n",
    "**Volume Mounts for Test Data:**\n",
    "```java\n",
    "// Mount SQL fixtures into database container\n",
    "@Container\n",
    "static PostgreSQLContainer<?> postgres = new PostgreSQLContainer<>(\"postgres:15\")\n",
    "    .withClasspathResourceMapping(\"fixtures/\", \"/docker-entrypoint-initdb.d/\", \n",
    "        BindMode.READ_ONLY);\n",
    "```\n",
    "\n",
    "### CI Optimization\n",
    "\n",
    "**Pre-pull Images:**\n",
    "```yaml\n",
    "# Speed up Testcontainers by pre-pulling images\n",
    "pre_pull:\n",
    "  stage: prepare\n",
    "  script:\n",
    "    - docker pull postgres:15-alpine\n",
    "    - docker pull redis:7-alpine\n",
    "    - docker pull localstack/localstack:latest\n",
    "  cache:\n",
    "    key: docker-images\n",
    "    paths:\n",
    "      - /var/lib/docker\n",
    "```\n",
    "\n",
    "**Reuse Containers (Experimental):**\n",
    "```java\n",
    "// Reuse containers between test classes (faster but less isolated)\n",
    "@Testcontainers\n",
    "@TestInstance(TestInstance.Lifecycle.PER_CLASS)  // Reuse instance\n",
    "public class IntegrationTests {\n",
    "    @Container\n",
    "    static PostgreSQLContainer<?> postgres = new PostgreSQLContainer<>(\"postgres:15\")\n",
    "        .withReuse(true);  // Enable reuse\n",
    "}\n",
    "```\n",
    "\n",
    "## 22.5 Parallel Test Execution\n",
    "\n",
    "Parallel execution reduces feedback time but requires careful resource management to prevent test interference.\n",
    "\n",
    "### Test Splitting Strategies\n",
    "\n",
    "**File-based Splitting:**\n",
    "```yaml\n",
    "# Split test files across parallel jobs\n",
    "test:\n",
    "  parallel: 4\n",
    "  script:\n",
    "    - |\n",
    "      # Get all test files\n",
    "      TEST_FILES=$(find tests -name \"*.test.js\" | sort)\n",
    "      TOTAL=$(echo \"$TEST_FILES\" | wc -l)\n",
    "      CHUNK=$((TOTAL / 4))\n",
    "      \n",
    "      # Get this job's slice\n",
    "      case $CI_NODE_INDEX in\n",
    "        1) SLICE=$(echo \"$TEST_FILES\" | head -n $CHUNK) ;;\n",
    "        2) SLICE=$(echo \"$TEST_FILES\" | head -n $((CHUNK*2)) | tail -n $CHUNK) ;;\n",
    "        3) SLICE=$(echo \"$TEST_FILES\" | head -n $((CHUNK*3)) | tail -n $CHUNK) ;;\n",
    "        4) SLICE=$(echo \"$TEST_FILES\" | tail -n $((TOTAL-CHUNK*3))) ;;\n",
    "      esac\n",
    "      \n",
    "      npm test -- $SLICE\n",
    "```\n",
    "\n",
    "**Timing-based Splitting (CircleCI):**\n",
    "```yaml\n",
    "# Automatically balance based on historical timing data\n",
    "test:\n",
    "  parallelism: 4\n",
    "  steps:\n",
    "    - run:\n",
    "        command: |\n",
    "          circleci tests glob \"tests/**/*.test.js\" | \\\n",
    "          circleci tests split --split-by=timings | \\\n",
    "          xargs npm test\n",
    "```\n",
    "\n",
    "**Jest Parallelization:**\n",
    "```javascript\n",
    "// jest.config.js\n",
    "module.exports = {\n",
    "  // Use 50% of available CPUs (leave headroom for other processes)\n",
    "  maxWorkers: '50%',\n",
    "  \n",
    "  // Shard for CI parallelization\n",
    "  ...(process.env.CI && {\n",
    "    shard: `${process.env.SHARD_INDEX}/${process.env.SHARD_TOTAL}`,\n",
    "  }),\n",
    "};\n",
    "```\n",
    "\n",
    "```yaml\n",
    "# Run sharded tests\n",
    "test:\n",
    "  parallel: 4\n",
    "  script:\n",
    "    - npm test -- --shard=$CI_NODE_INDEX/$CI_NODE_TOTAL\n",
    "```\n",
    "\n",
    "### Resource Isolation\n",
    "\n",
    "Prevent parallel tests from interfering:\n",
    "\n",
    "**Database per Test Worker:**\n",
    "```javascript\n",
    "// Dynamic database naming\n",
    "const workerId = process.env.JEST_WORKER_ID || '1';\n",
    "const dbName = `test_db_worker_${workerId}`;\n",
    "\n",
    "beforeAll(async () => {\n",
    "  await createDatabase(dbName);\n",
    "  process.env.DATABASE_URL = `postgres://localhost/${dbName}`;\n",
    "});\n",
    "```\n",
    "\n",
    "**Port Allocation:**\n",
    "```javascript\n",
    "// Find available ports dynamically\n",
    "const getPort = require('get-port');\n",
    "\n",
    "beforeAll(async () => {\n",
    "  const port = await getPort();\n",
    "  server.listen(port);\n",
    "});\n",
    "```\n",
    "\n",
    "## 22.6 Test Reports and Coverage\n",
    "\n",
    "Comprehensive reporting transforms test results into actionable insights and quality gates.\n",
    "\n",
    "### JUnit XML Integration\n",
    "\n",
    "Standard format supported by all CI platforms:\n",
    "\n",
    "```yaml\n",
    "# Generate and upload JUnit reports\n",
    "test:\n",
    "  script:\n",
    "    - npm test -- --reporter=junit --outputFile=junit.xml\n",
    "  artifacts:\n",
    "    reports:\n",
    "      junit: junit-results.xml\n",
    "    paths:\n",
    "      - junit-results.xml\n",
    "    expire_in: 1 week\n",
    "```\n",
    "\n",
    "**GitLab Test Visualization:**\n",
    "- Displays test suites, cases, and failure details in MR interface\n",
    "- Tracks test execution time trends\n",
    "- Identifies slow tests for optimization\n",
    "\n",
    "### Coverage Reporting\n",
    "\n",
    "**Line-by-Line Coverage:**\n",
    "```yaml\n",
    "# Upload to Codecov\n",
    "- name: Upload coverage to Codecov\n",
    "  uses: codecov/codecov-action@v3\n",
    "  with:\n",
    "    files: ./coverage/lcov.info\n",
    "    flags: unittests\n",
    "    name: codecov-umbrella\n",
    "    fail_ci_if_error: true\n",
    "    verbose: true\n",
    "```\n",
    "\n",
    "**Coverage Diff (Changed Lines Only):**\n",
    "```bash\n",
    "# Only require coverage on modified lines\n",
    "git diff origin/main...HEAD --name-only | grep '\\.js$' | xargs npx jest --coverage --collectCoverageFrom\n",
    "```\n",
    "\n",
    "### Quality Gates\n",
    "\n",
    "**SonarQube Integration:**\n",
    "```yaml\n",
    "sonarqube-check:\n",
    "  stage: test\n",
    "  image: sonarsource/sonar-scanner-cli:latest\n",
    "  script:\n",
    "    - sonar-scanner \n",
    "      -Dsonar.projectKey=myapp \n",
    "      -Dsonar.sources=. \n",
    "      -Dsonar.coverage.exclusions=**/*.test.js \n",
    "      -Dsonar.javascript.lcov.reportPaths=coverage/lcov.info\n",
    "  only:\n",
    "    - merge_requests\n",
    "    - main\n",
    "```\n",
    "\n",
    "**Quality Gate Conditions:**\n",
    "- Coverage on new code ≥ 80%\n",
    "- Duplicated lines on new code ≤ 3%\n",
    "- No blocker/critical issues\n",
    "- Test success rate = 100%\n",
    "\n",
    "## 22.7 Test Data Management\n",
    "\n",
    "Reliable tests require consistent, isolated test data that resets between runs.\n",
    "\n",
    "### Database Seeding Strategies\n",
    "\n",
    "**SQL Fixtures:**\n",
    "```yaml\n",
    "# Load schema and seed data before tests\n",
    "test:\n",
    "  before_script:\n",
    "    - psql -h postgres -U postgres -d testdb -f tests/fixtures/schema.sql\n",
    "    - psql -h postgres -U postgres -d testdb -f tests/fixtures/seed-data.sql\n",
    "  script:\n",
    "    - npm test\n",
    "```\n",
    "\n",
    "**Factory Pattern (Programmatic):**\n",
    "```javascript\n",
    "// factories/user.js\n",
    "const factory = require('factory-girl').factory;\n",
    "const User = require('../../src/models/User');\n",
    "\n",
    "factory.define('user', User, {\n",
    "  email: factory.seq('User.email', n => `user${n}@test.com`),\n",
    "  name: factory.chance('name'),\n",
    "  createdAt: new Date(),\n",
    "  updatedAt: new Date()\n",
    "});\n",
    "\n",
    "// In tests\n",
    "const user = await factory.create('user', { role: 'admin' });\n",
    "```\n",
    "\n",
    "**Docker Init Scripts:**\n",
    "```dockerfile\n",
    "# Dockerfile.test\n",
    "COPY tests/fixtures/ /docker-entrypoint-initdb.d/\n",
    "```\n",
    "\n",
    "### Data Isolation Levels\n",
    "\n",
    "**Transaction Rollback (Fastest):**\n",
    "```java\n",
    "@SpringBootTest\n",
    "@Transactional  // Roll back after each test\n",
    "public class UserTest {\n",
    "    // Tests run in transactions that rollback automatically\n",
    "}\n",
    "```\n",
    "\n",
    "**Database per Test (Most Isolated):**\n",
    "```javascript\n",
    "beforeEach(async () => {\n",
    "  const testDb = `test_${Date.now()}_${randomBytes(4).toString('hex')}`;\n",
    "  await createDatabase(testDb);\n",
    "  process.env.DATABASE_URL = `postgres://localhost/${testDb}`;\n",
    "});\n",
    "\n",
    "afterEach(async () => {\n",
    "  await dropDatabase(testDb);\n",
    "});\n",
    "```\n",
    "\n",
    "### Production Data Anonymization\n",
    "\n",
    "For realistic load testing:\n",
    "\n",
    "```yaml\n",
    "# Nightly job to refresh staging with anonymized production\n",
    "refresh_staging:\n",
    "  stage: prepare\n",
    "  only:\n",
    "    - schedules\n",
    "  script:\n",
    "    - pg_dump production_db | psql staging_db\n",
    "    - npm run db:anonymize  # Scramble PII\n",
    "    - npm run test:e2e\n",
    "```\n",
    "\n",
    "## 22.8 Flaky Test Handling\n",
    "\n",
    "Flaky tests—tests that pass and fail intermittently without code changes—destroy trust in CI and must be eliminated aggressively.\n",
    "\n",
    "### Detection and Tracking\n",
    "\n",
    "**Identify Flakiness:**\n",
    "```yaml\n",
    "# Run tests multiple times to detect flakiness\n",
    "flaky_check:\n",
    "  script:\n",
    "    - for i in {1..5}; do npm test; done\n",
    "  allow_failure: true  # Don't block, just report\n",
    "```\n",
    "\n",
    "**Test Analytics:**\n",
    "```javascript\n",
    "// Track flaky tests with Jest\n",
    "// jest.config.js\n",
    "module.exports = {\n",
    "  testRunner: 'jest-runner',\n",
    "  reporters: [\n",
    "    'default',\n",
    "    ['jest-junit', { outputDirectory: './reports' }],\n",
    "    ['jest-flake-tracker', { \n",
    "      outputFile: './reports/flaky.json',\n",
    "      threshold: 0.1  // Flag tests failing >10% of time\n",
    "    }]\n",
    "  ]\n",
    "};\n",
    "```\n",
    "\n",
    "### Mitigation Strategies\n",
    "\n",
    "**Retry with Exponential Backoff:**\n",
    "```yaml\n",
    "test:\n",
    "  retry: 2  # GitLab CI native retry\n",
    "  script:\n",
    "    - npm test\n",
    "```\n",
    "\n",
    "**Quarantine Flaky Tests:**\n",
    "```javascript\n",
    "// Move flaky tests to separate suite\n",
    "describe.skip('FLAKY: Payment Gateway Integration', () => {\n",
    "  // Tests under investigation\n",
    "});\n",
    "\n",
    "// Or mark with custom tag\n",
    "it('processes payments [flaky]', () => {\n",
    "  // Test logic\n",
    "});\n",
    "```\n",
    "\n",
    "```yaml\n",
    "# Run quarantined tests separately\n",
    "test:stable:\n",
    "  script:\n",
    "    - npm test -- --testNamePattern='^(?!.*\\\\[flaky\\\\])'\n",
    "\n",
    "test:flaky:\n",
    "  allow_failure: true\n",
    "  script:\n",
    "    - npm test -- --testNamePattern='\\\\[flaky\\\\]'\n",
    "```\n",
    "\n",
    "**Root Cause Fixes:**\n",
    "Common causes and solutions:\n",
    "- **Timing issues:** Replace `setTimeout` with explicit wait conditions\n",
    "- **Resource leaks:** Ensure connections closed, files deleted\n",
    "- **Shared state:** Reset singletons between tests\n",
    "- **Random data:** Use seeded random generators\n",
    "- **External dependencies:** Mock or use testcontainers\n",
    "\n",
    "### CI Configuration for Flaky Tests\n",
    "\n",
    "```yaml\n",
    "# Strict mode for main branch (no flakes allowed)\n",
    "test:strict:\n",
    "  rules:\n",
    "    - if: $CI_COMMIT_BRANCH == \"main\"\n",
    "  retry: 0  # No retries on main\n",
    "  allow_failure: false\n",
    "\n",
    "# Lenient mode for feature branches\n",
    "test:lenient:\n",
    "  rules:\n",
    "    - if: $CI_COMMIT_BRANCH != \"main\"\n",
    "  retry: 2\n",
    "  allow_failure: false\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary and Preview\n",
    "\n",
    "In this chapter, we examined testing strategies essential for validating containerized applications in CI pipelines. Unit testing in containers ensures consistent execution environments between CI and production, with coverage thresholds enforcing quality standards at the base of the testing pyramid. Integration testing leverages service containers and Testcontainers to validate real database interactions and service dependencies without mocking, ensuring compatibility with actual infrastructure. End-to-end testing with tools like Playwright and Cypress validates complete user workflows, though requiring careful parallelization and artifact management to maintain pipeline efficiency. We explored parallel test execution strategies including file-based splitting and timing-aware distribution to minimize feedback time, alongside resource isolation techniques to prevent test interference. Test reporting via JUnit XML and coverage tools like Codecov and SonarQube provides visibility into quality metrics, while test data management strategies—from transaction rollback to database-per-worker patterns—ensure test isolation and reproducibility. Finally, we addressed flaky test detection and mitigation, emphasizing that flaky tests must be quarantined or fixed immediately to maintain CI reliability.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Structure tests as a pyramid: 70% unit (fast, isolated), 20% integration (real dependencies), 10% E2E (slow, comprehensive) to balance coverage with execution speed\n",
    "- Use Testcontainers for integration tests to ensure database versions and configurations match production exactly, eliminating environment-specific failures\n",
    "- Implement parallel test execution with dynamic database naming (worker ID-based) to prevent cross-test contamination while minimizing total execution time\n",
    "- Never allow flaky tests to persist in the main branch; quarantine them immediately and prioritize root cause fixes over retry mechanisms\n",
    "- Require coverage on new/modified code only (diff coverage) rather than overall project coverage to avoid penalizing legacy code while ensuring new work meets standards\n",
    "\n",
    "**Next Chapter Preview:**\n",
    "Chapter 23: Code Quality and Security Scanning extends testing beyond functional correctness to structural quality and vulnerability detection. We will explore static application security testing (SAST), software composition analysis (SCA) for dependency vulnerabilities, container image scanning, and dynamic application security testing (DAST). This chapter examines how to integrate linting, secret detection, and compliance checking into CI pipelines as automated gates that prevent security debt from accumulating. Understanding these security scanning patterns ensures that the tested code from this chapter meets organizational security and compliance standards before deployment to Kubernetes clusters."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
