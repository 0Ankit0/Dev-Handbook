{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 62: Edge Computing and CI/CD\n",
    "\n",
    "While data center deployments benefit from abundant compute, reliable high-bandwidth networking, and physical security, edge computing operates under opposing constraints: devices may possess only ARM-based single-board computers with 512MB RAM, connectivity might be intermittent 4G/LTE or LoRaWAN with strict data caps, and hardware resides in unsecured retail stores, factory floors, or vehicles traversing cellular dead zones. Yet these environments increasingly require cloud-native capabilities\u2014container orchestration, automated rollouts, and GitOps workflows\u2014to process data locally for latency-sensitive applications (autonomous driving, industrial IoT, real-time fraud detection) and comply with data sovereignty regulations. This chapter examines how to adapt Kubernetes and CI/CD practices for resource-constrained, geographically distributed edge fleets, addressing multi-architecture container builds, delta update mechanisms to conserve bandwidth, and security postures for devices operating beyond traditional network perimeters.\n",
    "\n",
    "## 62.1 Edge Computing Overview\n",
    "\n",
    "Edge computing positions computational resources proximal to data sources, reducing round-trip latency to centralized clouds and enabling autonomous operation during network partitions. Unlike cloud data centers where infrastructure homogeneity simplifies deployment, edge environments exhibit extreme heterogeneity\u2014mixing x86 industrial PCs, ARM64 NVIDIA Jetson devices, and RISC-V microcontrollers\u2014often managed in fleets numbering tens of thousands across disparate geographic locations.\n",
    "\n",
    "### Edge Deployment Patterns\n",
    "\n",
    "**Heavy Edge (Far Edge):**\n",
    "Runs full Kubernetes clusters on robust hardware (factory servers, retail backrooms, cell towers). Characteristics include: 16-64GB RAM, persistent power, wired ethernet with intermittent cloud connectivity, managed via GitOps with local control planes.\n",
    "\n",
    "**Light Edge (Near Edge):**\n",
    "Single-node Kubernetes or container runtimes on constrained devices (kiosks, drones, sensors). Characteristics include: 512MB-4GB RAM, ARM processors, battery or solar power, wireless connectivity, requiring ultra-efficient resource utilization.\n",
    "\n",
    "**IoT Edge:**\n",
    " microcontroller-class devices running containerd or WebAssembly runtimes rather than full Kubernetes. Managed via fleet orchestrators (Azure IoT Edge, AWS Greengrass) rather than traditional CI/CD pipelines.\n",
    "\n",
    "### CI/CD Challenges at the Edge\n",
    "\n",
    "**Bandwidth Constraints:**\n",
    "Pushing 500MB container images to 10,000 devices over cellular networks is economically and technically infeasible. Delta updates, compression, and layer caching become critical.\n",
    "\n",
    "**Intermittent Connectivity:**\n",
    "Devices may be offline for hours or days. Rollouts must be asynchronous, resumable, and tolerant of mid-update connection drops without bricking devices.\n",
    "\n",
    "**Resource Heterogeneity:**\n",
    "Images must support multiple architectures (amd64, arm64, arm/v7) and varying CPU instruction sets (AVX2 vs. NEON).\n",
    "\n",
    "**Security Posture:**\n",
    "Devices operate in physically unsecured locations, requiring encrypted storage, hardware security modules (HSM), and mutual TLS with short-lived certificates.\n",
    "\n",
    "## 62.2 Lightweight Kubernetes Distributions\n",
    "\n",
    "Standard Kubernetes control planes require 2GB+ RAM and multiple nodes\u2014prohibitive for edge deployment. Lightweight distributions strip control plane components to essentials, enabling single-node operation on resource-constrained hardware.\n",
    "\n",
    "### K3s\n",
    "\n",
    "Rancher Labs' K3s is a certified Kubernetes distribution weighing under 100MB, optimized for ARM and x86 edge architectures. It replaces etcd with SQLite (or external databases for HA), bundles Flannel CNI, and removes alpha features and legacy cloud providers.\n",
    "\n",
    "**Architecture:**\n",
    "- **Single Binary:** 40MB binary containing apiserver, scheduler, controller-manager, and flannel.\n",
    "- **SQLite Backend:** Default storage eliminates etcd memory overhead (~1GB savings).\n",
    "- **Containerd Default:** Uses containerd directly, not Docker, reducing daemon overhead.\n",
    "- **ARM Support:** First-class support for Raspberry Pi, NVIDIA Jetson, and ARM64 servers.\n",
    "\n",
    "**Installation (Edge Device):**\n",
    "```bash\n",
    "# Install K3s on edge device (ARM64 or x86)\n",
    "curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC=\"server --disable traefik --write-kubeconfig-mode 644\" sh -\n",
    "\n",
    "# Verify\n",
    "kubectl get nodes\n",
    "# NAME        STATUS   ROLES                  AGE   VERSION\n",
    "# edge-node-1 Ready    control-plane,master   10s   v1.28.3+k3s1\n",
    "```\n",
    "\n",
    "**GitOps Agent Configuration:**\n",
    "For edge fleets, run K3s in agent mode connecting to cloud-hosted control planes (K3s \"servers\") or use fully autonomous single-node mode with local GitOps operators:\n",
    "\n",
    "```yaml\n",
    "# /etc/rancher/k3s/config.yaml (Agent mode)\n",
    "server: https://control-plane.company.com:6443\n",
    "token: ${K3S_TOKEN}\n",
    "node-label:\n",
    "  - \"edge.location=store-123\"\n",
    "  - \"edge.tier=far-edge\"\n",
    "kubelet-arg:\n",
    "  - \"system-reserved=cpu=100m,memory=200Mi\"\n",
    "  - \"kube-reserved=cpu=100m,memory=200Mi\"\n",
    "```\n",
    "\n",
    "### MicroK8s\n",
    "\n",
    "Canonical's MicroK8s offers snap-based installation with strict confinement, suitable for Ubuntu Core IoT deployments:\n",
    "\n",
    "```bash\n",
    "# Install on Ubuntu Core\n",
    "snap install microk8s --classic --channel=1.28/stable\n",
    "\n",
    "# Enable only required addons (resource conservation)\n",
    "microk8s enable dns\n",
    "microk8s enable storage\n",
    "microk8s enable registry\n",
    "\n",
    "# Join existing cluster (for multi-node edge sites)\n",
    "microk8s join 192.168.1.100:25000/${TOKEN}\n",
    "```\n",
    "\n",
    "**Resource Profiling:**\n",
    "MicroK8s can operate with as little as 540MB RAM when optimized:\n",
    "```bash\n",
    "microk8s status\n",
    "# Disable unused services\n",
    "microk8s disable metrics-server  # If external monitoring used\n",
    "microK8s disable dashboard       # If not needed locally\n",
    "```\n",
    "\n",
    "### K3os and Immutable Edge OS\n",
    "\n",
    "K3os combines Linux OS and K3s into an immutable image, enabling atomic updates and rollbacks at the OS level:\n",
    "\n",
    "```yaml\n",
    "# cloud-config.yml for K3os installation\n",
    "ssh_authorized_keys:\n",
    "  - ssh-rsa AAAAB3NzaC1...\n",
    "\n",
    "k3os:\n",
    "  password: changeme\n",
    "  server_url: https://control-plane.company.com:6443\n",
    "  token: ${CLUSTER_TOKEN}\n",
    "  labels:\n",
    "    - region=north-america\n",
    "    - site=retail-store-456\n",
    "  k3s_args:\n",
    "    - agent\n",
    "    - \"--node-label\"\n",
    "    - \"edge-type=pos-terminal\"\n",
    "```\n",
    "\n",
    "### Comparison Matrix\n",
    "\n",
    "| Distribution | Min RAM | Architecture | Storage Backend | Best Use Case |\n",
    "|-------------|---------|--------------|-----------------|---------------|\n",
    "| **K3s** | 512MB | x86_64, ARM64, ARMv7 | SQLite/Postgres | General edge, industrial IoT |\n",
    "| **MicroK8s** | 540MB | x86_64, ARM64 | dqlite | Ubuntu Core, development |\n",
    "| **k0s** | 1GB | x86_64, ARM64 | SQLite | Telco edge, multi-node sites |\n",
    "| **KubeEdge** | 256MB (edgecore) | x86_64, ARM64 | SQLite | Cloud-edge collaboration |\n",
    "\n",
    "## 62.3 Container Optimization for Edge\n",
    "\n",
    "Standard container images (Ubuntu, Debian-based) consume 100MB+ before application code. Edge devices require aggressive optimization to minimize pull times and storage usage.\n",
    "\n",
    "### Multi-Architecture Builds\n",
    "\n",
    "Edge fleets mix architectures (x86 servers with ARM sensors). CI pipelines must produce multi-arch manifests:\n",
    "\n",
    "```dockerfile\n",
    "# Dockerfile.optimized\n",
    "FROM --platform=$BUILDPLATFORM golang:1.21 AS builder\n",
    "WORKDIR /app\n",
    "COPY go.mod go.sum ./\n",
    "RUN go mod download\n",
    "COPY . .\n",
    "ARG TARGETOS\n",
    "ARG TARGETARCH\n",
    "RUN CGO_ENABLED=0 GOOS=$TARGETOS GOARCH=$TARGETARCH go build -ldflags=\"-w -s\" -o edge-app\n",
    "\n",
    "# Final stage - distroless for security and size\n",
    "FROM gcr.io/distroless/static:nonroot-${TARGETARCH}\n",
    "COPY --from=builder /app/edge-app /edge-app\n",
    "USER 65532:65532\n",
    "ENTRYPOINT [\"/edge-app\"]\n",
    "```\n",
    "\n",
    "**Buildx Configuration:**\n",
    "```bash\n",
    "# Create builder with emulation support\n",
    "docker buildx create --name multiarch --use --bootstrap\n",
    "docker run --privileged --rm tonistiigi/binfmt --install all\n",
    "\n",
    "# Build and push multi-arch manifest\n",
    "docker buildx build \\\n",
    "  --platform linux/amd64,linux/arm64,linux/arm/v7 \\\n",
    "  -t registry.company.com/edge-app:v1.2.0 \\\n",
    "  --push \\\n",
    "  -f Dockerfile.optimized .\n",
    "```\n",
    "\n",
    "**Manifest Inspection:**\n",
    "```bash\n",
    "docker manifest inspect registry.company.com/edge-app:v1.2.0\n",
    "# Shows manifests for amd64, arm64, arm/v7\n",
    "```\n",
    "\n",
    "### Distroless and Scratch Images\n",
    "\n",
    "Eliminate package managers, shells, and OS utilities to reduce attack surface and size:\n",
    "\n",
    "```dockerfile\n",
    "# For statically compiled Go/Rust apps\n",
    "FROM scratch\n",
    "COPY --from=builder /app/edge-app /edge-app\n",
    "COPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/\n",
    "USER 65532\n",
    "ENTRYPOINT [\"/edge-app\"]\n",
    "```\n",
    "\n",
    "**Size Comparison:**\n",
    "- Ubuntu base: ~120MB\n",
    "- Alpine: ~15MB\n",
    "- Distroless: ~5MB (application binary only)\n",
    "- Scratch: ~2MB (binary + certs only)\n",
    "\n",
    "### Layer Optimization\n",
    "\n",
    "Structure Dockerfile to maximize cache hits on edge devices with limited bandwidth:\n",
    "\n",
    "```dockerfile\n",
    "# Bad: Dependencies change forces full rebuild\n",
    "COPY . /app\n",
    "RUN go build\n",
    "\n",
    "# Good: Separate dependency layer (cached)\n",
    "COPY go.mod go.sum ./\n",
    "RUN go mod download  # Cached layer\n",
    "COPY . .\n",
    "RUN go build\n",
    "```\n",
    "\n",
    "**Image Pull Policies:**\n",
    "Configure K3s/MicroK8s to cache aggressively:\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "spec:\n",
    "  containers:\n",
    "  - name: app\n",
    "    image: registry.company.com/edge-app:v1.2.0\n",
    "    imagePullPolicy: IfNotPresent  # Use local cache if available\n",
    "```\n",
    "\n",
    "## 62.4 GitOps for Fleet Management\n",
    "\n",
    "Managing thousands of distributed edge devices requires GitOps patterns that tolerate intermittent connectivity and support progressive rollouts across geographic tiers.\n",
    "\n",
    "### Fleet Architecture\n",
    "\n",
    "**Hub-and-Spoke Model:**\n",
    "Cloud-hosted GitOps control plane (ArgoCD/Flux) manages regional \"hub\" clusters, which in turn manage local \"spoke\" edge devices via constrained connectivity.\n",
    "\n",
    "**Autonomous Edge Model:**\n",
    "Each edge device runs a local GitOps agent (Flux agent, ArgoCD agent) that pulls from cached Git repositories or local Git servers when cloud connectivity is unavailable.\n",
    "\n",
    "### Flux for Edge\n",
    "\n",
    "Flux v2's lightweight agents suit edge deployment:\n",
    "\n",
    "```yaml\n",
    "# Install Flux on edge device (lightweight)\n",
    "flux install --namespace=flux-system --components=source-controller,kustomize-controller\n",
    "\n",
    "# GitRepository with shortened sync interval for edge\n",
    "apiVersion: source.toolkit.fluxcd.io/v1\n",
    "kind: GitRepository\n",
    "metadata:\n",
    "  name: edge-config\n",
    "  namespace: flux-system\n",
    "spec:\n",
    "  interval: 5m  # Longer interval to conserve bandwidth\n",
    "  url: https://github.com/company/edge-configs.git\n",
    "  ref:\n",
    "    branch: main\n",
    "  secretRef:\n",
    "    name: git-credentials\n",
    "  # Verify commits for security\n",
    "  verify:\n",
    "    mode: head\n",
    "    secretRef:\n",
    "      name: git-pgp-public-keys\n",
    "---\n",
    "apiVersion: kustomize.toolkit.fluxcd.io/v1\n",
    "kind: Kustomization\n",
    "metadata:\n",
    "  name: edge-apps\n",
    "spec:\n",
    "  interval: 10m\n",
    "  path: ./overlays/store-123\n",
    "  prune: true\n",
    "  sourceRef:\n",
    "    kind: GitRepository\n",
    "    name: edge-config\n",
    "  healthChecks:\n",
    "  - apiVersion: apps/v1\n",
    "    kind: Deployment\n",
    "    name: pos-terminal\n",
    "    namespace: retail\n",
    "  timeout: 2m  # Shorter timeout for edge responsiveness\n",
    "```\n",
    "\n",
    "### ArgoCD Edge Agent\n",
    "\n",
    "ArgoCD's ApplicationSet controller manages fleets via generators:\n",
    "\n",
    "```yaml\n",
    "apiVersion: argoproj.io/v1alpha1\n",
    "kind: ApplicationSet\n",
    "metadata:\n",
    "  name: edge-fleet\n",
    "spec:\n",
    "  generators:\n",
    "  - list:\n",
    "      elements:\n",
    "      - cluster: store-001\n",
    "        url: https://192.168.1.101:6443\n",
    "        region: us-west\n",
    "      - cluster: store-002\n",
    "        url: https://192.168.1.102:6443\n",
    "        region: us-west\n",
    "      # ... thousands of stores\n",
    "  template:\n",
    "    metadata:\n",
    "      name: '{{cluster}}-pos-system'\n",
    "    spec:\n",
    "      project: edge-deployments\n",
    "      source:\n",
    "        repoURL: https://github.com/company/edge-apps.git\n",
    "        targetRevision: HEAD\n",
    "        path: pos-system/overlays/{{region}}\n",
    "      destination:\n",
    "        server: '{{url}}'\n",
    "        namespace: retail\n",
    "      syncPolicy:\n",
    "        automated:\n",
    "          prune: true\n",
    "          selfHeal: true\n",
    "        syncOptions:\n",
    "        - PruneLast=true\n",
    "        - CreateNamespace=true\n",
    "      ignoreDifferences:  # Handle edge-specific config drift\n",
    "      - group: apps\n",
    "        kind: Deployment\n",
    "        jsonPointers:\n",
    "        - /spec/replicas  # Allow HPA to manage replicas\n",
    "```\n",
    "\n",
    "### Progressive Rollouts Across Fleet\n",
    "\n",
    "Use Flagger or Argo Rollouts with geographic canarying:\n",
    "\n",
    "```yaml\n",
    "apiVersion: flagger.app/v1beta1\n",
    "kind: Canary\n",
    "metadata:\n",
    "  name: edge-app\n",
    "  namespace: retail\n",
    "spec:\n",
    "  targetRef:\n",
    "    apiVersion: apps/v1\n",
    "    kind: Deployment\n",
    "    name: pos-terminal\n",
    "  service:\n",
    "    port: 8080\n",
    "  analysis:\n",
    "    interval: 5m  # Longer intervals for edge\n",
    "    threshold: 3\n",
    "    maxWeight: 50\n",
    "    stepWeight: 25\n",
    "    metrics:\n",
    "    - name: request-success-rate\n",
    "      thresholdRange:\n",
    "        min: 95\n",
    "    webhooks:\n",
    "    # Verify connectivity before promotion\n",
    "    - name: connectivity-check\n",
    "      type: confirm-rollout\n",
    "      url: http://flagger-loadtester.test/\n",
    "      timeout: 30s\n",
    "      metadata:\n",
    "        cmd: \"curl -sf http://pos-terminal.retail:8080/health\"\n",
    "```\n",
    "\n",
    "## 62.5 Delta Updates and Bandwidth Optimization\n",
    "\n",
    "Pushing full container images (100MB+) to thousands of edge devices over metered cellular connections is cost-prohibitive. Delta update mechanisms transmit only changed layers or binary diffs.\n",
    "\n",
    "### Image Layer Deduplication\n",
    "\n",
    "Container registries support layer sharing, but edge devices require additional optimization:\n",
    "\n",
    "**CAS (Content Addressable Storage) Proxy:**\n",
    "Deploy registry proxies at regional hubs that cache layers and serve edge requests locally:\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: registry-cache\n",
    "spec:\n",
    "  template:\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: registry\n",
    "        image: registry:2\n",
    "        env:\n",
    "        - name: REGISTRY_PROXY_REMOTEURL\n",
    "          value: https://registry.company.com\n",
    "        - name: REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY\n",
    "          value: /var/lib/registry\n",
    "        volumeMounts:\n",
    "        - name: cache\n",
    "          mountPath: /var/lib/registry\n",
    "      volumes:\n",
    "      - name: cache\n",
    "        hostPath:\n",
    "          path: /opt/registry-cache  # Persistent local cache\n",
    "```\n",
    "\n",
    "### Binary Delta Updates with OSTree\n",
    "\n",
    "For OS-level updates (K3s upgrades, OS patches), OSTree provides Git-like content tracking with binary deltas:\n",
    "\n",
    "```bash\n",
    "# On build server\n",
    "ostree commit --branch=edge-os/1.2.0 --tree=dir=/buildroot\n",
    "\n",
    "# Generate delta from previous version\n",
    "ostree static-delta generate --from=edge-os/1.1.0 --to=edge-os/1.2.0\n",
    "\n",
    "# Edge device applies delta (downloads ~5MB vs 500MB full image)\n",
    "ostree pull --delta edge-os/1.2.0\n",
    "ostree admin deploy edge-os/1.2.0\n",
    "```\n",
    "\n",
    "### Containerd Image Pull Optimization\n",
    "\n",
    "Enable lazy pulling (eStargz) to start containers before full download:\n",
    "\n",
    "```toml\n",
    "# /etc/containerd/config.toml\n",
    "[plugins.\"io.containerd.grpc.v1.cri\".registry]\n",
    "  [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors]\n",
    "    [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"docker.io\"]\n",
    "      endpoint = [\"https://mirror.gcr.io\", \"https://registry-1.docker.io\"]\n",
    "\n",
    "[plugins.\"io.containerd.snapshotter.v1.stargz]\n",
    "  # Enable eStargz for lazy pulling\n",
    "```\n",
    "\n",
    "### Compressed Updates with Zstd\n",
    "\n",
    "Use Zstd compression for image layers (faster decompression than gzip on ARM):\n",
    "\n",
    "```dockerfile\n",
    "# Build with BuildKit and zstd\n",
    "docker buildx build \\\n",
    "  --output type=image,compression=zstd,force-compression=true \\\n",
    "  -t registry.company.com/edge-app:v1.2.0 \\\n",
    "  --push .\n",
    "```\n",
    "\n",
    "## 62.6 Security for Edge Deployments\n",
    "\n",
    "Edge devices operate outside physical security perimeters, requiring zero-trust architectures, hardware-backed identity, and encrypted storage.\n",
    "\n",
    "### Device Identity and Attestation\n",
    "\n",
    "**SPIFFE/SPIRE:**\n",
    "Issue short-lived X.509 certificates to edge workloads based on hardware attestation:\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: DaemonSet\n",
    "metadata:\n",
    "  name: spire-agent\n",
    "spec:\n",
    "  template:\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: spire-agent\n",
    "        image: ghcr.io/spiffe/spire-agent:1.8.0\n",
    "        volumeMounts:\n",
    "        - name: spire-socket\n",
    "          mountPath: /run/spire/sockets\n",
    "        args:\n",
    "        - -config\n",
    "        - /run/spire/config/agent.conf\n",
    "      volumes:\n",
    "      - name: spire-socket\n",
    "        hostPath:\n",
    "          path: /run/spire/sockets\n",
    "          type: DirectoryOrCreate\n",
    "---\n",
    "# Workload registration with TPM attestation\n",
    "apiVersion: spire.spiffe.io/v1alpha1\n",
    "kind: ClusterSPIFFEID\n",
    "metadata:\n",
    "  name: edge-pos-terminal\n",
    "spec:\n",
    "  spiffeIDTemplate: \"spiffe://company.com/edge/{{.Node.Labels.site}}/pos\"\n",
    "  podSelector:\n",
    "    matchLabels:\n",
    "      app: pos-terminal\n",
    "  nodeSelector:\n",
    "    matchLabels:\n",
    "      edge-type: far-edge\n",
    "  # Require TPM attestation\n",
    "  federatesWith: []\n",
    "```\n",
    "\n",
    "**TPM (Trusted Platform Module):**\n",
    "Store device private keys in TPM chips to prevent extraction even if device is physically compromised:\n",
    "\n",
    "```bash\n",
    "# Generate key in TPM\n",
    "tpm2tss-genkey -a rsa -s 2048 device_key.tss\n",
    "\n",
    "# Use with K3s\n",
    "k3s server --token-file /dev/tpm0  # Token sealed in TPM\n",
    "```\n",
    "\n",
    "### Network Security\n",
    "\n",
    "**mTLS with Cert-Manager:**\n",
    "Automatically rotate certificates for edge devices:\n",
    "\n",
    "```yaml\n",
    "apiVersion: cert-manager.io/v1\n",
    "kind: Certificate\n",
    "metadata:\n",
    "  name: edge-device-cert\n",
    "  namespace: edge-system\n",
    "spec:\n",
    "  secretName: edge-tls\n",
    "  issuerRef:\n",
    "    name: step-issuer  # Smallstep CA for edge\n",
    "    kind: StepIssuer\n",
    "  commonName: \"edge-device-{{.Values.siteId}}.company.com\"\n",
    "  dnsNames:\n",
    "  - \"edge-device-{{.Values.siteId}}.local\"\n",
    "  duration: 24h\n",
    "  renewBefore: 1h  # Short-lived for edge security\n",
    "```\n",
    "\n",
    "**WireGuard for Edge Connectivity:**\n",
    "Encrypted tunnels between edge and cloud over public internet:\n",
    "\n",
    "```yaml\n",
    "apiVersion: vpn.wireguard.io/v1alpha1\n",
    "kind: WireGuardPeer\n",
    "metadata:\n",
    "  name: edge-tunnel\n",
    "spec:\n",
    "  endpoint: cloud-vpn.company.com:51820\n",
    "  allowedIPs:\n",
    "  - 10.0.0.0/8\n",
    "  persistentKeepalive: 25  # Keep NAT mapping alive\n",
    "```\n",
    "\n",
    "### Image Signing and Verification\n",
    "\n",
    "Prevent malicious image execution on edge devices:\n",
    "\n",
    "```bash\n",
    "# Sign image with Cosign\n",
    "cosign sign --key cosign.key registry.company.com/edge-app:v1.2.0\n",
    "\n",
    "# Verify on edge device before deployment\n",
    "cosign verify --key cosign.pub registry.company.com/edge-app:v1.2.0\n",
    "```\n",
    "\n",
    "**Admission Control:**\n",
    "```yaml\n",
    "apiVersion: constraints.gatekeeper.sh/v1beta1\n",
    "kind: K8sVerifiedImage\n",
    "metadata:\n",
    "  name: verify-edge-images\n",
    "spec:\n",
    "  match:\n",
    "    kinds:\n",
    "    - apiGroups: [\"\"]\n",
    "      kinds: [\"Pod\"]\n",
    "    namespaces: [\"edge-apps\"]\n",
    "  parameters:\n",
    "    allowedRegistries:\n",
    "    - registry.company.com\n",
    "    requireSignature: true\n",
    "```\n",
    "\n",
    "## 62.7 A/B Testing and Canary Deployments at Edge\n",
    "\n",
    "Edge canary deployments must account for geographic isolation\u2014rolling out to \"Store 001\" shouldn't affect \"Store 002\" due to varying network conditions and local regulations.\n",
    "\n",
    "### Geographic Canary Strategy\n",
    "\n",
    "```yaml\n",
    "apiVersion: flagger.app/v1beta1\n",
    "kind: Canary\n",
    "metadata:\n",
    "  name: edge-pos-update\n",
    "spec:\n",
    "  targetRef:\n",
    "    apiVersion: apps/v1\n",
    "    kind: Deployment\n",
    "    name: pos-terminal\n",
    "  analysis:\n",
    "    interval: 10m  # Extended for edge stability observation\n",
    "    threshold: 5\n",
    "    maxWeight: 30  # Conservative max at edge\n",
    "    stepWeight: 10\n",
    "    metrics:\n",
    "    - name: transaction-error-rate\n",
    "      thresholdRange:\n",
    "        max: 0.01  # 1% max error rate for POS\n",
    "    - name: latency-p99\n",
    "      thresholdRange:\n",
    "        max: 500  # 500ms max for payment processing\n",
    "    webhooks:\n",
    "    - name: local-health-check\n",
    "      type: confirm-promotion\n",
    "      url: http://localhost:8080/health  # Local endpoint only\n",
    "      timeout: 30s\n",
    "```\n",
    "\n",
    "### Feature Flags for Edge\n",
    "\n",
    "Use lightweight feature flagging (Unleash, Flipt) to enable features without redeployment:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: feature-flags\n",
    "data:\n",
    "  config.json: |\n",
    "    {\n",
    "      \"flags\": {\n",
    "        \"new-payment-flow\": {\n",
    "          \"enabled\": true,\n",
    "          \"strategies\": [\n",
    "            {\n",
    "              \"name\": \"siteId\",\n",
    "              \"parameters\": {\n",
    "                \"siteIds\": \"store-001,store-002\"  # Gradual rollout\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "```\n",
    "\n",
    "### Rollback Mechanisms\n",
    "\n",
    "Edge rollbacks must succeed without cloud connectivity:\n",
    "\n",
    "**Local Helm Rollback:**\n",
    "```bash\n",
    "# Store last 3 revisions locally on device\n",
    "helm rollback edge-app 2 --namespace retail\n",
    "\n",
    "# Or use K3s etcd snapshots for full system restore\n",
    "k3s etcd-snapshot restore --snapshot-retention=3\n",
    "```\n",
    "\n",
    "**Blue/Green at Edge:**\n",
    "Maintain two partitions (A/B) on edge storage:\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "spec:\n",
    "  containers:\n",
    "  - name: app\n",
    "    image: registry.company.com/edge-app:stable  # Partition A\n",
    "    volumeMounts:\n",
    "    - name: rollback-volume\n",
    "      mountPath: /backup\n",
    "  - name: watchdog\n",
    "    image: watchdog:latest\n",
    "    env:\n",
    "    - name: ROLLBACK_COMMAND\n",
    "      value: \"kubectl set image deployment/app app=registry.company.com/edge-app:previous\"\n",
    "```\n",
    "\n",
    "## 62.8 Observability in Edge Environments\n",
    "\n",
    "Centralized monitoring fails when edges disconnect. Observability must be resilient, storing metrics locally and batching uploads during connectivity windows.\n",
    "\n",
    "### Edge-Native Monitoring\n",
    "\n",
    "**Prometheus Remote Write with Buffering:**\n",
    "```yaml\n",
    "# Prometheus configuration for edge\n",
    "remote_write:\n",
    "  - url: https://prometheus.company.com/api/v1/write\n",
    "    queue_config:\n",
    "      max_samples_per_send: 100  # Small batches for intermittent links\n",
    "      max_shards: 2\n",
    "      capacity: 2500\n",
    "    write_relabel_configs:\n",
    "      - source_labels: [__name__]\n",
    "        regex: 'edge_.*'\n",
    "        action: keep  # Only forward edge-specific metrics\n",
    "```\n",
    "\n",
    "**Grafana Agent (Lightweight):**\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: DaemonSet\n",
    "metadata:\n",
    "  name: grafana-agent\n",
    "spec:\n",
    "  template:\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: agent\n",
    "        image: grafana/agent:v0.39.0\n",
    "        args:\n",
    "        - -config.file=/etc/agent/agent.yaml\n",
    "        - -enable-features=remote-configs\n",
    "        volumeMounts:\n",
    "        - name: wal\n",
    "          mountPath: /var/lib/agent\n",
    "      volumes:\n",
    "      - name: wal\n",
    "        hostPath:\n",
    "          path: /opt/agent-wal  # Persist across restarts\n",
    "```\n",
    "\n",
    "### Distributed Tracing with Batching\n",
    "\n",
    "```yaml\n",
    "# OpenTelemetry Collector for edge\n",
    "apiVersion: opentelemetry.io/v1alpha1\n",
    "kind: OpenTelemetryCollector\n",
    "metadata:\n",
    "  name: edge-collector\n",
    "spec:\n",
    "  mode: deployment\n",
    "  config: |\n",
    "    receivers:\n",
    "      otlp:\n",
    "        protocols:\n",
    "          grpc:\n",
    "            endpoint: 0.0.0.0:4317\n",
    "    processors:\n",
    "      batch:\n",
    "        timeout: 60s  # Batch for 60s or until connection available\n",
    "        send_batch_size: 1024\n",
    "      resource:\n",
    "        attributes:\n",
    "        - key: edge.site\n",
    "          value: store-123\n",
    "          action: upsert\n",
    "    exporters:\n",
    "      otlphttp:\n",
    "        endpoint: https://tempo.company.com\n",
    "        tls:\n",
    "          insecure: false\n",
    "      file:  # Local backup if cloud unreachable\n",
    "        path: /var/log/traces/backup.json\n",
    "    service:\n",
    "      pipelines:\n",
    "        traces:\n",
    "          receivers: [otlp]\n",
    "          processors: [batch, resource]\n",
    "          exporters: [otlphttp, file]\n",
    "```\n",
    "\n",
    "### Log Shipping with Fluent Bit\n",
    "\n",
    "Lightweight log processor optimized for edge:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: fluent-bit-config\n",
    "data:\n",
    "  fluent-bit.conf: |\n",
    "    [INPUT]\n",
    "        Name              tail\n",
    "        Tag               edge.app\n",
    "        Path              /var/log/containers/*.log\n",
    "        Parser            docker\n",
    "        Mem_Buf_Limit     5MB  # Memory limit for buffering\n",
    "    \n",
    "    [OUTPUT]\n",
    "        Name              forward\n",
    "        Match             *\n",
    "        Host              cloud-aggregator.company.com\n",
    "        Port              24224\n",
    "        tls               On\n",
    "        tls.verify        On\n",
    "        Retry_Limit       10\n",
    "        storage.total_limit_size  100M  # Disk buffer when offline\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary and Preview\n",
    "\n",
    "This chapter explored the unique challenges of extending CI/CD pipelines to edge computing environments, where resource constraints, intermittent connectivity, and physical security concerns dominate architectural decisions. We established that lightweight Kubernetes distributions\u2014K3s, MicroK8s, and K3os\u2014enable container orchestration on hardware as minimal as ARM64 single-board computers with 512MB RAM, replacing etcd with SQLite and eliminating control plane overhead.\n",
    "\n",
    "Container optimization emerged as critical for bandwidth-constrained deployment, requiring multi-architecture builds (amd64, arm64, arm/v7), distroless base images reducing footprints from 100MB to 5MB, and layer caching strategies to maximize reuse across fleet updates. GitOps patterns adapted for edge tolerate intermittent connectivity through asynchronous reconciliation agents (Flux, ArgoCD) running locally on devices, with regional hub caches reducing redundant data transfer across cellular networks.\n",
    "\n",
    "Delta update mechanisms\u2014including OSTree for atomic OS updates, Zstd compression for image layers, and eStargz lazy pulling\u2014minimize bandwidth consumption when pushing updates to thousands of geographically distributed devices. Security postures for edge require hardware-backed identity (TPM attestation, SPIFFE/SPIRE short-lived certificates), mutual TLS with automated rotation, and admission controllers verifying image signatures before execution on physically accessible hardware.\n",
    "\n",
    "A/B testing strategies at the edge emphasize geographic isolation and conservative canary percentages (10-30% vs 50%+ in cloud), with local health verification and automatic rollback capabilities that function autonomously during cloud partitions. Observability shifts to store-and-forward architectures, with Prometheus remote write buffering, OpenTelemetry trace batching, and Fluent Bit log shipping designed to survive extended offline periods without data loss.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Use K3s for edge Kubernetes due to its SQLite backend and ARM support; disable Traefik and metrics-server if not required to save resources\n",
    "- Build multi-arch images using docker buildx with distroless or scratch bases to minimize pull times and storage on edge devices\n",
    "- Implement regional registry caches to serve image layers locally, reducing cellular bandwidth costs by 90%+\n",
    "- Never rely on continuous cloud connectivity; design GitOps agents to reconcile from local Git mirrors or cached states during partitions\n",
    "- Enforce image signing (Cosign, Notary) with admission control; edge devices are physically accessible and high-risk for tampering\n",
    "- Use short-lived certificates (24-hour TTL) with automatic rotation via cert-manager or SPIRE; compromise of edge credentials must not grant long-term access\n",
    "- Implement blue/green partitions on edge storage for instant rollback without network dependency\n",
    "- Buffer all observability data (metrics, logs, traces) to local disk with size limits to prevent storage exhaustion during extended outages\n",
    "\n",
    "**Next Chapter Preview:**\n",
    "This completes Part XII: Advanced Topics. The following section, Part XI: Real-World Projects, transitions from theoretical concepts to practical implementation through four comprehensive projects. Project 1: Simple Web Application CI/CD will guide you through building a complete pipeline for a containerized web application using GitHub Actions, Docker, and Kubernetes. Project 2: Microservices Architecture demonstrates service mesh implementation with Istio, distributed tracing, and canary deployments across multiple services. Project 3: Multi-Environment Enterprise Application covers Helm charts, GitOps with ArgoCD, security hardening, and disaster recovery for a production-grade deployment. Project 4: Database-Intensive Application focuses on stateful workload management, database migration strategies, and backup automation within CI/CD pipelines. These projects synthesize the principles covered throughout this handbook into actionable, industry-standard implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='61. mobile_app_cicd.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <span style='color:gray; font-size:1.05em;'>Next</span>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}