{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 45: Distributed Tracing\n",
    "\n",
    "While metrics reveal what is happening (high latency, error rates) and logs reveal why (error messages, stack traces), distributed tracing reveals where latency originates in complex, multi-service requests. When a user clicks \"Checkout\" on an e-commerce site, the request may traverse the API Gateway → Authentication Service → Cart Service → Inventory Service → Payment Service → Notification Service → Email Provider. A 500ms delay observed in metrics could originate in any of these hops, or in the network between them. Distributed tracing captures the complete request journey, breaking it into spans—timed operations representing individual units of work—connected by a trace ID that binds them into a single logical transaction.\n",
    "\n",
    "This chapter explores OpenTelemetry, the emerging industry standard for telemetry instrumentation, covering trace propagation across service boundaries, sampling strategies that balance observability overhead with data volume, and visualization tools that transform span data into actionable latency analysis.\n",
    "\n",
    "## 45.1 OpenTelemetry Fundamentals\n",
    "\n",
    "OpenTelemetry (OTel) is a Cloud Native Computing Foundation (CNCF) project that provides standardized APIs, libraries, agents, and collector services for capturing distributed traces, metrics, and logs. It supersedes previous standards like OpenTracing and OpenCensus, offering a unified, vendor-neutral instrumentation layer.\n",
    "\n",
    "### Architecture Components\n",
    "\n",
    "**API and SDK**\n",
    "The OpenTelemetry API defines interfaces for creating spans, adding attributes, and propagating context. The SDK implements these interfaces, handling batching, sampling, and export configuration. Applications depend only on the API, while operators configure the SDK via environment variables or code.\n",
    "\n",
    "**Instrumentation Libraries**\n",
    "Auto-instrumentation agents (Java agent, Python auto-instrumentation) attach to frameworks (Spring Boot, Django, Express) without code changes, automatically creating spans for HTTP requests, database queries, and message queue operations.\n",
    "\n",
    "**Collector**\n",
    "The OpenTelemetry Collector receives telemetry data (traces, metrics, logs), processes it (batching, filtering, enriching), and exports it to backends (Jaeger, Zipkin, Prometheus, commercial vendors). It operates as an agent (sidecar or DaemonSet) or gateway (cluster-wide service).\n",
    "\n",
    "**Protocol (OTLP)**\n",
    "The OpenTelemetry Protocol defines a standardized wire format for telemetry data, supporting gRPC and HTTP/protobuf or HTTP/JSON transports.\n",
    "\n",
    "### Java Auto-Instrumentation\n",
    "\n",
    "```java\n",
    "// No code changes required for basic tracing\n",
    "// Add JVM argument:\n",
    "// -javaagent:opentelemetry-javaagent.jar \\\n",
    "// -Dotel.service.name=payment-service \\\n",
    "// -Dotel.traces.exporter=otlp \\\n",
    "// -Dotel.exporter.otlp.endpoint=http://otel-collector:4317\n",
    "\n",
    "// Custom span for business logic\n",
    "import io.opentelemetry.api.GlobalOpenTelemetry;\n",
    "import io.opentelemetry.api.trace.Span;\n",
    "import io.opentelemetry.api.trace.Tracer;\n",
    "import io.opentelemetry.context.Scope;\n",
    "\n",
    "@Service\n",
    "public class PaymentProcessor {\n",
    "    private final Tracer tracer;\n",
    "    \n",
    "    public PaymentProcessor() {\n",
    "        // Get tracer from global singleton\n",
    "        this.tracer = GlobalOpenTelemetry.getTracer(\"payment-service\", \"1.0.0\");\n",
    "    }\n",
    "    \n",
    "    public PaymentResult processPayment(PaymentRequest request) {\n",
    "        // Create a span representing this operation\n",
    "        Span span = tracer.spanBuilder(\"process-payment\")\n",
    "            .setAttribute(\"payment.id\", request.getPaymentId())\n",
    "            .setAttribute(\"payment.amount\", request.getAmount().doubleValue())\n",
    "            .setAttribute(\"payment.currency\", request.getCurrency())\n",
    "            .setAttribute(\"user.id\", request.getUserId())\n",
    "            .startSpan();\n",
    "        \n",
    "        // Make this span the current span in this thread's context\n",
    "        try (Scope scope = span.makeCurrent()) {\n",
    "            \n",
    "            // Add events (timestamps with descriptions)\n",
    "            span.addEvent(\"Validating payment request\");\n",
    "            validateRequest(request);\n",
    "            \n",
    "            span.addEvent(\"Reserving inventory\");\n",
    "            inventoryService.reserve(request.getItems());\n",
    "            \n",
    "            span.addEvent(\"Processing charge\");\n",
    "            ChargeResult charge = paymentGateway.charge(request);\n",
    "            \n",
    "            span.setAttribute(\"payment.status\", charge.getStatus());\n",
    "            span.setAttribute(\"payment.gateway_transaction_id\", charge.getTransactionId());\n",
    "            \n",
    "            if (charge.isSuccessful()) {\n",
    "                span.setStatus(StatusCode.OK);\n",
    "            } else {\n",
    "                span.setStatus(StatusCode.ERROR, \"Payment declined: \" + charge.getDeclineReason());\n",
    "            }\n",
    "            \n",
    "            return new PaymentResult(charge);\n",
    "            \n",
    "        } catch (Exception e) {\n",
    "            // Record exception with stack trace\n",
    "            span.recordException(e);\n",
    "            span.setStatus(StatusCode.ERROR, \"Payment processing failed\");\n",
    "            throw e;\n",
    "        } finally {\n",
    "            // End span (records duration)\n",
    "            span.end();\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "- **GlobalOpenTelemetry**: Access point to the configured SDK. In auto-instrumentation, this is initialized by the Java agent using environment variables.\n",
    "- **Tracer**: Creates spans. The instrumentation scope name (\"payment-service\") identifies which library generated the spans.\n",
    "- **SpanBuilder**: Configures the span before creation. Attributes added here are key-value pairs (string, number, boolean) attached to the span.\n",
    "- **makeCurrent()**: Places the span in thread-local storage so child operations (HTTP calls, database queries) automatically create child spans linked to this parent.\n",
    "- **Scope**: Auto-closable resource that removes the span from context when done (try-with-resources ensures cleanup even on exceptions).\n",
    "- **Events**: Timestamped annotations within the span timeline, useful for marking sub-operations.\n",
    "- **Status**: Explicit success/error indication. Errors include descriptions and optionally stack traces.\n",
    "\n",
    "### Manual Context Propagation\n",
    "\n",
    "When crossing asynchronous boundaries or non-standard transports:\n",
    "\n",
    "```java\n",
    "import io.opentelemetry.context.Context;\n",
    "\n",
    "@Service\n",
    "public class AsyncPaymentProcessor {\n",
    "    \n",
    "    public CompletableFuture<PaymentResult> processAsync(PaymentRequest request) {\n",
    "        // Capture current context (contains current span if any)\n",
    "        Context parentContext = Context.current();\n",
    "        \n",
    "        return CompletableFuture.supplyAsync(() -> {\n",
    "            // Wrap runnable with parent context\n",
    "            try (Scope scope = parentContext.makeCurrent()) {\n",
    "                // Now inside the async thread, context is restored\n",
    "                // Any spans created here will be children of the parent\n",
    "                return processPayment(request);\n",
    "            }\n",
    "        });\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "When using `CompletableFuture` or thread pools, the `Context` doesn't automatically propagate across threads (unlike `ThreadLocal`). The parent context must be captured before the async operation and explicitly made current in the new thread. This ensures trace continuity across asynchronous boundaries.\n",
    "\n",
    "### Python Instrumentation\n",
    "\n",
    "```python\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.resources import SERVICE_NAME, Resource\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "\n",
    "# Configure SDK\n",
    "resource = Resource(attributes={SERVICE_NAME: \"order-service\"})\n",
    "provider = TracerProvider(resource=resource)\n",
    "processor = BatchSpanProcessor(OTLPSpanExporter(endpoint=\"otel-collector:4317\"))\n",
    "provider.add_span_processor(processor)\n",
    "trace.set_tracer_provider(provider)\n",
    "\n",
    "tracer = trace.get_tracer(\"order-service\", \"1.0.0\")\n",
    "\n",
    "class OrderService:\n",
    "    def create_order(self, request):\n",
    "        # Create span\n",
    "        with tracer.start_as_current_span(\"create-order\") as span:\n",
    "            # Set attributes\n",
    "            span.set_attribute(\"order.id\", request.order_id)\n",
    "            span.set_attribute(\"user.id\", request.user_id)\n",
    "            span.set_attribute(\"item.count\", len(request.items))\n",
    "            \n",
    "            # Add event\n",
    "            span.add_event(\"Validating inventory\")\n",
    "            \n",
    "            try:\n",
    "                # This HTTP call will be auto-instrumented if using requests instrumentation\n",
    "                response = self.inventory_client.check_availability(request.items)\n",
    "                \n",
    "                span.set_attribute(\"inventory.available\", response.available)\n",
    "                \n",
    "                if not response.available:\n",
    "                    span.set_status(trace.Status(trace.StatusCode.ERROR, \"Items out of stock\"))\n",
    "                    raise OutOfStockError()\n",
    "                \n",
    "                span.add_event(\"Creating order record\")\n",
    "                order = self.db.save_order(request)\n",
    "                \n",
    "                span.set_attribute(\"order.total\", float(order.total))\n",
    "                span.set_status(trace.Status(trace.StatusCode.OK))\n",
    "                \n",
    "                return order\n",
    "                \n",
    "            except Exception as e:\n",
    "                span.record_exception(e)\n",
    "                span.set_status(trace.Status(trace.StatusCode.ERROR, str(e)))\n",
    "                raise\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "The Python SDK uses context managers (`with` statement) for span lifecycle management. `start_as_current_span` automatically makes the span current in the context manager scope. Attributes use snake_case by convention in Python.\n",
    "\n",
    "## 45.2 Trace Context Propagation\n",
    "\n",
    "For distributed traces to span multiple services, trace context must propagate across network boundaries via standardized headers.\n",
    "\n",
    "### W3C Trace Context\n",
    "\n",
    "The W3C standard defines two headers:\n",
    "- `traceparent`: Describes the incoming request's position in the trace (trace ID, span ID, flags)\n",
    "- `tracestate**: Vendor-specific extensions\n",
    "\n",
    "**Traceparent Format:**\n",
    "```\n",
    "version-trace_id-span_id-flags\n",
    "00-0af7651916cd43dd8448eb211c80319c-b7ad6b7169203331-01\n",
    "```\n",
    "\n",
    "**Breakdown:**\n",
    "- `00`: Version\n",
    "- `0af7651916cd43dd8448eb211c80319c`: 16-byte hex trace ID (unique request identifier)\n",
    "- `b7ad6b7169203331`: 16-byte hex span ID (current operation identifier)\n",
    "- `01`: Flags (bit 0 = sampled)\n",
    "\n",
    "### HTTP Client Propagation\n",
    "\n",
    "**Java (Spring WebClient):**\n",
    "```java\n",
    "import io.opentelemetry.api.GlobalOpenTelemetry;\n",
    "import io.opentelemetry.context.propagation.ContextPropagators;\n",
    "import io.opentelemetry.context.propagation.TextMapPropagator;\n",
    "import org.springframework.web.reactive.function.client.ClientRequest;\n",
    "import org.springframework.web.reactive.function.client.WebClient;\n",
    "\n",
    "@Service\n",
    "public class PaymentClient {\n",
    "    private final WebClient webClient;\n",
    "    private final TextMapPropagator propagator;\n",
    "    \n",
    "    public PaymentClient(WebClient.Builder builder) {\n",
    "        this.webClient = builder.baseUrl(\"http://payment-service\").build();\n",
    "        // Get W3C propagator from global configuration\n",
    "        this.propagator = GlobalOpenTelemetry.getPropagators().getTextMapPropagator();\n",
    "    }\n",
    "    \n",
    "    public Mono<PaymentResult> charge(PaymentRequest request) {\n",
    "        return webClient.post()\n",
    "            .uri(\"/charge\")\n",
    "            .bodyValue(request)\n",
    "            .httpRequest(httpRequest -> {\n",
    "                // Inject current context into HTTP headers\n",
    "                propagator.inject(\n",
    "                    Context.current(),\n",
    "                    httpRequest.getHeaders(),\n",
    "                    (carrier, key, value) -> carrier.add(key, value)\n",
    "                );\n",
    "            })\n",
    "            .retrieve()\n",
    "            .bodyToMono(PaymentResult.class);\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "The `inject` method takes the current context (containing the active span), the carrier (HTTP headers), and a setter function that knows how to add headers to the carrier. This adds `traceparent` and `tracestate` headers to the outgoing HTTP request. The downstream service extracts these headers to continue the trace.\n",
    "\n",
    "### HTTP Server Extraction\n",
    "\n",
    "```java\n",
    "import io.opentelemetry.api.trace.Span;\n",
    "import io.opentelemetry.api.trace.SpanKind;\n",
    "import io.opentelemetry.context.Context;\n",
    "import io.opentelemetry.context.propagation.TextMapGetter;\n",
    "import org.springframework.stereotype.Component;\n",
    "\n",
    "import javax.servlet.Filter;\n",
    "import javax.servlet.FilterChain;\n",
    "import javax.servlet.ServletException;\n",
    "import javax.servlet.ServletRequest;\n",
    "import javax.servlet.ServletResponse;\n",
    "import javax.servlet.http.HttpServletRequest;\n",
    "import java.io.IOException;\n",
    "\n",
    "@Component\n",
    "public class TracingFilter implements Filter {\n",
    "    private final TextMapPropagator propagator;\n",
    "    \n",
    "    public TracingFilter() {\n",
    "        this.propagator = GlobalOpenTelemetry.getPropagators().getTextMapPropagator();\n",
    "    }\n",
    "    \n",
    "    @Override\n",
    "    public void doFilter(ServletRequest request, ServletResponse response, \n",
    "                        FilterChain chain) throws IOException, ServletException {\n",
    "        \n",
    "        HttpServletRequest httpRequest = (HttpServletRequest) request;\n",
    "        \n",
    "        // Extract context from incoming headers\n",
    "        Context extractedContext = propagator.extract(\n",
    "            Context.current(),\n",
    "            httpRequest,\n",
    "            new TextMapGetter<HttpServletRequest>() {\n",
    "                @Override\n",
    "                public Iterable<String> keys(HttpServletRequest carrier) {\n",
    "                    return Collections.list(carrier.getHeaderNames());\n",
    "                }\n",
    "                \n",
    "                @Override\n",
    "                public String get(HttpServletRequest carrier, String key) {\n",
    "                    return carrier.getHeader(key);\n",
    "                }\n",
    "            }\n",
    "        );\n",
    "        \n",
    "        // Create a new span as child of extracted context\n",
    "        Span span = GlobalOpenTelemetry.getTracer(\"order-service\")\n",
    "            .spanBuilder(httpRequest.getRequestURI())\n",
    "            .setParent(extractedContext)\n",
    "            .setSpanKind(SpanKind.SERVER)\n",
    "            .setAttribute(\"http.method\", httpRequest.getMethod())\n",
    "            .setAttribute(\"http.url\", httpRequest.getRequestURL().toString())\n",
    "            .startSpan();\n",
    "        \n",
    "        try (Scope scope = span.makeCurrent()) {\n",
    "            chain.doFilter(request, response);\n",
    "        } finally {\n",
    "            span.end();\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "The server extracts the `traceparent` header using the getter interface. `extractedContext` contains the parent span ID from the upstream service. The new span created is a child of that parent, linking them in the trace hierarchy. `SpanKind.SERVER` indicates this is an incoming request handling span.\n",
    "\n",
    "### Message Queue Propagation (Kafka)\n",
    "\n",
    "```java\n",
    "import org.apache.kafka.clients.producer.ProducerRecord;\n",
    "import io.opentelemetry.api.GlobalOpenTelemetry;\n",
    "\n",
    "@Service\n",
    "public class EventPublisher {\n",
    "    private final KafkaTemplate<String, String> kafkaTemplate;\n",
    "    private final TextMapPropagator propagator;\n",
    "    \n",
    "    public void publishOrderCreated(Order order) {\n",
    "        ProducerRecord<String, String> record = new ProducerRecord<>(\n",
    "            \"orders.created\", \n",
    "            order.getId(), \n",
    "            toJson(order)\n",
    "        );\n",
    "        \n",
    "        // Inject context into Kafka headers\n",
    "        propagator.inject(\n",
    "            Context.current(),\n",
    "            record.headers(),\n",
    "            (headers, key, value) -> headers.add(key, value.getBytes(StandardCharsets.UTF_8))\n",
    "        );\n",
    "        \n",
    "        kafkaTemplate.send(record);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Consumer side\n",
    "@KafkaListener(topics = \"orders.created\")\n",
    "public void handleOrderCreated(ConsumerRecord<String, String> record) {\n",
    "    // Extract from Kafka headers\n",
    "    Context extractedContext = propagator.extract(\n",
    "        Context.current(),\n",
    "        record.headers(),\n",
    "        new TextMapGetter<Headers>() {\n",
    "            @Override\n",
    "            public String get(Headers headers, String key) {\n",
    "                Header header = headers.lastHeader(key);\n",
    "                return header != null ? new String(header.value(), StandardCharsets.UTF_8) : null;\n",
    "            }\n",
    "            \n",
    "            @Override\n",
    "            public Iterable<String> keys(Headers headers) {\n",
    "                List<String> keys = new ArrayList<>();\n",
    "                headers.forEach(h -> keys.add(h.key()));\n",
    "                return keys;\n",
    "            }\n",
    "        }\n",
    "    );\n",
    "    \n",
    "    // Create span continuing the trace\n",
    "    Span span = tracer.spanBuilder(\"process-order-event\")\n",
    "        .setParent(extractedContext)\n",
    "        .setAttribute(\"kafka.topic\", record.topic())\n",
    "        .setAttribute(\"kafka.partition\", record.partition())\n",
    "        .setAttribute(\"kafka.offset\", record.offset())\n",
    "        .startSpan();\n",
    "    \n",
    "    try (Scope scope = span.makeCurrent()) {\n",
    "        processOrder(record.value());\n",
    "    } finally {\n",
    "        span.end();\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "Kafka headers (supported in 0.11+) carry trace context. The producer injects context into headers; the consumer extracts it. This maintains trace continuity even across asynchronous message queues, ensuring that an order created in the HTTP request trace continues into the background processing trace.\n",
    "\n",
    "## 45.3 Sampling Strategies\n",
    "\n",
    "Tracing every request in high-throughput systems (10,000+ RPS) generates prohibitive data volumes and costs. Sampling reduces data volume while maintaining statistical representativeness.\n",
    "\n",
    "### Head-Based Sampling\n",
    "\n",
    "The sampling decision is made at the start of the trace and propagated to all child spans.\n",
    "\n",
    "**Configuration:**\n",
    "```yaml\n",
    "# otel-collector-config.yaml\n",
    "processors:\n",
    "  probabilistic_sampler:\n",
    "    sampling_percentage: 10.0  # Sample 10% of traces\n",
    "    hash_seed: 22\n",
    "    \n",
    "  tail_sampling:  # Requires waiting for spans, more complex\n",
    "    decision_wait: 10s\n",
    "    num_traces: 100\n",
    "    expected_new_traces_per_sec: 10\n",
    "    policies:\n",
    "      - name: errors\n",
    "        type: status_code\n",
    "        status_code: {status_codes: [ERROR]}\n",
    "      - name: slow_requests\n",
    "        type: latency\n",
    "        latency: {threshold_ms: 1000}\n",
    "```\n",
    "\n",
    "**Environment Variables:**\n",
    "```bash\n",
    "# Java application\n",
    "export OTEL_TRACES_SAMPLER=traceidratio\n",
    "export OTEL_TRACES_SAMPLER_ARG=0.1  # 10% sampling\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "Head-based sampling is efficient (decision made once, no buffering required) but may miss interesting traces. If you sample based on trace ID hash, and the error happens only in specific trace IDs, you might miss all errors. However, it's stateless and suitable for most high-volume scenarios.\n",
    "\n",
    "### Tail-Based Sampling\n",
    "\n",
    "The sampling decision is made after the trace completes, based on full trace characteristics (errors, latency).\n",
    "\n",
    "```yaml\n",
    "# OpenTelemetry Collector configuration\n",
    "processors:\n",
    "  tail_sampling:\n",
    "    decision_wait: 10s  # Wait for spans to arrive\n",
    "    num_traces: 100000  # Buffer size\n",
    "    expected_new_traces_per_sec: 1000\n",
    "    \n",
    "    policies:\n",
    "      # Sample all errors\n",
    "      - name: errors\n",
    "        type: status_code\n",
    "        status_code: {status_codes: [ERROR]}\n",
    "        \n",
    "      # Sample slow traces (>1s)\n",
    "      - name: slow\n",
    "        type: latency\n",
    "        latency: {threshold_ms: 1000}\n",
    "        \n",
    "      # Sample specific operations\n",
    "      - name: important_ops\n",
    "        type: string_attribute\n",
    "        string_attribute:\n",
    "          key: http.route\n",
    "          values: [\"/api/v1/payments\", \"/api/v1/orders\"]\n",
    "          enabled_regex_matching: false\n",
    "          \n",
    "      # Probabilistic for remainder\n",
    "      - name: probabilistic\n",
    "        type: probabilistic\n",
    "        probabilistic: {sampling_percentage: 5}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "Tail-based sampling buffers spans for `decision_wait` seconds, then evaluates policies. If any policy matches (error occurred, latency > 1s, specific route), the entire trace is kept; otherwise, it's dropped. This captures 100% of errors while sampling healthy traffic at 5%. The trade-off is memory usage (buffering spans) and slight delay in export.\n",
    "\n",
    "### Parent-Based Sampling\n",
    "\n",
    "Respect the parent's sampling decision:\n",
    "\n",
    "```java\n",
    "// If parent span was sampled, sample this span\n",
    "// If parent was not sampled, don't sample this span\n",
    "Tracer tracer = GlobalOpenTelemetry.getTracer(\"service\");\n",
    "Span span = tracer.spanBuilder(\"child-operation\")\n",
    "    .setParent(parentContext)\n",
    "    .setAttribute(\"sampling.priority\", 10)  // Hint for some samplers\n",
    "    .startSpan();\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "Ensures trace consistency—all spans in a trace are either sampled or not. Without this, you might have a root span sampled but child spans dropped, resulting in broken traces in the backend.\n",
    "\n",
    "## 45.4 Baggage\n",
    "\n",
    "Baggage carries user-defined key-value pairs across service boundaries alongside trace context, useful for propagating tenant IDs, feature flags, or user context without adding to every function parameter.\n",
    "\n",
    "### Setting and Propagating Baggage\n",
    "\n",
    "```java\n",
    "import io.opentelemetry.api.baggage.Baggage;\n",
    "import io.opentelemetry.api.baggage.BaggageEntry;\n",
    "\n",
    "// In the API Gateway (entry point)\n",
    "public void handleRequest(HttpServletRequest request) {\n",
    "    // Extract tenant from JWT or header\n",
    "    String tenantId = extractTenant(request);\n",
    "    String featureFlag = request.getHeader(\"X-Feature-Flag\");\n",
    "    \n",
    "    // Create baggage\n",
    "    Baggage baggage = Baggage.builder()\n",
    "        .put(\"tenant.id\", tenantId)\n",
    "        .put(\"tenant.tier\", getTenantTier(tenantId))\n",
    "        .put(\"feature.new_checkout\", featureFlag)\n",
    "        .build();\n",
    "    \n",
    "    // Make baggage current (stored in context)\n",
    "    try (Scope baggageScope = baggage.makeCurrent()) {\n",
    "        // Process request - baggage automatically propagates\n",
    "        processRequest(request);\n",
    "    }\n",
    "}\n",
    "\n",
    "// In downstream service (automatically receives baggage)\n",
    "public void chargePayment(PaymentRequest request) {\n",
    "    // Access baggage without explicit parameter passing\n",
    "    Baggage baggage = Baggage.current();\n",
    "    String tenantId = baggage.getEntryValue(\"tenant.id\");\n",
    "    String tier = baggage.getEntryValue(\"tenant.tier\");\n",
    "    \n",
    "    // Add to span for filtering/analysis\n",
    "    Span.current().setAttribute(\"tenant.id\", tenantId);\n",
    "    Span.current().setAttribute(\"tenant.tier\", tier);\n",
    "    \n",
    "    // Use for business logic\n",
    "    if (\"enterprise\".equals(tier)) {\n",
    "        // Priority processing\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "Baggage is separate from span attributes—it travels with the context across process boundaries via the same propagation mechanism as trace context (W3C baggage header). Unlike span attributes which describe the operation, baggage describes the request context (who is making the request, what features are enabled).\n",
    "\n",
    "**Propagation Format:**\n",
    "```\n",
    "Baggage: tenant.id=acme-corp,tenant.tier=enterprise,feature.new_checkout=enabled\n",
    "```\n",
    "\n",
    "### Python Baggage Example\n",
    "\n",
    "```python\n",
    "from opentelemetry import baggage\n",
    "from opentelemetry.propagate import extract, inject, set_global_textmap\n",
    "from opentelemetry.propagators.b3 import B3Format\n",
    "\n",
    "# Set baggage\n",
    "ctx = baggage.set_baggage(\"tenant.id\", \"12345\")\n",
    "ctx = baggage.set_baggage(\"user.type\", \"premium\", context=ctx)\n",
    "\n",
    "# Make current\n",
    "token = context.attach(ctx)\n",
    "\n",
    "try:\n",
    "    # HTTP call automatically includes baggage headers\n",
    "    response = requests.get(\"http://downstream-service/api\", \n",
    "                          headers=inject_current_context())\n",
    "finally:\n",
    "    context.detach(token)\n",
    "\n",
    "# In downstream service\n",
    "current_baggage = baggage.get_baggage(\"tenant.id\")\n",
    "span.set_attribute(\"tenant.id\", current_baggage)\n",
    "```\n",
    "\n",
    "## 45.5 Correlation with Logs and Metrics\n",
    "\n",
    "### Trace ID in Logs\n",
    "\n",
    "Ensure every log entry includes the trace ID for correlation:\n",
    "\n",
    "```java\n",
    "// Logback configuration (logback-spring.xml)\n",
    "<appender name=\"JSON_CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\">\n",
    "    <encoder class=\"net.logstash.logback.encoder.LogstashEncoder\">\n",
    "        <includeMdc>true</includeMdc>\n",
    "        <provider class=\"net.logstash.logback.composite.loggingevent.MdcJsonProvider\">\n",
    "            <includeMdcKeyName>trace_id</includeMdcKeyName>\n",
    "            <includeMdcKeyName>span_id</includeMdcKeyName>\n",
    "        </provider>\n",
    "    </encoder>\n",
    "</appender>\n",
    "\n",
    "// Code to ensure trace context is in MDC\n",
    "import io.opentelemetry.api.trace.Span;\n",
    "import io.opentelemetry.api.trace.SpanContext;\n",
    "import org.slf4j.MDC;\n",
    "\n",
    "public class TraceContextFilter implements Filter {\n",
    "    @Override\n",
    "    public void doFilter(ServletRequest request, ServletResponse response, \n",
    "                        FilterChain chain) throws IOException, ServletException {\n",
    "        \n",
    "        SpanContext spanContext = Span.current().getSpanContext();\n",
    "        \n",
    "        if (spanContext.isValid()) {\n",
    "            MDC.put(\"trace_id\", spanContext.getTraceId());\n",
    "            MDC.put(\"span_id\", spanContext.getSpanId());\n",
    "            MDC.put(\"trace_flags\", spanContext.getTraceFlags().toString());\n",
    "        }\n",
    "        \n",
    "        try {\n",
    "            chain.doFilter(request, response);\n",
    "        } finally {\n",
    "            MDC.remove(\"trace_id\");\n",
    "            MDC.remove(\"span_id\");\n",
    "            MDC.remove(\"trace_flags\");\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "The filter extracts the trace ID from the current OpenTelemetry span and places it in MDC (Mapped Diagnostic Context). Logback's JSON encoder includes MDC fields in the log output. Now logs and traces are linked: find a slow trace ID in Jaeger, search for that ID in Kibana/Loki to see application logs for that exact request.\n",
    "\n",
    "### Exemplars (Trace-Metric Link)\n",
    "\n",
    "Exemplars link metrics to example traces:\n",
    "\n",
    "```java\n",
    "// Micrometer with OpenTelemetry integration\n",
    "import io.micrometer.core.instrument.Timer;\n",
    "import io.micrometer.core.instrument.MeterRegistry;\n",
    "\n",
    "@Component\n",
    "public class PaymentMetrics {\n",
    "    private final Timer paymentTimer;\n",
    "    \n",
    "    public PaymentMetrics(MeterRegistry registry) {\n",
    "        this.paymentTimer = Timer.builder(\"payment.duration\")\n",
    "            .description(\"Payment processing time\")\n",
    "            .register(registry);\n",
    "    }\n",
    "    \n",
    "    public void recordPayment(PaymentRequest request, long durationMs) {\n",
    "        // Micrometer automatically attaches current span context as exemplar\n",
    "        paymentTimer.record(durationMs, TimeUnit.MILLISECONDS);\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Prometheus Configuration:**\n",
    "```yaml\n",
    "# Enable exemplars in Prometheus\n",
    "storage:\n",
    "  tsdb:\n",
    "    exemplars:\n",
    "      max_size: 10000000\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "When Prometheus scrapes the `/actuator/prometheus` endpoint, Micrometer includes exemplars—references to specific trace IDs that contributed to the metric value. In Grafana, when viewing a histogram of latency, you can click on a data point and see \"Example Trace\" linking to Jaeger. This bridges aggregated metrics and individual traces.\n",
    "\n",
    "## 45.6 Visualization with Jaeger\n",
    "\n",
    "Jaeger is an open-source distributed tracing system inspired by Google's Dapper.\n",
    "\n",
    "### Jaeger Architecture\n",
    "\n",
    "```\n",
    "Application → OpenTelemetry SDK → OTLP → Jaeger Collector → Storage (Elasticsearch/Cassandra/Badger) → Jaeger Query → Jaeger UI\n",
    "```\n",
    "\n",
    "### Deployment\n",
    "\n",
    "```yaml\n",
    "# jaeger-deployment.yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: jaeger\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: jaeger\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: jaeger\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: jaeger\n",
    "          image: jaegertracing/all-in-one:1.50\n",
    "          env:\n",
    "            - name: COLLECTOR_OTLP_ENABLED\n",
    "              value: \"true\"\n",
    "          ports:\n",
    "            - containerPort: 16686  # UI\n",
    "            - containerPort: 4317   # OTLP gRPC\n",
    "            - containerPort: 4318   # OTLP HTTP\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: jaeger-query\n",
    "spec:\n",
    "  selector:\n",
    "    app: jaeger\n",
    "  ports:\n",
    "    - port: 16686\n",
    "      targetPort: 16686\n",
    "```\n",
    "\n",
    "### Using the Jaeger UI\n",
    "\n",
    "**Trace View:**\n",
    "- **Timeline**: Shows spans horizontally with duration bars. Long bars indicate slow operations.\n",
    "- **Service Dependencies**: Graph showing which services call which others.\n",
    "- **Trace Comparison**: Compare two traces side-by-side to find performance regressions.\n",
    "\n",
    "**Search Query:**\n",
    "```\n",
    "service=payment-service \n",
    "operation=process-payment \n",
    "tags={\"http.status_code\":500} \n",
    "duration>1s \n",
    "start=2024-01-15T10:00:00 \n",
    "end=2024-01-15T11:00:00\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "Search for traces where the payment-service had errors (status 500) and duration > 1 second in a specific time range. The results show the full trace, revealing whether the slowness was in the database (span name \"postgres-query\" duration 900ms) or external API (\"stripe-api\" duration 100ms).\n",
    "\n",
    "## 45.7 Performance Considerations\n",
    "\n",
    "### Overhead Management\n",
    "\n",
    "Tracing adds overhead: CPU for serialization, memory for buffering, network for export.\n",
    "\n",
    "**Optimization Strategies:**\n",
    "\n",
    "```yaml\n",
    "# Batch export configuration\n",
    "exporters:\n",
    "  otlp:\n",
    "    endpoint: otel-collector:4317\n",
    "    timeout: 10s\n",
    "    sending_queue:\n",
    "      enabled: true\n",
    "      num_consumers: 10\n",
    "      queue_size: 1000\n",
    "    retry_on_failure:\n",
    "      enabled: true\n",
    "      initial_interval: 5s\n",
    "      max_interval: 30s\n",
    "      max_elapsed_time: 300s\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "- **Batching**: Export spans in batches (e.g., every 1 second or 512 spans) rather than one-by-one to reduce network calls.\n",
    "- **Queue**: Asynchronous export prevents application blocking if collector is slow.\n",
    "- **Retry**: Handles transient network failures without losing data.\n",
    "\n",
    "### Sampling in High-Throughput Services\n",
    "\n",
    "For services handling 50,000+ RPS:\n",
    "\n",
    "```java\n",
    "// Adaptive sampling based on load\n",
    "Tracer tracer = TracerProvider.builder()\n",
    "    .setSampler(Sampler.traceIdRatioBased(0.01))  // 1% sampling at high load\n",
    "    .build()\n",
    "    .getTracer(\"high-volume-service\");\n",
    "```\n",
    "\n",
    "Or use the OpenTelemetry Collector to sample centrally:\n",
    "\n",
    "```yaml\n",
    "processors:\n",
    "  probabilistic_sampler:\n",
    "    sampling_percentage: 1.0  # Only sample 1% at collector level\n",
    "```\n",
    "\n",
    "### Context Propagation Cost\n",
    "\n",
    "Avoid propagating huge baggage:\n",
    "\n",
    "```java\n",
    "// Bad - large payload in baggage\n",
    "Baggage.builder()\n",
    "    .put(\"user.data\", largeJsonString)  // Don't do this\n",
    "    .build();\n",
    "\n",
    "// Good - minimal context\n",
    "Baggage.builder()\n",
    "    .put(\"user.id\", userId)  // Just the ID\n",
    "    .build();\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "Baggage travels in HTTP headers on every outbound request. Large baggage increases header size, potentially exceeding limits (8KB common in load balancers) and adding latency.\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary and Preview\n",
    "\n",
    "This chapter established distributed tracing as the third pillar of observability, complementing logs and metrics by revealing request flow and latency decomposition across microservices. We examined OpenTelemetry as the unified instrumentation standard, covering the API/SDK separation that allows vendor-neutral instrumentation, auto-instrumentation agents that capture framework-level operations without code changes, and the OpenTelemetry Protocol (OTLP) for efficient data transport.\n",
    "\n",
    "Trace context propagation via W3C Trace Context ensures requests maintain their identity across HTTP calls and message queues, enabling complete request chains from edge to database. We explored head-based sampling for efficient high-volume tracing decisions, tail-based sampling for intelligent retention of error or slow traces, and baggage for propagating business context (tenant IDs, feature flags) without polluting function signatures. The integration of traces with logs (via trace IDs in MDC) and metrics (via exemplars) creates a unified observability experience where quantitative anomalies in metrics lead to representative traces and detailed logs.\n",
    "\n",
    "Visualization tools like Jaeger transform span data into dependency graphs and timelines that make latency bottlenecks immediately visible. Performance considerations including batch export, queue-based asynchronous transmission, and appropriate sampling rates ensure tracing overhead remains below 5% even in high-throughput systems.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Adopt OpenTelemetry for all new instrumentation, using auto-instrumentation agents for existing applications to capture traces without code modification, and manual span creation only for critical business operations requiring custom attributes.\n",
    "- Always propagate W3C Trace Context headers (traceparent) in HTTP clients and message producers; ensure downstream services extract these headers to maintain trace continuity across service boundaries.\n",
    "- Use tail-based sampling in the OpenTelemetry Collector to retain 100% of error traces and slow requests (>1s) while sampling healthy traffic at 1-5%, balancing observability depth with storage costs.\n",
    "- Include trace_id and span_id in structured logs using MDC or equivalent context mechanisms, enabling correlation between traces and logs for root cause analysis.\n",
    "- Use baggage sparingly for lightweight context propagation (tenant IDs, user types), never for large payloads, and always add baggage values to span attributes at service boundaries for searchability.\n",
    "- Configure batch span processors with queue sizes appropriate for your throughput (typically 2048-4096 spans) and export intervals (1-5 seconds) to minimize network overhead while preventing memory pressure.\n",
    "\n",
    "**Next Chapter Preview:**\n",
    "Chapter 46: Debugging CI/CD Pipelines addresses the operational challenges of maintaining complex continuous delivery systems. We will explore strategies for diagnosing pipeline failures, container debugging techniques (exec, debug containers, ephemeral containers), Kubernetes pod troubleshooting (crash loops, image pull errors, resource constraints), network debugging across clusters, and permission issues in CI environments. The chapter covers log aggregation from CI runners, build reproducibility strategies, and tools for tracing pipeline execution across multiple stages and repositories, ensuring that when deployments fail, teams can rapidly identify whether the issue lies in code, configuration, infrastructure, or the pipeline itself."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
