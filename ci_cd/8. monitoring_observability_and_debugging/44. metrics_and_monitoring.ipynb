{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 44: Metrics and Monitoring\n",
    "\n",
    "Metrics provide quantitative insight into system behavior, transforming qualitative observations (\"the system seems slow\") into measurable data points that drive automated alerting and capacity planning. Unlike logs that describe discrete events, metrics represent time-series data—numerical values collected at regular intervals that reveal trends, patterns, and anomalies across distributed systems. Effective monitoring strategies distinguish between infrastructure metrics (CPU, memory, disk), application metrics (request latency, error rates, business KPIs), and client-side metrics (real user monitoring), establishing service level objectives (SLOs) that define acceptable reliability thresholds.\n",
    "\n",
    "This chapter establishes quantitative observability practices using Prometheus as the foundational metrics system, covering metric instrumentation, service discovery for dynamic environments, query language (PromQL) for operational analysis, and alerting strategies that balance sensitivity with noise reduction.\n",
    "\n",
    "## 44.1 Prometheus Fundamentals\n",
    "\n",
    "Prometheus is an open-source systems monitoring and alerting toolkit built around a dimensional data model, flexible query language, and pull-based architecture. Originally developed at SoundCloud, it became a Cloud Native Computing Foundation (CNCF) graduated project and serves as the de facto standard for Kubernetes monitoring.\n",
    "\n",
    "### Architecture Components\n",
    "\n",
    "**Prometheus Server**\n",
    "The core component that scrapes metrics from targets, stores them in a time-series database, and evaluates alerting rules. It operates on a pull model, periodically fetching metrics via HTTP endpoints.\n",
    "\n",
    "**Client Libraries**\n",
    "Instrumentation libraries for application metrics in various languages (Go, Java, Python, Ruby, etc.).\n",
    "\n",
    "**Exporters**\n",
    "Sidecar processes that expose metrics from third-party systems (Node Exporter for hardware/OS metrics, MySQL Exporter, Blackbox Exporter for probing).\n",
    "\n",
    "**Alertmanager**\n",
    "Handles alerts sent by Prometheus, deduplicating, grouping, and routing them to notification channels (PagerDuty, Slack, email).\n",
    "\n",
    "**Pushgateway**\n",
    "Accepts push-based metrics for short-lived jobs that cannot be scraped (batch jobs, CI/CD pipelines).\n",
    "\n",
    "### Deployment in Kubernetes\n",
    "\n",
    "```yaml\n",
    "# prometheus-deployment.yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: prometheus\n",
    "  namespace: monitoring\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: prometheus\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: prometheus\n",
    "    spec:\n",
    "      serviceAccountName: prometheus\n",
    "      containers:\n",
    "        - name: prometheus\n",
    "          image: prom/prometheus:v2.48.0\n",
    "          args:\n",
    "            - '--config.file=/etc/prometheus/prometheus.yml'\n",
    "            - '--storage.tsdb.path=/prometheus/'\n",
    "            - '--storage.tsdb.retention.time=15d'\n",
    "            - '--storage.tsdb.retention.size=50GB'\n",
    "            - '--web.console.libraries=/usr/share/prometheus/console_libraries'\n",
    "            - '--web.console.templates=/usr/share/prometheus/consoles'\n",
    "            - '--web.enable-lifecycle'\n",
    "            - '--web.enable-admin-api'\n",
    "          ports:\n",
    "            - containerPort: 9090\n",
    "              name: web\n",
    "          resources:\n",
    "            requests:\n",
    "              memory: \"4Gi\"\n",
    "              cpu: \"1000m\"\n",
    "            limits:\n",
    "              memory: \"8Gi\"\n",
    "              cpu: \"2000m\"\n",
    "          volumeMounts:\n",
    "            - name: prometheus-config\n",
    "              mountPath: /etc/prometheus\n",
    "            - name: prometheus-storage\n",
    "              mountPath: /prometheus\n",
    "          livenessProbe:\n",
    "            httpGet:\n",
    "              path: /-/healthy\n",
    "              port: 9090\n",
    "            initialDelaySeconds: 30\n",
    "            periodSeconds: 15\n",
    "          readinessProbe:\n",
    "            httpGet:\n",
    "              path: /-/ready\n",
    "              port: 9090\n",
    "            initialDelaySeconds: 5\n",
    "            periodSeconds: 5\n",
    "      volumes:\n",
    "        - name: prometheus-config\n",
    "          configMap:\n",
    "            name: prometheus-config\n",
    "        - name: prometheus-storage\n",
    "          persistentVolumeClaim:\n",
    "            claimName: prometheus-storage\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: prometheus-config\n",
    "  namespace: monitoring\n",
    "data:\n",
    "  prometheus.yml: |\n",
    "    global:\n",
    "      scrape_interval: 15s\n",
    "      evaluation_interval: 15s\n",
    "      external_labels:\n",
    "        cluster: production\n",
    "        replica: '{{.ExternalURL}}'\n",
    "    \n",
    "    alerting:\n",
    "      alertmanagers:\n",
    "        - static_configs:\n",
    "            - targets:\n",
    "              - alertmanager:9093\n",
    "    \n",
    "    rule_files:\n",
    "      - /etc/prometheus/rules/*.yml\n",
    "    \n",
    "    scrape_configs:\n",
    "      - job_name: 'prometheus'\n",
    "        static_configs:\n",
    "          - targets: ['localhost:9090']\n",
    "      \n",
    "      - job_name: 'kubernetes-apiservers'\n",
    "        kubernetes_sd_configs:\n",
    "          - role: endpoints\n",
    "        scheme: https\n",
    "        tls_config:\n",
    "          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n",
    "        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n",
    "        relabel_configs:\n",
    "          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]\n",
    "            action: keep\n",
    "            regex: default;kubernetes;https\n",
    "      \n",
    "      - job_name: 'kubernetes-nodes'\n",
    "        kubernetes_sd_configs:\n",
    "          - role: node\n",
    "        relabel_configs:\n",
    "          - action: labelmap\n",
    "            regex: __meta_kubernetes_node_label_(.+)\n",
    "      \n",
    "      - job_name: 'kubernetes-pods'\n",
    "        kubernetes_sd_configs:\n",
    "          - role: pod\n",
    "        relabel_configs:\n",
    "          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n",
    "            action: keep\n",
    "            regex: true\n",
    "          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n",
    "            action: replace\n",
    "            target_label: __metrics_path__\n",
    "            regex: (.+)\n",
    "          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n",
    "            action: replace\n",
    "            regex: ([^:]+)(?::\\d+)?;(\\d+)\n",
    "            replacement: $1:$2\n",
    "            target_label: __address__\n",
    "          - action: labelmap\n",
    "            regex: __meta_kubernetes_pod_label_(.+)\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "The Prometheus configuration defines scrape targets:\n",
    "- **kubernetes-pods**: Discovers Pods with `prometheus.io/scrape: \"true\"` annotation, extracting port and path from annotations. The `relabel_configs` transform Kubernetes metadata into Prometheus labels.\n",
    "- **kubernetes-nodes**: Scrapes node-level metrics (kubelet).\n",
    "- **kubernetes-apiservers**: Scrapes Kubernetes API server metrics.\n",
    "\n",
    "## 44.2 Metric Types Deep Dive\n",
    "\n",
    "Prometheus defines four core metric types, each suited to different measurement scenarios.\n",
    "\n",
    "### Counter\n",
    "\n",
    "Counters represent cumulative values that only increase (or reset to zero on restart). Use for: request counts, error counts, tasks completed.\n",
    "\n",
    "```java\n",
    "import io.micrometer.core.instrument.Counter;\n",
    "import io.micrometer.core.instrument.MeterRegistry;\n",
    "\n",
    "@Component\n",
    "public class PaymentMetrics {\n",
    "    private final Counter paymentCounter;\n",
    "    private final Counter errorCounter;\n",
    "    \n",
    "    public PaymentMetrics(MeterRegistry registry) {\n",
    "        this.paymentCounter = Counter.builder(\"payments_processed_total\")\n",
    "            .description(\"Total payments processed\")\n",
    "            .tag(\"service\", \"payment-service\")\n",
    "            .register(registry);\n",
    "            \n",
    "        this.errorCounter = Counter.builder(\"payments_failed_total\")\n",
    "            .description(\"Total payment failures\")\n",
    "            .tag(\"service\", \"payment-service\")\n",
    "            .register(registry);\n",
    "    }\n",
    "    \n",
    "    public void recordPayment(PaymentResult result) {\n",
    "        paymentCounter.increment();\n",
    "        \n",
    "        // Dimensional labels for analysis\n",
    "        Counter.builder(\"payments_by_method_total\")\n",
    "            .tag(\"method\", result.getPaymentMethod())\n",
    "            .tag(\"currency\", result.getCurrency())\n",
    "            .tag(\"status\", result.getStatus())\n",
    "            .register(registry)\n",
    "            .increment();\n",
    "    }\n",
    "    \n",
    "    public void recordError(String errorType, boolean retryable) {\n",
    "        errorCounter.increment();\n",
    "        \n",
    "        Counter.builder(\"payment_errors_total\")\n",
    "            .tag(\"error_type\", errorType)\n",
    "            .tag(\"retryable\", String.valueOf(retryable))\n",
    "            .register(registry)\n",
    "            .increment();\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**PromQL Queries:**\n",
    "```promql\n",
    "# Total payments in last 5 minutes\n",
    "rate(payments_processed_total[5m])\n",
    "\n",
    "# Error rate by type\n",
    "sum(rate(payment_errors_total[5m])) by (error_type)\n",
    "\n",
    "# Success ratio\n",
    "rate(payments_processed_total[5m]) \n",
    "/ \n",
    "(rate(payments_processed_total[5m]) + rate(payments_failed_total[5m]))\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "Counters are monotonic (only increase). The `rate()` function calculates per-second increase over the time range, handling counter resets automatically. Labels (`method`, `currency`) enable dimensional analysis—aggregating by different dimensions without separate metric names.\n",
    "\n",
    "### Gauge\n",
    "\n",
    "Gauges represent values that can arbitrarily go up and down. Use for: temperatures, current memory usage, queue depths, in-progress requests.\n",
    "\n",
    "```java\n",
    "@Component\n",
    "public class SystemMetrics {\n",
    "    private final AtomicInteger activeConnections = new AtomicInteger(0);\n",
    "    private final Gauge connectionsGauge;\n",
    "    private final Gauge memoryGauge;\n",
    "    private final Gauge queueDepthGauge;\n",
    "    \n",
    "    public SystemMetrics(MeterRegistry registry) {\n",
    "        // Connection gauge\n",
    "        this.connectionsGauge = Gauge.builder(\"db_active_connections\")\n",
    "            .description(\"Current active database connections\")\n",
    "            .register(registry, activeConnections, AtomicInteger::get);\n",
    "        \n",
    "        // Memory gauge (updated periodically)\n",
    "        this.memoryGauge = Gauge.builder(\"jvm_memory_used_bytes\")\n",
    "            .description(\"JVM memory used\")\n",
    "            .tag(\"area\", \"heap\")\n",
    "            .register(registry);\n",
    "        \n",
    "        // Queue depth\n",
    "        this.queueDepthGauge = Gauge.builder(\"payment_queue_depth\")\n",
    "            .description(\"Pending payments in queue\")\n",
    "            .register(registry);\n",
    "        \n",
    "        // Update gauges periodically\n",
    "        Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(\n",
    "            this::updateGauges, 0, 15, TimeUnit.SECONDS\n",
    "        );\n",
    "    }\n",
    "    \n",
    "    public void connectionOpened() {\n",
    "        activeConnections.incrementAndGet();\n",
    "    }\n",
    "    \n",
    "    public void connectionClosed() {\n",
    "        activeConnections.decrementAndGet();\n",
    "    }\n",
    "    \n",
    "    public void updateQueueDepth(int depth) {\n",
    "        queueDepthGauge.set(depth);\n",
    "    }\n",
    "    \n",
    "    private void updateGauges() {\n",
    "        Runtime runtime = Runtime.getRuntime();\n",
    "        long usedMemory = runtime.totalMemory() - runtime.freeMemory();\n",
    "        memoryGauge.set(usedMemory);\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**PromQL Queries:**\n",
    "```promql\n",
    "# Current connections\n",
    "db_active_connections\n",
    "\n",
    "# Memory usage trend\n",
    "jvm_memory_used_bytes[1h]\n",
    "\n",
    "# Queue depth alerts\n",
    "payment_queue_depth > 1000\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "Gauges report point-in-time values. Unlike counters, `rate()` doesn't apply—gauges can decrease. Alert on thresholds (queue depth > 1000) or visualize trends over time.\n",
    "\n",
    "### Histogram\n",
    "\n",
    "Histograms sample observations (request durations, response sizes) into configurable buckets, providing distribution data.\n",
    "\n",
    "```java\n",
    "@Component\n",
    "public class RequestMetrics {\n",
    "    private final Histogram requestDuration;\n",
    "    private final Histogram paymentAmount;\n",
    "    \n",
    "    public RequestMetrics(MeterRegistry registry) {\n",
    "        // Request duration histogram\n",
    "        this.requestDuration = Histogram.builder(\"http_request_duration_seconds\")\n",
    "            .description(\"HTTP request duration in seconds\")\n",
    "            .baseUnit(\"seconds\")\n",
    "            .tags(\"service\", \"payment-service\")\n",
    "            // Explicit buckets for SLA boundaries\n",
    "            .serviceLevelObjectives(\n",
    "                Duration.ofMillis(100),  // 100ms\n",
    "                Duration.ofMillis(250),  // 250ms\n",
    "                Duration.ofMillis(500),  // 500ms\n",
    "                Duration.ofSeconds(1),   // 1s\n",
    "                Duration.ofSeconds(2),   // 2s\n",
    "                Duration.ofSeconds(5)    // 5s\n",
    "            )\n",
    "            .register(registry);\n",
    "        \n",
    "        // Payment amount distribution\n",
    "        this.paymentAmount = Histogram.builder(\"payment_amount_usd\")\n",
    "            .description(\"Payment amount distribution\")\n",
    "            .baseUnit(\"dollars\")\n",
    "            .buckets(10, 25, 50, 100, 250, 500, 1000, 2500, 5000, 10000)\n",
    "            .register(registry);\n",
    "    }\n",
    "    \n",
    "    public void recordRequest(HttpServletRequest request, \n",
    "                              HttpServletResponse response,\n",
    "                              long durationMs) {\n",
    "        double durationSeconds = durationMs / 1000.0;\n",
    "        \n",
    "        requestDuration.record(durationSeconds, \n",
    "            Tags.of(\"method\", request.getMethod(),\n",
    "                   \"path\", request.getRequestURI(),\n",
    "                   \"status\", String.valueOf(response.getStatus())));\n",
    "    }\n",
    "    \n",
    "    public void recordPayment(BigDecimal amount) {\n",
    "        paymentAmount.record(amount.doubleValue(),\n",
    "            Tags.of(\"currency\", \"USD\"));\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**PromQL Queries:**\n",
    "```promql\n",
    "# 95th percentile latency\n",
    "histogram_quantile(0.95, \n",
    "  sum(rate(http_request_duration_seconds_bucket[5m])) by (le)\n",
    ")\n",
    "\n",
    "# Average payment amount\n",
    "sum(payment_amount_usd_sum) / sum(payment_amount_usd_count)\n",
    "\n",
    "# Request rate by status\n",
    "sum(rate(http_request_duration_seconds_count[5m])) by (status)\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "Histograms expose `_bucket` (cumulative counters per bucket), `_sum` (sum of all observations), and `_count` (total observations). `histogram_quantile` calculates percentiles from buckets. The `le` (less than or equal) label distinguishes buckets.\n",
    "\n",
    "### Summary\n",
    "\n",
    "Summaries calculate configurable quantiles (percentiles) over a sliding time window, using less memory than histograms but without aggregation across instances.\n",
    "\n",
    "```java\n",
    "@Component\n",
    "public class LatencySummary {\n",
    "    private final DistributionSummary responseTime;\n",
    "    \n",
    "    public LatencySummary(MeterRegistry registry) {\n",
    "        this.responseTime = DistributionSummary.builder(\"response_time_ms\")\n",
    "            .description(\"Response time in milliseconds\")\n",
    "            .baseUnit(\"milliseconds\")\n",
    "            .publishPercentiles(0.5, 0.95, 0.99)\n",
    "            .register(registry);\n",
    "    }\n",
    "    \n",
    "    public void record(long milliseconds) {\n",
    "        responseTime.record(milliseconds);\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Key Difference:**\n",
    "- **Histogram**: Pre-defined buckets, aggregatable across instances, client-side calculation\n",
    "- **Summary**: Calculated percentiles (0.5, 0.95, 0.99), not aggregatable across instances, server-side calculation\n",
    "\n",
    "Use histograms when you need to aggregate across services (e.g., cluster-wide latency percentiles). Use summaries when you need precise percentiles for a single instance and memory efficiency matters.\n",
    "\n",
    "## 44.3 Service Discovery\n",
    "\n",
    "Prometheus discovers targets dynamically in Kubernetes environments.\n",
    "\n",
    "### Kubernetes SD Configuration\n",
    "\n",
    "```yaml\n",
    "# prometheus-kubernetes-sd.yml\n",
    "scrape_configs:\n",
    "  # API servers\n",
    "  - job_name: 'kubernetes-apiservers'\n",
    "    kubernetes_sd_configs:\n",
    "      - role: endpoints\n",
    "    scheme: https\n",
    "    tls_config:\n",
    "      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n",
    "    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n",
    "    relabel_configs:\n",
    "      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]\n",
    "        action: keep\n",
    "        regex: default;kubernetes;https\n",
    "\n",
    "  # Nodes (kubelet)\n",
    "  - job_name: 'kubernetes-nodes'\n",
    "    kubernetes_sd_configs:\n",
    "      - role: node\n",
    "    scheme: https\n",
    "    tls_config:\n",
    "      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n",
    "      insecure_skip_verify: true\n",
    "    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n",
    "    relabel_configs:\n",
    "      - action: labelmap\n",
    "        regex: __meta_kubernetes_node_label_(.+)\n",
    "\n",
    "  # Pods (application metrics)\n",
    "  - job_name: 'kubernetes-pods'\n",
    "    kubernetes_sd_configs:\n",
    "      - role: pod\n",
    "    relabel_configs:\n",
    "      # Scrape only pods with annotation\n",
    "      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n",
    "        action: keep\n",
    "        regex: true\n",
    "      \n",
    "      # Use custom port if specified\n",
    "      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]\n",
    "        action: replace\n",
    "        target_label: __address__\n",
    "        regex: ([^:]+)(?::\\d+)?;(\\d+)\n",
    "        replacement: $1:$2\n",
    "      \n",
    "      # Set metrics path\n",
    "      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n",
    "        action: replace\n",
    "        target_label: __metrics_path__\n",
    "        regex: (.+)\n",
    "      \n",
    "      # Add labels\n",
    "      - action: labelmap\n",
    "        regex: __meta_kubernetes_pod_label_(.+)\n",
    "      - source_labels: [__meta_kubernetes_namespace]\n",
    "        target_label: kubernetes_namespace\n",
    "      - source_labels: [__meta_kubernetes_pod_name]\n",
    "        target_label: kubernetes_pod_name\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "- **role: pod**: Discovers all Pods in the cluster\n",
    "- **relabel_configs**: Transform discovered metadata into scrape configuration\n",
    "- **keep**: Only scrape Pods with `prometheus.io/scrape: \"true\"` annotation\n",
    "- **replace**: Construct target address from Pod IP and annotation-specified port\n",
    "\n",
    "### Pod Annotations\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: payment-service\n",
    "spec:\n",
    "  template:\n",
    "    metadata:\n",
    "      annotations:\n",
    "        prometheus.io/scrape: \"true\"\n",
    "        prometheus.io/port: \"8080\"\n",
    "        prometheus.io/path: \"/actuator/prometheus\"\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: payment\n",
    "          image: payment-service:v2.1.0\n",
    "          ports:\n",
    "            - containerPort: 8080\n",
    "```\n",
    "\n",
    "## 44.4 PromQL\n",
    "\n",
    "Prometheus Query Language (PromQL) retrieves and manipulates time-series data.\n",
    "\n",
    "### Basic Selectors\n",
    "\n",
    "```promql\n",
    "# Select all time series with metric name\n",
    "http_requests_total\n",
    "\n",
    "# Select with label matchers\n",
    "http_requests_total{service=\"payment-service\", status=\"200\"}\n",
    "\n",
    "# Regex matchers\n",
    "http_requests_total{service=~\"payment.*\", status!~\"4..|5..\"}\n",
    "\n",
    "# Range vectors (last 5 minutes)\n",
    "http_requests_total[5m]\n",
    "\n",
    "# Offset (1 hour ago)\n",
    "http_requests_total offset 1h\n",
    "```\n",
    "\n",
    "### Aggregation Operators\n",
    "\n",
    "```promql\n",
    "# Sum across all instances\n",
    "sum(http_requests_total)\n",
    "\n",
    "# Sum by label\n",
    "sum(http_requests_total) by (service, status)\n",
    "\n",
    "# Average\n",
    "avg(http_request_duration_seconds_sum) by (service)\n",
    "\n",
    "# Percentiles (histograms)\n",
    "histogram_quantile(0.95, \n",
    "  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)\n",
    ")\n",
    "\n",
    "# Top 3 services by request rate\n",
    "topk(3, \n",
    "  sum(rate(http_requests_total[5m])) by (service)\n",
    ")\n",
    "\n",
    "# Rate of change\n",
    "rate(http_requests_total[5m])\n",
    "\n",
    "# Increase over time range\n",
    "increase(http_requests_total[1h])\n",
    "```\n",
    "\n",
    "### Advanced Queries\n",
    "\n",
    "```promql\n",
    "# Error rate calculation\n",
    "sum(rate(http_requests_total{status=~\"5..\"}[5m])) \n",
    "/ \n",
    "sum(rate(http_requests_total[5m]))\n",
    "\n",
    "# Latency SLO: 99th percentile < 200ms\n",
    "histogram_quantile(0.99, \n",
    "  sum(rate(http_request_duration_seconds_bucket[5m])) by (le)\n",
    ") < 0.2\n",
    "\n",
    "# Predict disk full in 4 hours\n",
    "predict_linear(\n",
    "  node_filesystem_avail_bytes{mountpoint=\"/\"}[1h], \n",
    "  4 * 3600\n",
    ") < 0\n",
    "\n",
    "# Joining metrics\n",
    "node_cpu_seconds_total * on(instance) group_left(nodename) \n",
    "  node_uname_info\n",
    "```\n",
    "\n",
    "## 44.5 Grafana Dashboards\n",
    "\n",
    "### Dashboard as Code\n",
    "\n",
    "```yaml\n",
    "# dashboards/payment-service.json (simplified)\n",
    "{\n",
    "  \"dashboard\": {\n",
    "    \"title\": \"Payment Service\",\n",
    "    \"tags\": [\"microservice\", \"payment\", \"production\"],\n",
    "    \"timezone\": \"UTC\",\n",
    "    \"schemaVersion\": 36,\n",
    "    \"panels\": [\n",
    "      {\n",
    "        \"id\": 1,\n",
    "        \"title\": \"Request Rate\",\n",
    "        \"type\": \"timeseries\",\n",
    "        \"targets\": [\n",
    "          {\n",
    "            \"expr\": \"sum(rate(http_requests_total{service=\\\"payment-service\\\"}[5m])) by (status)\",\n",
    "            \"legendFormat\": \"{{status}}\"\n",
    "          }\n",
    "        ],\n",
    "        \"fieldConfig\": {\n",
    "          \"defaults\": {\n",
    "            \"unit\": \"reqps\",\n",
    "            \"min\": 0,\n",
    "            \"color\": {\n",
    "              \"mode\": \"palette-classic\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"id\": 2,\n",
    "        \"title\": \"Latency Distribution\",\n",
    "        \"type\": \"heatmap\",\n",
    "        \"targets\": [\n",
    "          {\n",
    "            \"expr\": \"sum(rate(http_request_duration_seconds_bucket{service=\\\"payment-service\\\"}[5m])) by (le)\",\n",
    "            \"format\": \"heatmap\"\n",
    "          }\n",
    "        ],\n",
    "        \"dataFormat\": \"tsbuckets\",\n",
    "        \"heatmap\": {\n",
    "          \"color\": {\n",
    "            \"mode\": \"opacity\",\n",
    "            \"fill\": \"dark-orange\"\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"id\": 3,\n",
    "        \"title\": \"Error Budget\",\n",
    "        \"type\": \"stat\",\n",
    "        \"targets\": [\n",
    "          {\n",
    "            \"expr\": \"1 - (sum(rate(http_requests_total{service=\\\"payment-service\\\",status=~\\\"5..\\\"}[30d])) / sum(rate(http_requests_total{service=\\\"payment-service\\\"}[30d])))\",\n",
    "            \"legendFormat\": \"Availability\"\n",
    "          }\n",
    "        ],\n",
    "        \"fieldConfig\": {\n",
    "          \"defaults\": {\n",
    "            \"unit\": \"percentunit\",\n",
    "            \"thresholds\": {\n",
    "              \"steps\": [\n",
    "                { \"color\": \"red\", \"value\": 0 },\n",
    "                { \"color\": \"yellow\", \"value\": 0.99 },\n",
    "                { \"color\": \"green\", \"value\": 0.999 }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "- **Timeseries**: Line graphs showing request rates over time, colored by status code.\n",
    "- **Heatmap**: Latency distribution showing frequency of different response times (bucketed).\n",
    "- **Stat**: Single value panel showing error budget remaining (99.9% availability target).\n",
    "\n",
    "## 44.6 SLOs and Error Budgets\n",
    "\n",
    "Service Level Objectives (SLOs) define target reliability levels. Error budgets quantify how much unreliability is acceptable.\n",
    "\n",
    "### Defining SLIs and SLOs\n",
    "\n",
    "```yaml\n",
    "# slo-definitions.yml\n",
    "slos:\n",
    "  - name: payment-service-availability\n",
    "    description: \"Successful payment requests\"\n",
    "    service: payment-service\n",
    "    type: availability\n",
    "    \n",
    "    # SLI: What we measure\n",
    "    sli:\n",
    "      numerator: |\n",
    "        sum(rate(http_requests_total{service=\"payment-service\",status!~\"5..\"}[{{.window}}]))\n",
    "      denominator: |\n",
    "        sum(rate(http_requests_total{service=\"payment-service\"}[{{.window}}]))\n",
    "    \n",
    "    # SLO: Target threshold\n",
    "    target: 0.999  # 99.9%\n",
    "    \n",
    "    # Windows for evaluation\n",
    "    windows:\n",
    "      - name: \"30d\"\n",
    "        duration: 30d\n",
    "        burn_rates:\n",
    "          - name: \"fast\"\n",
    "            factor: 14.4  # 2% budget in 1 hour\n",
    "            alert: page\n",
    "          - name: \"slow\"\n",
    "            factor: 2  # 5% budget in 6 hours\n",
    "            alert: ticket\n",
    "\n",
    "  - name: payment-service-latency\n",
    "    description: \"Fast payment processing\"\n",
    "    service: payment-service\n",
    "    type: latency\n",
    "    \n",
    "    sli:\n",
    "      query: |\n",
    "        histogram_quantile(0.99,\n",
    "          sum(rate(http_request_duration_seconds_bucket{service=\"payment-service\"}[{{.window}}])) by (le)\n",
    "        ) < 0.5  # 500ms\n",
    "    \n",
    "    target: 0.99  # 99% of requests under 500ms\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "- **SLI (Service Level Indicator)**: The query that measures service behavior. For availability: good requests / total requests.\n",
    "- **SLO (Service Level Objective)**: The target percentage (99.9% availability).\n",
    "- **Error Budget**: 0.1% of requests can fail (or 0.1% of time can be >500ms for latency).\n",
    "- **Burn Rates**: How fast the error budget is consumed. 14.4x burn rate means exhausting 2% of monthly budget in 1 hour—page immediately. 2x means 5% in 6 hours—create ticket.\n",
    "\n",
    "### Prometheus Alerting Rules\n",
    "\n",
    "```yaml\n",
    "# rules/slo-alerts.yml\n",
    "groups:\n",
    "  - name: slo-alerts\n",
    "    interval: 30s\n",
    "    rules:\n",
    "      # Fast burn alert - page immediately\n",
    "      - alert: ErrorBudgetFastBurn\n",
    "        expr: |\n",
    "          (\n",
    "            sum(rate(http_requests_total{status=~\"5..\"}[1h])) \n",
    "            / \n",
    "            sum(rate(http_requests_total[1h]))\n",
    "          ) \n",
    "          > 14.4 * (1 - 0.999)  # 14.4x burn rate\n",
    "        for: 2m\n",
    "        labels:\n",
    "          severity: critical\n",
    "          team: platform\n",
    "        annotations:\n",
    "          summary: \"Fast error budget burn detected\"\n",
    "          description: \"Error rate is {{ $value | humanizePercentage }} over last hour\"\n",
    "          \n",
    "      # Slow burn alert - ticket\n",
    "      - alert: ErrorBudgetSlowBurn\n",
    "        expr: |\n",
    "          (\n",
    "            sum(rate(http_requests_total{status=~\"5..\"}[6h])) \n",
    "            / \n",
    "            sum(rate(http_requests_total[6h]))\n",
    "          ) \n",
    "          > 2 * (1 - 0.999)  # 2x burn rate\n",
    "        for: 30m\n",
    "        labels:\n",
    "          severity: warning\n",
    "          team: platform\n",
    "        annotations:\n",
    "          summary: \"Slow error budget burn detected\"\n",
    "          \n",
    "      # Latency SLO violation\n",
    "      - alert: HighLatency99th\n",
    "        expr: |\n",
    "          histogram_quantile(0.99,\n",
    "            sum(rate(http_request_duration_seconds_bucket[5m])) by (le)\n",
    "          ) > 0.5\n",
    "        for: 5m\n",
    "        labels:\n",
    "          severity: warning\n",
    "        annotations:\n",
    "          summary: \"99th percentile latency exceeds 500ms\"\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "- **Fast burn**: Triggers if error rate exceeds 14.4 × 0.001 = 1.44% over 1 hour. This would consume 2% of monthly budget in 1 hour.\n",
    "- **Slow burn**: Triggers if error rate exceeds 2 × 0.001 = 0.2% over 6 hours.\n",
    "- **histogram_quantile**: Calculates the 99th percentile from bucket data. If > 0.5 (500ms), alert.\n",
    "\n",
    "## 44.7 Alerting\n",
    "\n",
    "### Alertmanager Configuration\n",
    "\n",
    "```yaml\n",
    "# alertmanager.yml\n",
    "global:\n",
    "  smtp_smarthost: 'smtp.company.com:587'\n",
    "  smtp_from: 'alerts@company.com'\n",
    "  smtp_auth_username: 'alerts@company.com'\n",
    "  smtp_auth_password: '${SMTP_PASSWORD}'\n",
    "  slack_api_url: '${SLACK_WEBHOOK_URL}'\n",
    "  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'\n",
    "  opsgenie_api_url: 'https://api.opsgenie.com/'\n",
    "  resolve_timeout: 5m\n",
    "\n",
    "templates:\n",
    "  - '/etc/alertmanager/templates/*.tmpl'\n",
    "\n",
    "route:\n",
    "  receiver: 'default-receiver'\n",
    "  group_by: ['alertname', 'cluster', 'service']\n",
    "  group_wait: 30s\n",
    "  group_interval: 5m\n",
    "  repeat_interval: 12h\n",
    "  \n",
    "  routes:\n",
    "    # Critical alerts -> PagerDuty immediately\n",
    "    - match:\n",
    "        severity: critical\n",
    "      receiver: 'pagerduty-critical'\n",
    "      continue: true\n",
    "      \n",
    "    # Platform team alerts\n",
    "    - match_re:\n",
    "        team: platform|sre\n",
    "      receiver: 'slack-platform'\n",
    "      group_by: ['alertname', 'namespace']\n",
    "      \n",
    "    # Payment service alerts -> dedicated channel\n",
    "    - match:\n",
    "        service: payment-service\n",
    "      receiver: 'slack-payments'\n",
    "      routes:\n",
    "        - match:\n",
    "            severity: critical\n",
    "          receiver: 'pagerduty-payments'\n",
    "\n",
    "inhibit_rules:\n",
    "  # Inhibit warning if critical is firing\n",
    "  - source_match:\n",
    "      severity: 'critical'\n",
    "    target_match:\n",
    "      severity: 'warning'\n",
    "    equal: ['alertname', 'cluster', 'service']\n",
    "    \n",
    "  # Inhibit node alerts if cluster is down\n",
    "  - source_match:\n",
    "      alertname: 'ClusterDown'\n",
    "    target_match_re:\n",
    "      alertname: 'Node.*'\n",
    "    equal: ['cluster']\n",
    "\n",
    "receivers:\n",
    "  - name: 'default-receiver'\n",
    "    slack_configs:\n",
    "      - channel: '#alerts'\n",
    "        title: '{{ template \"slack.default.title\" . }}'\n",
    "        text: '{{ template \"slack.default.text\" . }}'\n",
    "        send_resolved: true\n",
    "        \n",
    "  - name: 'slack-platform'\n",
    "    slack_configs:\n",
    "      - channel: '#platform-alerts'\n",
    "        title: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'\n",
    "        fields:\n",
    "          - title: Severity\n",
    "            value: '{{ .CommonLabels.severity }}'\n",
    "          - title: Service\n",
    "            value: '{{ .CommonLabels.service }}'\n",
    "            \n",
    "  - name: 'pagerduty-critical'\n",
    "    pagerduty_configs:\n",
    "      - service_key: '${PAGERDUTY_SERVICE_KEY}'\n",
    "        severity: '{{ .CommonLabels.severity }}'\n",
    "        description: '{{ .CommonAnnotations.summary }}'\n",
    "        details:\n",
    "          firing: '{{ template \"pagerduty.default.instances\" . }}'\n",
    "          runbook_url: '{{ .CommonAnnotations.runbook_url }}'\n",
    "          \n",
    "  - name: 'email-sre'\n",
    "    email_configs:\n",
    "      - to: 'sre@company.com'\n",
    "        from: 'alerts@company.com'\n",
    "        smarthost: 'smtp.company.com:587'\n",
    "        auth_username: 'alerts@company.com'\n",
    "        auth_password: '${EMAIL_PASSWORD}'\n",
    "        headers:\n",
    "          Subject: '{{ .CommonAnnotations.summary }}'\n",
    "        html: '{{ template \"email.default.html\" . }}'\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "- **route**: Tree-based routing. Alerts traverse the tree, matching conditions. `continue: true` allows matching multiple routes.\n",
    "- **inhibit_rules**: Suppresses notifications. If \"ClusterDown\" fires, inhibit all \"NodeDown\" alerts (they're symptoms, not causes).\n",
    "- **group_by**: Groups alerts with same labels into single notification (prevents spam).\n",
    "- **group_wait**: Wait 30s for additional alerts to arrive before sending first notification.\n",
    "- **repeat_interval**: Re-alert every 12 hours if condition persists.\n",
    "\n",
    "## 44.8 CI/CD Integration\n",
    "\n",
    "### Deployment Metrics\n",
    "\n",
    "Track deployment frequency and success:\n",
    "\n",
    "```yaml\n",
    "# CI pipeline metric push\n",
    "- name: Record Deployment\n",
    "  run: |\n",
    "    cat <<EOF | curl -X POST http://pushgateway:9091/metrics/job/ci-pipeline \\\n",
    "      --data-binary @-\n",
    "    # HELP deployment_timestamp_seconds Unix timestamp of deployment\n",
    "    # TYPE deployment_timestamp_seconds gauge\n",
    "    deployment_timestamp_seconds{service=\"payment-service\",version=\"${{ github.sha }}\",environment=\"production\",status=\"success\"} $(date +%s)\n",
    "    \n",
    "    # HELP deployment_duration_seconds Duration of deployment pipeline\n",
    "    # TYPE deployment_duration_seconds gauge\n",
    "    deployment_duration_seconds{service=\"payment-service\",environment=\"production\"} ${{ steps.deploy.outputs.duration }}\n",
    "    EOF\n",
    "```\n",
    "\n",
    "### Canary Analysis Metrics\n",
    "\n",
    "Flagger and Argo Rollouts use metrics for automated promotion:\n",
    "\n",
    "```yaml\n",
    "# AnalysisTemplate for CI/CD\n",
    "apiVersion: flagger.app/v1beta1\n",
    "kind: MetricTemplate\n",
    "metadata:\n",
    "  name: deployment-success\n",
    "spec:\n",
    "  provider:\n",
    "    type: prometheus\n",
    "    address: http://prometheus:9090\n",
    "  query: |\n",
    "    sum(\n",
    "      rate(\n",
    "        http_requests_total{\n",
    "          service=\"{{ service }}\",\n",
    "          version=\"canary\",\n",
    "          status!~\"5..\"\n",
    "        }[1m]\n",
    "      )\n",
    "    )\n",
    "    /\n",
    "    sum(\n",
    "      rate(\n",
    "        http_requests_total{\n",
    "          service=\"{{ service }}\",\n",
    "          version=\"canary\"\n",
    "        }[1m]\n",
    "      )\n",
    "    )\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary and Preview\n",
    "\n",
    "This chapter established metrics and monitoring as quantitative foundations for reliability engineering, complementing the qualitative insights of logging with measurable, actionable data. We examined Prometheus as the central metrics system, exploring its pull-based architecture, dimensional data model using key-value labels, and the four core metric types: counters for cumulative events, gauges for point-in-time values, histograms for distribution analysis, and summaries for configurable quantiles. The distinction between these types—particularly the aggregability of histograms versus the precise quantiles of summaries—guides instrumentation decisions based on query requirements and resource constraints.\n",
    "\n",
    "PromQL query language enables sophisticated operational analysis, from simple selectors to complex aggregations, percentile calculations using `histogram_quantile`, and rate calculations that handle counter resets. Service discovery mechanisms automatically detect Kubernetes targets, using relabeling to transform pod metadata into scrape configurations without manual maintenance. The Alertmanager routing tree provides sophisticated notification management, with inhibition rules that suppress symptomatic alerts during root cause events, and grouping that prevents alert storms.\n",
    "\n",
    "Service Level Objectives (SLOs) and error budgets translate business requirements into technical targets, defining acceptable unreliability levels and burn rates that trigger alerts before budget exhaustion. CI/CD integration ensures deployment events are tracked as metrics, enabling correlation between releases and metric changes, while canary analysis uses automated metric evaluation to determine promotion or rollback without human judgment.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Instrument applications with Prometheus client libraries using appropriate metric types: counters for monotonic events, gauges for fluctuating values, histograms for latency distributions with SLO-aligned buckets, and summaries only when precise quantiles without aggregation are required.\n",
    "- Use histograms with explicit buckets aligned to SLO boundaries (e.g., 100ms, 250ms, 500ms) rather than default buckets, enabling accurate SLO measurement via `histogram_quantile`.\n",
    "- Implement distributed tracing context (trace_id, span_id) in metric labels to correlate metrics with logs and traces during incident investigation.\n",
    "- Configure Alertmanager with inhibition rules to suppress symptomatic alerts when root cause alerts fire, and use grouping to batch related alerts into single notifications.\n",
    "- Define SLOs with explicit error budgets and burn rate alerts (fast burn at 14.4x, slow burn at 2x) to detect reliability degradation before budget exhaustion.\n",
    "- Integrate deployment markers into metrics (deployment_timestamp gauge) to correlate metric changes with releases, enabling quick identification of problematic deployments.\n",
    "\n",
    "**Next Chapter Preview:**\n",
    "Chapter 45: Distributed Tracing completes the observability triad by examining request flow across microservices. We will explore OpenTelemetry as the unified instrumentation standard, trace context propagation (W3C Trace Context, B3), span creation and attributes, sampling strategies (head-based, tail-based, probabilistic), and trace visualization in Jaeger and Zipkin. The chapter covers baggage for cross-service context propagation, correlation with logs and metrics using trace IDs, and performance considerations for high-throughput services, establishing the final observability pillar that enables understanding of request latency decomposition across distributed architectures."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
