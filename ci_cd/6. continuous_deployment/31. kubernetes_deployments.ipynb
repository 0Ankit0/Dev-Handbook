{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 31: Kubernetes Deployments\n",
    "\n",
    "While Chapter 30 established deployment strategies conceptually, this chapter examines the Kubernetes-native mechanisms that implement these patterns. The Kubernetes Deployment resource provides declarative updates for Pods and ReplicaSets, automating the transition from desired state to actual state while maintaining application availability.\n",
    "\n",
    "Understanding the Deployment controller's internal mechanics—from ReplicaSet management to revision history retention—is essential for troubleshooting stuck rollouts, implementing canary releases, and executing safe rollbacks in production environments.\n",
    "\n",
    "## 31.1 Deployments Deep Dive\n",
    "\n",
    "The Deployment controller manages the lifecycle of stateless applications, providing declarative rollouts, scaling, and rollback capabilities through abstraction layers that separate user intent from execution mechanics.\n",
    "\n",
    "### Architecture and Relationships\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Deployment] -->|manages| B[ReplicaSet v1]\n",
    "    A -->|manages| C[ReplicaSet v2]\n",
    "    B -->|owns| D[Pod 1.1]\n",
    "    B -->|owns| E[Pod 1.2]\n",
    "    C -->|owns| F[Pod 2.1]\n",
    "    C -->|owns| G[Pod 2.2]\n",
    "    \n",
    "    style A fill:#f9f,stroke:#333,stroke-width:2px\n",
    "    style B fill:#bbf,stroke:#333\n",
    "    style C fill:#bbf,stroke:#333,stroke-dasharray: 5 5\n",
    "```\n",
    "\n",
    "**Deployment → ReplicaSet → Pod Hierarchy:**\n",
    "- **Deployment**: User-facing abstraction defining desired state (image, replicas, strategy)\n",
    "- **ReplicaSet**: Immutable snapshot of a specific pod template; created by Deployment during updates\n",
    "- **Pod**: Actual running containers scheduled by ReplicaSet controller\n",
    "\n",
    "### Deployment Specification\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: payment-service\n",
    "  namespace: production\n",
    "  labels:\n",
    "    app: payment-service\n",
    "    version: v2.3.1\n",
    "    tier: backend\n",
    "spec:\n",
    "  replicas: 5\n",
    "  revisionHistoryLimit: 10  # Retain 10 old ReplicaSets for rollback\n",
    "  progressDeadlineSeconds: 600  # 10 minutes to progress before marked failed\n",
    "  minReadySeconds: 30  # Pod must be ready for 30s before considered available\n",
    "  \n",
    "  strategy:\n",
    "    type: RollingUpdate  # or Recreate\n",
    "    rollingUpdate:\n",
    "      maxSurge: 25%      # Can exceed desired count by 25%\n",
    "      maxUnavailable: 0  # Never drop below desired count\n",
    "  \n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: payment-service\n",
    "    matchExpressions:\n",
    "      - {key: tier, operator: In, values: [backend, api]}\n",
    "  \n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: payment-service\n",
    "        version: v2.3.1\n",
    "        tier: backend\n",
    "      annotations:\n",
    "        prometheus.io/scrape: \"true\"\n",
    "        prometheus.io/port: \"8080\"\n",
    "        deployment.kubernetes.io/revision: \"3\"\n",
    "    spec:\n",
    "      affinity:\n",
    "        podAntiAffinity:\n",
    "          preferredDuringSchedulingIgnoredDuringExecution:\n",
    "          - weight: 100\n",
    "            podAffinityTerm:\n",
    "              labelSelector:\n",
    "                matchExpressions:\n",
    "                - key: app\n",
    "                  operator: In\n",
    "                  values:\n",
    "                  - payment-service\n",
    "              topologyKey: kubernetes.io/hostname\n",
    "      \n",
    "      containers:\n",
    "      - name: payment-api\n",
    "        image: registry.company.com/payment-service:v2.3.1\n",
    "        imagePullPolicy: IfNotPresent\n",
    "        \n",
    "        ports:\n",
    "        - name: http\n",
    "          containerPort: 8080\n",
    "          protocol: TCP\n",
    "        \n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"512Mi\"\n",
    "            cpu: \"500m\"\n",
    "          limits:\n",
    "            memory: \"1Gi\"\n",
    "            cpu: \"1000m\"\n",
    "        \n",
    "        readinessProbe:  # Critical for rolling updates\n",
    "          httpGet:\n",
    "            path: /health/ready\n",
    "            port: 8080\n",
    "            httpHeaders:\n",
    "            - name: Accept\n",
    "              value: application/json\n",
    "          initialDelaySeconds: 10\n",
    "          periodSeconds: 5\n",
    "          successThreshold: 2  # Must pass twice to be ready\n",
    "          failureThreshold: 3\n",
    "        \n",
    "        livenessProbe:  # Restart if deadlocked\n",
    "          httpGet:\n",
    "            path: /health/live\n",
    "            port: 8080\n",
    "          initialDelaySeconds: 30\n",
    "          periodSeconds: 10\n",
    "          timeoutSeconds: 5\n",
    "          failureThreshold: 3\n",
    "        \n",
    "        startupProbe:  # For slow-starting applications\n",
    "          httpGet:\n",
    "            path: /health/started\n",
    "            port: 8080\n",
    "          initialDelaySeconds: 10\n",
    "          periodSeconds: 5\n",
    "          failureThreshold: 30  # 30 * 5 = 150s max startup time\n",
    "        \n",
    "        env:\n",
    "        - name: POD_NAME\n",
    "          valueFrom:\n",
    "            fieldRef:\n",
    "              fieldPath: metadata.name\n",
    "        - name: DEPLOYMENT_REVISION\n",
    "          valueFrom:\n",
    "            fieldRef:\n",
    "              fieldPath: metadata.annotations['deployment.kubernetes.io/revision']\n",
    "        \n",
    "        volumeMounts:\n",
    "        - name: tmp\n",
    "          mountPath: /tmp\n",
    "      \n",
    "      securityContext:\n",
    "        runAsNonRoot: true\n",
    "        runAsUser: 1000\n",
    "        fsGroup: 2000\n",
    "        seccompProfile:\n",
    "          type: RuntimeDefault\n",
    "      \n",
    "      volumes:\n",
    "      - name: tmp\n",
    "        emptyDir: {}\n",
    "      \n",
    "      terminationGracePeriodSeconds: 60  # Time for graceful shutdown\n",
    "```\n",
    "\n",
    "## 31.2 ReplicaSets\n",
    "\n",
    "ReplicaSets ensure a specified number of pod replicas are running at any given time. While Deployments manage ReplicaSets, understanding their behavior is crucial for advanced operations.\n",
    "\n",
    "### ReplicaSet Mechanics\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: ReplicaSet\n",
    "metadata:\n",
    "  name: payment-service-7c9b8f4d5  # Generated by Deployment\n",
    "  ownerReferences:  # Links to parent Deployment\n",
    "  - apiVersion: apps/v1\n",
    "    kind: Deployment\n",
    "    name: payment-service\n",
    "    uid: a3f5c8d2-1234-5678-9abc-def012345678\n",
    "    controller: true\n",
    "    blockOwnerDeletion: true\n",
    "spec:\n",
    "  replicas: 5\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: payment-service\n",
    "      pod-template-hash: 7c9b8f4d5  # Unique hash of pod template\n",
    "  template:\n",
    "    # Pod template identical to Deployment's template\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: payment-service\n",
    "        pod-template-hash: 7c9b8f4d5\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: payment-api\n",
    "        image: registry.company.com/payment-service:v2.3.1\n",
    "```\n",
    "\n",
    "**Key Behaviors:**\n",
    "- **Immutable Templates**: Changing a ReplicaSet's pod template has no effect on existing pods (only affects new replicas)\n",
    "- **Label Matching**: ReplicaSets select pods based on labels, not ownership—orphaned pods with matching labels are adopted\n",
    "- **Hash Generation**: The `pod-template-hash` label ensures ReplicaSets manage only pods created from their specific template\n",
    "\n",
    "### Manual ReplicaSet Management (Anti-Pattern)\n",
    "\n",
    "While Deployments automate ReplicaSet management, manual intervention is occasionally required:\n",
    "\n",
    "```bash\n",
    "# View ReplicaSets created by Deployment\n",
    "kubectl get rs -l app=payment-service\n",
    "\n",
    "# Scale specific ReplicaSet (bypassing Deployment - not recommended)\n",
    "kubectl scale rs payment-service-7c9b8f4d5 --replicas=10\n",
    "\n",
    "# Orphan pods from ReplicaSet (remove labels)\n",
    "kubectl label pod payment-service-xxx app- pod-template-hash-\n",
    "```\n",
    "\n",
    "**Warning**: Manual ReplicaSet manipulation breaks Deployment's declarative model. Use only for emergency debugging.\n",
    "\n",
    "## 31.3 Rolling Update Configuration\n",
    "\n",
    "Rolling updates replace pods gradually, ensuring zero downtime by maintaining availability throughout the transition.\n",
    "\n",
    "### Update Mechanics\n",
    "\n",
    "When a Deployment's pod template changes (image tag, labels, or spec), the controller:\n",
    "\n",
    "1. Creates a new ReplicaSet with the updated template\n",
    "2. Scales up the new ReplicaSet while scaling down the old one\n",
    "3. Respects `maxSurge` and `maxUnavailable` constraints\n",
    "4. Waits for new pods to become `Ready` (readiness probe) before terminating old pods\n",
    "\n",
    "### Configuration Parameters\n",
    "\n",
    "**maxSurge:**\n",
    "- **Definition**: Maximum number of pods that can be created above the desired replica count during update\n",
    "- **Values**: Absolute number or percentage (rounded up)\n",
    "- **Default**: 25%\n",
    "- **Example**: With `replicas: 10` and `maxSurge: 25%`, up to 13 pods may exist temporarily (10 desired + 3 surge)\n",
    "\n",
    "**maxUnavailable:**\n",
    "- **Definition**: Maximum number of pods that can be unavailable during update\n",
    "- **Values**: Absolute number or percentage (rounded down)\n",
    "- **Default**: 25%\n",
    "- **Example**: With `replicas: 10` and `maxUnavailable: 0`, all 10 pods must remain available (requires surge capacity)\n",
    "\n",
    "**Optimization Scenarios:**\n",
    "\n",
    "```yaml\n",
    "# Zero-downtime conservative (slower, safer)\n",
    "strategy:\n",
    "  rollingUpdate:\n",
    "    maxSurge: 1        # Add one pod at a time\n",
    "    maxUnavailable: 0  # Never drop below desired count\n",
    "  type: RollingUpdate\n",
    "\n",
    "# Fast rollout (acceptable brief capacity reduction)\n",
    "strategy:\n",
    "  rollingUpdate:\n",
    "    maxSurge: 100%     # Double capacity temporarily\n",
    "    maxUnavailable: 50%  # Allow half to be down\n",
    "  type: RollingUpdate\n",
    "\n",
    "# Recreate-equivalent (for incompatible changes)\n",
    "strategy:\n",
    "  type: Recreate  # Terminates all before creating new\n",
    "```\n",
    "\n",
    "### Monitoring Rollout Progress\n",
    "\n",
    "```bash\n",
    "# Watch rollout in real-time\n",
    "kubectl rollout status deployment/payment-service --timeout=5m\n",
    "\n",
    "# Detailed view of ReplicaSets\n",
    "kubectl get rs -l app=payment-service -w\n",
    "\n",
    "# Check pod distribution between versions\n",
    "kubectl get pods -l app=payment-service -L pod-template-hash\n",
    "\n",
    "# Events during rollout\n",
    "kubectl get events --field-selector involvedObject.name=payment-service --watch\n",
    "```\n",
    "\n",
    "## 31.4 Revision History\n",
    "\n",
    "Deployments maintain a history of ReplicaSets to enable rollback to previous versions. Each unique pod template generates a revision.\n",
    "\n",
    "### Revision Tracking\n",
    "\n",
    "```bash\n",
    "# View revision history\n",
    "kubectl rollout history deployment/payment-service\n",
    "\n",
    "# Output:\n",
    "# REVISION  CHANGE-CAUSE\n",
    "# 1         kubectl apply --record --filename=payment-v1.yaml\n",
    "# 2         kubectl set image deployment/payment-service payment-api=v2.0.0\n",
    "# 3         kubectl apply --filename=payment-v2.3.1.yaml --record\n",
    "```\n",
    "\n",
    "**Change-Cause Annotation:**\n",
    "To track why changes occurred, use the `--record` flag (deprecated in favor of annotations) or manual annotations:\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  annotations:\n",
    "    kubernetes.io/change-cause: \"Upgraded to v2.3.1 for CVE-2024-1234 fix\"\n",
    "```\n",
    "\n",
    "### Revision Retention\n",
    "\n",
    "```yaml\n",
    "spec:\n",
    "  revisionHistoryLimit: 5  # Keep 5 old ReplicaSets (default 10)\n",
    "```\n",
    "\n",
    "**Storage Considerations:**\n",
    "- Each retained ReplicaSet consumes etcd storage\n",
    "- Large clusters with frequent updates may need lower limits\n",
    "- Setting to 0 prevents rollback but cleans up old ReplicaSets immediately\n",
    "\n",
    "## 31.5 Rollback Procedures\n",
    "\n",
    "When deployments fail, Kubernetes provides mechanisms to revert to previous stable versions quickly.\n",
    "\n",
    "### Automated Rollback\n",
    "\n",
    "```bash\n",
    "# Rollback to previous revision\n",
    "kubectl rollout undo deployment/payment-service\n",
    "\n",
    "# Rollback to specific revision\n",
    "kubectl rollout undo deployment/payment-service --to-revision=2\n",
    "\n",
    "# Verify rollback\n",
    "kubectl rollout status deployment/payment-service\n",
    "kubectl get pods -l app=payment-service\n",
    "```\n",
    "\n",
    "**Rollback Mechanics:**\n",
    "1. Deployment controller reverts pod template to specified revision\n",
    "2. New ReplicaSet created with old template (becomes new \"current\")\n",
    "3. Scale transition follows rolling update strategy\n",
    "4. Failed revision ReplicaSet retained for analysis\n",
    "\n",
    "### Rollback Verification\n",
    "\n",
    "```bash\n",
    "# Check if rollback completed\n",
    "kubectl get deployment payment-service -o jsonpath='{.metadata.annotations.deployment\\.kubernetes\\.io/revision}'\n",
    "\n",
    "# Compare current vs desired state\n",
    "kubectl get deployment payment-service -o yaml | grep -A 5 \"containerImage\"\n",
    "\n",
    "# View rollback events\n",
    "kubectl describe deployment payment-service | grep -A 10 \"Events\"\n",
    "```\n",
    "\n",
    "### Database Rollback Considerations\n",
    "\n",
    "Kubernetes rollbacks only revert application code, not database schemas:\n",
    "\n",
    "```yaml\n",
    "# Pre-rollback job for database compatibility check\n",
    "apiVersion: batch/v1\n",
    "kind: Job\n",
    "metadata:\n",
    "  name: pre-rollback-db-check\n",
    "spec:\n",
    "  template:\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: check\n",
    "        image: migrate/migrate\n",
    "        command:\n",
    "        - sh\n",
    "        - -c\n",
    "        - |\n",
    "          # Verify backward compatibility before rollback\n",
    "          migrate -path /migrations -database \"$DB_URL\" validate\n",
    "      restartPolicy: Never\n",
    "```\n",
    "\n",
    "## 31.6 Paused and Resumed Deployments\n",
    "\n",
    "Pausing deployments enables manual canary validation and staged rollouts.\n",
    "\n",
    "### Pause Mechanism\n",
    "\n",
    "```bash\n",
    "# Pause deployment mid-rollout\n",
    "kubectl rollout pause deployment/payment-service\n",
    "\n",
    "# Status shows \"ProgressPaused\"\n",
    "kubectl get deployment payment-service -o jsonpath='{.status.conditions[?(@.type==\"Progressing\")].reason}'\n",
    "\n",
    "# Resume after validation\n",
    "kubectl rollout resume deployment/payment-service\n",
    "```\n",
    "\n",
    "**Use Cases:**\n",
    "- **Canary Validation**: Deploy 1 pod, pause, test manually, then resume\n",
    "- **Maintenance Windows**: Pause before peak traffic, resume during low-traffic period\n",
    "- **Coordinated Changes**: Pause multiple deployments, resume simultaneously\n",
    "\n",
    "### Scripted Canary with Pause\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "# manual-canary.sh\n",
    "\n",
    "DEPLOYMENT=\"payment-service\"\n",
    "NAMESPACE=\"production\"\n",
    "\n",
    "# Start rollout\n",
    "kubectl set image deployment/$DEPLOYMENT payment-api=payment-service:v2.4.0 -n $NAMESPACE\n",
    "\n",
    "# Wait for one pod to be ready\n",
    "echo \"Waiting for first canary pod...\"\n",
    "kubectl rollout pause deployment/$DEPLOYMENT -n $NAMESPACE\n",
    "\n",
    "# Get canary pod name\n",
    "CANARY_POD=$(kubectl get pods -n $NAMESPACE -l app=$DEPLOYMENT -o jsonpath='{.items[0].metadata.name}')\n",
    "\n",
    "# Port-forward for manual testing\n",
    "kubectl port-forward $CANARY_POD 8080:8080 -n $NAMESPACE &\n",
    "PF_PID=$!\n",
    "\n",
    "# Wait for user confirmation\n",
    "read -p \"Test canary at http://localhost:8080. Proceed? (y/n) \" -n 1 -r\n",
    "echo\n",
    "\n",
    "kill $PF_PID\n",
    "\n",
    "if [[ $REPLY =~ ^[Yy]$ ]]; then\n",
    "  echo \"Resuming rollout...\"\n",
    "  kubectl rollout resume deployment/$DEPLOYMENT -n $NAMESPACE\n",
    "  kubectl rollout status deployment/$DEPLOYMENT -n $NAMESPACE\n",
    "else\n",
    "  echo \"Rolling back...\"\n",
    "  kubectl rollout undo deployment/$DEPLOYMENT -n $NAMESPACE\n",
    "fi\n",
    "```\n",
    "\n",
    "## 31.7 Deployment Status and Conditions\n",
    "\n",
    "Deployments expose conditions that reflect their current state, essential for automated tooling and monitoring.\n",
    "\n",
    "### Condition Types\n",
    "\n",
    "**Available:** Minimum replicas available (Ready for minReadySeconds)\n",
    "**Progressing:** ReplicaSet is scaling or pods are being updated\n",
    "**ReplicaFailure:** Error creating/deleting pods\n",
    "\n",
    "```yaml\n",
    "status:\n",
    "  conditions:\n",
    "  - type: Available\n",
    "    status: \"True\"\n",
    "    lastUpdateTime: \"2024-01-15T10:30:00Z\"\n",
    "    reason: MinimumReplicasAvailable\n",
    "    message: Deployment has minimum availability.\n",
    "  \n",
    "  - type: Progressing\n",
    "    status: \"True\"\n",
    "    lastUpdateTime: \"2024-01-15T10:35:00Z\"\n",
    "    reason: NewReplicaSetAvailable\n",
    "    message: ReplicaSet \"payment-service-7c9b8f4d5\" has successfully progressed.\n",
    "```\n",
    "\n",
    "### Progress Deadline\n",
    "\n",
    "```yaml\n",
    "spec:\n",
    "  progressDeadlineSeconds: 600  # 10 minutes\n",
    "```\n",
    "\n",
    "If deployment doesn't progress (new pods not becoming ready) within this window, status becomes `ProgressDeadlineExceeded`:\n",
    "\n",
    "```bash\n",
    "# Check for stuck deployments\n",
    "kubectl get deployments --all-namespaces -o json | \\\n",
    "  jq '.items[] | select(.status.conditions[] | .reason == \"ProgressDeadlineExceeded\") | .metadata.name'\n",
    "```\n",
    "\n",
    "## 31.8 Advanced Deployment Controllers\n",
    "\n",
    "Native Deployments support only RollingUpdate and Recreate strategies. For Blue/Green, Canary, or A/B testing, advanced controllers are required.\n",
    "\n",
    "### Argo Rollouts\n",
    "\n",
    "Argo Rollouts replaces Deployment with enhanced strategies:\n",
    "\n",
    "```yaml\n",
    "apiVersion: argoproj.io/v1alpha1\n",
    "kind: Rollout\n",
    "metadata:\n",
    "  name: payment-service\n",
    "spec:\n",
    "  replicas: 5\n",
    "  strategy:\n",
    "    canary:\n",
    "      canaryService: payment-service-canary  # Separate service for canary\n",
    "      stableService: payment-service-stable  # Stable service\n",
    "      trafficRouting:\n",
    "        istio:\n",
    "          virtualService:\n",
    "            name: payment-service-vs\n",
    "            routes:\n",
    "            - primary\n",
    "      steps:\n",
    "      - setWeight: 10\n",
    "      - pause: {duration: 2m}  # Wait 2 minutes\n",
    "      - setWeight: 25\n",
    "      - analysis:\n",
    "          templates:\n",
    "          - templateName: success-rate\n",
    "          args:\n",
    "          - name: service-name\n",
    "            value: payment-service\n",
    "      - setWeight: 50\n",
    "      - pause: {duration: 2m}\n",
    "      - setWeight: 100\n",
    "      analysis:\n",
    "        threshold: 5  # Max failures\n",
    "        interval: 1m\n",
    "        successfulRunHistoryLimit: 10\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "- Automated metric analysis (Prometheus, Datadog, CloudWatch)\n",
    "- Automated promotion/rollback based on SLOs\n",
    "- Blue/Green and Canary strategies\n",
    "- Integration with Ingress controllers and Service Meshes\n",
    "\n",
    "### Flagger\n",
    "\n",
    "Flagger automates canary deployments using Prometheus metrics:\n",
    "\n",
    "```yaml\n",
    "apiVersion: flagger.app/v1beta1\n",
    "kind: Canary\n",
    "metadata:\n",
    "  name: payment-service\n",
    "spec:\n",
    "  targetRef:\n",
    "    apiVersion: apps/v1\n",
    "    kind: Deployment\n",
    "    name: payment-service\n",
    "  service:\n",
    "    port: 80\n",
    "    targetPort: 8080\n",
    "    gateways:\n",
    "    - istio-gateway\n",
    "    hosts:\n",
    "    - api.company.com\n",
    "  analysis:\n",
    "    interval: 30s\n",
    "    threshold: 5\n",
    "    maxWeight: 50\n",
    "    stepWeight: 10\n",
    "    metrics:\n",
    "    - name: request-success-rate\n",
    "      thresholdRange:\n",
    "        min: 99\n",
    "      interval: 1m\n",
    "    - name: request-duration\n",
    "      thresholdRange:\n",
    "        max: 500\n",
    "      interval: 1m\n",
    "    webhooks:\n",
    "    - name: load-test\n",
    "      url: http://flagger-loadtester.test/\n",
    "      timeout: 5s\n",
    "      metadata:\n",
    "        cmd: \"hey -z 1m -q 10 -c 2 http://payment-service-canary/\"\n",
    "```\n",
    "\n",
    "## 31.9 Integration with Service Meshes\n",
    "\n",
    "Service meshes enable fine-grained traffic splitting beyond what Kubernetes Services provide.\n",
    "\n",
    "### Istio Integration\n",
    "\n",
    "```yaml\n",
    "apiVersion: networking.istio.io/v1beta1\n",
    "kind: VirtualService\n",
    "metadata:\n",
    "  name: payment-service\n",
    "spec:\n",
    "  hosts:\n",
    "  - payment-service.production.svc.cluster.local\n",
    "  http:\n",
    "  - match:\n",
    "    - headers:\n",
    "        end-user:\n",
    "          exact: \"canary-tester\"\n",
    "    route:\n",
    "    - destination:\n",
    "        host: payment-service\n",
    "        subset: v2\n",
    "      weight: 100\n",
    "  - route:\n",
    "    - destination:\n",
    "        host: payment-service\n",
    "        subset: v1\n",
    "      weight: 90\n",
    "    - destination:\n",
    "        host: payment-service\n",
    "        subset: v2\n",
    "      weight: 10\n",
    "---\n",
    "apiVersion: networking.istio.io/v1beta1\n",
    "kind: DestinationRule\n",
    "metadata:\n",
    "  name: payment-service\n",
    "spec:\n",
    "  host: payment-service\n",
    "  subsets:\n",
    "  - name: v1\n",
    "    labels:\n",
    "      version: v1\n",
    "  - name: v2\n",
    "    labels:\n",
    "      version: v2\n",
    "  trafficPolicy:\n",
    "    connectionPool:\n",
    "      tcp:\n",
    "        maxConnections: 100\n",
    "      http:\n",
    "        http1MaxPendingRequests: 50\n",
    "    outlierDetection:\n",
    "      consecutiveErrors: 5\n",
    "      interval: 30s\n",
    "      baseEjectionTime: 30s\n",
    "```\n",
    "\n",
    "### Linkerd Integration\n",
    "\n",
    "```yaml\n",
    "apiVersion: split.smi-spec.io/v1alpha4\n",
    "kind: TrafficSplit\n",
    "metadata:\n",
    "  name: payment-service-canary\n",
    "spec:\n",
    "  service: payment-service\n",
    "  backends:\n",
    "  - service: payment-service-v1\n",
    "    weight: 90\n",
    "  - service: payment-service-v2\n",
    "    weight: 10\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary and Preview\n",
    "\n",
    "In this chapter, we examined the Kubernetes Deployment controller as the foundational mechanism for stateless application management. We detailed the hierarchical relationship where Deployments manage ReplicaSets, which in turn manage Pods, enabling the immutable infrastructure pattern central to Kubernetes operations. The RollingUpdate strategy configuration through `maxSurge` and `maxUnavailable` parameters allows fine-tuning of the availability-vs-speed trade-off, with zero-downtime deployments requiring careful probe configuration—particularly readiness probes that prevent premature traffic routing to initializing containers. Revision history retention enables rapid rollbacks to previous stable states, though operators must remember that Kubernetes rollbacks affect only application code, not database schemas, requiring backward-compatible migration strategies. We explored the pause/resume functionality for manual canary validation and staged rollouts, alongside the progress deadline mechanism that detects stuck deployments. For advanced patterns beyond native capabilities, we introduced Argo Rollouts and Flagger as controllers enabling automated canary analysis and Blue/Green deployments, and demonstrated service mesh integration with Istio and Linkerd for sophisticated traffic splitting and resilience patterns.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Configure readiness probes correctly—without them, Kubernetes considers pods ready immediately on container start, causing 502 errors during rolling updates as traffic routes to initializing applications\n",
    "- Set `maxUnavailable: 0` for critical services to ensure zero-downtime deployments, accepting the infrastructure cost of `maxSurge` capacity requirements\n",
    "- Retain revision history (default 10) for rapid rollback capability, but monitor etcd storage usage in large clusters with frequent deployments\n",
    "- Use `kubectl rollout pause` to implement manual canary releases with native Deployments, validating a single new pod before permitting full rollout\n",
    "- Deployments only manage stateless applications; for stateful workloads requiring ordered deployment, use StatefulSets (Chapter 16)\n",
    "- Integrate Argo Rollouts or Flagger for production canary deployments requiring automated metric-based promotion/rollback rather than manual verification\n",
    "\n",
    "**Next Chapter Preview:**\n",
    "Chapter 32: Helm - Kubernetes Package Manager introduces templating and packaging for Kubernetes manifests. We will explore Helm charts as reusable, configurable deployment packages, examining values files for environment-specific configuration, chart dependencies for complex application stacks, and Helm hooks for pre/post-deployment automation. This chapter bridges the gap between raw Kubernetes manifests and production-grade deployment automation, enabling the sophisticated deployment patterns described in this chapter to be packaged, versioned, and distributed as reusable components across multiple environments and teams."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
