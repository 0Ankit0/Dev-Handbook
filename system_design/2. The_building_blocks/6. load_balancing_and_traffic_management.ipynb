{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06018a62",
   "metadata": {},
   "source": [
    "# **Chapter 6: Load Balancing & Traffic Management**\n",
    "\n",
    "Modern distributed systems must handle millions of concurrent requests while maintaining high availability and low latency. Load balancing distributes traffic across multiple servers to prevent any single server from becoming a bottleneck. This chapter explores load balancing at different layers, algorithms for distributing traffic, health monitoring, and advanced patterns like API gateways and service mesh.\n",
    "\n",
    "---\n",
    "\n",
    "## **6.1 Introduction to Load Balancing**\n",
    "\n",
    "**Load Balancer**: A reverse proxy that distributes incoming network traffic across a group of backend servers (server pool or server farm). It acts as a traffic cop, routing client requests to available servers capable of fulfilling those requests.\n",
    "\n",
    "**Why Load Balancing Matters**:\n",
    "```\n",
    "Without Load Balancer:\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   Client 1  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502  Server     \u2502\n",
    "\u2502   Client 2  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502  (Single)   \u2502\n",
    "\u2502   Client 3  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502  100% Load  \u2502\n",
    "\u2502   ...       \u2502         \u2502  Overwhelmed\u2502\n",
    "\u2502   Client N  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502  Crashes    \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "With Load Balancer:\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   Client 1  \u2502         \u2502  Server 1   \u2502         \u2502  Server 2   \u2502\n",
    "\u2502   Client 2  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502  33% Load   \u2502         \u2502  33% Load   \u2502\n",
    "\u2502   Client 3  \u2502    \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\u2502   ...       \u2502    \u2502                        \u2502\n",
    "\u2502   Client N  \u2502\u2500\u2500\u2500\u2500\u2524    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2514\u2500\u2500>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500>\u2502 Load        \u2502        \u2502  Server 3   \u2502\n",
    "                        \u2502 Balancer    \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502  34% Load   \u2502\n",
    "                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "Benefits:\n",
    "- No single point of overload\n",
    "- Horizontal scaling (add more servers)\n",
    "- High availability (if one fails, others continue)\n",
    "- Better performance (distribute load)\n",
    "```\n",
    "\n",
    "**Load Balancer Responsibilities**:\n",
    "1. **Traffic Distribution**: Distribute requests evenly across servers\n",
    "2. **Health Monitoring**: Check server health, remove unhealthy servers\n",
    "3. **Session Persistence**: Route same client to same server (if needed)\n",
    "4. **SSL/TLS Termination**: Handle encryption/decryption\n",
    "5. **Compression**: Compress responses to reduce bandwidth\n",
    "6. **Caching**: Cache responses to reduce backend load\n",
    "\n",
    "---\n",
    "\n",
    "## **6.2 Layer 4 vs. Layer 7 Load Balancing**\n",
    "\n",
    "Load balancers operate at different layers of the OSI model, offering different capabilities and performance characteristics.\n",
    "\n",
    "### **Layer 4 (Transport Layer) Load Balancing**\n",
    "\n",
    "**Concept**: Operates at the transport layer (TCP/UDP). Makes routing decisions based on IP address and port number, without inspecting the actual content of the message.\n",
    "\n",
    "**How It Works**:\n",
    "```\n",
    "Client Request                    Layer 4 LB                     Backend Servers\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502 IP: 203.0.113.1 \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502 Inspect:        \u2502            \u2502 Server 1    \u2502\n",
    "\u2502 Port: 54321     \u2502   TCP SYN    \u2502 - Source IP     \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502 10.0.1.10   \u2502\n",
    "\u2502                 \u2502              \u2502 - Dest IP       \u2502   TCP SYN  \u2502             \u2502\n",
    "\u2502                 \u2502              \u2502 - Source Port   \u2502            \u2502             \u2502\n",
    "\u2502                 \u2502              \u2502 - Dest Port     \u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\u2502                 \u2502              \u2502                 \u2502\n",
    "\u2502                 \u2502              \u2502 Decision: Route \u2502            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                 \u2502              \u2502 based on IP:Port\u2502            \u2502 Server 2    \u2502\n",
    "\u2502                 \u2502              \u2502 (No content     \u2502            \u2502 10.0.1.11   \u2502\n",
    "\u2502                 \u2502              \u2502 inspection)     \u2502            \u2502             \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "Characteristics:\n",
    "- Fast (no content inspection)\n",
    "- Simple (just NAT - Network Address Translation)\n",
    "- Protocol agnostic (works with any TCP/UDP protocol)\n",
    "- Can't make content-based decisions\n",
    "```\n",
    "\n",
    "**Implementation** (HAProxy Layer 4):\n",
    "```haproxy\n",
    "# HAProxy configuration for Layer 4 (TCP) load balancing\n",
    "global\n",
    "    maxconn 4096\n",
    "\n",
    "defaults\n",
    "    mode tcp                    # Layer 4 mode\n",
    "    timeout connect 5000ms\n",
    "    timeout client 50000ms\n",
    "    timeout server 50000ms\n",
    "\n",
    "frontend tcp_frontend\n",
    "    bind *:3306                 # Listen on port 3306 (MySQL)\n",
    "    default_backend mysql_servers\n",
    "\n",
    "backend mysql_servers\n",
    "    balance roundrobin          # Round-robin algorithm\n",
    "    server mysql1 10.0.1.10:3306 check\n",
    "    server mysql2 10.0.1.11:3306 check\n",
    "    server mysql3 10.0.1.12:3306 check\n",
    "```\n",
    "\n",
    "**Implementation** (NGINX Layer 4/Stream module):\n",
    "```nginx\n",
    "# nginx.conf - Layer 4 load balancing using stream module\n",
    "stream {\n",
    "    upstream mysql_backend {\n",
    "        server 10.0.1.10:3306;\n",
    "        server 10.0.1.11:3306;\n",
    "        server 10.0.1.12:3306;\n",
    "    }\n",
    "\n",
    "    server {\n",
    "        listen 3306;\n",
    "        proxy_pass mysql_backend;\n",
    "        proxy_timeout 3s;\n",
    "        proxy_connect_timeout 1s;\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Implementation** (Python socket example):\n",
    "```python\n",
    "import socket\n",
    "import select\n",
    "import threading\n",
    "\n",
    "class Layer4LoadBalancer:\n",
    "    def __init__(self, listen_host, listen_port, backend_servers):\n",
    "        self.listen_host = listen_host\n",
    "        self.listen_port = listen_port\n",
    "        self.backend_servers = backend_servers\n",
    "        self.current_index = 0\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def get_next_backend(self):\n",
    "        \"\"\"Round-robin selection of backend server\"\"\"\n",
    "        with self.lock:\n",
    "            backend = self.backend_servers[self.current_index]\n",
    "            self.current_index = (self.current_index + 1) % len(self.backend_servers)\n",
    "            return backend\n",
    "    \n",
    "    def handle_client(self, client_socket):\n",
    "        \"\"\"Handle client connection by forwarding to backend\"\"\"\n",
    "        backend_host, backend_port = self.get_next_backend()\n",
    "        \n",
    "        try:\n",
    "            # Connect to backend\n",
    "            backend_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            backend_socket.connect((backend_host, backend_port))\n",
    "            \n",
    "            # Forward data in both directions\n",
    "            self.forward_data(client_socket, backend_socket)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to backend {backend_host}:{backend_port}: {e}\")\n",
    "        finally:\n",
    "            client_socket.close()\n",
    "            if 'backend_socket' in locals():\n",
    "                backend_socket.close()\n",
    "    \n",
    "    def forward_data(self, client_socket, backend_socket):\n",
    "        \"\"\"Forward data between client and backend\"\"\"\n",
    "        sockets = [client_socket, backend_socket]\n",
    "        \n",
    "        while True:\n",
    "            readable, _, _ = select.select(sockets, [], [], 1)\n",
    "            \n",
    "            for sock in readable:\n",
    "                data = sock.recv(4096)\n",
    "                if not data:\n",
    "                    return\n",
    "                \n",
    "                if sock is client_socket:\n",
    "                    # Client -> Backend\n",
    "                    backend_socket.send(data)\n",
    "                else:\n",
    "                    # Backend -> Client\n",
    "                    client_socket.send(data)\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start the load balancer\"\"\"\n",
    "        server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "        server.bind((self.listen_host, self.listen_port))\n",
    "        server.listen(5)\n",
    "        \n",
    "        print(f\"Layer 4 Load Balancer listening on {self.listen_host}:{self.listen_port}\")\n",
    "        \n",
    "        while True:\n",
    "            client_socket, address = server.accept()\n",
    "            print(f\"Connection from {address}\")\n",
    "            \n",
    "            # Handle client in new thread\n",
    "            thread = threading.Thread(target=self.handle_client, args=(client_socket,))\n",
    "            thread.start()\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    backends = [\n",
    "        (\"10.0.1.10\", 3306),  # MySQL Server 1\n",
    "        (\"10.0.1.11\", 3306),  # MySQL Server 2\n",
    "        (\"10.0.1.12\", 3306),  # MySQL Server 3\n",
    "    ]\n",
    "    \n",
    "    lb = Layer4LoadBalancer(\"0.0.0.0\", 3306, backends)\n",
    "    lb.start()\n",
    "```\n",
    "\n",
    "**Advantages**:\n",
    "- **High Performance**: No content inspection (just packet forwarding)\n",
    "- **Low Latency**: Minimal processing overhead\n",
    "- **Protocol Agnostic**: Works with any TCP/UDP protocol (MySQL, Redis, custom protocols)\n",
    "- **Secure**: Can't inspect content (privacy advantage in some cases)\n",
    "- **DDoS Resilience**: Can handle higher traffic volumes\n",
    "\n",
    "**Disadvantages**:\n",
    "- **No Content-Based Routing**: Can't route based on URL, headers, or content\n",
    "- **No Caching**: Can't cache responses (doesn't understand HTTP)\n",
    "- **No SSL Offloading**: Must pass encrypted traffic through (or terminate at backend)\n",
    "- **No HTTP-Specific Features**: No cookie handling, compression, redirects\n",
    "\n",
    "**Use Cases**:\n",
    "- Database load balancing (MySQL, PostgreSQL, MongoDB)\n",
    "- Cache clusters (Redis, Memcached)\n",
    "- Custom TCP protocols\n",
    "- Real-time gaming servers (UDP)\n",
    "- When maximum performance is required\n",
    "\n",
    "---\n",
    "\n",
    "### **Layer 7 (Application Layer) Load Balancing**\n",
    "\n",
    "**Concept**: Operates at the application layer (HTTP/HTTPS). Makes routing decisions based on content of the message\u2014URL, headers, cookies, or body content.\n",
    "\n",
    "**How It Works**:\n",
    "```\n",
    "Client Request                    Layer 7 LB                     Backend Servers\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502 GET /api/users  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502 Inspect:        \u2502            \u2502 API Server  \u2502\n",
    "\u2502 Host: api.com   \u2502   HTTP       \u2502 - URL (/api/*)  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502 10.0.1.10   \u2502\n",
    "\u2502 Cookie: sess=abc\u2502   Request    \u2502 - Host header   \u2502            \u2502             \u2502\n",
    "\u2502                 \u2502              \u2502 - Cookies       \u2502            \u2502             \u2502\n",
    "\u2502                 \u2502              \u2502 - Headers       \u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\u2502                 \u2502              \u2502 - Body content  \u2502\n",
    "\u2502                 \u2502              \u2502                 \u2502            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                 \u2502              \u2502 Decision: Route \u2502            \u2502 Web Server  \u2502\n",
    "\u2502                 \u2502              \u2502 based on URL    \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502 10.0.1.11   \u2502\n",
    "\u2502                 \u2502              \u2502 /static/* ->    \u2502            \u2502 (Static)    \u2502\n",
    "\u2502                 \u2502              \u2502 /api/* ->       \u2502            \u2502             \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "Characteristics:\n",
    "- Slower (content inspection required)\n",
    "- Smart routing (based on URL, headers, cookies)\n",
    "- Can cache responses\n",
    "- SSL termination\n",
    "- Compression\n",
    "- HTTP-specific features\n",
    "```\n",
    "\n",
    "**Implementation** (NGINX Layer 7):\n",
    "```nginx\n",
    "# nginx.conf - Layer 7 (HTTP) load balancing\n",
    "http {\n",
    "    upstream api_servers {\n",
    "        least_conn;                    # Least connections algorithm\n",
    "        server 10.0.1.10:8080 weight=3;  # API Server 1 (higher capacity)\n",
    "        server 10.0.1.11:8080 weight=2;  # API Server 2\n",
    "        server 10.0.1.12:8080 backup;    # API Server 3 (backup only)\n",
    "        \n",
    "        keepalive 32;                  # Keep connections alive\n",
    "    }\n",
    "    \n",
    "    upstream static_servers {\n",
    "        server 10.0.1.20:80;\n",
    "        server 10.0.1.21:80;\n",
    "    }\n",
    "    \n",
    "    # Rate limiting\n",
    "    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;\n",
    "    \n",
    "    server {\n",
    "        listen 80;\n",
    "        server_name api.example.com;\n",
    "        \n",
    "        # SSL Termination\n",
    "        listen 443 ssl;\n",
    "        ssl_certificate /etc/nginx/ssl/cert.pem;\n",
    "        ssl_certificate_key /etc/nginx/ssl/key.pem;\n",
    "        \n",
    "        # Compression\n",
    "        gzip on;\n",
    "        gzip_types application/json text/css application/javascript;\n",
    "        \n",
    "        # Caching\n",
    "        proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=my_cache:10m;\n",
    "        \n",
    "        # Route based on URL path\n",
    "        location /api/ {\n",
    "            limit_req zone=api_limit burst=20 nodelay;\n",
    "            \n",
    "            proxy_pass http://api_servers;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            \n",
    "            # Health check\n",
    "            health_check interval=5s fails=3 passes=2;\n",
    "        }\n",
    "        \n",
    "        location /static/ {\n",
    "            proxy_pass http://static_servers;\n",
    "            expires 30d;              # Cache static assets\n",
    "            add_header Cache-Control \"public, immutable\";\n",
    "        }\n",
    "        \n",
    "        # Redirect HTTP to HTTPS\n",
    "        if ($scheme != \"https\") {\n",
    "            return 301 https://$host$request_uri;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Implementation** (HAProxy Layer 7):\n",
    "```haproxy\n",
    "# HAProxy Layer 7 configuration\n",
    "global\n",
    "    maxconn 4096\n",
    "    daemon\n",
    "\n",
    "defaults\n",
    "    mode http                    # Layer 7 mode\n",
    "    timeout connect 5s\n",
    "    timeout client 50s\n",
    "    timeout server 50s\n",
    "    option httpchk GET /health   # HTTP health check\n",
    "\n",
    "frontend http_frontend\n",
    "    bind *:80\n",
    "    bind *:443 ssl crt /etc/haproxy/certs.pem\n",
    "    \n",
    "    # ACLs (Access Control Lists) for routing\n",
    "    acl is_api path_beg /api\n",
    "    acl is_static path_beg /static\n",
    "    acl is_mobile hdr_sub(User-Agent) Mobile|Android|iPhone\n",
    "    \n",
    "    # Routing rules\n",
    "    use_backend api_servers if is_api\n",
    "    use_backend static_servers if is_static\n",
    "    use_backend mobile_servers if is_mobile\n",
    "    \n",
    "    default_backend web_servers\n",
    "\n",
    "backend api_servers\n",
    "    balance roundrobin\n",
    "    option httpchk GET /api/health\n",
    "    server api1 10.0.1.10:8080 check weight 3\n",
    "    server api2 10.0.1.11:8080 check weight 2\n",
    "    server api3 10.0.1.12:8080 check weight 2 backup\n",
    "\n",
    "backend static_servers\n",
    "    balance leastconn\n",
    "    server static1 10.0.1.20:80 check\n",
    "    server static2 10.0.1.21:80 check\n",
    "\n",
    "backend mobile_servers\n",
    "    server mobile1 10.0.1.30:80 check\n",
    "\n",
    "backend web_servers\n",
    "    balance source              # IP Hash (sticky sessions)\n",
    "    server web1 10.0.1.40:80 check\n",
    "    server web2 10.0.1.41:80 check\n",
    "```\n",
    "\n",
    "**Implementation** (Python Flask-based Layer 7 LB):\n",
    "```python\n",
    "from flask import Flask, request, Response\n",
    "import requests\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Backend configurations\n",
    "BACKENDS = {\n",
    "    'api': [\n",
    "        'http://10.0.1.10:8080',\n",
    "        'http://10.0.1.11:8080',\n",
    "        'http://10.0.1.12:8080'\n",
    "    ],\n",
    "    'static': [\n",
    "        'http://10.0.1.20:80',\n",
    "        'http://10.0.1.21:80'\n",
    "    ]\n",
    "}\n",
    "\n",
    "class Layer7LoadBalancer:\n",
    "    def __init__(self):\n",
    "        self.api_index = 0\n",
    "        self.sessions = {}  # Session affinity storage\n",
    "    \n",
    "    def get_backend(self, service, request):\n",
    "        \"\"\"Select backend based on routing logic\"\"\"\n",
    "        if service == 'api':\n",
    "            # Round-robin for API\n",
    "            backend = BACKENDS['api'][self.api_index]\n",
    "            self.api_index = (self.api_index + 1) % len(BACKENDS['api'])\n",
    "            return backend\n",
    "        \n",
    "        elif service == 'static':\n",
    "            # Random for static assets\n",
    "            return random.choice(BACKENDS['static'])\n",
    "        \n",
    "        elif service == 'sticky':\n",
    "            # IP Hash for session affinity\n",
    "            client_ip = request.remote_addr\n",
    "            hash_val = int(hashlib.md5(client_ip.encode()).hexdigest(), 16)\n",
    "            index = hash_val % len(BACKENDS['api'])\n",
    "            return BACKENDS['api'][index]\n",
    "    \n",
    "    def route_request(self, request):\n",
    "        \"\"\"Route request based on URL path and headers\"\"\"\n",
    "        path = request.path\n",
    "        \n",
    "        # Content-based routing\n",
    "        if path.startswith('/api/'):\n",
    "            backend = self.get_backend('api', request)\n",
    "        elif path.startswith('/static/'):\n",
    "            backend = self.get_backend('static', request)\n",
    "        else:\n",
    "            # Default to sticky session for web\n",
    "            backend = self.get_backend('sticky', request)\n",
    "        \n",
    "        # Forward request\n",
    "        target_url = f\"{backend}{path}\"\n",
    "        \n",
    "        # Copy headers\n",
    "        headers = {key: value for key, value in request.headers}\n",
    "        headers['X-Forwarded-For'] = request.remote_addr\n",
    "        \n",
    "        # Forward request to backend\n",
    "        try:\n",
    "            resp = requests.request(\n",
    "                method=request.method,\n",
    "                url=target_url,\n",
    "                headers=headers,\n",
    "                data=request.get_data(),\n",
    "                cookies=request.cookies,\n",
    "                timeout=5\n",
    "            )\n",
    "            \n",
    "            # Create response\n",
    "            response = Response(\n",
    "                resp.content,\n",
    "                status=resp.status_code,\n",
    "                headers=dict(resp.headers)\n",
    "            )\n",
    "            return response\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return Response(f\"Backend error: {str(e)}\", status=502)\n",
    "\n",
    "lb = Layer7LoadBalancer()\n",
    "\n",
    "@app.route('/', defaults={'path': ''})\n",
    "@app.route('/<path:path>', methods=['GET', 'POST', 'PUT', 'DELETE'])\n",
    "def catch_all(path):\n",
    "    \"\"\"Catch-all route to load balancer\"\"\"\n",
    "    return lb.route_request(request)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=80)\n",
    "```\n",
    "\n",
    "**Advantages**:\n",
    "- **Smart Routing**: Route based on URL, headers, cookies, or content\n",
    "- **SSL/TLS Termination**: Handle encryption at load balancer (reduces backend load)\n",
    "- **Caching**: Cache responses to reduce backend load\n",
    "- **Compression**: Compress responses (gzip/brotli)\n",
    "- **Content Switching**: Different backends for different content types\n",
    "- **Security**: WAF (Web Application Firewall), DDoS protection, rate limiting\n",
    "- **Analytics**: Log and analyze HTTP traffic\n",
    "\n",
    "**Disadvantages**:\n",
    "- **Higher Latency**: Content inspection adds overhead\n",
    "- **Resource Intensive**: More CPU/memory required than Layer 4\n",
    "- **Protocol Specific**: Only works with HTTP/HTTPS (or specific L7 protocols)\n",
    "- **Complexity**: More complex configuration and debugging\n",
    "\n",
    "**Use Cases**:\n",
    "- Web applications (HTTP/HTTPS)\n",
    "- Microservices routing (path-based)\n",
    "- SSL termination\n",
    "- Content caching\n",
    "- A/B testing (route based on headers/cookies)\n",
    "- Mobile vs. Desktop routing\n",
    "- API gateways\n",
    "\n",
    "---\n",
    "\n",
    "### **Comparison: Layer 4 vs. Layer 7**\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502 Feature               \u2502 Layer 4 (Transport)    \u2502 Layer 7 (Application)  \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 OSI Layer             \u2502 Transport (TCP/UDP)    \u2502 Application (HTTP)     \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Routing Decision      \u2502 IP + Port              \u2502 URL, Headers, Cookies  \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Content Inspection    \u2502 No                     \u2502 Yes                    \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Performance           \u2502 High (simple NAT)      \u2502 Lower (inspection)     \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Latency               \u2502 Low (~1ms)             \u2502 Higher (~5-10ms)       \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 SSL/TLS Termination   \u2502 No (pass-through)      \u2502 Yes                    \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Caching               \u2502 No                     \u2502 Yes                    \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Compression           \u2502 No                     \u2502 Yes                    \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Protocol Support      \u2502 Any TCP/UDP            \u2502 HTTP/HTTPS primarily   \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Session Affinity      \u2502 IP-based only          \u2502 Cookie-based, IP-based \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Use Cases             \u2502 Databases, Cache,      \u2502 Web apps, APIs,        \u2502\n",
    "\u2502                       \u2502 Custom protocols       \u2502 Microservices          \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6.3 Load Balancing Algorithms**\n",
    "\n",
    "Load balancers use different algorithms to determine which backend server receives the next request. The choice of algorithm depends on your use case, server capabilities, and traffic patterns.\n",
    "\n",
    "### **Round Robin**\n",
    "\n",
    "**Concept**: Distribute requests sequentially to each server in the list. After reaching the end, start again from the first server.\n",
    "\n",
    "**How It Works**:\n",
    "```\n",
    "Request 1 -> Server 1\n",
    "Request 2 -> Server 2\n",
    "Request 3 -> Server 3\n",
    "Request 4 -> Server 1\n",
    "Request 5 -> Server 2\n",
    "Request 6 -> Server 3\n",
    "...\n",
    "```\n",
    "\n",
    "**Implementation**:\n",
    "```python\n",
    "class RoundRobinBalancer:\n",
    "    def __init__(self, servers):\n",
    "        self.servers = servers\n",
    "        self.current_index = 0\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def get_server(self):\n",
    "        with self.lock:\n",
    "            server = self.servers[self.current_index]\n",
    "            self.current_index = (self.current_index + 1) % len(self.servers)\n",
    "            return server\n",
    "\n",
    "# Usage\n",
    "servers = ['10.0.1.10', '10.0.1.11', '10.0.1.12']\n",
    "balancer = RoundRobinBalancer(servers)\n",
    "\n",
    "for i in range(6):\n",
    "    print(f\"Request {i+1} -> {balancer.get_server()}\")\n",
    "\n",
    "# Output:\n",
    "# Request 1 -> 10.0.1.10\n",
    "# Request 2 -> 10.0.1.11\n",
    "# Request 3 -> 10.0.1.12\n",
    "# Request 4 -> 10.0.1.10\n",
    "# Request 5 -> 10.0.1.11\n",
    "# Request 6 -> 10.0.1.12\n",
    "```\n",
    "\n",
    "**Advantages**:\n",
    "- **Simple**: Easy to understand and implement\n",
    "- **Fair**: Equal distribution among servers\n",
    "- **Stateless**: No tracking required\n",
    "\n",
    "**Disadvantages**:\n",
    "- **Ignores Server Load**: Doesn't consider current connections or response time\n",
    "- **No Session Affinity**: Same client may hit different servers\n",
    "- **Uneven if Weights Differ**: Doesn't account for server capacity differences\n",
    "\n",
    "**When to Use**:\n",
    "- When all servers have equal capacity\n",
    "- When requests are roughly equal in processing time\n",
    "- Stateless applications\n",
    "\n",
    "---\n",
    "\n",
    "### **Weighted Round Robin**\n",
    "\n",
    "**Concept**: Like round robin, but servers with higher weights receive proportionally more requests.\n",
    "\n",
    "**How It Works**:\n",
    "```\n",
    "Servers:\n",
    "- Server 1: Weight 3\n",
    "- Server 2: Weight 2\n",
    "- Server 3: Weight 1\n",
    "\n",
    "Distribution:\n",
    "Request 1 -> Server 1\n",
    "Request 2 -> Server 1\n",
    "Request 3 -> Server 1\n",
    "Request 4 -> Server 2\n",
    "Request 5 -> Server 2\n",
    "Request 6 -> Server 3\n",
    "Request 7 -> Server 1\n",
    "...\n",
    "```\n",
    "\n",
    "**Implementation**:\n",
    "```python\n",
    "class WeightedRoundRobinBalancer:\n",
    "    def __init__(self, servers_with_weights):\n",
    "        \"\"\"\n",
    "        servers_with_weights: [('10.0.1.10', 3), ('10.0.1.11', 2), ('10.0.1.12', 1)]\n",
    "        \"\"\"\n",
    "        self.servers = []\n",
    "        for server, weight in servers_with_weights:\n",
    "            # Add server 'weight' times to the list\n",
    "            self.servers.extend([server] * weight)\n",
    "        \n",
    "        self.current_index = 0\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def get_server(self):\n",
    "        with self.lock:\n",
    "            server = self.servers[self.current_index]\n",
    "            self.current_index = (self.current_index + 1) % len(self.servers)\n",
    "            return server\n",
    "\n",
    "# Usage\n",
    "servers = [('10.0.1.10', 3), ('10.0.1.11', 2), ('10.0.1.12', 1)]\n",
    "balancer = WeightedRoundRobinBalancer(servers)\n",
    "\n",
    "distribution = {}\n",
    "for i in range(60):\n",
    "    server = balancer.get_server()\n",
    "    distribution[server] = distribution.get(server, 0) + 1\n",
    "\n",
    "print(\"Distribution:\", distribution)\n",
    "# Output: {'10.0.1.10': 30, '10.0.1.11': 20, '10.0.1.12': 10} (3:2:1 ratio)\n",
    "```\n",
    "\n",
    "**Advantages**:\n",
    "- **Capacity Aware**: Higher capacity servers get more traffic\n",
    "- **Simple**: Still relatively simple to implement\n",
    "- **Flexible**: Easy to adjust weights based on server performance\n",
    "\n",
    "**When to Use**:\n",
    "- When servers have different capacities (CPU, memory)\n",
    "- When you want to gradually introduce new servers (start with low weight)\n",
    "- When some servers are faster than others\n",
    "\n",
    "---\n",
    "\n",
    "### **Least Connections**\n",
    "\n",
    "**Concept**: Route request to the server with the fewest active connections. Assumes current connections indicate current load.\n",
    "\n",
    "**How It Works**:\n",
    "```\n",
    "Current Connections:\n",
    "- Server 1: 10 connections\n",
    "- Server 2: 5 connections\n",
    "- Server 3: 8 connections\n",
    "\n",
    "Next Request -> Server 2 (fewest connections)\n",
    "\n",
    "After routing:\n",
    "- Server 1: 10 connections\n",
    "- Server 2: 6 connections (+1)\n",
    "- Server 3: 8 connections\n",
    "```\n",
    "\n",
    "**Implementation**:\n",
    "```python\n",
    "import threading\n",
    "\n",
    "class LeastConnectionsBalancer:\n",
    "    def __init__(self, servers):\n",
    "        self.servers = {server: 0 for server in servers}  # connection counts\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def get_server(self):\n",
    "        with self.lock:\n",
    "            # Find server with minimum connections\n",
    "            min_server = min(self.servers, key=self.servers.get)\n",
    "            self.servers[min_server] += 1\n",
    "            return min_server\n",
    "    \n",
    "    def release_connection(self, server):\n",
    "        \"\"\"Call when connection is closed\"\"\"\n",
    "        with self.lock:\n",
    "            if self.servers[server] > 0:\n",
    "                self.servers[server] -= 1\n",
    "    \n",
    "    def get_stats(self):\n",
    "        return dict(self.servers)\n",
    "\n",
    "# Usage\n",
    "servers = ['10.0.1.10', '10.0.1.11', '10.0.1.12']\n",
    "balancer = LeastConnectionsBalancer(servers)\n",
    "\n",
    "# Simulate connections\n",
    "for i in range(10):\n",
    "    server = balancer.get_server()\n",
    "    print(f\"Request {i+1} -> {server} (connections: {balancer.get_stats()})\")\n",
    "\n",
    "# Note: In real implementation, you'd call release_connection() when done\n",
    "```\n",
    "\n",
    "**Advantages**:\n",
    "- **Load Aware**: Considers current server load\n",
    "- **Dynamic**: Adapts to changing traffic patterns\n",
    "- **Better for Long Connections**: Good for WebSocket, database connections\n",
    "\n",
    "**Disadvantages**:\n",
    "- **Connection Count \u2260 Load**: A server with few connections might be processing heavy requests\n",
    "- **Overhead**: Requires tracking connection counts\n",
    "- **Uneven Distribution**: Can lead to uneven distribution if connections have different durations\n",
    "\n",
    "**When to Use**:\n",
    "- When connections have variable durations\n",
    "- Long-lived connections (WebSockets, streaming)\n",
    "- When server load correlates with connection count\n",
    "\n",
    "---\n",
    "\n",
    "### **Least Response Time**\n",
    "\n",
    "**Concept**: Route request to the server with the fastest response time. Combines least connections with response time metrics.\n",
    "\n",
    "**How It Works**:\n",
    "```\n",
    "Metrics:\n",
    "- Server 1: 5 connections, avg response time 100ms\n",
    "- Server 2: 3 connections, avg response time 200ms\n",
    "- Server 3: 4 connections, avg response time 50ms\n",
    "\n",
    "Next Request -> Server 3 (fastest response time, despite having 4 connections)\n",
    "```\n",
    "\n",
    "**Implementation**:\n",
    "```python\n",
    "import time\n",
    "import threading\n",
    "from collections import deque\n",
    "\n",
    "class LeastResponseTimeBalancer:\n",
    "    def __init__(self, servers):\n",
    "        self.servers = servers\n",
    "        self.response_times = {server: deque(maxlen=10) for server in servers}  # Keep last 10\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def record_response_time(self, server, response_time):\n",
    "        \"\"\"Record response time for a server\"\"\"\n",
    "        with self.lock:\n",
    "            self.response_times[server].append(response_time)\n",
    "    \n",
    "    def get_average_response_time(self, server):\n",
    "        \"\"\"Calculate average response time\"\"\"\n",
    "        times = self.response_times[server]\n",
    "        return sum(times) / len(times) if times else float('inf')\n",
    "    \n",
    "    def get_server(self):\n",
    "        with self.lock:\n",
    "            # Find server with lowest average response time\n",
    "            best_server = min(self.servers, key=self.get_average_response_time)\n",
    "            return best_server\n",
    "\n",
    "# Usage with timing\n",
    "servers = ['10.0.1.10', '10.0.1.11', '10.0.1.12']\n",
    "balancer = LeastResponseTimeBalancer(servers)\n",
    "\n",
    "# Simulate requests\n",
    "for i in range(10):\n",
    "    server = balancer.get_server()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # ... make request to server ...\n",
    "    time.sleep(0.1)  # Simulated processing\n",
    "    response_time = time.time() - start_time\n",
    "    \n",
    "    balancer.record_response_time(server, response_time)\n",
    "    print(f\"Request {i+1} -> {server} (avg response: {balancer.get_average_response_time(server):.3f}s)\")\n",
    "```\n",
    "\n",
    "**Advantages**:\n",
    "- **Performance Aware**: Routes to fastest server\n",
    "- **Adaptive**: Adapts to server performance changes\n",
    "- **Optimal User Experience**: Users get fastest responses\n",
    "\n",
    "**Disadvantages**:\n",
    "- **Measurement Overhead**: Requires tracking response times\n",
    "- **Fluctuation**: Response times can fluctuate, causing thrashing\n",
    "- **Cold Start**: New servers have no history (assumed slow)\n",
    "\n",
    "**When to Use**:\n",
    "- When server performance varies\n",
    "- When you want to optimize for response time\n",
    "- When servers have different hardware capabilities\n",
    "\n",
    "---\n",
    "\n",
    "### **IP Hash (Source IP Hash)**\n",
    "\n",
    "**Concept**: Hash the client's IP address to determine which server receives the request. Same client always goes to same server (session affinity/sticky sessions).\n",
    "\n",
    "**How It Works**:\n",
    "```\n",
    "Client IP: 203.0.113.45\n",
    "Hash: hash(203.0.113.45) % 3 = 1\n",
    "\n",
    "Request from 203.0.113.45 -> Server 2 (index 1)\n",
    "\n",
    "All subsequent requests from same IP -> Server 2\n",
    "```\n",
    "\n",
    "**Implementation**:\n",
    "```python\n",
    "import hashlib\n",
    "\n",
    "class IPHashBalancer:\n",
    "    def __init__(self, servers):\n",
    "        self.servers = servers\n",
    "        self.num_servers = len(servers)\n",
    "    \n",
    "    def get_server(self, client_ip):\n",
    "        \"\"\"Get server based on client IP hash\"\"\"\n",
    "        # Create hash of IP address\n",
    "        hash_obj = hashlib.md5(client_ip.encode())\n",
    "        hash_val = int(hash_obj.hexdigest(), 16)\n",
    "        \n",
    "        # Map hash to server index\n",
    "        server_index = hash_val % self.num_servers\n",
    "        return self.servers[server_index]\n",
    "\n",
    "# Usage\n",
    "servers = ['10.0.1.10', '10.0.1.11', '10.0.1.12']\n",
    "balancer = IPHashBalancer(servers)\n",
    "\n",
    "# Test with different IPs\n",
    "test_ips = ['203.0.113.1', '203.0.113.2', '203.0.113.1', '198.51.100.5', '203.0.113.1']\n",
    "\n",
    "for ip in test_ips:\n",
    "    server = balancer.get_server(ip)\n",
    "    print(f\"Client {ip} -> {server}\")\n",
    "\n",
    "# Output:\n",
    "# Client 203.0.113.1 -> 10.0.1.11\n",
    "# Client 203.0.113.2 -> 10.0.1.12\n",
    "# Client 203.0.113.1 -> 10.0.1.11 (same as first!)\n",
    "# Client 198.51.100.5 -> 10.0.1.10\n",
    "# Client 203.0.113.1 -> 10.0.1.11 (same again - sticky!)\n",
    "```\n",
    "\n",
    "**Advantages**:\n",
    "- **Session Affinity**: Same client always hits same server (good for sessions)\n",
    "- **Stateless LB**: No need to track sessions at load balancer\n",
    "- **Even Distribution**: Good distribution if IP addresses are random\n",
    "\n",
    "**Disadvantages**:\n",
    "- **Uneven Distribution**: If many clients behind NAT (same public IP), one server gets overloaded\n",
    "- **No Failover**: If server fails, clients on that server lose sessions\n",
    "- **Caching Issues**: If server cache differs, users see inconsistent data\n",
    "\n",
    "**When to Use**:\n",
    "- When session state is stored on server (not in database)\n",
    "- When you need sticky sessions without cookies\n",
    "- When clients are well-distributed across IP ranges\n",
    "\n",
    "---\n",
    "\n",
    "### **Consistent Hashing (for Distributed Systems)**\n",
    "\n",
    "**Concept**: We covered this in Chapter 2, but it's crucial for load balancing too. Maps clients to servers on a hash ring, minimizing remapping when servers are added/removed.\n",
    "\n",
    "**Use Case**: Distributed caching, distributed databases, CDNs.\n",
    "\n",
    "**Implementation**:\n",
    "```python\n",
    "import hashlib\n",
    "import bisect\n",
    "\n",
    "class ConsistentHashBalancer:\n",
    "    def __init__(self, servers=None, replicas=100):\n",
    "        self.replicas = replicas  # Virtual nodes per server\n",
    "        self.ring = []  # Sorted list of hash values\n",
    "        self.nodes = {}  # hash -> server mapping\n",
    "        \n",
    "        if servers:\n",
    "            for server in servers:\n",
    "                self.add_server(server)\n",
    "    \n",
    "    def _hash(self, key):\n",
    "        return int(hashlib.md5(key.encode()).hexdigest(), 16)\n",
    "    \n",
    "    def add_server(self, server):\n",
    "        \"\"\"Add server to ring\"\"\"\n",
    "        for i in range(self.replicas):\n",
    "            virtual_node = f\"{server}:{i}\"\n",
    "            hash_val = self._hash(virtual_node)\n",
    "            self.nodes[hash_val] = server\n",
    "            bisect.insort(self.ring, hash_val)\n",
    "    \n",
    "    def remove_server(self, server):\n",
    "        \"\"\"Remove server from ring\"\"\"\n",
    "        for i in range(self.replicas):\n",
    "            virtual_node = f\"{server}:{i}\"\n",
    "            hash_val = self._hash(virtual_node)\n",
    "            if hash_val in self.nodes:\n",
    "                del self.nodes[hash_val]\n",
    "                self.ring.remove(hash_val)\n",
    "    \n",
    "    def get_server(self, client_key):\n",
    "        \"\"\"Get server for client key\"\"\"\n",
    "        if not self.ring:\n",
    "            return None\n",
    "        \n",
    "        hash_val = self._hash(client_key)\n",
    "        \n",
    "        # Find first server clockwise from hash\n",
    "        idx = bisect.bisect_right(self.ring, hash_val)\n",
    "        if idx == len(self.ring):\n",
    "            idx = 0\n",
    "        \n",
    "        return self.nodes[self.ring[idx]]\n",
    "\n",
    "# Usage\n",
    "servers = ['10.0.1.10', '10.0.1.11', '10.0.1.12']\n",
    "balancer = ConsistentHashBalancer(servers)\n",
    "\n",
    "# Test distribution\n",
    "distribution = {}\n",
    "for i in range(1000):\n",
    "    client = f\"client_{i}\"\n",
    "    server = balancer.get_server(client)\n",
    "    distribution[server] = distribution.get(server, 0) + 1\n",
    "\n",
    "print(\"Distribution:\", distribution)\n",
    "\n",
    "# Add new server (minimal remapping)\n",
    "balancer.add_server('10.0.1.13')\n",
    "\n",
    "# Check how many clients moved\n",
    "moved = 0\n",
    "for i in range(1000):\n",
    "    client = f\"client_{i}\"\n",
    "    new_server = balancer.get_server(client)\n",
    "    # Compare with old assignment...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6.4 Health Checks and Circuit Breakers**\n",
    "\n",
    "Load balancers must know which backend servers are healthy and available. Health checks monitor server status, while circuit breakers prevent cascading failures.\n",
    "\n",
    "### **Health Checks**\n",
    "\n",
    "**Active Health Checks**: Load balancer periodically pings servers to check health.\n",
    "\n",
    "**Types**:\n",
    "1. **TCP Check**: Try to establish TCP connection\n",
    "2. **HTTP Check**: Send HTTP request, check response code\n",
    "3. **Custom Check**: Application-specific health endpoint\n",
    "\n",
    "**Implementation** (NGINX):\n",
    "```nginx\n",
    "upstream backend {\n",
    "    server 10.0.1.10:8080;\n",
    "    server 10.0.1.11:8080;\n",
    "    \n",
    "    # Health check\n",
    "    health_check interval=5s fails=3 passes=2 \n",
    "                 uri=/health \n",
    "                 http_200;\n",
    "}\n",
    "\n",
    "server {\n",
    "    location / {\n",
    "        proxy_pass http://backend;\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Implementation** (Python):\n",
    "```python\n",
    "import threading\n",
    "import requests\n",
    "import time\n",
    "from enum import Enum\n",
    "\n",
    "class ServerStatus(Enum):\n",
    "    HEALTHY = \"healthy\"\n",
    "    UNHEALTHY = \"unhealthy\"\n",
    "    CHECKING = \"checking\"\n",
    "\n",
    "class HealthChecker:\n",
    "    def __init__(self, servers, check_interval=5, timeout=2):\n",
    "        self.servers = {server: ServerStatus.HEALTHY for server in servers}\n",
    "        self.check_interval = check_interval\n",
    "        self.timeout = timeout\n",
    "        self.healthy_servers = set(servers)\n",
    "        self.lock = threading.Lock()\n",
    "        \n",
    "        # Start health check thread\n",
    "        self.checker_thread = threading.Thread(target=self._health_check_loop, daemon=True)\n",
    "        self.checker_thread.start()\n",
    "    \n",
    "    def _check_server(self, server):\n",
    "        \"\"\"Check if server is healthy\"\"\"\n",
    "        try:\n",
    "            # HTTP health check\n",
    "            response = requests.get(f\"http://{server}/health\", timeout=self.timeout)\n",
    "            return response.status_code == 200\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def _health_check_loop(self):\n",
    "        \"\"\"Continuously check server health\"\"\"\n",
    "        while True:\n",
    "            for server in list(self.servers.keys()):\n",
    "                is_healthy = self._check_server(server)\n",
    "                \n",
    "                with self.lock:\n",
    "                    current_status = self.servers[server]\n",
    "                    \n",
    "                    if is_healthy and current_status != ServerStatus.HEALTHY:\n",
    "                        # Server recovered\n",
    "                        self.servers[server] = ServerStatus.HEALTHY\n",
    "                        self.healthy_servers.add(server)\n",
    "                        print(f\"Server {server} is now HEALTHY\")\n",
    "                    \n",
    "                    elif not is_healthy and current_status == ServerStatus.HEALTHY:\n",
    "                        # Server failed\n",
    "                        self.servers[server] = ServerStatus.UNHEALTHY\n",
    "                        self.healthy_servers.discard(server)\n",
    "                        print(f\"Server {server} is now UNHEALTHY\")\n",
    "            \n",
    "            time.sleep(self.check_interval)\n",
    "    \n",
    "    def get_healthy_servers(self):\n",
    "        \"\"\"Return list of healthy servers\"\"\"\n",
    "        with self.lock:\n",
    "            return list(self.healthy_servers)\n",
    "\n",
    "# Usage\n",
    "servers = ['10.0.1.10:8080', '10.0.1.11:8080', '10.0.1.12:8080']\n",
    "health_checker = HealthChecker(servers)\n",
    "\n",
    "# Get only healthy servers for load balancing\n",
    "healthy_servers = health_checker.get_healthy_servers()\n",
    "balancer = RoundRobinBalancer(healthy_servers)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Circuit Breakers**\n",
    "\n",
    "**Concept**: Prevent cascading failures by temporarily rejecting requests to failing services, giving them time to recover.\n",
    "\n",
    "**States**:\n",
    "1. **Closed**: Normal operation, requests pass through\n",
    "2. **Open**: Failure threshold exceeded, requests fail fast (no call to service)\n",
    "3. **Half-Open**: Testing if service recovered, limited requests allowed\n",
    "\n",
    "**Implementation** (using `pybreaker` library):\n",
    "```python\n",
    "import pybreaker\n",
    "import requests\n",
    "from flask import Flask, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Circuit breaker configuration\n",
    "circuit_breaker = pybreaker.CircuitBreaker(\n",
    "    fail_max=5,      # Open after 5 failures\n",
    "    reset_timeout=60,  # Try again after 60 seconds\n",
    "    expected_exception=requests.RequestException\n",
    ")\n",
    "\n",
    "@circuit_breaker\n",
    "def call_external_service():\n",
    "    \"\"\"Call external API with circuit breaker protection\"\"\"\n",
    "    response = requests.get('http://external-api.com/data', timeout=2)\n",
    "    return response.json()\n",
    "\n",
    "@app.route('/data')\n",
    "def get_data():\n",
    "    try:\n",
    "        data = call_external_service()\n",
    "        return jsonify(data)\n",
    "    except pybreaker.CircuitBreakerError:\n",
    "        # Circuit is open - fail fast\n",
    "        return jsonify({\"error\": \"Service temporarily unavailable\"}), 503\n",
    "    except requests.RequestException:\n",
    "        # Other request errors\n",
    "        return jsonify({\"error\": \"Service error\"}), 502\n",
    "\n",
    "# Manual implementation\n",
    "class CircuitBreaker:\n",
    "    def __init__(self, failure_threshold=5, recovery_timeout=60):\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.recovery_timeout = recovery_timeout\n",
    "        self.failure_count = 0\n",
    "        self.last_failure_time = None\n",
    "        self.state = 'CLOSED'  # CLOSED, OPEN, HALF_OPEN\n",
    "    \n",
    "    def call(self, func, *args, **kwargs):\n",
    "        \"\"\"Call function with circuit breaker protection\"\"\"\n",
    "        if self.state == 'OPEN':\n",
    "            if time.time() - self.last_failure_time > self.recovery_timeout:\n",
    "                self.state = 'HALF_OPEN'\n",
    "                print(\"Circuit breaker entering HALF_OPEN state\")\n",
    "            else:\n",
    "                raise Exception(\"Circuit breaker is OPEN\")\n",
    "        \n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            self._on_success()\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self._on_failure()\n",
    "            raise e\n",
    "    \n",
    "    def _on_success(self):\n",
    "        \"\"\"Handle successful call\"\"\"\n",
    "        if self.state == 'HALF_OPEN':\n",
    "            self.state = 'CLOSED'\n",
    "            print(\"Circuit breaker CLOSED (service recovered)\")\n",
    "        self.failure_count = 0\n",
    "    \n",
    "    def _on_failure(self):\n",
    "        \"\"\"Handle failed call\"\"\"\n",
    "        self.failure_count += 1\n",
    "        self.last_failure_time = time.time()\n",
    "        \n",
    "        if self.failure_count >= self.failure_threshold:\n",
    "            self.state = 'OPEN'\n",
    "            print(f\"Circuit breaker OPENED after {self.failure_count} failures\")\n",
    "\n",
    "# Usage\n",
    "cb = CircuitBreaker(failure_threshold=3, recovery_timeout=30)\n",
    "\n",
    "def make_request():\n",
    "    # This might fail\n",
    "    response = requests.get('http://unreliable-service.com')\n",
    "    return response.json()\n",
    "\n",
    "try:\n",
    "    result = cb.call(make_request)\n",
    "except Exception as e:\n",
    "    print(f\"Request failed: {e}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6.5 Global Server Load Balancing (GSLB) and Geo-DNS**\n",
    "\n",
    "**GSLB**: Distributes traffic across multiple geographically distributed data centers based on proximity, load, or health.\n",
    "\n",
    "**How It Works**:\n",
    "```\n",
    "User in Tokyo requests api.example.com\n",
    "    \u2502\n",
    "    \u25bc\n",
    "DNS Server (GSLB)\n",
    "    \u2502\n",
    "    \u251c\u2500\u25ba Checks user's location (via DNS resolver IP)\n",
    "    \u251c\u2500\u25ba Checks health of data centers\n",
    "    \u251c\u2500\u25ba Checks load of data centers\n",
    "    \u2502\n",
    "    \u2514\u2500\u25ba Returns IP of Tokyo Data Center (closest, healthy, low load)\n",
    "\n",
    "User connects to Tokyo Data Center (low latency: 20ms)\n",
    "\n",
    "Alternative:\n",
    "User in New York requests api.example.com\n",
    "    \u2502\n",
    "    \u25bc\n",
    "DNS Server (GSLB)\n",
    "    \u2502\n",
    "    \u2514\u2500\u25ba Returns IP of Virginia Data Center (closest to New York)\n",
    "\n",
    "User connects to Virginia Data Center (low latency: 30ms)\n",
    "```\n",
    "\n",
    "**Implementation** (AWS Route 53):\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "# Route 53 configuration for GSLB\n",
    "route53 = boto3.client('route53')\n",
    "\n",
    "# Create latency-based routing policy\n",
    "response = route53.change_resource_record_sets(\n",
    "    HostedZoneId='ZONE_ID',\n",
    "    ChangeBatch={\n",
    "        'Changes': [\n",
    "            {\n",
    "                'Action': 'CREATE',\n",
    "                'ResourceRecordSet': {\n",
    "                    'Name': 'api.example.com',\n",
    "                    'Type': 'A',\n",
    "                    'SetIdentifier': 'Tokyo',\n",
    "                    'Region': 'ap-northeast-1',  # Asia Pacific (Tokyo)\n",
    "                    'HealthCheckId': 'tokyo-health-check-id',\n",
    "                    'TTL': 60,\n",
    "                    'ResourceRecords': [{'Value': '203.0.113.10'}]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'Action': 'CREATE',\n",
    "                'ResourceRecordSet': {\n",
    "                    'Name': 'api.example.com',\n",
    "                    'Type': 'A',\n",
    "                    'SetIdentifier': 'Virginia',\n",
    "                    'Region': 'us-east-1',  # US East (Virginia)\n",
    "                    'HealthCheckId': 'virginia-health-check-id',\n",
    "                    'TTL': 60,\n",
    "                    'ResourceRecords': [{'Value': '198.51.100.10'}]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'Action': 'CREATE',\n",
    "                'ResourceRecordSet': {\n",
    "                    'Name': 'api.example.com',\n",
    "                    'Type': 'A',\n",
    "                    'SetIdentifier': 'Ireland',\n",
    "                    'Region': 'eu-west-1',  # Europe (Ireland)\n",
    "                    'HealthCheckId': 'ireland-health-check-id',\n",
    "                    'TTL': 60,\n",
    "                    'ResourceRecords': [{'Value': '192.0.2.10'}]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6.6 API Gateway Pattern**\n",
    "\n",
    "**API Gateway**: A single entry point for all clients, handling cross-cutting concerns like authentication, rate limiting, caching, and routing to microservices.\n",
    "\n",
    "**Architecture**:\n",
    "```\n",
    "Clients (Web, Mobile, 3rd Party)\n",
    "    \u2502\n",
    "    \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502         API Gateway                  \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n",
    "\u2502  \u2502 Authentication & Authorization\u2502  \u2502\n",
    "\u2502  \u2502 Rate Limiting                 \u2502  \u2502\n",
    "\u2502  \u2502 SSL Termination               \u2502  \u2502\n",
    "\u2502  \u2502 Caching                       \u2502  \u2502\n",
    "\u2502  \u2502 Request/Response Transformation\u2502 \u2502\n",
    "\u2502  \u2502 Routing                       \u2502  \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "         \u2502          \u2502\n",
    "         \u25bc          \u25bc\n",
    "   User Service  Order Service\n",
    "   (Users)       (Orders)\n",
    "         \u2502\n",
    "         \u25bc\n",
    "   Inventory Service\n",
    "   (Inventory)\n",
    "```\n",
    "\n",
    "**Implementation** (Kong API Gateway):\n",
    "```yaml\n",
    "# kong.yml configuration\n",
    "services:\n",
    "  - name: user-service\n",
    "    url: http://user-service:8080\n",
    "    routes:\n",
    "      - name: user-routes\n",
    "        paths:\n",
    "          - /api/users\n",
    "    plugins:\n",
    "      - name: rate-limiting\n",
    "        config:\n",
    "          minute: 100\n",
    "      - name: jwt\n",
    "        config:\n",
    "          uri_param_names: []\n",
    "          cookie_names: []\n",
    "          key_claim_name: iss\n",
    "          secret_is_base64: false\n",
    "          claims_to_verify:\n",
    "            - exp\n",
    "\n",
    "  - name: order-service\n",
    "    url: http://order-service:8080\n",
    "    routes:\n",
    "      - name: order-routes\n",
    "        paths:\n",
    "          - /api/orders\n",
    "    plugins:\n",
    "      - name: rate-limiting\n",
    "        config:\n",
    "          minute: 50\n",
    "      - name: proxy-cache\n",
    "        config:\n",
    "          content_type:\n",
    "            - application/json\n",
    "          cache_ttl: 300\n",
    "          strategy: memory\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6.7 Service Mesh Introduction**\n",
    "\n",
    "**Service Mesh**: Infrastructure layer that handles service-to-service communication, providing observability, security, and reliability without changing application code.\n",
    "\n",
    "**Architecture** (Istio/Linkerd):\n",
    "```\n",
    "Application Pod                    Application Pod\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502  App Container        \u2502         \u2502  App Container        \u2502\n",
    "\u2502  (Your Application)   \u2502<\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502  (Your Application)   \u2502\n",
    "\u2502                      \u2502         \u2502                      \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "           \u2502                                 \u2502\n",
    "           \u2502 Sidecar Proxy                   \u2502 Sidecar Proxy\n",
    "           \u2502 (Envoy)                         \u2502 (Envoy)\n",
    "           \u2502                                 \u2502\n",
    "           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                           \u2502\n",
    "                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                    \u2502  Control    \u2502\n",
    "                    \u2502  Plane      \u2502\n",
    "                    \u2502 (Istiod)    \u2502\n",
    "                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "Features:\n",
    "- mTLS (automatic encryption between services)\n",
    "- Traffic routing (canary deployments, A/B testing)\n",
    "- Observability (metrics, tracing, logs)\n",
    "- Circuit breaking, retries, timeouts\n",
    "- No code changes required in application\n",
    "```\n",
    "\n",
    "**Example** (Istio Traffic Management):\n",
    "```yaml\n",
    "apiVersion: networking.istio.io/v1beta1\n",
    "kind: VirtualService\n",
    "metadata:\n",
    "  name: user-service\n",
    "spec:\n",
    "  hosts:\n",
    "  - user-service\n",
    "  http:\n",
    "  - route:\n",
    "    - destination:\n",
    "        host: user-service\n",
    "        subset: v1\n",
    "      weight: 90\n",
    "    - destination:\n",
    "        host: user-service\n",
    "        subset: v2\n",
    "      weight: 10\n",
    "    timeout: 5s\n",
    "    retries:\n",
    "      attempts: 3\n",
    "      perTryTimeout: 2s\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6.8 Key Takeaways**\n",
    "\n",
    "1. **Layer 4 for performance, Layer 7 for features**: Use Layer 4 (TCP/UDP) for maximum performance and protocol flexibility. Use Layer 7 (HTTP) for content-based routing, SSL termination, and caching.\n",
    "\n",
    "2. **Choose algorithms wisely**: Round Robin for equal capacity, Weighted Round Robin for heterogeneous servers, Least Connections for long-lived connections, IP Hash for session affinity.\n",
    "\n",
    "3. **Health checks are essential**: Active health checks prevent routing to failed servers. Circuit breakers prevent cascading failures.\n",
    "\n",
    "4. **GSLB for global scale**: Use Geo-DNS or latency-based routing to direct users to the nearest healthy data center.\n",
    "\n",
    "5. **API Gateway for cross-cutting concerns**: Centralize authentication, rate limiting, and routing in the gateway, keeping microservices focused on business logic.\n",
    "\n",
    "6. **Service Mesh for microservices**: When you have many services, use a service mesh (Istio, Linkerd) to handle communication, security, and observability without code changes.\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "In this chapter, we explored load balancing and traffic management\u2014the critical infrastructure that enables high availability and scalability in distributed systems. We compared Layer 4 (transport) and Layer 7 (application) load balancing, understanding when each is appropriate.\n",
    "\n",
    "We examined various load balancing algorithms (Round Robin, Weighted, Least Connections, IP Hash) and their use cases. We covered health checks and circuit breakers for maintaining system resilience, and explored Global Server Load Balancing (GSLB) for distributing traffic across geographic regions.\n",
    "\n",
    "We introduced the API Gateway pattern for centralizing cross-cutting concerns, and touched on Service Mesh (Istio, Linkerd) as a modern approach to handling service-to-service communication in microservices architectures.\n",
    "\n",
    "**Coming up next**: In Chapter 7, we'll explore Microservices Architecture\u2014covering monolithic vs. microservices, service decomposition, inter-service communication, service discovery, and the challenges of distributed systems.\n",
    "\n",
    "---\n",
    "\n",
    "**Exercises**:\n",
    "\n",
    "1. **Load Balancer Selection**: For each scenario, would you use Layer 4 or Layer 7 load balancing? Which algorithm?\n",
    "   - Database cluster (PostgreSQL read replicas)\n",
    "   - Web application with static assets and API endpoints\n",
    "   - WebSocket chat application requiring session affinity\n",
    "   - Microservices architecture with 50 different services\n",
    "\n",
    "2. **Circuit Breaker Implementation**: Implement a circuit breaker for a payment service that:\n",
    "   - Opens after 3 consecutive failures\n",
    "   - Enters half-open state after 30 seconds\n",
    "   - Closes after 2 consecutive successes in half-open state\n",
    "   - Tracks failure statistics\n",
    "\n",
    "3. **GSLB Design**: You're designing a global application with users in North America, Europe, and Asia. Each region has a data center. Design a GSLB strategy that:\n",
    "   - Routes users to nearest healthy data center\n",
    "   - Fails over to next nearest if primary is down\n",
    "   - Handles data sovereignty (EU data stays in EU)\n",
    "\n",
    "4. **API Gateway Configuration**: Design an API Gateway configuration for an e-commerce platform with:\n",
    "   - Public APIs (rate limited, cached)\n",
    "   - Partner APIs (authenticated, different rate limits)\n",
    "   - Internal APIs (no rate limiting, service mesh)\n",
    "\n",
    "5. **Load Balancing Math**: You have 3 servers with capacities:\n",
    "   - Server A: 32 CPU cores, 64GB RAM (high capacity)\n",
    "   - Server B: 16 CPU cores, 32GB RAM (medium capacity)\n",
    "   - Server C: 8 CPU cores, 16GB RAM (low capacity)\n",
    "   \n",
    "   If using Weighted Round Robin, what weights would you assign? If you expect 10,000 requests and Server B fails after 5,000 requests, how many requests does each server handle?\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='5. message_queues_and_event_driven_architecture.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='../3. Distributes_systems_fundamentals/7. communication_protocols_and_data_formats.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}