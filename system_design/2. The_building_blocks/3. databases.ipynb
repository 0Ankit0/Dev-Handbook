{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83264a89",
   "metadata": {},
   "source": [
    "# **Chapter 3: Databases \u2013 The Persistence Layer**\n",
    "\n",
    "Databases are the heart of most systems. They store and retrieve data reliably, ensuring data survives crashes, power failures, and disasters. Understanding database internals, capabilities, and trade-offs is essential for every system designer.\n",
    "\n",
    "---\n",
    "\n",
    "## **3.1 The Role of Databases in System Design**\n",
    "\n",
    "**Definition**: A database is an organized collection of structured information, or data, typically stored electronically in a computer system. A database is usually controlled by a database management system (DBMS).\n",
    "\n",
    "**Why Databases Matter**:\n",
    "- **Data persistence**: Survive application restarts and system crashes\n",
    "- **Data integrity**: ACID guarantees ensure consistent state\n",
    "- **Data querying**: Efficiently retrieve and filter large datasets\n",
    "- **Data relationships**: Enforce relationships between related entities\n",
    "- **Data security**: Control access and permissions\n",
    "\n",
    "**Database Evolution Timeline**:\n",
    "```\n",
    "1960s: Hierarchical and Network Models (IMS, IDMS)\n",
    "1970s: Relational Model (System R, Ingres)\n",
    "1980s: Commercial SQL Databases (Oracle, DB2)\n",
    "1990s: Open Source SQL (PostgreSQL, MySQL)\n",
    "2000s: NoSQL Revolution (MongoDB, Cassandra, DynamoDB)\n",
    "2010s: NewSQL and Cloud Databases (Spanner, Aurora)\n",
    "2020s: Multi-model and Serverless Databases (CockroachDB, FaunaDB)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3.2 Relational Databases (RDBMS)**\n",
    "\n",
    "Relational databases organize data into tables with rows and columns, enforcing relationships through foreign keys. They use SQL (Structured Query Language) for data manipulation.\n",
    "\n",
    "### **ACID Properties: The Gold Standard of Data Integrity**\n",
    "\n",
    "**ACID** stands for Atomicity, Consistency, Isolation, Durability\u2014guarantees that database transactions are reliable.\n",
    "\n",
    "**Atomicity**: A transaction is all-or-nothing. Either all operations complete, or none do.\n",
    "\n",
    "**Example**:\n",
    "```sql\n",
    "-- Bank transfer: Transfer $100 from Account A to Account B\n",
    "BEGIN TRANSACTION;\n",
    "\n",
    "UPDATE accounts SET balance = balance - 100 WHERE id = 'A';\n",
    "-- What if this succeeds but the next update fails?\n",
    "UPDATE accounts SET balance = balance + 100 WHERE id = 'B';\n",
    "\n",
    "COMMIT;  -- Either both updates happen, or neither happens\n",
    "\n",
    "-- If second update fails, entire transaction is rolled back:\n",
    "ROLLBACK;\n",
    "```\n",
    "\n",
    "**Atomicity ensures**: The money never disappears\u2014it's either transferred or stays where it is.\n",
    "\n",
    "**Consistency**: Database transitions from one valid state to another valid state, respecting all constraints.\n",
    "\n",
    "**Example**:\n",
    "```sql\n",
    "CREATE TABLE accounts (\n",
    "    id VARCHAR(10) PRIMARY KEY,\n",
    "    balance DECIMAL(10, 2) CHECK (balance >= 0)  -- Constraint: no negative balances\n",
    ");\n",
    "\n",
    "-- This transaction will FAIL because it violates the consistency constraint:\n",
    "BEGIN TRANSACTION;\n",
    "UPDATE accounts SET balance = balance - 100 WHERE id = 'A';  -- Balance becomes -50\n",
    "-- Database detects constraint violation and rolls back entire transaction\n",
    "ROLLBACK;\n",
    "```\n",
    "\n",
    "**Consistency ensures**: Business rules are always enforced, even in failure scenarios.\n",
    "\n",
    "**Isolation**: Concurrent transactions don't interfere with each other. Each transaction sees a consistent snapshot of the database.\n",
    "\n",
    "**Isolation Levels** (PostgreSQL example):\n",
    "```sql\n",
    "-- Read Uncommitted: Can see uncommitted changes from other transactions (dangerous!)\n",
    "SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n",
    "\n",
    "-- Read Committed: Can only see committed changes (default in PostgreSQL, SQL Server)\n",
    "SET TRANSACTION ISOLATION LEVEL READ COMMITTED;\n",
    "\n",
    "-- Repeatable Read: If you read a row twice during a transaction, it's the same\n",
    "SET TRANSACTION ISOLATION LEVEL REPEATABLE READ;\n",
    "\n",
    "-- Serializable: Transactions are truly isolated; behaves like single-threaded (safest, slowest)\n",
    "SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;\n",
    "```\n",
    "\n",
    "**Example: Lost Update Problem** (without proper isolation):\n",
    "```\n",
    "Time  Transaction 1                          Transaction 2          Balance\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "0     Read balance: 100                                             100\n",
    "1                                            Read balance: 100      100\n",
    "2     Add 50 \u2192 Write 150                                            150\n",
    "3                                            Add 20 \u2192 Write 120     120\n",
    "4                                            Commit                  120\n",
    "5     Commit                                                           120\n",
    "\n",
    "Expected: 170 (100 + 50 + 20)\n",
    "Actual: 120 (Transaction 2 overwrote Transaction 1)\n",
    "```\n",
    "\n",
    "**With Isolation**: Transaction 2 would be blocked until Transaction 1 commits, or would detect conflict and retry.\n",
    "\n",
    "**Durability**: Once a transaction commits, changes are permanent\u2014even if power fails immediately after.\n",
    "\n",
    "**How databases achieve durability**:\n",
    "- **Write-ahead logging (WAL)**: Changes are written to a log file before being written to data files\n",
    "- **Checkpointing**: Periodically writing consistent snapshots to disk\n",
    "- **Replication**: Copying data to multiple machines\n",
    "\n",
    "**Durability sequence**:\n",
    "```\n",
    "1. Client sends transaction\n",
    "2. Database writes transaction to WAL log (synchronously, confirmed by disk)\n",
    "3. Database tells client \"transaction committed\"\n",
    "4. Later, database lazily updates actual data files from WAL\n",
    "\n",
    "If power fails after step 2 but before step 4:\n",
    "- On restart, database replays WAL log\n",
    "- All committed transactions are recovered\n",
    "- Client was told success, so they expect success\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Schema Design: Normalization and Denormalization**\n",
    "\n",
    "**Normalization**: Organizing data to minimize redundancy and dependency.\n",
    "\n",
    "**Normalization Levels**:\n",
    "- **1NF**: Each cell contains a single value (no multi-valued attributes)\n",
    "- **2NF**: 1NF + no partial dependencies (no non-key attribute depends on part of a primary key)\n",
    "- **3NF**: 2NF + no transitive dependencies (no non-key attribute depends on another non-key attribute)\n",
    "\n",
    "**Example**: Denormalized \u2192 Normalized\n",
    "\n",
    "**Denormalized (violates 3NF)**:\n",
    "```sql\n",
    "CREATE TABLE orders (\n",
    "    order_id INT PRIMARY KEY,\n",
    "    customer_name VARCHAR(100),\n",
    "    customer_address VARCHAR(200),\n",
    "    customer_email VARCHAR(100),\n",
    "    order_date DATE,\n",
    "    total_amount DECIMAL(10, 2)\n",
    ");\n",
    "\n",
    "-- Problems:\n",
    "-- Customer info repeated for every order (redundancy)\n",
    "-- Update customer address \u2192 must update all their orders\n",
    "```\n",
    "\n",
    "**Normalized (3NF)**:\n",
    "```sql\n",
    "CREATE TABLE customers (\n",
    "    customer_id INT PRIMARY KEY,\n",
    "    name VARCHAR(100),\n",
    "    address VARCHAR(200),\n",
    "    email VARCHAR(100)\n",
    ");\n",
    "\n",
    "CREATE TABLE orders (\n",
    "    order_id INT PRIMARY KEY,\n",
    "    customer_id INT,\n",
    "    order_date DATE,\n",
    "    total_amount DECIMAL(10, 2),\n",
    "    FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n",
    ");\n",
    "\n",
    "-- Benefits:\n",
    "-- Customer info stored once\n",
    "-- Update address \u2192 single row update\n",
    "-- Add customer \u2192 no need to create order first\n",
    "```\n",
    "\n",
    "**Trade-offs**:\n",
    "- **Normalized**: Less redundancy, better data integrity, more joins required (slower reads)\n",
    "- **Denormalized**: Faster reads, more redundancy, risk of data inconsistencies\n",
    "\n",
    "**When to use which**:\n",
    "- **Normalized**: Transactional systems (banking, CRM), data integrity critical\n",
    "- **Denormalized**: Analytical systems (data warehouses), read-heavy workloads\n",
    "\n",
    "---\n",
    "\n",
    "### **Indexing: The Speed Dial for Databases**\n",
    "\n",
    "**Index**: Data structure that allows efficient lookups without scanning entire tables.\n",
    "\n",
    "**Problem**: Without an index, finding a row requires scanning the entire table.\n",
    "```sql\n",
    "-- Table with 1 million rows\n",
    "SELECT * FROM users WHERE email = 'alice@example.com';\n",
    "\n",
    "-- Without index: Scan all 1 million rows \u2192 ~100ms (average 500,000 rows checked)\n",
    "-- With index on email: Jump directly to row \u2192 ~0.1ms (binary search)\n",
    "```\n",
    "\n",
    "**B-Tree Index**: The most common index type.\n",
    "\n",
    "**B-Tree Structure**:\n",
    "```\n",
    "                    [Root Node]\n",
    "                    /      \\\n",
    "                [100]     [300]\n",
    "               /    \\     /    \\\n",
    "            [50]  [75] [200] [400]\n",
    "           /  \\   /  \\  /  \\   /  \\\n",
    "         ...  ... ... ... ... ... ...\n",
    "\n",
    "Search for 200:\n",
    "1. Root: 200 > 100 \u2192 go right\n",
    "2. Level 1: 200 < 300 \u2192 go left\n",
    "3. Level 2: Found node containing 200\n",
    "4. Return data (O(log n) lookup)\n",
    "```\n",
    "\n",
    "**Properties of B-Trees**:\n",
    "- **Balanced**: All leaves are at the same level (guaranteed O(log n) operations)\n",
    "- **Multi-way**: Each node has multiple keys and children (not just 2 like binary trees)\n",
    "- **Disk-friendly**: Optimized for disk access patterns (nodes match disk block size)\n",
    "\n",
    "**Creating Indexes**:\n",
    "```sql\n",
    "-- Single-column index\n",
    "CREATE INDEX idx_users_email ON users(email);\n",
    "\n",
    "-- Composite index (order matters!)\n",
    "CREATE INDEX idx_orders_customer_date ON orders(customer_id, order_date);\n",
    "\n",
    "-- Unique index (also enforces uniqueness constraint)\n",
    "CREATE UNIQUE INDEX idx_users_username ON users(username);\n",
    "\n",
    "-- Partial index (index only subset of rows)\n",
    "CREATE INDEX idx_active_users ON users(last_login) WHERE active = true;\n",
    "```\n",
    "\n",
    "**Index Selection** (PostgreSQL example):\n",
    "```sql\n",
    "-- Query\n",
    "SELECT * FROM orders \n",
    "WHERE customer_id = 123 AND order_date >= '2024-01-01';\n",
    "\n",
    "-- Which index is used?\n",
    "-- If only idx_customer_id exists: Use it, filter by date manually\n",
    "-- If only idx_date exists: Use it, filter by customer_id manually\n",
    "-- If idx_customer_date exists: Use it, both conditions satisfied (best!)\n",
    "-- If idx_date_customer exists: Use it, but less efficient (wrong order)\n",
    "```\n",
    "\n",
    "**When Indexes Are Used vs. Not Used**:\n",
    "```sql\n",
    "-- Index used: WHERE clause on indexed column\n",
    "SELECT * FROM users WHERE email = 'alice@example.com';  -- Uses email index\n",
    "\n",
    "-- Index used: ORDER BY on indexed column\n",
    "SELECT * FROM users ORDER BY email;  -- Uses email index\n",
    "\n",
    "-- Index NOT used: Function on indexed column\n",
    "SELECT * FROM users WHERE LOWER(email) = 'alice@example.com';  -- Can't use index!\n",
    "-- Solution: Create functional index or store lowercase version\n",
    "\n",
    "-- Index NOT used: OR condition (sometimes)\n",
    "SELECT * FROM users WHERE email = 'alice@example.com' OR id = 123;\n",
    "-- If both indexed, might use union of indexes (index-only scan)\n",
    "\n",
    "-- Index NOT used: Leading wildcard in LIKE\n",
    "SELECT * FROM users WHERE email LIKE '%@example.com';  -- Can't use index\n",
    "-- This IS used:\n",
    "SELECT * FROM users WHERE email LIKE 'alice@%';\n",
    "```\n",
    "\n",
    "**Trade-offs**:\n",
    "- **Pros**: 100-1,000x faster lookups\n",
    "- **Cons**: Slower writes (each INSERT/UPDATE/DELETE must update index), more storage (20-100% of table size)\n",
    "\n",
    "**Rule of thumb**: Index columns frequently used in WHERE clauses and JOINs, but don't over-index.\n",
    "\n",
    "---\n",
    "\n",
    "### **Foreign Keys and Relationships**\n",
    "\n",
    "**Foreign Key**: A field in one table that uniquely identifies a row in another table, establishing relationships.\n",
    "\n",
    "**Types of Relationships**:\n",
    "\n",
    "**One-to-One**: Each row in Table A relates to at most one row in Table B.\n",
    "```sql\n",
    "CREATE TABLE users (\n",
    "    user_id INT PRIMARY KEY,\n",
    "    username VARCHAR(50),\n",
    "    email VARCHAR(100)\n",
    ");\n",
    "\n",
    "CREATE TABLE user_profiles (\n",
    "    profile_id INT PRIMARY KEY,\n",
    "    user_id INT UNIQUE,  -- UNIQUE enforces one-to-one\n",
    "    bio TEXT,\n",
    "    avatar_url VARCHAR(200),\n",
    "    FOREIGN KEY (user_id) REFERENCES users(user_id)\n",
    ");\n",
    "\n",
    "-- Each user has at most one profile\n",
    "-- Each profile belongs to exactly one user\n",
    "```\n",
    "\n",
    "**One-to-Many**: Each row in Table A relates to many rows in Table B.\n",
    "```sql\n",
    "CREATE TABLE departments (\n",
    "    dept_id INT PRIMARY KEY,\n",
    "    dept_name VARCHAR(100)\n",
    ");\n",
    "\n",
    "CREATE TABLE employees (\n",
    "    emp_id INT PRIMARY KEY,\n",
    "    emp_name VARCHAR(100),\n",
    "    dept_id INT,\n",
    "    FOREIGN KEY (dept_id) REFERENCES departments(dept_id)\n",
    ");\n",
    "\n",
    "-- Each department has many employees\n",
    "-- Each employee belongs to exactly one department\n",
    "```\n",
    "\n",
    "**Many-to-Many**: Each row in Table A relates to many rows in Table B, and vice versa. Requires junction table.\n",
    "```sql\n",
    "CREATE TABLE students (\n",
    "    student_id INT PRIMARY KEY,\n",
    "    student_name VARCHAR(100)\n",
    ");\n",
    "\n",
    "CREATE TABLE courses (\n",
    "    course_id INT PRIMARY KEY,\n",
    "    course_name VARCHAR(100)\n",
    ");\n",
    "\n",
    "-- Junction table\n",
    "CREATE TABLE enrollments (\n",
    "    enrollment_id INT PRIMARY KEY,\n",
    "    student_id INT,\n",
    "    course_id INT,\n",
    "    enrollment_date DATE,\n",
    "    FOREIGN KEY (student_id) REFERENCES students(student_id),\n",
    "    FOREIGN KEY (course_id) REFERENCES courses(course_id),\n",
    "    UNIQUE (student_id, course_id)  -- Prevent duplicate enrollments\n",
    ");\n",
    "\n",
    "-- Each student can enroll in many courses\n",
    "-- Each course can have many students\n",
    "```\n",
    "\n",
    "**Referential Integrity**: Foreign keys enforce that relationships remain consistent.\n",
    "```sql\n",
    "-- Cannot delete a department that still has employees\n",
    "DELETE FROM departments WHERE dept_id = 10;\n",
    "-- ERROR: update or delete on table \"departments\" violates foreign key constraint\n",
    "-- Detail: Key (dept_id)=(10) is still referenced from table \"employees\".\n",
    "\n",
    "-- Solutions:\n",
    "-- 1. Delete employees first (CASCADE)\n",
    "DELETE FROM employees WHERE dept_id = 10;\n",
    "DELETE FROM departments WHERE dept_id = 10;\n",
    "\n",
    "-- 2. Define ON DELETE CASCADE (automatically deletes related rows)\n",
    "ALTER TABLE employees \n",
    "DROP CONSTRAINT employees_dept_id_fkey,\n",
    "ADD CONSTRAINT employees_dept_id_fkey \n",
    "FOREIGN KEY (dept_id) REFERENCES departments(dept_id) \n",
    "ON DELETE CASCADE;\n",
    "\n",
    "-- Now deleting department also deletes its employees\n",
    "DELETE FROM departments WHERE dept_id = 10;  -- Also deletes all employees in dept 10\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Transactions: Multi-Operation Atomicity**\n",
    "\n",
    "**Transaction**: A sequence of operations performed as a single logical unit of work.\n",
    "\n",
    "**Transaction Lifecycle**:\n",
    "```\n",
    "1. BEGIN TRANSACTION\n",
    "   - Start transaction\n",
    "   - Acquire locks on affected rows\n",
    "   - Create savepoint (for rollback)\n",
    "\n",
    "2. Execute operations (SELECT, INSERT, UPDATE, DELETE)\n",
    "   - Changes are visible only within this transaction\n",
    "   - Other transactions see data as it was before this transaction started\n",
    "\n",
    "3. COMMIT or ROLLBACK\n",
    "   - COMMIT: Make changes permanent and visible to other transactions\n",
    "   - ROLLBACK: Revert all changes, as if this transaction never happened\n",
    "```\n",
    "\n",
    "**Example**: Transfer money between accounts\n",
    "```sql\n",
    "-- Transaction ensures atomicity\n",
    "BEGIN TRANSACTION;\n",
    "\n",
    "-- Check sufficient funds (for consistency)\n",
    "SELECT balance FROM accounts WHERE id = 'A' FOR UPDATE;\n",
    "-- FOR UPDATE locks the row, preventing other transactions from modifying it\n",
    "\n",
    "-- If balance >= 100, proceed with transfer\n",
    "UPDATE accounts SET balance = balance - 100 WHERE id = 'A';\n",
    "UPDATE accounts SET balance = balance + 100 WHERE id = 'B';\n",
    "\n",
    "-- Record the transfer\n",
    "INSERT INTO transfers (from_account, to_account, amount, timestamp)\n",
    "VALUES ('A', 'B', 100.00, NOW());\n",
    "\n",
    "-- All operations succeeded: make permanent\n",
    "COMMIT;\n",
    "\n",
    "-- If any operation failed (e.g., insufficient funds):\n",
    "-- ROLLBACK;  -- Revert all changes\n",
    "```\n",
    "\n",
    "**Transaction Isolation Issues**:\n",
    "\n",
    "**Dirty Read**: Reading uncommitted changes from another transaction.\n",
    "```\n",
    "Time  Transaction A                      Transaction B\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "0     BEGIN;\n",
    "1     UPDATE accounts SET balance = 50 WHERE id = 'A';\n",
    "2                                         SELECT balance FROM accounts WHERE id = 'A';\n",
    "                                          \u2192 Returns 50 (uncommitted!)\n",
    "3     ROLLBACK;  -- Revert back to 100\n",
    "4                                         -- Transaction B saw 50, but actual is 100\n",
    "                                          \u2192 Dirty read!\n",
    "```\n",
    "\n",
    "**Prevention**: Use READ COMMITTED or higher isolation level.\n",
    "\n",
    "**Non-Repeatable Read**: Reading same row twice within a transaction, getting different results.\n",
    "```\n",
    "Time  Transaction A                      Transaction B\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "0     BEGIN;\n",
    "1     SELECT balance FROM accounts WHERE id = 'A';\n",
    "      \u2192 Returns 100\n",
    "2                                         BEGIN;\n",
    "3                                         UPDATE accounts SET balance = 150 WHERE id = 'A';\n",
    "4                                         COMMIT;\n",
    "5     SELECT balance FROM accounts WHERE id = 'A';\n",
    "      \u2192 Returns 150 (different from first read!)\n",
    "      \u2192 Non-repeatable read!\n",
    "```\n",
    "\n",
    "**Prevention**: Use REPEATABLE READ or SERIALIZABLE isolation level.\n",
    "\n",
    "**Phantom Read**: Same query returns different sets of rows within a transaction.\n",
    "```\n",
    "Time  Transaction A                      Transaction B\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "0     BEGIN;\n",
    "1     SELECT * FROM accounts WHERE balance > 1000;\n",
    "      \u2192 Returns 5 rows\n",
    "2                                         BEGIN;\n",
    "3                                         INSERT INTO accounts VALUES ('E', 2000);\n",
    "4                                         COMMIT;\n",
    "5     SELECT * FROM accounts WHERE balance > 1000;\n",
    "      \u2192 Returns 6 rows (phantom row appeared!)\n",
    "      \u2192 Phantom read!\n",
    "```\n",
    "\n",
    "**Prevention**: Use SERIALIZABLE isolation level (prevents phantom reads).\n",
    "\n",
    "---\n",
    "\n",
    "### **Popular RDBMS Systems**\n",
    "\n",
    "**PostgreSQL**: Open-source, feature-rich, extensible.\n",
    "- **Strengths**: Advanced data types (JSON, UUID, arrays), extensive indexing, excellent query optimizer\n",
    "- **Best for**: Complex queries, geospatial data, JSON workloads\n",
    "- **Companies**: Apple, Spotify, Reddit, Instagram\n",
    "\n",
    "**MySQL**: Open-source, widely used, good for web applications.\n",
    "- **Strengths**: Easy to set up, strong community support, excellent for read-heavy workloads\n",
    "- **Best for**: Web applications, e-commerce, CMS\n",
    "- **Companies**: Facebook, YouTube, Uber (originally)\n",
    "\n",
    "**SQL Server**: Microsoft's enterprise database.\n",
    "- **Strengths**: Tight integration with Microsoft ecosystem, excellent tooling\n",
    "- **Best for**: Windows environments, enterprise applications\n",
    "- **Companies**: Various enterprises, Microsoft products\n",
    "\n",
    "**Oracle**: Commercial, enterprise-grade, high performance.\n",
    "- **Strengths**: Extreme scalability, advanced features, excellent for very large datasets\n",
    "- **Best for**: Very large enterprises, mission-critical systems\n",
    "- **Companies**: Banks, airlines, large corporations\n",
    "\n",
    "---\n",
    "\n",
    "## **3.3 NoSQL Databases: The Flexible Alternative**\n",
    "\n",
    "NoSQL databases emerged to address limitations of relational databases: scalability, flexibility, and specific data models. \"NoSQL\" originally meant \"Not Only SQL\" \u2014 it's about using the right tool for the job.\n",
    "\n",
    "### **The NoSQL Landscape**\n",
    "\n",
    "NoSQL databases are categorized by data model:\n",
    "```\n",
    "NoSQL Databases\n",
    "    \u2502\n",
    "    \u251c\u2500\u2192 Key-Value Stores (Redis, DynamoDB, Memcached)\n",
    "    \u251c\u2500\u2192 Document Stores (MongoDB, Couchbase, RavenDB)\n",
    "    \u251c\u2500\u2192 Wide-Column Stores (Cassandra, HBase, ScyllaDB)\n",
    "    \u2514\u2500\u2192 Graph Databases (Neo4j, ArangoDB, Amazon Neptune)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Key-Value Stores**\n",
    "\n",
    "**Concept**: Store data as key-value pairs, like a hash map distributed across multiple servers.\n",
    "\n",
    "**Characteristics**:\n",
    "- **Simple API**: GET key, PUT key, DELETE key\n",
    "- **Extreme performance**: O(1) access time (constant time regardless of data size)\n",
    "- **Flexible values**: Can store any data (strings, numbers, JSON, binary)\n",
    "- **Schemaless**: No predefined structure for values\n",
    "\n",
    "**Example Use Cases**:\n",
    "```python\n",
    "# Redis example (Python)\n",
    "import redis\n",
    "\n",
    "# Connect to Redis\n",
    "r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "\n",
    "# Store simple value\n",
    "r.set('user:123:name', 'Alice')\n",
    "name = r.get('user:123:name')  # Returns b'Alice'\n",
    "\n",
    "# Store JSON value\n",
    "import json\n",
    "user_data = {'id': 123, 'name': 'Alice', 'email': 'alice@example.com'}\n",
    "r.set('user:123', json.dumps(user_data))\n",
    "user = json.loads(r.get('user:123'))\n",
    "\n",
    "# Set expiration (key automatically deleted after 1 hour)\n",
    "r.setex('session:abc123', 3600, 'user:123')\n",
    "\n",
    "# Atomic increment (perfect for counters)\n",
    "r.incr('page_views:home')  # Increment by 1\n",
    "r.incrby('page_views:home', 10)  # Increment by 10\n",
    "\n",
    "# Lists (perfect for queues)\n",
    "r.lpush('user:123:notifications', 'Welcome to our service!')\n",
    "r.lpush('user:123:notifications', 'You have a new follower')\n",
    "notifications = r.lrange('user:123:notifications', 0, -1)  # Get all\n",
    "```\n",
    "\n",
    "**Key-Value Use Cases**:\n",
    "- **Session storage**: Web application sessions (fast lookups, automatic expiration)\n",
    "- **Caching**: Store expensive query results (reduce database load)\n",
    "- **Rate limiting**: Track request counts per user (atomic operations)\n",
    "- **Leaderboards**: High-performance counters and rankings\n",
    "- **Message queues**: Lightweight pub/sub and list-based queues\n",
    "\n",
    "**Popular Key-Value Stores**:\n",
    "\n",
    "**Redis**: In-memory key-value store with persistence.\n",
    "- **Strengths**: Extremely fast, rich data structures, atomic operations\n",
    "- **Weaknesses**: Memory-limited (must fit in RAM), single-threaded processing\n",
    "- **Best for**: Caching, session storage, real-time analytics\n",
    "\n",
    "**Amazon DynamoDB**: Fully managed, serverless key-value and document database.\n",
    "- **Strengths**: Serverless (auto-scaling), single-digit millisecond latency, global tables\n",
    "- **Weaknesses**: Expensive for high-throughput write workloads, limited query capabilities\n",
    "- **Best for**: Serverless applications, mobile backends, gaming leaderboards\n",
    "\n",
    "**Memcached**: Simple, high-performance distributed memory object caching system.\n",
    "- **Strengths**: Simplicity, extremely fast for caching, multi-threaded\n",
    "- **Weaknesses**: Limited data structures, no persistence, no built-in replication\n",
    "- **Best for**: Simple caching layer\n",
    "\n",
    "---\n",
    "\n",
    "### **Document Stores**\n",
    "\n",
    "**Concept**: Store, retrieve, and manage document-oriented information. Documents are typically JSON (or BSON in MongoDB) format.\n",
    "\n",
    "**Characteristics**:\n",
    "- **Flexible schema**: Each document can have different structure\n",
    "- **Nested documents**: Store related data together (no joins needed)\n",
    "- **Rich querying**: Query on any field, including nested fields\n",
    "- **Schema validation**: Optional validation rules for document structure\n",
    "\n",
    "**Example Document (MongoDB)**:\n",
    "```javascript\n",
    "{\n",
    "  \"_id\": ObjectId(\"64c8e1234567890abcdef123\"),\n",
    "  \"firstName\": \"Alice\",\n",
    "  \"lastName\": \"Johnson\",\n",
    "  \"age\": 28,\n",
    "  \"email\": \"alice@example.com\",\n",
    "  \"address\": {\n",
    "    \"street\": \"123 Main St\",\n",
    "    \"city\": \"San Francisco\",\n",
    "    \"state\": \"CA\",\n",
    "    \"zipCode\": \"94102\"\n",
    "  },\n",
    "  \"orders\": [\n",
    "    {\n",
    "      \"orderId\": \"ORD001\",\n",
    "      \"date\": \"2024-01-15T08:30:00Z\",\n",
    "      \"total\": 125.50,\n",
    "      \"items\": [\n",
    "        {\"productId\": \"P123\", \"name\": \"Widget\", \"quantity\": 2, \"price\": 25.00},\n",
    "        {\"productId\": \"P456\", \"name\": \"Gadget\", \"quantity\": 1, \"price\": 75.50}\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"orderId\": \"ORD002\",\n",
    "      \"date\": \"2024-02-20T14:15:00Z\",\n",
    "      \"total\": 89.99,\n",
    "      \"items\": [\n",
    "        {\"productId\": \"P789\", \"name\": \"Thingamajig\", \"quantity\": 3, \"price\": 29.99}\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"createdAt\": \"2023-08-01T10:00:00Z\",\n",
    "  \"updatedAt\": \"2024-02-20T14:15:00Z\"\n",
    "}\n",
    "```\n",
    "\n",
    "**MongoDB Example**:\n",
    "```javascript\n",
    "// Insert document\n",
    "db.users.insertOne({\n",
    "  firstName: \"Alice\",\n",
    "  lastName: \"Johnson\",\n",
    "  age: 28,\n",
    "  email: \"alice@example.com\"\n",
    "});\n",
    "\n",
    "// Query documents\n",
    "db.users.find({ age: { $gte: 25 } })  // Find users 25 or older\n",
    "db.users.find({ \n",
    "  firstName: \"Alice\",\n",
    "  \"address.city\": \"San Francisco\"  // Query nested field\n",
    "})\n",
    "\n",
    "// Update document (upsert = insert if not exists)\n",
    "db.users.updateOne(\n",
    "  { email: \"alice@example.com\" },\n",
    "  { $set: { lastLogin: new Date() } },\n",
    "  { upsert: true }\n",
    ")\n",
    "\n",
    "// Array operations\n",
    "db.users.updateOne(\n",
    "  { email: \"alice@example.com\" },\n",
    "  { $push: { orders: { orderId: \"ORD003\", total: 199.99 } } }\n",
    ")\n",
    "\n",
    "// Aggregation pipeline (like SQL GROUP BY)\n",
    "db.users.aggregate([\n",
    "  { $match: { age: { $gte: 18 } } },  // Filter\n",
    "  { $group: { \n",
    "    _id: \"$address.state\",  // Group by state\n",
    "    count: { $sum: 1 },     // Count users per state\n",
    "    avgAge: { $avg: \"$age\" }  // Average age per state\n",
    "  }},\n",
    "  { $sort: { count: -1 } }  // Sort by count descending\n",
    "])\n",
    "```\n",
    "\n",
    "**Document Store Use Cases**:\n",
    "- **Content management**: Blog posts, product catalogs (flexible schema)\n",
    "- **User profiles**: Social media profiles (nested data, varying fields)\n",
    "- **Mobile applications**: Offline-first apps (JSON sync)\n",
    "- **Product catalogs**: E-commerce (nested variants, flexible attributes)\n",
    "- **Event logging**: Application logs, audit trails (structured JSON)\n",
    "\n",
    "**Popular Document Stores**:\n",
    "\n",
    "**MongoDB**: Most popular document database.\n",
    "- **Strengths**: Rich query language, flexible schema, strong community\n",
    "- **Weaknesses**: Transactions historically weaker than RDBMS, joins are expensive\n",
    "- **Best for**: Content management, product catalogs, mobile backends\n",
    "\n",
    "**Couchbase**: Enterprise-grade document database with SQL-like query language.\n",
    "- **Strengths**: N1QL (SQL for JSON), excellent performance, built-in caching\n",
    "- **Weaknesses**: Steeper learning curve, smaller community\n",
    "- **Best for**: Enterprise applications, real-time analytics\n",
    "\n",
    "**RavenDB**: ACID-compliant document database with built-in indexing.\n",
    "- **Strengths**: Strong consistency, automatic indexing, easy setup\n",
    "- **Weaknesses**: Smaller ecosystem, less battle-tested than MongoDB\n",
    "- **Best for**: Applications requiring strong consistency\n",
    "\n",
    "---\n",
    "\n",
    "### **Wide-Column Stores**\n",
    "\n",
    "**Concept**: Store data in columns rather than rows, optimized for wide tables (many columns) and petabyte-scale datasets.\n",
    "\n",
    "**Characteristics**:\n",
    "- **Column-family organization**: Data is stored by column families, not rows\n",
    "- **Scalable writes**: Optimized for write-heavy workloads\n",
    "- **Flexible schema**: Rows can have different columns\n",
    "- **Distributed**: Designed for massive horizontal scaling\n",
    "\n",
    "**Data Model**:\n",
    "```\n",
    "Table: users\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "Row Key       Column Family                Column Family\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "user123       profile                      activity\n",
    "              \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "              name: \"Alice\"                login_ts: 1704067200\n",
    "              age: 28                      last_action: \"view_profile\"\n",
    "              email: \"alice@...\"           page_views: 1500\n",
    "              \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "              preferences\n",
    "              \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "              theme: \"dark\"\n",
    "              notifications: \"email\"\n",
    "\n",
    "user456       profile                      activity\n",
    "              \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "              name: \"Bob\"                  login_ts: 1704070800\n",
    "              age: 35                      last_action: \"purchase\"\n",
    "              email: \"bob@...\"             total_spent: 1250.50\n",
    "              \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "              preferences\n",
    "              \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "              theme: \"light\"\n",
    "              notifications: \"sms\"\n",
    "```\n",
    "\n",
    "**Key insight**: Related columns are stored together (column families). Reading only name and age is fast\u2014you only read the profile column family, not the entire row.\n",
    "\n",
    "**Cassandra Example**:\n",
    "```sql\n",
    "-- Create keyspace (like a database)\n",
    "CREATE KEYSPACE myapp \n",
    "WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 3};\n",
    "\n",
    "-- Use keyspace\n",
    "USE myapp;\n",
    "\n",
    "-- Create table (column family)\n",
    "CREATE TABLE users (\n",
    "  user_id UUID PRIMARY KEY,\n",
    "  name TEXT,\n",
    "  email TEXT,\n",
    "  age INT,\n",
    "  created_at TIMESTAMP\n",
    ");\n",
    "\n",
    "-- Insert data\n",
    "INSERT INTO users (user_id, name, email, age, created_at)\n",
    "VALUES (uuid(), 'Alice', 'alice@example.com', 28, toTimestamp(now()));\n",
    "\n",
    "-- Query data (WHERE must include partition key)\n",
    "SELECT * FROM users WHERE user_id = 123e4567-e89b-12d3-a456-426614174000;\n",
    "\n",
    "-- Create table with clustering key (sort order)\n",
    "CREATE TABLE messages (\n",
    "  user_id UUID,\n",
    "  message_id TIMEUUID,\n",
    "  content TEXT,\n",
    "  created_at TIMESTAMP,\n",
    "  PRIMARY KEY (user_id, message_id)  -- Composite primary key\n",
    ") WITH CLUSTERING ORDER BY (message_id DESC);  -- Sort messages by time, descending\n",
    "\n",
    "-- Insert messages\n",
    "INSERT INTO messages (user_id, message_id, content, created_at)\n",
    "VALUES (123e4567-e89b-12d3-a456-426614174000, now(), 'Hello!', toTimestamp(now()));\n",
    "\n",
    "-- Query messages (efficiently retrieves in sorted order)\n",
    "SELECT * FROM messages WHERE user_id = 123e4567-e89b-12d3-a456-426614174000;\n",
    "-- Returns messages sorted by message_id (which is time-based) in descending order\n",
    "```\n",
    "\n",
    "**Cassandra Data Model Concepts**:\n",
    "\n",
    "**Partition Key**: Determines which node stores the data (like hashing in distributed hash tables).\n",
    "```sql\n",
    "-- Single partition key\n",
    "CREATE TABLE users (\n",
    "  user_id UUID PRIMARY KEY  -- Partition key\n",
    ");\n",
    "\n",
    "-- Composite partition key (multiple columns)\n",
    "CREATE TABLE user_events (\n",
    "  user_id UUID,\n",
    "  event_type TEXT,\n",
    "  event_id TIMEUUID,\n",
    "  event_data TEXT,\n",
    "  PRIMARY KEY ((user_id, event_type), event_id)  -- (user_id, event_type) is partition key\n",
    ");\n",
    "```\n",
    "\n",
    "**Clustering Key**: Determines how data is sorted within a partition (like ORDER BY in SQL).\n",
    "```sql\n",
    "-- Event timeline example\n",
    "CREATE TABLE events (\n",
    "  user_id UUID,\n",
    "  timestamp TIMESTAMP,\n",
    "  event_type TEXT,\n",
    "  event_data TEXT,\n",
    "  PRIMARY KEY (user_id, timestamp)  -- user_id is partition key, timestamp is clustering key\n",
    ") WITH CLUSTERING ORDER BY (timestamp DESC);  -- Most recent events first\n",
    "```\n",
    "\n",
    "**Query Patterns**: Design your schema based on query patterns (data modeling is query-driven).\n",
    "```sql\n",
    "-- Good: Efficient query (includes partition key)\n",
    "SELECT * FROM events WHERE user_id = 123e4567-e89b-12d3-a456-426614174000;\n",
    "\n",
    "-- Bad: Inefficient query (doesn't include partition key)\n",
    "-- Requires full cluster scan (very slow!)\n",
    "SELECT * FROM events WHERE timestamp > '2024-01-01';\n",
    "\n",
    "-- Solution: Denormalize into separate table for this query\n",
    "CREATE TABLE events_by_date (\n",
    "  event_date DATE,\n",
    "  timestamp TIMESTAMP,\n",
    "  user_id UUID,\n",
    "  event_type TEXT,\n",
    "  event_data TEXT,\n",
    "  PRIMARY KEY (event_date, timestamp)  -- Partition by date\n",
    ");\n",
    "\n",
    "-- Now efficient:\n",
    "SELECT * FROM events_by_date WHERE event_date = '2024-01-01';\n",
    "```\n",
    "\n",
    "**Wide-Column Use Cases**:\n",
    "- **Time series data**: IoT sensor readings, application metrics\n",
    "- **Log data**: Application logs, audit trails (append-only)\n",
    "- **Messaging systems**: Chat messages, notifications (time-ordered)\n",
    "- **Product catalogs**: E-commerce with many attributes (flexible schema)\n",
    "- **User activity tracking**: Social media feeds, analytics events\n",
    "\n",
    "**Popular Wide-Column Stores**:\n",
    "\n",
    "**Apache Cassandra**: Most popular open-source wide-column store.\n",
    "- **Strengths**: Linear scalability, multi-datacenter replication, tunable consistency\n",
    "- **Weaknesses**: Complex data modeling (query-driven), limited query capabilities\n",
    "- **Best for**: Time series data, write-heavy workloads, global applications\n",
    "\n",
    "**HBase**: Hadoop-based wide-column store.\n",
    "- **Strengths**: Integrates with Hadoop ecosystem, strong consistency, real-time random access\n",
    "- **Weaknesses**: Requires Zookeeper, complex setup, Java-only client\n",
    "- **Best for**: Big data analytics, real-time processing on Hadoop\n",
    "\n",
    "**ScyllaDB**: C++ rewrite of Cassandra for extreme performance.\n",
    "- **Strengths**: 10x faster than Cassandra, shared-nothing architecture, low latency\n",
    "- **Weaknesses**: Smaller community, fewer integrations\n",
    "- **Best for**: High-throughput, low-latency workloads\n",
    "\n",
    "---\n",
    "\n",
    "### **Graph Databases**\n",
    "\n",
    "**Concept**: Store data as nodes (entities), edges (relationships), and properties. Optimized for querying complex relationships.\n",
    "\n",
    "**Characteristics**:\n",
    "- **Nodes**: Entities (users, products, locations)\n",
    "- **Edges**: Relationships (follows, purchased, located_in)\n",
    "- **Properties**: Key-value pairs on nodes and edges\n",
    "- **Graph traversals**: Efficiently navigate relationships\n",
    "\n",
    "**Data Model**:\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   Person    \u2502                      \u2502   Person    \u2502\n",
    "\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502                      \u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n",
    "\u2502 name: Alice \u2502                      \u2502 name: Bob   \u2502\n",
    "\u2502 age: 28     \u2502                      \u2502 age: 32     \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "       \u2502                                    \u2502\n",
    "       \u2502 knows                              \u2502 knows\n",
    "       \u2502 (since: 2019)                     \u2502 (since: 2020)\n",
    "       \u2502                                    \u2502\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502              Person                             \u2502\n",
    "\u2502              \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                           \u2502\n",
    "\u2502              name: Carol                         \u2502\n",
    "\u2502              age: 35                            \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**Neo4j Example**:\n",
    "```cypher\n",
    "-- Create nodes and relationships\n",
    "CREATE (alice:Person {name: 'Alice', age: 28})\n",
    "CREATE (bob:Person {name: 'Bob', age: 32})\n",
    "CREATE (carol:Person {name: 'Carol', age: 35})\n",
    "CREATE (alice)-[:KNOWS {since: 2019}]->(bob)\n",
    "CREATE (bob)-[:KNOWS {since: 2020}]->(carol)\n",
    "CREATE (alice)-[:KNOWS {since: 2021}]->(carol);\n",
    "\n",
    "-- Find friends of friends (2 hops away)\n",
    "MATCH (a:Person {name: 'Alice'})-[:KNOWS]->(friend:Person)-[:KNOWS]->(fof:Person)\n",
    "WHERE NOT (a)-[:KNOWS]->(fof)  -- Not already friends\n",
    "RETURN fof.name, friend.name;\n",
    "\n",
    "-- Find the shortest path between two people\n",
    "MATCH p = shortestPath(\n",
    "  (alice:Person {name: 'Alice'})-[*]-(bob:Person {name: 'Bob'})\n",
    ")\n",
    "RETURN p;\n",
    "\n",
    "-- Find common friends\n",
    "MATCH (alice:Person {name: 'Alice'})-[:KNOWS]->(friend:Person)<-[:KNOWS]-(bob:Person {name: 'Bob'})\n",
    "RETURN friend.name;\n",
    "\n",
    "-- Recommend products based on purchases (recommendation engine)\n",
    "MATCH (user:Person {name: 'Alice'})-[:PURCHASED]->(product:Product)<-[:PURCHASED]-(other:Person)-[:PURCHASED]->(recommendation:Product)\n",
    "WHERE NOT (user)-[:PURCHASED]->(recommendation)  -- Alice hasn't purchased\n",
    "RETURN recommendation.name, count(*) AS frequency\n",
    "ORDER BY frequency DESC\n",
    "LIMIT 10;\n",
    "```\n",
    "\n",
    "**Graph Database Use Cases**:\n",
    "- **Social networks**: Finding friends of friends, influence analysis\n",
    "- **Recommendation engines**: Product recommendations, content suggestions\n",
    "- **Fraud detection**: Finding suspicious patterns, money laundering networks\n",
    "- **Identity management**: Access control, permission hierarchies\n",
    "- **Network topology**: IT infrastructure, dependency graphs\n",
    "\n",
    "**Popular Graph Databases**:\n",
    "\n",
    "**Neo4j**: Most popular graph database.\n",
    "- **Strengths**: Cypher query language (graph-focused), excellent performance for graph traversals, strong ecosystem\n",
    "- **Weaknesses**: Scaling requires Enterprise edition, horizontal scaling is challenging\n",
    "- **Best for**: Social networks, recommendation engines, fraud detection\n",
    "\n",
    "**Amazon Neptune**: Fully managed graph database service.\n",
    "- **Strengths**: Serverless, supports both property graphs and RDF graphs, integrated with AWS\n",
    "- **Weaknesses**: Proprietary, limited to AWS, higher cost for high throughput\n",
    "- **Best for**: AWS-based applications requiring graph capabilities\n",
    "\n",
    "**ArangoDB**: Multi-model database (supports graphs, documents, key-value).\n",
    "- **Strengths**: Multi-model (one database for multiple use cases), flexible, ACID transactions\n",
    "- **Weaknesses**: Jack of all trades (not specialized), smaller community\n",
    "- **Best for**: Applications needing multiple data models\n",
    "\n",
    "---\n",
    "\n",
    "## **3.4 Database Scaling: From Single Server to Global Distribution**\n",
    "\n",
    "### **Vertical Scaling vs. Horizontal Scaling**\n",
    "\n",
    "**Vertical Scaling (Scale Up)**: Adding more resources to a single server.\n",
    "\n",
    "**Example**:\n",
    "```\n",
    "Before: 1 server with 16 cores, 64GB RAM, 1TB SSD\n",
    "After:  1 server with 64 cores, 256GB RAM, 4TB SSD\n",
    "\n",
    "Pros:\n",
    "- Simple: No application changes required\n",
    "- Consistent performance: No data synchronization issues\n",
    "- Easier operations: Single point of maintenance\n",
    "\n",
    "Cons:\n",
    "- Expensive: High-end hardware costs more per unit of performance\n",
    "- Limited: Eventually hit hardware limits\n",
    "- Single point of failure: Entire system goes down if server fails\n",
    "- Downtime: Requires reboot for upgrades\n",
    "```\n",
    "\n",
    "**Horizontal Scaling (Scale Out)**: Adding more servers.\n",
    "\n",
    "**Example**:\n",
    "```\n",
    "Before: 1 server with 16 cores, 64GB RAM, 1TB SSD\n",
    "After:  4 servers with 16 cores, 64GB RAM, 1TB SSD each\n",
    "\n",
    "Pros:\n",
    "- Cost-effective: Commodity hardware is cheaper\n",
    "- Unlimited: Theoretically infinite scaling\n",
    "- Resilient: System continues if one server fails\n",
    "- No downtime: Add/remove servers without affecting application\n",
    "\n",
    "Cons:\n",
    "- Complex: Requires application changes (data partitioning, sharding)\n",
    "- Consistency challenges: Distributed systems complexity\n",
    "- Increased operations: More servers to manage\n",
    "- Distributed transactions: Harder to maintain ACID properties\n",
    "```\n",
    "\n",
    "**When to Use Which**:\n",
    "```\n",
    "Use Vertical Scaling When:\n",
    "- Data fits in memory (< 100GB)\n",
    "- Traffic is manageable (< 10,000 QPS)\n",
    "- Team is small (limited operations capacity)\n",
    "- Consistency is critical (banking, finance)\n",
    "\n",
    "Use Horizontal Scaling When:\n",
    "- Data exceeds single machine capacity (> 10TB)\n",
    "- Traffic is high (> 10,000 QPS)\n",
    "- Team is experienced (can manage complexity)\n",
    "- Availability is critical (can tolerate eventual consistency)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Read Replicas: Scaling Reads**\n",
    "\n",
    "**Problem**: Application is read-heavy (90% reads, 10% writes), but the single database can't handle the load.\n",
    "\n",
    "**Solution**: Create read replicas\u2014copies of the primary database that handle read queries.\n",
    "\n",
    "**Architecture**:\n",
    "```\n",
    "Application Servers\n",
    "    \u2502\n",
    "    \u251c\u2500\u2192 [Primary Database] \u2190\u2500\u2500 Writes go here\n",
    "    \u2502      (Master)         \u2502\n",
    "    \u2502      \u2502                \u2502\n",
    "    \u2502      \u251c\u2500\u2192 Replica 1    \u2502\n",
    "    \u2502      \u251c\u2500\u2192 Replica 2    \u2502\n",
    "    \u2502      \u2514\u2500\u2192 Replica 3    \u2502\n",
    "    \u2502                       \u2502\n",
    "    \u2514\u2500\u2192 [Load Balancer] \u2190\u2500\u2500 Reads go here\n",
    "          (Routes to any replica)\n",
    "```\n",
    "\n",
    "**How It Works**:\n",
    "1. **Write operation**: Application writes to primary database\n",
    "2. **Replication**: Primary asynchronously propagates changes to replicas\n",
    "3. **Read operation**: Application reads from any replica (load balanced)\n",
    "\n",
    "**Replication Lag**: The time between a write being applied to the primary and being visible on replicas.\n",
    "\n",
    "**Example**:\n",
    "```sql\n",
    "-- Primary database (write)\n",
    "INSERT INTO users (name, email) VALUES ('Alice', 'alice@example.com');\n",
    "-- Transaction committed at 10:00:00.000\n",
    "\n",
    "-- Read replica at 10:00:00.100\n",
    "SELECT * FROM users WHERE email = 'alice@example.com';\n",
    "-- Returns 0 rows (not yet replicated)\n",
    "\n",
    "-- Read replica at 10:00:00.500\n",
    "SELECT * FROM users WHERE email = 'alice@example.com';\n",
    "-- Returns 1 row (now replicated)\n",
    "\n",
    "-- Replication lag: 500ms\n",
    "```\n",
    "\n",
    "**Handling Replication Lag**:\n",
    "\n",
    "**Strategy 1: Accept eventual consistency**\n",
    "```python\n",
    "# After writing, read from primary for a short time\n",
    "def create_user(user_data):\n",
    "    # Write to primary\n",
    "    db_primary.insert(user_data)\n",
    "    \n",
    "    # For the next 2 seconds, read from primary\n",
    "    redis.setex(f\"read_primary:{user_id}\", 2, \"true\")\n",
    "\n",
    "def get_user(user_id):\n",
    "    if redis.exists(f\"read_primary:{user_id}\"):\n",
    "        return db_primary.get(user_id)\n",
    "    else:\n",
    "        return db_replica.get(user_id)\n",
    "```\n",
    "\n",
    "**Strategy 2: Always read from primary for critical data**\n",
    "```python\n",
    "# Banking transactions always read from primary\n",
    "def get_account_balance(account_id):\n",
    "    # Financial data must be consistent\n",
    "    return db_primary.query(\"SELECT balance FROM accounts WHERE id = ?\", account_id)\n",
    "\n",
    "def get_profile(user_id):\n",
    "    # Profile data can be eventually consistent\n",
    "    return db_replica.query(\"SELECT * FROM profiles WHERE id = ?\", user_id)\n",
    "```\n",
    "\n",
    "**Setting Up Read Replicas** (PostgreSQL example):\n",
    "```sql\n",
    "-- On primary server:\n",
    "-- 1. Create replication user\n",
    "CREATE USER replicator WITH REPLICATION ENCRYPTED PASSWORD 'password';\n",
    "\n",
    "-- 2. Configure postgresql.conf:\n",
    "wal_level = replica\n",
    "max_wal_senders = 5\n",
    "max_replication_slots = 5\n",
    "\n",
    "-- 3. Reload configuration\n",
    "SELECT pg_reload_conf();\n",
    "\n",
    "-- 4. Take base backup for replicas\n",
    "pg_basebackup -h primary_host -D /var/lib/postgresql/data -U replicator -P -v -R\n",
    "\n",
    "-- On replica server:\n",
    "-- 1. Configure postgresql.conf:\n",
    "hot_standby = on\n",
    "max_standby_streaming_delay = 30s\n",
    "\n",
    "-- 2. Start replica\n",
    "# PostgreSQL automatically starts in replication mode\n",
    "```\n",
    "\n",
    "**Scaling Calculations**:\n",
    "```\n",
    "Scenario: 10,000 QPS with 90% reads (9,000 read QPS, 1,000 write QPS)\n",
    "\n",
    "Single database: Can handle 2,000 QPS total\n",
    "-- Insufficient! Need scaling.\n",
    "\n",
    "Option 1: Read Replicas\n",
    "- Primary: Handles 1,000 write QPS + some reads\n",
    "- Replicas needed for 9,000 read QPS: 9,000 / 2,000 = 4.5 \u2192 5 replicas\n",
    "- Total servers: 1 primary + 5 replicas = 6 servers\n",
    "- Write capacity: Still 1,000 QPS (single primary)\n",
    "- Read capacity: 10,000 QPS (5 replicas \u00d7 2,000 QPS each)\n",
    "\n",
    "Option 2: Horizontal Partitioning (Sharding)\n",
    "- Shard by user_id (10 shards)\n",
    "- Each shard handles ~10% of traffic\n",
    "- Write capacity: 10,000 QPS (10 shards \u00d7 1,000 QPS each)\n",
    "- Read capacity: 20,000 QPS (10 shards \u00d7 2,000 QPS each)\n",
    "- Total servers: 10 shards (each primary + replicas)\n",
    "\n",
    "Decision: Read replicas are simpler for read-heavy workloads.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Connection Pooling: Managing Database Connections**\n",
    "\n",
    "**Problem**: Each HTTP request opens a new database connection \u2192 thousands of connections \u2192 database overwhelmed.\n",
    "\n",
    "**Solution**: Connection pool\u2014a cache of database connections that can be reused.\n",
    "\n",
    "**Without Connection Pooling**:\n",
    "```\n",
    "Request 1: Open connection \u2192 Query \u2192 Close connection (50ms overhead)\n",
    "Request 2: Open connection \u2192 Query \u2192 Close connection (50ms overhead)\n",
    "Request 3: Open connection \u2192 Query \u2192 Close connection (50ms overhead)\n",
    "...\n",
    "Request 1000: Open connection \u2192 Query \u2192 Close connection (50ms overhead)\n",
    "\n",
    "Total overhead: 1000 \u00d7 50ms = 50 seconds just opening/closing connections!\n",
    "```\n",
    "\n",
    "**With Connection Pooling**:\n",
    "```\n",
    "Application Startup:\n",
    "- Create pool of 20 connections\n",
    "- All connections established and authenticated\n",
    "\n",
    "Request 1:    Get connection from pool \u2192 Query \u2192 Return to pool (0ms overhead)\n",
    "Request 2:    Get connection from pool \u2192 Query \u2192 Return to pool (0ms overhead)\n",
    "Request 3:    Wait for available connection \u2192 Query \u2192 Return to pool\n",
    "Request 4:    Get connection from pool \u2192 Query \u2192 Return to pool\n",
    "...\n",
    "Request 1000: Wait for available connection \u2192 Query \u2192 Return to pool\n",
    "\n",
    "Total overhead: 0ms (connections reused!)\n",
    "```\n",
    "\n",
    "**Connection Pool Configuration**:\n",
    "```python\n",
    "# PostgreSQL connection pool (Python using psycopg2)\n",
    "from psycopg2 import pool\n",
    "\n",
    "# Create connection pool\n",
    "connection_pool = pool.SimpleConnectionPool(\n",
    "    minconn=5,      # Minimum connections to keep open\n",
    "    maxconn=20,     # Maximum connections allowed\n",
    "    host='localhost',\n",
    "    database='mydb',\n",
    "    user='user',\n",
    "    password='password'\n",
    ")\n",
    "\n",
    "# Get connection from pool\n",
    "def get_user(user_id):\n",
    "    connection = connection_pool.getconn()\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))\n",
    "        return cursor.fetchone()\n",
    "    finally:\n",
    "        # Always return connection to pool\n",
    "        connection_pool.putconn(connection)\n",
    "\n",
    "# When shutting down application\n",
    "connection_pool.closeall()\n",
    "```\n",
    "\n",
    "**Pool Sizing**:\n",
    "```\n",
    "Rule of thumb: pool_size = (core_count \u00d7 2) + effective_spindle_count\n",
    "\n",
    "Example: 8-core server with 1 database (1 spindle)\n",
    "- pool_size = (8 \u00d7 2) + 1 = 17 connections\n",
    "\n",
    "But consider:\n",
    "- More connections = More concurrency, but context switching overhead\n",
    "- Too few connections = Requests wait for available connections\n",
    "- Connection wait time = (request_time \u00d7 (requests_per_second \u00d7 pool_size))\n",
    "\n",
    "If request_time = 100ms, requests_per_second = 1000, pool_size = 20:\n",
    "- Total connections needed = 1000 \u00d7 0.1 = 100\n",
    "- But pool only has 20 \u2192 80 requests wait\n",
    "\n",
    "Solution: Scale horizontally (add more application servers with their own pools)\n",
    "```\n",
    "\n",
    "**Connection Pool Libraries**:\n",
    "- **PostgreSQL**: PgBouncer (external connection pooler), connection pool built into drivers\n",
    "- **MySQL**: MySQL Proxy, connection pool built into drivers\n",
    "- **MongoDB**: Built-in connection pooling in driver\n",
    "- **Redis**: Built-in connection pooling in client\n",
    "\n",
    "---\n",
    "\n",
    "## **3.5 Indexing Strategies: Making Queries Fast**\n",
    "\n",
    "We've covered basic indexes earlier. Now, let's dive deeper into advanced indexing strategies.\n",
    "\n",
    "### **Composite Indexes: Multiple Columns**\n",
    "\n",
    "**Composite Index**: Index on multiple columns, order matters.\n",
    "\n",
    "**Example**:\n",
    "```sql\n",
    "-- Table: orders (customer_id, order_date, amount, status)\n",
    "CREATE INDEX idx_orders_customer_date ON orders(customer_id, order_date);\n",
    "\n",
    "-- This query uses the index efficiently:\n",
    "SELECT * FROM orders \n",
    "WHERE customer_id = 123 AND order_date >= '2024-01-01';\n",
    "-- Uses index: Both columns match index order\n",
    "\n",
    "-- This query uses index partially:\n",
    "SELECT * FROM orders \n",
    "WHERE customer_id = 123;\n",
    "-- Uses index: First column matches (can use index, but less efficient)\n",
    "\n",
    "-- This query DOES NOT use index:\n",
    "SELECT * FROM orders \n",
    "WHERE order_date >= '2024-01-01';\n",
    "-- Cannot use index: Doesn't include first column (customer_id)\n",
    "\n",
    "-- This query DOES NOT use index:\n",
    "SELECT * FROM orders \n",
    "WHERE order_date >= '2024-01-01' AND customer_id = 123;\n",
    "-- Cannot use index: Columns not in index order\n",
    "```\n",
    "\n",
    "**Rule of Thumb**: For composite index (A, B, C), queries can use index for:\n",
    "- WHERE A = value \u2713\n",
    "- WHERE A = value AND B = value \u2713\n",
    "- WHERE A = value AND B = value AND C = value \u2713\n",
    "- WHERE B = value \u2717 (unless A is also specified)\n",
    "- WHERE C = value \u2717 (unless A and B are also specified)\n",
    "\n",
    "**Index Order Strategy**: Put most selective column first.\n",
    "```sql\n",
    "-- Scenario 1: customer_id is highly selective (many distinct values)\n",
    "-- Query: WHERE customer_id = 123 AND status = 'pending'\n",
    "-- Better: INDEX(customer_id, status)\n",
    "-- Reason: customer_id narrows down to few rows, then status filters further\n",
    "\n",
    "-- Scenario 2: status is not selective (only 3 values: pending, shipped, delivered)\n",
    "-- Query: WHERE status = 'pending' AND order_date >= '2024-01-01'\n",
    "-- Better: INDEX(status, order_date)\n",
    "-- Reason: status narrows to 1/3 of data, then date filters further\n",
    "-- Alternative: Separate index on order_date if queries often search by date only\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Covering Indexes: Index-Only Scans**\n",
    "\n",
    "**Covering Index**: Index that contains all columns needed by query, eliminating table access.\n",
    "\n",
    "**Example**:\n",
    "```sql\n",
    "-- Table: users (id, name, email, age, city)\n",
    "CREATE INDEX idx_users_name_email ON users(name, email);\n",
    "\n",
    "-- Query:\n",
    "SELECT name, email FROM users WHERE name LIKE 'Ali%';\n",
    "\n",
    "-- Without covering index:\n",
    "1. Use index to find rows matching name LIKE 'Ali%'\n",
    "2. For each matching row, access table to get email\n",
    "3. Return results\n",
    "\n",
    "-- With covering index (name and email in index):\n",
    "1. Use index to find rows matching name LIKE 'Ali%'\n",
    "2. Email is already in index (no table access needed!)\n",
    "3. Return results\n",
    "\n",
    "-- Performance improvement: 2-10x faster (no table I/O)\n",
    "```\n",
    "\n",
    "**When to Use**:\n",
    "- Frequently executed queries\n",
    "- Queries that only select a few columns\n",
    "- Columns often used in WHERE clauses\n",
    "\n",
    "---\n",
    "\n",
    "### **Partial Indexes: Indexing Subset of Data**\n",
    "\n",
    "**Partial Index**: Index that only includes rows matching a condition.\n",
    "\n",
    "**Example**:\n",
    "```sql\n",
    "-- Table: orders (customer_id, order_date, amount, status)\n",
    "-- Query: SELECT * FROM orders WHERE status = 'pending';\n",
    "\n",
    "-- Regular index:\n",
    "CREATE INDEX idx_orders_status ON orders(status);\n",
    "-- Indexes ALL rows (including shipped, delivered, cancelled)\n",
    "\n",
    "-- Partial index:\n",
    "CREATE INDEX idx_orders_pending ON orders(status) WHERE status = 'pending';\n",
    "-- Only indexes pending orders\n",
    "\n",
    "-- Benefits:\n",
    "1. Smaller index (only pending orders, maybe 10% of data)\n",
    "2. Faster index maintenance (only updates pending rows)\n",
    "3. Faster queries (index is smaller, fits in memory)\n",
    "4. Less storage (index is 90% smaller)\n",
    "\n",
    "-- Query uses partial index:\n",
    "SELECT * FROM orders WHERE status = 'pending';  -- Uses partial index\n",
    "\n",
    "-- Query does NOT use partial index (condition doesn't match):\n",
    "SELECT * FROM orders WHERE status = 'shipped';  -- Cannot use partial index\n",
    "```\n",
    "\n",
    "**Use Cases**:\n",
    "- Filtering on status (pending, active, deleted)\n",
    "- Time-based queries (recent data only)\n",
    "- User-specific data (only active users)\n",
    "- Hot/cold data separation\n",
    "\n",
    "---\n",
    "\n",
    "### **Functional Indexes: Indexing Computed Values**\n",
    "\n",
    "**Functional Index**: Index on expression or function result.\n",
    "\n",
    "**Example**:\n",
    "```sql\n",
    "-- Table: users (id, name, email)\n",
    "-- Query: SELECT * FROM users WHERE LOWER(email) = 'ALICE@EXAMPLE.COM';\n",
    "\n",
    "-- Without functional index:\n",
    "-- Cannot use regular index (email indexed, but LOWER(email) not indexed)\n",
    "-- Full table scan required\n",
    "\n",
    "-- With functional index:\n",
    "CREATE INDEX idx_users_email_lower ON users(LOWER(email));\n",
    "\n",
    "-- Now query uses index:\n",
    "SELECT * FROM users WHERE LOWER(email) = 'ALICE@EXAMPLE.COM';\n",
    "-- Index is used (matches functional index)\n",
    "\n",
    "-- Another example: Full-text search\n",
    "-- Query: SELECT * FROM articles WHERE title LIKE '%database%';\n",
    "-- Slow: Leading wildcard prevents index usage\n",
    "\n",
    "-- With functional index (using PostgreSQL's full-text search):\n",
    "CREATE INDEX idx_articles_search ON articles USING gin(to_tsvector('english', title || ' ' || content));\n",
    "\n",
    "-- Query uses index:\n",
    "SELECT * FROM articles \n",
    "WHERE to_tsvector('english', title || ' ' || content) @@ to_tsquery('english', 'database');\n",
    "-- Fast: Full-text search using index\n",
    "```\n",
    "\n",
    "**Use Cases**:\n",
    "- Case-insensitive searches (LOWER, UPPER)\n",
    "- Date calculations (DATE_TRUNC, EXTRACT)\n",
    "- Full-text search (to_tsvector, to_tsquery)\n",
    "- Mathematical operations (ABS, ROUND)\n",
    "\n",
    "---\n",
    "\n",
    "### **B-Tree vs. Hash Indexes**\n",
    "\n",
    "**B-Tree Index**: Default index type in most databases.\n",
    "- **Supports**: Range queries, ORDER BY, pattern matching (LIKE 'abc%')\n",
    "- **Structure**: Balanced tree (log n operations)\n",
    "- **Use cases**: Most queries, range searches, sorting\n",
    "\n",
    "**Hash Index**: Hash-based index.\n",
    "- **Supports**: Equality queries only (=)\n",
    "- **Structure**: Hash table (O(1) average operations)\n",
    "- **Use cases**: Exact lookups, key-value operations\n",
    "\n",
    "**Comparison**:\n",
    "```sql\n",
    "-- Table: users (id, name, email, username)\n",
    "\n",
    "-- B-Tree index:\n",
    "CREATE INDEX idx_users_email ON users(email);\n",
    "\n",
    "-- Hash index:\n",
    "CREATE INDEX idx_users_username_hash ON users USING HASH(username);\n",
    "\n",
    "-- Query 1: Equality\n",
    "SELECT * FROM users WHERE username = 'alice';\n",
    "-- Both indexes work (hash might be slightly faster)\n",
    "\n",
    "-- Query 2: Range query\n",
    "SELECT * FROM users WHERE email LIKE 'alice%';\n",
    "-- B-Tree index works, hash index doesn't (full table scan)\n",
    "\n",
    "-- Query 3: ORDER BY\n",
    "SELECT * FROM users WHERE email = 'alice@example.com';\n",
    "-- B-Tree index works (already sorted), hash index doesn't\n",
    "```\n",
    "\n",
    "**When to Use Hash Indexes**:\n",
    "- Only equality queries needed\n",
    "- Very high selectivity (many distinct values)\n",
    "- In-memory or small datasets\n",
    "\n",
    "---\n",
    "\n",
    "## **3.6 Sharding: Distributing Data Across Multiple Databases**\n",
    "\n",
    "**Sharding**: Horizontal partitioning\u2014splitting data across multiple database instances.\n",
    "\n",
    "### **Why Shard?**\n",
    "\n",
    "**Problem**: Single database can't handle the load.\n",
    "```\n",
    "Single Database:\n",
    "- Data: 10TB (exceeds single machine storage)\n",
    "- QPS: 50,000 (exceeds single machine capacity)\n",
    "- Connections: 10,000 (exceeds single machine limits)\n",
    "\n",
    "Solution: Shard across multiple databases\n",
    "```\n",
    "\n",
    "**Sharding Benefits**:\n",
    "- **Scalability**: Each shard handles subset of data (linear scalability)\n",
    "- **Performance**: Smaller datasets per shard (faster queries)\n",
    "- **Availability**: One shard failure doesn't affect others\n",
    "\n",
    "**Sharding Challenges**:\n",
    "- **Complexity**: Application must know which shard to query\n",
    "- **Joins**: Cross-shard joins are expensive or impossible\n",
    "- **Transactions**: Distributed transactions are complex\n",
    "- **Rebalancing**: Adding/removing shards is expensive (data movement)\n",
    "\n",
    "---\n",
    "\n",
    "### **Sharding Strategies**\n",
    "\n",
    "**Strategy 1: Hash-based Sharding**\n",
    "\n",
    "**Concept**: Hash a key (e.g., user_id) to determine shard.\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "def get_shard(user_id, num_shards):\n",
    "    # Hash user_id and modulo number of shards\n",
    "    hash_value = hash(user_id)\n",
    "    shard_id = hash_value % num_shards\n",
    "    return shard_id\n",
    "\n",
    "# Example with 4 shards\n",
    "user_ids = [123, 456, 789, 101112, 131415]\n",
    "for user_id in user_ids:\n",
    "    shard = get_shard(user_id, 4)\n",
    "    print(f\"User {user_id} \u2192 Shard {shard}\")\n",
    "\n",
    "# Output:\n",
    "# User 123 \u2192 Shard 3\n",
    "# User 456 \u2192 Shard 0\n",
    "# User 789 \u2192 Shard 1\n",
    "# User 101112 \u2192 Shard 0\n",
    "# User 131415 \u2192 Shard 3\n",
    "```\n",
    "\n",
    "**Pros**:\n",
    "- **Even distribution**: Data evenly spread across shards (if hash function is good)\n",
    "- **Simple**: Easy to implement\n",
    "- **Predictable**: Same key always maps to same shard\n",
    "\n",
    "**Cons**:\n",
    "- **No range queries**: Cannot efficiently query ranges (e.g., users 1000-2000)\n",
    "- **Rebalancing**: Adding shards requires remapping all keys (expensive)\n",
    "- **Hot spots**: If one key has much more data, that shard is overloaded\n",
    "\n",
    "**Use cases**: User data, key-value lookups, even distribution required\n",
    "\n",
    "---\n",
    "\n",
    "**Strategy 2: Range-based Sharding**\n",
    "\n",
    "**Concept**: Shard by value ranges (e.g., user_id 0-999 on shard 0, 1000-1999 on shard 1).\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "# Shard configuration\n",
    "shard_ranges = [\n",
    "    (0, 9999),        # Shard 0: user_id 0-9999\n",
    "    (10000, 19999),   # Shard 1: user_id 10000-19999\n",
    "    (20000, 29999),   # Shard 2: user_id 20000-29999\n",
    "    (30000, 39999),   # Shard 3: user_id 30000-39999\n",
    "]\n",
    "\n",
    "def get_shard(user_id):\n",
    "    for shard_id, (min_id, max_id) in enumerate(shard_ranges):\n",
    "        if min_id <= user_id <= max_id:\n",
    "            return shard_id\n",
    "    return None  # User_id outside range\n",
    "\n",
    "# Examples\n",
    "print(f\"User 5000 \u2192 Shard {get_shard(5000)}\")   # Shard 0\n",
    "print(f\"User 15000 \u2192 Shard {get_shard(15000)}\") # Shard 1\n",
    "print(f\"User 25000 \u2192 Shard {get_shard(25000)}\") # Shard 2\n",
    "```\n",
    "\n",
    "**Pros**:\n",
    "- **Range queries**: Efficient range queries within shard\n",
    "- **Ordered data**: Data naturally ordered (useful for time-series)\n",
    "- **Predictable**: Easy to understand distribution\n",
    "\n",
    "**Cons**:\n",
    "- **Uneven distribution**: Some ranges may have more data than others\n",
    "- **Hot spots**: Popular ranges overload shards\n",
    "- **Rebalancing**: Changing ranges requires moving data\n",
    "\n",
    "**Use cases**: Time-series data, geographic data, range queries required\n",
    "\n",
    "---\n",
    "\n",
    "**Strategy 3: Directory-based Sharding**\n",
    "\n",
    "**Concept**: Maintain a directory (lookup table) mapping keys to shards.\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "# Directory (could be in Redis, database, or service)\n",
    "shard_directory = {\n",
    "    123: 0,      # User 123 is on shard 0\n",
    "    456: 1,      # User 456 is on shard 1\n",
    "    789: 2,      # User 789 is on shard 2\n",
    "    101112: 0,   # User 101112 is also on shard 0\n",
    "    131415: 3,   # User 131415 is on shard 3\n",
    "}\n",
    "\n",
    "def get_shard(user_id):\n",
    "    return shard_directory.get(user_id)\n",
    "\n",
    "# When creating new user:\n",
    "def create_user(user_id, user_data):\n",
    "    # Choose shard based on current load\n",
    "    shard_id = choose_least_loaded_shard()\n",
    "    \n",
    "    # Store on shard\n",
    "    shard_databases[shard_id].insert(user_id, user_data)\n",
    "    \n",
    "    # Update directory\n",
    "    shard_directory[user_id] = shard_id\n",
    "\n",
    "# When querying user:\n",
    "def get_user(user_id):\n",
    "    shard_id = get_shard(user_id)\n",
    "    return shard_databases[shard_id].get(user_id)\n",
    "```\n",
    "\n",
    "**Pros**:\n",
    "- **Flexible**: Can manually control placement\n",
    "- **Rebalancing**: Easy to move users between shards (just update directory)\n",
    "- **Load-aware**: Can place users based on current load\n",
    "\n",
    "**Cons**:\n",
    "- **Directory overhead**: Need to maintain and query directory\n",
    "- **Single point of failure**: Directory failure breaks entire system\n",
    "- **Complex**: Additional infrastructure to manage\n",
    "\n",
    "**Use cases**: When flexibility and manual control over placement are needed\n",
    "\n",
    "---\n",
    "\n",
    "### **Sharding Key Selection**\n",
    "\n",
    "**Sharding Key**: Column used to determine shard placement (also called partition key).\n",
    "\n",
    "**Criteria for Good Sharding Key**:\n",
    "1. **High cardinality**: Many distinct values (even distribution)\n",
    "2. **Access pattern**: Most queries include sharding key (avoid cross-shard queries)\n",
    "3. **No hotspots**: No single key has disproportionate data\n",
    "4. **Stable**: Key doesn't change (no need to move data)\n",
    "\n",
    "**Examples**:\n",
    "\n",
    "**Good Sharding Keys**:\n",
    "```sql\n",
    "-- User ID: High cardinality, stable, most queries include user_id\n",
    "Shard key: user_id\n",
    "\n",
    "-- Order ID: High cardinality, stable\n",
    "Shard key: order_id\n",
    "\n",
    "-- Customer ID + Date: Composite sharding key for time-series\n",
    "Shard key: (customer_id, order_date)\n",
    "```\n",
    "\n",
    "**Bad Sharding Keys**:\n",
    "```sql\n",
    "-- Status: Low cardinality (only 3 values: active, inactive, deleted)\n",
    "-- Uneven distribution: 90% of users might be active\n",
    "Shard key: status  \u2192 BAD\n",
    "\n",
    "-- Timestamp: Range-based sharding causes hot spots (recent data popular)\n",
    "Shard key: created_at  \u2192 BAD (unless range-based sharding is desired)\n",
    "\n",
    "-- Country: Uneven distribution (some countries have many more users)\n",
    "Shard key: country  \u2192 BAD\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Cross-Shard Queries: The Join Problem**\n",
    "\n",
    "**Problem**: Querying data across multiple shards requires joining data from multiple databases.\n",
    "\n",
    "**Example**:\n",
    "```sql\n",
    "-- Sharded by user_id (4 shards)\n",
    "-- Shard 0: users 0-9999\n",
    "-- Shard 1: users 10000-19999\n",
    "-- Shard 2: users 20000-29999\n",
    "-- Shard 3: users 30000-39999\n",
    "\n",
    "-- Table: orders (order_id, user_id, product_id, amount, order_date)\n",
    "-- Table: products (product_id, name, price, category)\n",
    "\n",
    "-- Query: Get all orders for user 12345 (on shard 1) with product names\n",
    "SELECT o.order_id, o.amount, p.name, p.price\n",
    "FROM orders o\n",
    "JOIN products p ON o.product_id = p.product_id\n",
    "WHERE o.user_id = 12345;\n",
    "\n",
    "-- Problem: Products table is on all shards (or separate shard)\n",
    "-- Need to query shard 1 for orders, then query all shards for products\n",
    "```\n",
    "\n",
    "**Solutions**:\n",
    "\n",
    "**Solution 1: Denormalization (Duplicate Data)**\n",
    "```sql\n",
    "-- Duplicate product name in orders table\n",
    "CREATE TABLE orders (\n",
    "    order_id INT,\n",
    "    user_id INT,      -- Shard key\n",
    "    product_id INT,\n",
    "    product_name VARCHAR(100),  -- Denormalized!\n",
    "    product_price DECIMAL(10, 2),  -- Denormalized!\n",
    "    amount DECIMAL(10, 2),\n",
    "    order_date DATE\n",
    ");\n",
    "\n",
    "-- Query: No join needed!\n",
    "SELECT order_id, amount, product_name, product_price\n",
    "FROM orders\n",
    "WHERE user_id = 12345;\n",
    "\n",
    "-- Trade-offs:\n",
    "-- + No cross-shard joins (fast queries)\n",
    "# - Data redundancy (product name stored multiple times)\n",
    "# - Update anomalies (must update product name in all orders)\n",
    "```\n",
    "\n",
    "**Solution 2: Application-side joins**\n",
    "```python\n",
    "def get_orders_with_products(user_id):\n",
    "    # Step 1: Get orders from correct shard\n",
    "    shard_id = get_shard(user_id)\n",
    "    orders = shard_databases[shard_id].query(\n",
    "        \"SELECT * FROM orders WHERE user_id = ?\", user_id\n",
    "    )\n",
    "    \n",
    "    # Step 2: Get product_ids from orders\n",
    "    product_ids = [order['product_id'] for order in orders]\n",
    "    \n",
    "    # Step 3: Get products from product shard (or all shards)\n",
    "    # Assume products are sharded by product_id\n",
    "    products = {}\n",
    "    for product_id in product_ids:\n",
    "        product_shard = get_shard(product_id)\n",
    "        products[product_id] = shard_databases[product_shard].get_product(product_id)\n",
    "    \n",
    "    # Step 4: Join in application\n",
    "    result = []\n",
    "    for order in orders:\n",
    "        product = products[order['product_id']]\n",
    "        result.append({\n",
    "            'order_id': order['order_id'],\n",
    "            'amount': order['amount'],\n",
    "            'product_name': product['name'],\n",
    "            'product_price': product['price']\n",
    "        })\n",
    "    \n",
    "    return result\n",
    "```\n",
    "\n",
    "**Solution 3: Two-phase commit (distributed transaction)**\n",
    "```python\n",
    "# Expensive and complex, but ensures consistency\n",
    "def create_order(user_id, product_data):\n",
    "    # Phase 1: Prepare\n",
    "    order_shard = get_shard(user_id)\n",
    "    product_shard = get_shard(product_data['product_id'])\n",
    "    \n",
    "    # Reserve on both shards\n",
    "    order_id = order_shard.prepare_order(user_id, product_data)\n",
    "    product_shard.reserve_product(product_data['product_id'], order_id)\n",
    "    \n",
    "    # Phase 2: Commit\n",
    "    order_shard.commit_order(order_id)\n",
    "    product_shard.commit_reservation(product_data['product_id'])\n",
    "    \n",
    "    # If any step fails, rollback both\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3.7 The CAP Theorem Deep Dive**\n",
    "\n",
    "We introduced CAP briefly in Chapter 1. Now, let's explore it in detail.\n",
    "\n",
    "### **CAP Theorem: Consistency, Availability, Partition Tolerance**\n",
    "\n",
    "**CAP Theorem**: In a distributed system, during a network partition, you must choose between Consistency (C) and Availability (A). Partition Tolerance (P) is mandatory in distributed systems.\n",
    "\n",
    "**Three Properties**:\n",
    "\n",
    "**C - Consistency**: Every read receives the most recent write or an error.\n",
    "- **Strong consistency**: All nodes see same data at same time\n",
    "- **Example**: Bank account balance\u2014always accurate\n",
    "\n",
    "**A - Availability**: Every request receives a response, without guarantee it contains the most recent write.\n",
    "- **High availability**: System always responds (even with stale data)\n",
    "- **Example**: Twitter feed\u2014better to see old tweets than error\n",
    "\n",
    "**P - Partition Tolerance**: System continues to operate despite network failures.\n",
    "- **Network partition**: Communication break between nodes\n",
    "- **Mandatory**: Networks always fail eventually\n",
    "\n",
    "**The Trade-off**: When P occurs (network partition), must choose C or A.\n",
    "\n",
    "```\n",
    "                    Network Partition\n",
    "                         \u2502\n",
    "                         \u25bc\n",
    "         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "         \u2502                           \u2502\n",
    "    Choose C                   Choose A\n",
    "         \u2502                           \u2502\n",
    "         \u25bc                           \u25bc\n",
    "    Reject writes              Accept writes\n",
    "    (return error)           (might be inconsistent)\n",
    "         \u2502                           \u2502\n",
    "         \u25bc                           \u25bc\n",
    "   Data always               System always\n",
    "   consistent               available\n",
    "   (but unavailable)        (but possibly stale)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **CP Systems: Choosing Consistency**\n",
    "\n",
    "**CP Systems**: Prioritize consistency over availability. During partition, system rejects writes or reads until partition is resolved.\n",
    "\n",
    "**Examples**:\n",
    "- **Banking systems**: Data accuracy is critical\n",
    "- **Databases**: HBase, MongoDB (with specific settings), PostgreSQL\n",
    "- **Blockchain**: Immutable ledger requires consistency\n",
    "\n",
    "**Example Scenario**:\n",
    "```\n",
    "Primary Database: New York (active)\n",
    "Replica Database: London (sync replica)\n",
    "\n",
    "Network partition: New York \u2194 London communication breaks\n",
    "\n",
    "Client request: Write transaction to London replica\n",
    "\n",
    "CP System Response:\n",
    "- London replica: Cannot accept write (not sure if it conflicts with New York)\n",
    "- Return error: \"Service unavailable, please try later\"\n",
    "- Data remains consistent (no conflicting writes)\n",
    "- But system is unavailable (London users cannot write)\n",
    "\n",
    "When partition heals:\n",
    "- Sync changes from New York to London\n",
    "- London becomes available again\n",
    "```\n",
    "\n",
    "**PostgreSQL (CP Configuration)**:\n",
    "```sql\n",
    "-- Set synchronous commit for strong consistency\n",
    "SET synchronous_commit = on;\n",
    "\n",
    "-- Set transaction isolation level for serializable isolation\n",
    "SET default_transaction_isolation = 'serializable';\n",
    "\n",
    "-- Result: Strong consistency, but lower availability during partitions\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **AP Systems: Choosing Availability**\n",
    "\n",
    "**AP Systems**: Prioritize availability over consistency. During partition, system accepts reads and writes, serving potentially stale data.\n",
    "\n",
    "**Examples**:\n",
    "- **Social media**: Better to see old feed than error\n",
    "- **E-commerce shopping cart**: Better to add item than lose sale\n",
    "- **Databases**: DynamoDB, Cassandra, CouchDB\n",
    "\n",
    "**Example Scenario**:\n",
    "```\n",
    "Database: DynamoDB (multi-region, 3 replicas)\n",
    "Region: US-East-1 (primary), US-West-2 (replica), EU-West-1 (replica)\n",
    "\n",
    "Network partition: US-East-1 \u2194 US-West-2 communication breaks\n",
    "\n",
    "Client request: Write user profile (update email) to US-West-2\n",
    "\n",
    "AP System Response:\n",
    "- US-West-2: Accept write (stores locally)\n",
    "- Return success: \"Profile updated\"\n",
    "- System remains available\n",
    "- But data is inconsistent (US-East-1 doesn't have new email)\n",
    "\n",
    "When partition heals:\n",
    "- US-East-1 syncs with US-West-2\n",
    "- Conflict resolution: Last-write-wins (based on timestamp)\n",
    "- Data becomes consistent again\n",
    "```\n",
    "\n",
    "**DynamoDB (AP Configuration)**:\n",
    "```javascript\n",
    "// Write with eventual consistency (AP)\n",
    "const params = {\n",
    "  TableName: 'Users',\n",
    "  Item: {\n",
    "    userId: '123',\n",
    "    name: 'Alice',\n",
    "    email: 'alice@example.com'\n",
    "  },\n",
    "  // No consistency specified \u2192 eventual consistency (AP)\n",
    "};\n",
    "\n",
    "// Query with eventual consistency (AP)\n",
    "const params = {\n",
    "  TableName: 'Users',\n",
    "  Key: { userId: '123' },\n",
    "  ConsistentRead: false  // Eventual consistency (AP)\n",
    "};\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **CA Systems: The Impossibility**\n",
    "\n",
    "**CA Systems**: Theoretically possible, but only in non-distributed systems (single machine). In distributed systems, P is mandatory, so CA is impossible.\n",
    "\n",
    "**Example**: Single database instance on one machine (no network partitions).\n",
    "- **Consistent**: All reads see latest writes\n",
    "- **Available**: Always responds (unless machine crashes)\n",
    "- **No partition tolerance**: Not distributed (single point of failure)\n",
    "\n",
    "**Reality**: Any distributed system must be either CP or AP. CA is only possible in non-distributed systems.\n",
    "\n",
    "---\n",
    "\n",
    "### **PACELC Theorem: Extension of CAP**\n",
    "\n",
    "**PACELC**: An extension of CAP. In case of **P**artition (P), trade off between **A**vailability (A) and **C**onsistency (C); else (E), when there is no partition, trade off between **L**atency (L) and **C**onsistency (C).\n",
    "\n",
    "**Visualization**:\n",
    "```\n",
    "                    Network Partition?\n",
    "                    \u2502\n",
    "              \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "              \u2502 No        \u2502 Yes\n",
    "              \u25bc           \u25bc\n",
    "         Trade off    Trade off\n",
    "         Latency      Availability\n",
    "         vs           vs\n",
    "         Consistency  Consistency\n",
    "```\n",
    "\n",
    "**Examples**:\n",
    "```\n",
    "Scenario 1: No partition (normal operation)\n",
    "- Choose: Latency vs. Consistency\n",
    "- Option 1: Strong consistency (slower due to synchronous replication)\n",
    "- Option 2: Weak consistency (faster due to asynchronous replication)\n",
    "\n",
    "Scenario 2: Partition occurs\n",
    "- Choose: Availability vs. Consistency\n",
    "- Option 1: CP (reject writes to maintain consistency)\n",
    "- Option 2: AP (accept writes, eventual consistency)\n",
    "```\n",
    "\n",
    "**Real-World Systems**:\n",
    "\n",
    "**PostgreSQL (CP/EC)**:\n",
    "```sql\n",
    "-- Synchronous commit (strong consistency, higher latency)\n",
    "SET synchronous_commit = on;\n",
    "-- Result: Strong consistency, but higher latency (synchronous writes)\n",
    "\n",
    "-- Asynchronous commit (weak consistency, lower latency)\n",
    "SET synchronous_commit = off;\n",
    "-- Result: Lower latency, but risk of data loss if crash\n",
    "```\n",
    "\n",
    "**DynamoDB (AP/EL)**:\n",
    "```javascript\n",
    "// Strongly consistent read (higher latency, but latest data)\n",
    "const params = {\n",
    "  Key: { userId: '123' },\n",
    "  ConsistentRead: true  // Synchronous read (higher latency)\n",
    "};\n",
    "\n",
    "// Eventually consistent read (lower latency, but possibly stale data)\n",
    "const params = {\n",
    "  Key: { userId: '123' },\n",
    "  ConsistentRead: false  // Asynchronous read (lower latency)\n",
    "};\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Choosing CP or AP: Decision Framework**\n",
    "\n",
    "**Decision Framework**:\n",
    "```\n",
    "Question 1: Can your application tolerate inconsistent data?\n",
    "- No \u2192 CP (banking, financial transactions, inventory)\n",
    "- Yes \u2192 Question 2\n",
    "\n",
    "Question 2: How critical is availability?\n",
    "- Extremely critical \u2192 AP (social media, shopping carts, user profiles)\n",
    "- Moderately critical \u2192 Question 3\n",
    "\n",
    "Question 3: What's your primary concern?\n",
    "- Data accuracy \u2192 CP (analytics, reporting, inventory)\n",
    "- User experience \u2192 AP (news feeds, notifications, search)\n",
    "```\n",
    "\n",
    "**Real-World Examples**:\n",
    "\n",
    "**CP Use Cases**:\n",
    "- **Banking**: Account balances must be accurate\n",
    "- **Inventory**: Product counts must be accurate (no overselling)\n",
    "- **Payments**: Transaction records must be consistent\n",
    "- **Auctions**: Bids must be processed in order\n",
    "- **Authentication**: Login state must be consistent\n",
    "\n",
    "**AP Use Cases**:\n",
    "- **Social media feeds**: Better to show old posts than error\n",
    "- **Shopping carts**: Better to save cart than lose sale\n",
    "- **User profiles**: Better to show old profile than error\n",
    "- **Notifications**: Better to show old notifications than miss new ones\n",
    "- **Search results**: Better to show old results than error\n",
    "\n",
    "**Hybrid Approaches**:\n",
    "```python\n",
    "# Some data CP, some data AP (same application)\n",
    "# Banking app example:\n",
    "\n",
    "class BankService:\n",
    "    # Account balances: CP (consistency critical)\n",
    "    def get_balance(self, account_id):\n",
    "        # Strongly consistent read\n",
    "        return db_primary.query(\"SELECT balance FROM accounts WHERE id = ?\", account_id)\n",
    "    \n",
    "    def transfer(self, from_id, to_id, amount):\n",
    "        # Strongly consistent transaction\n",
    "        db_primary.begin_transaction()\n",
    "        db_primary.update(\"UPDATE accounts SET balance = balance - ? WHERE id = ?\", amount, from_id)\n",
    "        db_primary.update(\"UPDATE accounts SET balance = balance + ? WHERE id = ?\", amount, to_id)\n",
    "        db_primary.commit()\n",
    "    \n",
    "    # Transaction history: AP (availability critical)\n",
    "    def get_transaction_history(self, account_id):\n",
    "        # Eventually consistent read (from replica)\n",
    "        return db_replica.query(\"SELECT * FROM transactions WHERE account_id = ?\", account_id)\n",
    "    \n",
    "    # Notifications: AP (availability critical)\n",
    "    def send_notification(self, user_id, message):\n",
    "        # Write to queue (eventually consistent)\n",
    "        queue.publish({'user_id': user_id, 'message': message})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3.8 Key Takeaways**\n",
    "\n",
    "1. **Database choice is critical**: RDBMS for consistency and complex queries, NoSQL for scale and flexibility. Choose based on your requirements.\n",
    "\n",
    "2. **ACID guarantees come with trade-offs**: Strong consistency reduces availability and performance. Not all systems need ACID.\n",
    "\n",
    "3. **Indexing is performance**: Well-designed indexes can improve query performance 100-1,000x. But indexes slow writes and consume storage.\n",
    "\n",
    "4. **Scaling requires architectural changes**: Vertical scaling has limits; horizontal scaling (read replicas, sharding) requires application changes.\n",
    "\n",
    "5. **Sharding is complex**: Simple to understand, hard to implement correctly. Consider database services that handle sharding for you (DynamoDB, CockroachDB, Azure Cosmos DB).\n",
    "\n",
    "6. **CAP theorem is a decision framework**: Choose CP for data accuracy, AP for availability. Understand your requirements before choosing a database.\n",
    "\n",
    "7. **Hybrid approaches are common**: Many systems use CP for critical data and AP for non-critical data. Don't feel compelled to choose one for everything.\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "In this chapter, we explored databases\u2014the foundation of data persistence in system design. We started with relational databases, understanding ACID properties, schema design, indexing, and transactions.\n",
    "\n",
    "We then explored the NoSQL landscape, examining key-value stores, document databases, wide-column stores, and graph databases. Each has strengths for specific use cases.\n",
    "\n",
    "We covered database scaling strategies, from vertical scaling to horizontal scaling, read replicas, connection pooling, and sharding. We understood that scaling introduces complexity but is necessary for high-traffic systems.\n",
    "\n",
    "Finally, we deep-dived into the CAP theorem, understanding the trade-offs between consistency and availability in distributed systems, and how to choose between CP and AP based on application requirements.\n",
    "\n",
    "**Coming up next**: In Chapter 4, we'll explore Caching\u2014Speed at Scale. We'll cover caching patterns, eviction policies, distributed caching, CDNs, and cache consistency strategies.\n",
    "\n",
    "---\n",
    "\n",
    "**Exercises**:\n",
    "\n",
    "1. **Database Selection**: For each scenario, recommend a database (RDBMS or NoSQL) and explain why:\n",
    "   - A banking application processing financial transactions\n",
    "   - A social media platform storing user posts and comments\n",
    "   - An IoT platform collecting sensor readings from millions of devices\n",
    "   - A fraud detection system analyzing transaction patterns\n",
    "\n",
    "2. **Index Design**: For this schema, design indexes for these queries:\n",
    "```sql\n",
    "CREATE TABLE orders (\n",
    "    order_id INT PRIMARY KEY,\n",
    "    customer_id INT,\n",
    "    product_id INT,\n",
    "    order_date DATE,\n",
    "    amount DECIMAL(10, 2),\n",
    "    status VARCHAR(20)\n",
    ");\n",
    "\n",
    "-- Queries:\n",
    "-- a. Get all orders for a customer\n",
    "-- b. Get all orders in a date range\n",
    "-- c. Get all pending orders for a customer\n",
    "-- d. Get total amount spent by a customer\n",
    "```\n",
    "\n",
    "3. **Sharding Strategy**: You're building a messaging app with 100 million users. Each user has 10,000 messages on average. Design a sharding strategy:\n",
    "   - What sharding key would you use? Why?\n",
    "   - How many shards would you start with?\n",
    "   - How would you handle cross-shard queries (e.g., search all messages containing a keyword)?\n",
    "\n",
    "4. **CAP Analysis**: For each system, would you choose CP or AP? Why?\n",
    "   - A stock trading platform\n",
    "   - A social media news feed\n",
    "   - A collaborative document editor (Google Docs-style)\n",
    "   - A multiplayer game leaderboard\n",
    "\n",
    "5. **Read Replica Strategy**: You have an application with 20,000 QPS (90% reads). Each database server can handle 5,000 QPS. How many read replicas do you need? How would you handle replication lag?\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='../1. Foundations_and_prerequisites/2. prerequisites_and_core_concepts.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='4. caching.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}