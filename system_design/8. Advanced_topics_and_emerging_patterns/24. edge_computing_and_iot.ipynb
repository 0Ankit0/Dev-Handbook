{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ae42c2",
   "metadata": {},
   "source": [
    "# **Chapter 24: Edge Computing & IoT**\n",
    "\n",
    "The Internet of Things (IoT) transforms everyday objects into data-generating endpoints\u2014from smart thermostats and fitness trackers to industrial sensors and autonomous vehicles. Unlike traditional cloud computing where data travels to centralized data centers, edge computing processes data near its source. This chapter explores architectures for handling millions of devices, intermittent connectivity, and the unique challenges of distributed computing at the network edge.\n",
    "\n",
    "---\n",
    "\n",
    "## **24.1 Edge Architecture Patterns**\n",
    "\n",
    "Edge computing sits between devices and the cloud, reducing latency, bandwidth costs, and dependency on constant connectivity. The architecture you choose depends on your latency requirements, compute constraints, and data privacy needs.\n",
    "\n",
    "### **The Three-Tier Architecture**\n",
    "\n",
    "Most IoT systems use a three-layer approach:\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    Cloud Layer                               \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n",
    "\u2502  \u2502 Data Lake\u2502  \u2502  ML      \u2502  \u2502 Business \u2502  \u2502 Device   \u2502    \u2502\n",
    "\u2502  \u2502 (S3)     \u2502  \u2502 Training \u2502  \u2502 Logic    \u2502  \u2502 Management\u2502   \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                              \u2191\n",
    "                              \u2502 Internet\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    Edge Layer (Fog)                          \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n",
    "\u2502  \u2502 Local    \u2502  \u2502 Stream   \u2502  \u2502 Device   \u2502  \u2502  Cache   \u2502    \u2502\n",
    "\u2502  \u2502  DB      \u2502  \u2502 Processing\u2502 \u2502  Gateway \u2502  \u2502          \u2502    \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n",
    "\u2502         Raspberry Pi / Industrial PC / AWS Greengrass       \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                              \u2191\n",
    "                              \u2502 Local Network (WiFi/Bluetooth/LoRa)\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    Device Layer                              \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n",
    "\u2502  \u2502 Sensors  \u2502  \u2502 Actuators\u2502  \u2502 Cameras  \u2502  \u2502  Micro-  \u2502    \u2502\n",
    "\u2502  \u2502 (Temp)   \u2502  \u2502 (Valves) \u2502  \u2502          \u2502  \u2502 controllers\u2502  \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n",
    "\u2502              Arduino / ESP32 / Raspberry Pi Pico            \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**Data Flow**:\n",
    "1. **Device Layer**: Collects raw data (temperature readings, motion detection)\n",
    "2. **Edge Layer**: Aggregates, filters, and processes locally (average temperature over 5 minutes, trigger local alarms)\n",
    "3. **Cloud Layer**: Long-term storage, machine learning, global dashboards\n",
    "\n",
    "**Example: Smart Factory**\n",
    "```\n",
    "Machine Sensors (1000 devices):\n",
    "  \u2193 Every 100ms (10 readings/second per device)\n",
    "Edge Gateway:\n",
    "  \u2193 Aggregate to 1 reading/second (90% data reduction)\n",
    "  \u2193 Detect anomalies locally (emergency stop in <10ms)\n",
    "  \u2193 Send hourly summaries to cloud\n",
    "Cloud:\n",
    "  \u2193 Predictive maintenance ML models\n",
    "  \u2193 Global efficiency dashboards\n",
    "```\n",
    "\n",
    "### **Edge Computing Patterns**\n",
    "\n",
    "**Pattern 1: Local Processing with Cloud Sync**\n",
    "```python\n",
    "# Edge device code (Raspberry Pi)\n",
    "class LocalProcessor:\n",
    "    def __init__(self):\n",
    "        self.local_buffer = []\n",
    "        self.last_cloud_sync = time.time()\n",
    "        self.anomaly_model = load_tflite_model()  # Lightweight ML\n",
    "    \n",
    "    def process_sensor_data(self, reading):\n",
    "        # Immediate local action (no cloud latency)\n",
    "        if self.detect_anomaly(reading):\n",
    "            self.trigger_alarm()  # < 10ms response\n",
    "        \n",
    "        # Buffer for batch upload\n",
    "        self.local_buffer.append({\n",
    "            'timestamp': time.time(),\n",
    "            'value': reading,\n",
    "            'device_id': self.device_id\n",
    "        })\n",
    "        \n",
    "        # Sync to cloud every 5 minutes or when buffer full\n",
    "        if (time.time() - self.last_cloud_sync > 300 or \n",
    "            len(self.local_buffer) > 1000):\n",
    "            self.sync_to_cloud()\n",
    "    \n",
    "    def detect_anomaly(self, reading):\n",
    "        # Run inference locally using TensorFlow Lite\n",
    "        prediction = self.anomaly_model.predict([reading])\n",
    "        return prediction[0] > 0.95  # 95% confidence threshold\n",
    "    \n",
    "    def sync_to_cloud(self):\n",
    "        try:\n",
    "            requests.post('https://api.cloud.com/metrics', \n",
    "                         json=self.local_buffer)\n",
    "            self.local_buffer = []  # Clear on success\n",
    "            self.last_cloud_sync = time.time()\n",
    "        except requests.exceptions.RequestException:\n",
    "            # Keep data if offline, retry later\n",
    "            pass  # Buffer persists for next attempt\n",
    "```\n",
    "\n",
    "**Pattern 2: Function as a Service at the Edge**\n",
    "AWS Greengrass and Azure IoT Edge allow you to deploy Lambda functions to edge devices:\n",
    "\n",
    "```python\n",
    "# AWS Lambda function deployed to edge gateway\n",
    "import greengrasssdk\n",
    "import json\n",
    "\n",
    "client = greengrasssdk.client('iot-data')\n",
    "\n",
    "def function_handler(event, context):\n",
    "    \"\"\"\n",
    "    Triggered when temperature exceeds threshold\n",
    "    Runs locally on edge device, not in AWS cloud\n",
    "    \"\"\"\n",
    "    temperature = event['temperature']\n",
    "    device_id = event['device_id']\n",
    "    \n",
    "    # Local decision (no internet required)\n",
    "    if temperature > 100:  # Celsius\n",
    "        # Trigger local actuator immediately\n",
    "        client.publish(\n",
    "            topic=f'actuators/{device_id}/cooling',\n",
    "            payload=json.dumps({'action': 'activate', 'duration': 60})\n",
    "        )\n",
    "        \n",
    "        # Also notify cloud for logging\n",
    "        client.publish(\n",
    "            topic='cloud/alerts',\n",
    "            payload=json.dumps({\n",
    "                'severity': 'high',\n",
    "                'message': f'Overheating detected on {device_id}',\n",
    "                'timestamp': context.timestamp\n",
    "            })\n",
    "        )\n",
    "    \n",
    "    return {'status': 'processed_locally'}\n",
    "```\n",
    "\n",
    "**Pattern 3: Stream Processing at the Edge**\n",
    "Apache Flink and Kafka can run on edge devices to process data streams before sending to cloud:\n",
    "\n",
    "```python\n",
    "# Edge stream processing with Kafka Streams\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "import json\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    'sensor-raw-data',\n",
    "    bootstrap_servers=['localhost:9092'],  # Local edge broker\n",
    "    value_deserializer=lambda m: json.loads(m.decode('utf-8'))\n",
    ")\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['cloud-kafka.example.com:9092'],\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    ")\n",
    "\n",
    "# Process locally, send aggregates to cloud\n",
    "windowed_data = {}\n",
    "\n",
    "for message in consumer:\n",
    "    sensor_id = message.value['sensor_id']\n",
    "    timestamp = message.value['timestamp']\n",
    "    value = message.value['value']\n",
    "    \n",
    "    # 1-minute tumbling window\n",
    "    window_key = (sensor_id, timestamp // 60)\n",
    "    \n",
    "    if window_key not in windowed_data:\n",
    "        windowed_data[window_key] = []\n",
    "    \n",
    "    windowed_data[window_key].append(value)\n",
    "    \n",
    "    # When window complete, compute statistics\n",
    "    if len(windowed_data[window_key]) >= 60:  # 1 minute of data\n",
    "        stats = {\n",
    "            'sensor_id': sensor_id,\n",
    "            'window_start': window_key[1] * 60,\n",
    "            'avg': sum(windowed_data[window_key]) / 60,\n",
    "            'max': max(windowed_data[window_key]),\n",
    "            'min': min(windowed_data[window_key]),\n",
    "            'sample_count': 60\n",
    "        }\n",
    "        \n",
    "        # Send only summary to cloud (99% bandwidth reduction)\n",
    "        producer.send('sensor-aggregates', stats)\n",
    "        del windowed_data[window_key]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **24.2 IoT Protocols: MQTT, CoAP, and LoRaWAN**\n",
    "\n",
    "IoT devices have constrained resources (battery, bandwidth, CPU) and use specialized protocols optimized for these constraints.\n",
    "\n",
    "### **MQTT: The Standard for IoT Messaging**\n",
    "\n",
    "**MQTT (Message Queuing Telemetry Transport)** is a lightweight publish-subscribe protocol designed for unreliable networks and low-power devices.\n",
    "\n",
    "**Key Concepts**:\n",
    "- **Broker**: Central server that receives all messages and routes them to subscribers\n",
    "- **Topic**: Hierarchical string (e.g., `factory/line1/machine3/temperature`)\n",
    "- **QoS Levels**: Quality of Service guarantees\n",
    "  - QoS 0: At most once (fire and forget)\n",
    "  - QoS 1: At least once (acknowledged, may duplicate)\n",
    "  - QoS 2: Exactly once (two-phase handshake, highest overhead)\n",
    "\n",
    "**Topic Hierarchy Best Practices**:\n",
    "```\n",
    "Level 1: Building/Floor      factory/line1/\n",
    "Level 2: Zone/Line                  machine3/\n",
    "Level 3: Device                        sensor/\n",
    "Level 4: Measurement                      temperature\n",
    "\n",
    "Full topic: factory/line1/machine3/sensor/temperature\n",
    "Wildcards:\n",
    "  - factory/+/machine3/#  (All floors, machine3, all sensors)\n",
    "  - factory/line1/+/+/temperature  (All machines on line1, temp only)\n",
    "```\n",
    "\n",
    "**Python Implementation** (Paho-MQTT):\n",
    "```python\n",
    "import paho.mqtt.client as mqtt\n",
    "import json\n",
    "import time\n",
    "\n",
    "class IoTDevice:\n",
    "    def __init__(self, device_id, broker_host):\n",
    "        self.device_id = device_id\n",
    "        self.client = mqtt.Client(client_id=device_id)\n",
    "        self.client.on_connect = self.on_connect\n",
    "        self.client.on_message = self.on_command\n",
    "        \n",
    "        # Enable TLS for security\n",
    "        self.client.tls_set(ca_certs=\"ca.crt\")\n",
    "        self.client.username_pw_set(\"device\", \"password\")\n",
    "        \n",
    "        self.client.connect(broker_host, 8883, 60)\n",
    "    \n",
    "    def on_connect(self, client, userdata, flags, rc):\n",
    "        print(f\"Connected with result code {rc}\")\n",
    "        # Subscribe to commands for this specific device\n",
    "        client.subscribe(f\"commands/{self.device_id}/#\")\n",
    "    \n",
    "    def on_command(self, client, userdata, msg):\n",
    "        \"\"\"Handle incoming commands from cloud\"\"\"\n",
    "        payload = json.loads(msg.payload)\n",
    "        command = payload.get('command')\n",
    "        \n",
    "        if command == 'reboot':\n",
    "            self.reboot()\n",
    "        elif command == 'update_config':\n",
    "            self.update_config(payload['config'])\n",
    "        elif command == 'calibrate':\n",
    "            self.calibrate_sensor()\n",
    "    \n",
    "    def publish_telemetry(self, temperature, humidity):\n",
    "        payload = {\n",
    "            'device_id': self.device_id,\n",
    "            'timestamp': time.time(),\n",
    "            'temperature': temperature,\n",
    "            'humidity': humidity,\n",
    "            'battery': self.get_battery_level()\n",
    "        }\n",
    "        \n",
    "        # QoS 1: Ensure delivery, allow duplicates\n",
    "        self.client.publish(\n",
    "            f\"telemetry/{self.device_id}\",\n",
    "            json.dumps(payload),\n",
    "            qos=1,\n",
    "            retain=False  # Don't retain last message\n",
    "        )\n",
    "    \n",
    "    def run(self):\n",
    "        self.client.loop_start()\n",
    "        while True:\n",
    "            temp, hum = self.read_sensors()\n",
    "            self.publish_telemetry(temp, hum)\n",
    "            time.sleep(60)  # Send every minute\n",
    "\n",
    "# Usage\n",
    "device = IoTDevice(\"sensor_001\", \"mqtt.example.com\")\n",
    "device.run()\n",
    "```\n",
    "\n",
    "**MQTT Broker Comparison**:\n",
    "```\n",
    "Broker        Best For                  Max Connections  Performance\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "Mosquitto     Small deployments         10,000+          100k msg/sec\n",
    "EMQ X         Enterprise/Cloud          1M+              5M msg/sec\n",
    "HiveMQ        Enterprise with SLA       10M+             10M msg/sec\n",
    "AWS IoT Core  AWS integration           Unlimited        Pay per message\n",
    "Azure IoT Hub Azure integration         Unlimited        Pay per message\n",
    "```\n",
    "\n",
    "### **CoAP: REST for IoT**\n",
    "\n",
    "**CoAP (Constrained Application Protocol)** is like HTTP but optimized for UDP and constrained devices (sensors with 100KB RAM).\n",
    "\n",
    "**Comparison with HTTP**:\n",
    "```\n",
    "HTTP:  GET /api/temperature HTTP/1.1\n",
    "        Host: sensor.example.com\n",
    "        Accept: application/json\n",
    "        [Headers: ~200 bytes]\n",
    "        \n",
    "CoAP:  CON GET /temperature\n",
    "        [4 bytes header + 1 byte token]\n",
    "        \n",
    "Overhead reduction: 98%\n",
    "```\n",
    "\n",
    "**CoAP Features**:\n",
    "- **UDP based**: No connection overhead (unlike TCP)\n",
    "- **Observe pattern**: Subscribe to resources (like MQTT topics)\n",
    "- **Block-wise transfer**: Send large data in chunks for memory-constrained devices\n",
    "\n",
    "**Python Example** (Aiocoap):\n",
    "```python\n",
    "import asyncio\n",
    "from aiocoap import Context, Message\n",
    "from aiocoap.resource import Resource, Site\n",
    "\n",
    "class TemperatureResource(Resource):\n",
    "    async def render_get(self, request):\n",
    "        temp = read_temperature_sensor()\n",
    "        payload = json.dumps({'temperature': temp}).encode('utf-8')\n",
    "        \n",
    "        return Message(\n",
    "            payload=payload,\n",
    "            content_format=50  # application/json\n",
    "        )\n",
    "    \n",
    "    async def render_put(self, request):\n",
    "        # Update configuration\n",
    "        config = json.loads(request.payload)\n",
    "        update_device_config(config)\n",
    "        return Message(code=CHANGED)\n",
    "\n",
    "# Server setup\n",
    "root = Site()\n",
    "root.add_resource(['temperature'], TemperatureResource())\n",
    "\n",
    "asyncio.Task(Context.create_server_context(root))\n",
    "asyncio.get_event_loop().run_forever()\n",
    "\n",
    "# Client usage\n",
    "async def get_temperature():\n",
    "    protocol = await Context.create_client_context()\n",
    "    request = Message(code=GET, uri='coap://sensor.local/temperature')\n",
    "    response = await protocol.request(request).response\n",
    "    return json.loads(response.payload)\n",
    "```\n",
    "\n",
    "### **LoRaWAN: Long Range, Low Power**\n",
    "\n",
    "For devices kilometers away from infrastructure (agriculture sensors, smart meters), LoRaWAN provides:\n",
    "- **Range**: 2-15 km (urban to rural)\n",
    "- **Power**: 10-year battery life\n",
    "- **Data rate**: 0.3-50 kbps (not for video, perfect for telemetry)\n",
    "\n",
    "**Architecture**:\n",
    "```\n",
    "End Device (Sensor) \u2192 Gateway \u2192 Network Server \u2192 Application Server\n",
    "     \u2191                      \u2193           \u2193                \u2193\n",
    "  Sends every          Receives all  Manages        Your code\n",
    "  10 minutes           local traffic join process   (AWS IoT)\n",
    "  (low power)          forwards to                  processes data\n",
    "                       internet\n",
    "```\n",
    "\n",
    "**Duty Cycle Limitations**:\n",
    "LoRaWAN regulations limit how often devices can transmit (1% duty cycle in Europe). If your message takes 1 second to send, you must wait 99 seconds before sending again.\n",
    "\n",
    "**Adaptive Data Rate (ADR)**:\n",
    "```python\n",
    "class LoRaDevice:\n",
    "    def __init__(self):\n",
    "        self.spreading_factor = 7  # 7-12 (higher = longer range, slower)\n",
    "        self.tx_power = 14         # dBm\n",
    "    \n",
    "    def optimize_for_conditions(self, snr):\n",
    "        \"\"\"\n",
    "        ADR: Adjust data rate based on signal quality\n",
    "        High SNR (good signal): Lower spreading factor (faster, less power)\n",
    "        Low SNR (weak signal): Higher spreading factor (slower, more range)\n",
    "        \"\"\"\n",
    "        if snr > 10:\n",
    "            self.spreading_factor = max(7, self.spreading_factor - 1)\n",
    "        elif snr < -10:\n",
    "            self.spreading_factor = min(12, self.spreading_factor + 1)\n",
    "        \n",
    "        # Higher spreading factor = lower data rate\n",
    "        # SF7: ~5.5 kbps, SF12: ~0.25 kbps\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **24.3 Time-Series Databases**\n",
    "\n",
    "IoT devices generate time-stamped data: temperature every minute, vibration every millisecond, GPS every second. Traditional relational databases struggle with high ingestion rates and time-based queries. Time-series databases (TSDB) are optimized for this workload.\n",
    "\n",
    "### **InfluxDB: The Purpose-Built TSDB**\n",
    "\n",
    "**Data Model**:\n",
    "```\n",
    "Measurement: temperature\n",
    "Tags (indexed): location=factory1, machine=compressor_a, sensor_id=temp_01\n",
    "Fields (data): value=75.5, unit=celsius\n",
    "Timestamp: 2024-01-15T10:30:00Z\n",
    "```\n",
    "\n",
    "**Key Optimizations**:\n",
    "1. **High write throughput**: 1M+ points/second on single node\n",
    "2. **Compression**: 10:1 ratio vs. CSV (gorilla compression for floats)\n",
    "3. **Retention policies**: Auto-delete old data or downsample\n",
    "\n",
    "**Code Example**:\n",
    "```python\n",
    "from influxdb_client import InfluxDBClient, Point\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "\n",
    "client = InfluxDBClient(\n",
    "    url=\"http://localhost:8086\",\n",
    "    token=\"my-token\",\n",
    "    org=\"my-org\"\n",
    ")\n",
    "\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "\n",
    "# Write sensor data\n",
    "point = Point(\"temperature\") \\\n",
    "    .tag(\"location\", \"factory1\") \\\n",
    "    .tag(\"machine\", \"compressor_a\") \\\n",
    "    .field(\"value\", 75.5) \\\n",
    "    .field(\"unit\", \"celsius\") \\\n",
    "    .time(datetime.utcnow())\n",
    "\n",
    "write_api.write(bucket=\"sensors\", record=point)\n",
    "\n",
    "# Query with time range and aggregation\n",
    "query_api = client.query_api()\n",
    "query = '''\n",
    "    from(bucket: \"sensors\")\n",
    "        |> range(start: -1h)                    // Last hour\n",
    "        |> filter(fn: (r) => r._measurement == \"temperature\")\n",
    "        |> filter(fn: (r) => r.machine == \"compressor_a\")\n",
    "        |> aggregateWindow(every: 5m, fn: mean) // 5-minute averages\n",
    "        |> yield(name: \"mean\")\n",
    "'''\n",
    "\n",
    "tables = query_api.query(query)\n",
    "for table in tables:\n",
    "    for record in table.records:\n",
    "        print(f\"Time: {record.get_time()}, Temp: {record.get_value()}\")\n",
    "\n",
    "# Continuous Query: Downsample raw data to hourly averages\n",
    "downsample_query = '''\n",
    "    option task = {\n",
    "        name: \"downsample_temperature\",\n",
    "        every: 1h,\n",
    "    }\n",
    "\n",
    "    from(bucket: \"sensors_raw\")\n",
    "        |> range(start: -task.every)\n",
    "        |> filter(fn: (r) => r._measurement == \"temperature\")\n",
    "        |> aggregateWindow(every: 1h, fn: mean)\n",
    "        |> to(bucket: \"sensors_hourly\")\n",
    "'''\n",
    "```\n",
    "\n",
    "### **TimescaleDB: PostgreSQL for Time-Series**\n",
    "\n",
    "If you already use PostgreSQL, TimescaleDB adds time-series capabilities as an extension.\n",
    "\n",
    "**Hypertables**: Automatically partition data by time:\n",
    "```sql\n",
    "-- Convert regular table to hypertable\n",
    "CREATE TABLE sensor_data (\n",
    "    time TIMESTAMPTZ NOT NULL,\n",
    "    device_id TEXT,\n",
    "    temperature DOUBLE PRECISION,\n",
    "    humidity DOUBLE PRECISION\n",
    ");\n",
    "\n",
    "-- Partition by time (chunks of 1 day)\n",
    "SELECT create_hypertable('sensor_data', 'time', chunk_time_interval => INTERVAL '1 day');\n",
    "\n",
    "-- Automatic partitioning:\n",
    "-- Chunk 1: Jan 1-2, Chunk 2: Jan 2-3, etc.\n",
    "-- Old chunks auto-compressed, recent chunks fast for writes\n",
    "```\n",
    "\n",
    "**Continuous Aggregation** (like materialized views for time-series):\n",
    "```sql\n",
    "-- Create 1-hour rollups for dashboard queries\n",
    "CREATE MATERIALIZED VIEW sensor_hourly\n",
    "WITH (timescaledb.continuous) AS\n",
    "SELECT\n",
    "    time_bucket('1 hour', time) AS bucket,\n",
    "    device_id,\n",
    "    AVG(temperature) as avg_temp,\n",
    "    MAX(temperature) as max_temp,\n",
    "    MIN(temperature) as min_temp,\n",
    "    COUNT(*) as sample_count\n",
    "FROM sensor_data\n",
    "GROUP BY bucket, device_id;\n",
    "\n",
    "-- Auto-refresh every hour\n",
    "SELECT add_continuous_aggregate_policy('sensor_hourly',\n",
    "    start_offset => INTERVAL '1 month',\n",
    "    end_offset => INTERVAL '1 hour',\n",
    "    schedule_interval => INTERVAL '1 hour'\n",
    ");\n",
    "```\n",
    "\n",
    "**Query Performance**:\n",
    "```sql\n",
    "-- Fast time-range queries (uses chunk exclusion)\n",
    "SELECT * FROM sensor_data \n",
    "WHERE time > NOW() - INTERVAL '1 hour'\n",
    "  AND device_id = 'sensor_001';\n",
    "\n",
    "-- EXPLAIN shows only recent chunks scanned, not entire table\n",
    "```\n",
    "\n",
    "### **Choosing Your TSDB**\n",
    "\n",
    "```\n",
    "Database       Best For                SQL Support  Scaling        Compression\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "InfluxDB       Pure IoT/Monitoring     Flux (custom)  Clustering      High\n",
    "TimescaleDB    Existing Postgres       Full SQL       Partitioning    Medium\n",
    "Prometheus     Metrics/Monitoring      PromQL         Federation      High\n",
    "OpenTSDB       Hadoop ecosystem        Yes            HBase-based     Medium\n",
    "QuestDB        Fast SQL analytics      Full SQL       Horizontal      Medium\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **24.4 Offline-First Architecture and Data Synchronization**\n",
    "\n",
    "IoT devices lose connectivity. Ships at sea, sensors in tunnels, devices in rural areas\u2014they must continue working offline and sync when connection returns.\n",
    "\n",
    "### **The CAP Theorem at the Edge**\n",
    "\n",
    "Like distributed systems, edge devices face CAP constraints:\n",
    "- **Consistency**: All copies of data are the same\n",
    "- **Availability**: Device works offline\n",
    "- **Partition tolerance**: Network failures inevitable\n",
    "\n",
    "**Edge Choice**: Prioritize **Availability** (offline operation) and **Partition tolerance**, accept **Eventual Consistency**.\n",
    "\n",
    "### **Conflict-Free Replicated Data Types (CRDTs)**\n",
    "\n",
    "CRDTs are data structures that can be modified independently on different devices and merged automatically without conflicts.\n",
    "\n",
    "**Example: G-Counter (Grow-only Counter)**\n",
    "```python\n",
    "class GCounter:\n",
    "    \"\"\"Increment-only counter that merges correctly\"\"\"\n",
    "    def __init__(self, device_id):\n",
    "        self.device_id = device_id\n",
    "        self.payload = {device_id: 0}  # Each device tracks own count\n",
    "    \n",
    "    def increment(self):\n",
    "        self.payload[self.device_id] += 1\n",
    "    \n",
    "    def value(self):\n",
    "        return sum(self.payload.values())\n",
    "    \n",
    "    def merge(self, other):\n",
    "        \"\"\"Merge another device's counter\"\"\"\n",
    "        for device, count in other.payload.items():\n",
    "            self.payload[device] = max(\n",
    "                self.payload.get(device, 0),\n",
    "                count\n",
    "            )\n",
    "\n",
    "# Device A counts 5 events offline\n",
    "device_a = GCounter(\"A\")\n",
    "for _ in range(5):\n",
    "    device_a.increment()\n",
    "\n",
    "# Device B counts 3 events offline  \n",
    "device_b = GCounter(\"B\")\n",
    "for _ in range(3):\n",
    "    device_b.increment()\n",
    "\n",
    "# Later, they sync\n",
    "device_a.merge(device_b)\n",
    "print(device_a.value())  # 8 (correct, no conflicts)\n",
    "```\n",
    "\n",
    "**Example: LWW-Element-Set (Last-Write-Wins Set)**\n",
    "```python\n",
    "class LWWSet:\n",
    "    \"\"\"Set with add/remove timestamps. Last operation wins.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.add_set = {}  # {element: timestamp}\n",
    "        self.remove_set = {}  # {element: timestamp}\n",
    "    \n",
    "    def add(self, element, timestamp):\n",
    "        self.add_set[element] = max(\n",
    "            self.add_set.get(element, 0),\n",
    "            timestamp\n",
    "        )\n",
    "    \n",
    "    def remove(self, element, timestamp):\n",
    "        self.remove_set[element] = max(\n",
    "            self.remove_set.get(element, 0),\n",
    "            timestamp\n",
    "        )\n",
    "    \n",
    "    def contains(self, element):\n",
    "        add_time = self.add_set.get(element, 0)\n",
    "        remove_time = self.remove_set.get(element, 0)\n",
    "        return add_time > remove_time  # Added after last removal\n",
    "    \n",
    "    def merge(self, other):\n",
    "        for elem, ts in other.add_set.items():\n",
    "            self.add(elem, ts)\n",
    "        for elem, ts in other.remove_set.items():\n",
    "            self.remove(elem, ts)\n",
    "```\n",
    "\n",
    "### **Delta Sync Protocols**\n",
    "\n",
    "Instead of sending entire datasets, send only changes (deltas).\n",
    "\n",
    "**Operational Transformation (like Google Docs)**:\n",
    "```python\n",
    "class DocumentSync:\n",
    "    def __init__(self):\n",
    "        self.operations = []  # Log of all changes\n",
    "        self.version = 0\n",
    "    \n",
    "    def local_change(self, operation):\n",
    "        \"\"\"User makes a change offline\"\"\"\n",
    "        operation['timestamp'] = time.time()\n",
    "        operation['version'] = self.version\n",
    "        self.operations.append(operation)\n",
    "        self.apply_operation(operation)\n",
    "        self.version += 1\n",
    "    \n",
    "    def sync_with_server(self):\n",
    "        \"\"\"When online, send pending operations\"\"\"\n",
    "        unsynced = [op for op in self.operations if not op.get('synced')]\n",
    "        \n",
    "        if not unsynced:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            response = requests.post('/api/sync', json={\n",
    "                'device_id': self.device_id,\n",
    "                'base_version': self.last_synced_version,\n",
    "                'operations': unsynced\n",
    "            })\n",
    "            \n",
    "            server_operations = response.json()['operations']\n",
    "            \n",
    "            # Transform server operations against local pending ones\n",
    "            for server_op in server_operations:\n",
    "                self.transform_against_pending(server_op)\n",
    "                self.apply_operation(server_op)\n",
    "            \n",
    "            # Mark local as synced\n",
    "            for op in unsynced:\n",
    "                op['synced'] = True\n",
    "            \n",
    "            self.last_synced_version = response.json()['new_version']\n",
    "            \n",
    "        except requests.exceptions.RequestException:\n",
    "            # Stay offline, retry later\n",
    "            pass\n",
    "    \n",
    "    def transform_against_pending(self, server_op):\n",
    "        \"\"\"Adjust server operation to account for local pending changes\"\"\"\n",
    "        # If server says \"insert 'x' at position 5\" \n",
    "        # but locally we inserted 2 chars at position 3\n",
    "        # Transform to \"insert 'x' at position 7\"\n",
    "        for local_op in self.pending_operations():\n",
    "            server_op = transform(server_op, local_op)\n",
    "        return server_op\n",
    "```\n",
    "\n",
    "### **Store-and-Forward Queues**\n",
    "\n",
    "For devices that are intermittently connected (delivery drones, agricultural sensors):\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "import json\n",
    "\n",
    "class PersistentQueue:\n",
    "    \"\"\"SQLite-backed queue for offline message buffering\"\"\"\n",
    "    def __init__(self, db_path):\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self._create_table()\n",
    "    \n",
    "    def _create_table(self):\n",
    "        self.conn.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS messages (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                topic TEXT NOT NULL,\n",
    "                payload TEXT NOT NULL,\n",
    "                qos INTEGER DEFAULT 1,\n",
    "                timestamp REAL NOT NULL,\n",
    "                retry_count INTEGER DEFAULT 0\n",
    "            )\n",
    "        ''')\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def enqueue(self, topic, payload, qos=1):\n",
    "        \"\"\"Store message for later transmission\"\"\"\n",
    "        self.conn.execute(\n",
    "            'INSERT INTO messages (topic, payload, qos, timestamp) VALUES (?, ?, ?, ?)',\n",
    "            (topic, json.dumps(payload), qos, time.time())\n",
    "        )\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def dequeue_for_sync(self, batch_size=100):\n",
    "        \"\"\"Get messages to send when online\"\"\"\n",
    "        cursor = self.conn.execute(\n",
    "            'SELECT id, topic, payload, qos FROM messages ORDER BY timestamp LIMIT ?',\n",
    "            (batch_size,)\n",
    "        )\n",
    "        return cursor.fetchall()\n",
    "    \n",
    "    def ack(self, message_id):\n",
    "        \"\"\"Remove successfully sent message\"\"\"\n",
    "        self.conn.execute('DELETE FROM messages WHERE id = ?', (message_id,))\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def retry_later(self, message_id):\n",
    "        \"\"\"Increment retry count, will be retried on next sync\"\"\"\n",
    "        self.conn.execute(\n",
    "            'UPDATE messages SET retry_count = retry_count + 1 WHERE id = ?',\n",
    "            (message_id,)\n",
    "        )\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def size(self):\n",
    "        \"\"\"Number of pending messages\"\"\"\n",
    "        cursor = self.conn.execute('SELECT COUNT(*) FROM messages')\n",
    "        return cursor.fetchone()[0]\n",
    "\n",
    "# Usage in device\n",
    "queue = PersistentQueue('/data/messages.db')\n",
    "\n",
    "def publish_sensor_data(data):\n",
    "    if is_online():\n",
    "        mqtt_client.publish('sensors/data', data)\n",
    "    else:\n",
    "        queue.enqueue('sensors/data', data)\n",
    "        print(f\"Buffered message. Queue size: {queue.size()}\")\n",
    "\n",
    "def sync_when_online():\n",
    "    if not is_online():\n",
    "        return\n",
    "    \n",
    "    messages = queue.dequeue_for_sync()\n",
    "    for msg_id, topic, payload, qos in messages:\n",
    "        try:\n",
    "            mqtt_client.publish(topic, json.loads(payload), qos=qos)\n",
    "            queue.ack(msg_id)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to send {msg_id}, will retry\")\n",
    "            queue.retry_later(msg_id)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **24.5 Security at the Edge**\n",
    "\n",
    "Edge devices are physically accessible and often deployed in insecure locations. Security requires defense in depth.\n",
    "\n",
    "### **Device Identity and Attestation**\n",
    "\n",
    "Each device needs a unique identity, established during manufacturing:\n",
    "\n",
    "```python\n",
    "import hashlib\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "from cryptography.hazmat.primitives.asymmetric import rsa, padding\n",
    "\n",
    "class SecureDevice:\n",
    "    def __init__(self):\n",
    "        # Generated during manufacturing, stored in secure element (TPM)\n",
    "        self.private_key = load_from_secure_element()\n",
    "        self.device_cert = load_certificate()\n",
    "        self.ca_cert = load_ca_certificate()\n",
    "    \n",
    "    def generate_session_token(self, challenge):\n",
    "        \"\"\"Prove identity to server using private key\"\"\"\n",
    "        signature = self.private_key.sign(\n",
    "            challenge.encode(),\n",
    "            padding.PSS(mgf=padding.MGF1(hashes.SHA256()), salt_length=padding.PSS.MAX_LENGTH),\n",
    "            hashes.SHA256()\n",
    "        )\n",
    "        return {\n",
    "            'device_id': self.get_device_id(),\n",
    "            'certificate': self.device_cert,\n",
    "            'signature': signature.hex()\n",
    "        }\n",
    "    \n",
    "    def verify_server(self, server_cert):\n",
    "        \"\"\"Verify server certificate against CA\"\"\"\n",
    "        try:\n",
    "            server_cert.verify_directly_issued_by(self.ca_cert)\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False  # Possible man-in-the-middle attack\n",
    "```\n",
    "\n",
    "### **Over-the-Air (OTA) Updates**\n",
    "\n",
    "Secure firmware updates are critical but dangerous\u2014bricked devices in remote locations are expensive to fix.\n",
    "\n",
    "**Safe Update Process**:\n",
    "```python\n",
    "class OTAUpdater:\n",
    "    def __init__(self):\n",
    "        self.current_version = read_current_version()\n",
    "        self.update_partition = '/dev/mmcblk0p2'  # A/B partitioning\n",
    "    \n",
    "    def check_for_update(self):\n",
    "        \"\"\"Poll for updates when bandwidth available\"\"\"\n",
    "        try:\n",
    "            metadata = requests.get('https://updates.example.com/latest').json()\n",
    "            \n",
    "            if metadata['version'] > self.current_version:\n",
    "                self.download_update(metadata)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Update check failed: {e}\")\n",
    "    \n",
    "    def download_update(self, metadata):\n",
    "        \"\"\"Download to inactive partition\"\"\"\n",
    "        # Verify signature before writing\n",
    "        firmware = download(metadata['url'])\n",
    "        \n",
    "        expected_hash = metadata['sha256']\n",
    "        actual_hash = hashlib.sha256(firmware).hexdigest()\n",
    "        \n",
    "        if expected_hash != actual_hash:\n",
    "            raise SecurityError(\"Firmware integrity check failed\")\n",
    "        \n",
    "        # Write to inactive partition (B while A is running)\n",
    "        write_to_partition(firmware, self.update_partition)\n",
    "        mark_partition_bootable(self.update_partition)\n",
    "        \n",
    "        # Schedule reboot (during low-activity window)\n",
    "        schedule_reboot()\n",
    "    \n",
    "    def rollback_on_failure(self):\n",
    "        \"\"\"If new firmware crashes, automatic rollback\"\"\"\n",
    "        if boot_count_since_update() > 3 and not health_check_passed():\n",
    "            # Mark current partition bad, revert to previous\n",
    "            mark_partition_bad(current_partition())\n",
    "            switch_to_previous_partition()\n",
    "            reboot()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **24.6 Key Takeaways**\n",
    "\n",
    "1. **Edge computing reduces latency and bandwidth**: Process data locally, send only summaries to cloud. Critical for real-time control systems.\n",
    "\n",
    "2. **MQTT is the lingua franca of IoT**: Lightweight pub-sub with QoS levels for unreliable networks. Use topic hierarchies for clean architecture.\n",
    "\n",
    "3. **Time-series databases handle high ingestion**: InfluxDB and TimescaleDB optimize for time-range queries and high write throughput with compression.\n",
    "\n",
    "4. **Design for offline operation**: CRDTs and delta sync allow devices to work disconnected and merge changes seamlessly when reconnected.\n",
    "\n",
    "5. **Security starts at manufacturing**: Device identity in hardware secure elements, signed firmware updates, and mutual TLS prevent physical and network attacks.\n",
    "\n",
    "6. **Protocol choice depends on constraints**: MQTT for reliable delivery, CoAP for ultra-low power, LoRaWAN for long-range low-bandwidth scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "This chapter explored the unique challenges of edge computing and IoT. We architected three-tier systems that process data locally while maintaining cloud visibility, implemented MQTT and CoAP for device communication, and optimized storage with time-series databases. We solved the offline synchronization problem using CRDTs and persistent queues, and established security practices for physically vulnerable devices.\n",
    "\n",
    "The edge is the new frontier of computing\u2014billions of devices generating exabytes of data. Success requires respecting constraints (power, bandwidth, connectivity) while maintaining system reliability and security.\n",
    "\n",
    "**Coming up next**: In Chapter 25, we'll cover the final section\u2014The System Design Interview\u2014focusing on interview strategy, communication techniques, and mock interview walkthroughs to help you demonstrate these architectural skills in high-pressure interview settings.\n",
    "\n",
    "---\n",
    "\n",
    "## **Exercises**\n",
    "\n",
    "1. **Edge Architecture Design**: Design a system for smart street lights:\n",
    "   - 10,000 lights across a city\n",
    "   - Must respond to motion sensors in <50ms (local processing)\n",
    "   - Report energy usage hourly to cloud\n",
    "   - Continue operating if internet down\n",
    "   - Draw the architecture diagram and specify protocols (MQTT topics, database choice)\n",
    "\n",
    "2. **MQTT Topic Design**: Create a topic hierarchy for a multi-tenant building automation system with:\n",
    "   - 50 buildings\n",
    "   - 20 floors per building\n",
    "   - 100 rooms per floor\n",
    "   - 5 sensors per room (temp, humidity, occupancy, light, CO2)\n",
    "   Design topics that allow:\n",
    "   - Subscribing to all sensors in one room\n",
    "   - Subscribing to all temperature sensors in one building\n",
    "   - Commands to specific actuators (HVAC, lights)\n",
    "\n",
    "3. **Time-Series Optimization**: You have 1 million sensors sending data every 10 seconds. Calculate:\n",
    "   - Daily data points (86.4 billion)\n",
    "   - Storage required for 1 year at 100 bytes per point (raw)\n",
    "   - Storage with InfluxDB compression (10:1 ratio)\n",
    "   - Cost difference between keeping 1 year raw vs. 1 week raw + 1 year downsampled (hourly averages only)\n",
    "\n",
    "4. **CRDT Implementation**: Implement a PN-Counter (Positive-Negative Counter) that supports both increments and decrements, merging correctly across devices. Demonstrate with Device A incrementing 5 times and decrementing 2, while Device B increments 3 times and decrements 1.\n",
    "\n",
    "5. **Offline Sync Strategy**: Design a synchronization protocol for a smart inventory system where warehouse scanners operate offline in the basement (no WiFi) and sync when brought upstairs. Handle conflicts where two scanners update the same item's count while offline.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='23. ai_ml_system_design.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='../9. The_system_design_interview/25. interview_strategy_and_communication.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}