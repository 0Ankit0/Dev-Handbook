{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc1a4e8",
   "metadata": {},
   "source": [
    "# **Chapter 16: User-Facing Applications**\n",
    "\n",
    "Now that we've covered the theoretical foundations and building blocks of distributed systems, it's time to apply this knowledge to real-world problems. This chapter walks through the design of six widely-used systems, progressing from simple to complex.\n",
    "\n",
    "Each case study follows the **4S Framework** introduced in Chapter 10:\n",
    "- **S**cope: Requirements and constraints\n",
    "- **S**ketch: Back-of-the-envelope calculations\n",
    "- **S**olidify: Data models and APIs\n",
    "- **S**cale: Deep dives into bottlenecks and trade-offs\n",
    "\n",
    "By the end of this chapter, you'll understand how to approach any system design interview or real-world architecture challenge.\n",
    "\n",
    "---\n",
    "\n",
    "## **16.1 Design a URL Shortener (TinyURL)**\n",
    "\n",
    "Let's start with the classic URL shortener\u2014a system that takes a long URL like `https://example.com/articles/how-to-design-systems` and converts it to `https://tinyurl.com/x7y9z2`.\n",
    "\n",
    "### **Step 1: Scope (Requirements)**\n",
    "\n",
    "**Functional Requirements** (Must-haves):\n",
    "1. **Shorten URL**: Given a long URL, generate a unique short alias\n",
    "2. **Redirect**: Given a short URL, redirect to the original long URL\n",
    "3. **Custom aliases** (optional): Users can specify custom short codes\n",
    "4. **Expiration** (optional): URLs expire after a set time\n",
    "5. **Analytics** (optional): Track click counts\n",
    "\n",
    "**Non-Functional Requirements**:\n",
    "1. **High availability**: 99.9% uptime (short links must work)\n",
    "2. **Low latency**: Redirect should happen in < 100ms\n",
    "3. **Scalability**: Handle 100 million new URLs per month, 10 billion redirects per month\n",
    "4. **Uniqueness**: No two long URLs should map to the same short URL (unless specified)\n",
    "\n",
    "**Out of Scope** (for this design):\n",
    "- User authentication/management\n",
    "- URL editing after creation\n",
    "- Malware detection in URLs\n",
    "\n",
    "### **Step 2: Sketch (Back-of-the-Envelope)**\n",
    "\n",
    "**Traffic Estimates**:\n",
    "```\n",
    "New URL creations:\n",
    "- 100 million per month\n",
    "- 100M / 30 days / 86,400 seconds \u2248 40 URLs/second (average)\n",
    "- Peak traffic: 10x average = 400 URLs/second\n",
    "\n",
    "URL redirects:\n",
    "- 10 billion per month\n",
    "- 10B / 30 / 86,400 \u2248 3,800 redirects/second (average)\n",
    "- Peak: 38,000 redirects/second\n",
    "\n",
    "Read-to-write ratio: 100:1 (very read-heavy)\n",
    "```\n",
    "\n",
    "**Storage Estimates**:\n",
    "```\n",
    "Per URL record:\n",
    "- short_code: 6 bytes (e.g., \"x7y9z2\")\n",
    "- long_url: 500 bytes average\n",
    "- created_at: 8 bytes (timestamp)\n",
    "- expiration: 8 bytes\n",
    "- user_id: 16 bytes (UUID)\n",
    "\n",
    "Total per record: ~550 bytes\n",
    "\n",
    "5-year storage:\n",
    "- 100M URLs/month \u00d7 12 months \u00d7 5 years = 6 billion URLs\n",
    "- 6B \u00d7 550 bytes = 3.3 TB\n",
    "\n",
    "With replicas (3x) and overhead: ~10 TB\n",
    "```\n",
    "\n",
    "**Bandwidth Estimates**:\n",
    "```\n",
    "Incoming (writes): 400 URLs/sec \u00d7 550 bytes = 220 KB/sec\n",
    "Outgoing (reads): 38,000 redirects/sec \u00d7 550 bytes = 21 MB/sec\n",
    "```\n",
    "\n",
    "### **Step 3: Solidify (API and Data Model)**\n",
    "\n",
    "**API Design**:\n",
    "\n",
    "```\n",
    "POST /api/v1/shorten\n",
    "Request:\n",
    "{\n",
    "  \"long_url\": \"https://example.com/articles/how-to-design-systems\",\n",
    "  \"custom_alias\": \"system-design\",  // optional\n",
    "  \"expiration_days\": 30             // optional, default 365\n",
    "}\n",
    "\n",
    "Response:\n",
    "{\n",
    "  \"short_url\": \"https://tinyurl.com/x7y9z2\",\n",
    "  \"created_at\": \"2024-01-15T10:30:00Z\",\n",
    "  \"expires_at\": \"2024-02-14T10:30:00Z\"\n",
    "}\n",
    "\n",
    "GET /{short_code}\n",
    "Response: HTTP 302 Redirect to original URL\n",
    "         (or 404 if not found/expired)\n",
    "\n",
    "GET /api/v1/stats/{short_code}\n",
    "Response:\n",
    "{\n",
    "  \"short_code\": \"x7y9z2\",\n",
    "  \"long_url\": \"https://...\",\n",
    "  \"click_count\": 15000,\n",
    "  \"created_at\": \"...\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Database Schema**:\n",
    "\n",
    "**URL Table** (Primary storage):\n",
    "```sql\n",
    "CREATE TABLE urls (\n",
    "    id BIGINT AUTO_INCREMENT PRIMARY KEY,\n",
    "    short_code VARCHAR(10) UNIQUE NOT NULL,\n",
    "    long_url VARCHAR(2048) NOT NULL,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    expires_at TIMESTAMP,\n",
    "    click_count BIGINT DEFAULT 0,\n",
    "    user_id VARCHAR(36),\n",
    "    \n",
    "    INDEX idx_short_code (short_code),\n",
    "    INDEX idx_expires_at (expires_at)\n",
    ");\n",
    "```\n",
    "\n",
    "**Why separate `id` and `short_code`?**\n",
    "- `id` is for internal database operations (B-tree indexing efficiency)\n",
    "- `short_code` is what users see (base62 encoded)\n",
    "\n",
    "### **Step 4: Scale (High-Level Design)**\n",
    "\n",
    "**Architecture Overview**:\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   Client    \u2502\u2500\u2500\u2500\u2500\u2500\u2500>\u2502 Load Balancer\u2502\u2500\u2500\u2500\u2500\u2500\u2500>\u2502   Web       \u2502\n",
    "\u2502             \u2502      \u2502 (Round Robin)\u2502      \u2502   Servers   \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                                  \u2502\n",
    "                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                    \u2502                             \u2502                             \u2502\n",
    "                    \u25bc                             \u25bc                             \u25bc\n",
    "            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "            \u2502   Cache      \u2502             \u2502   Database   \u2502              \u2502   Analytics  \u2502\n",
    "            \u2502   (Redis)    \u2502<\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502   (MySQL/    \u2502              \u2502   (Kafka)    \u2502\n",
    "            \u2502              \u2502   Cache miss\u2502   Postgres)  \u2502              \u2502              \u2502\n",
    "            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**The Encoding Strategy (Critical Design Decision)**\n",
    "\n",
    "How do we generate unique short codes?\n",
    "\n",
    "**Option 1: Hash-based (MD5/SHA256)**\n",
    "- Hash the long URL, take first 6 characters\n",
    "- Problem: Collisions! Two different URLs might have same first 6 chars\n",
    "- Solution: If collision, add counter or rehash\n",
    "- Problem: Can't support custom aliases easily\n",
    "\n",
    "**Option 2: Base62 Encoding of Auto-increment ID (Recommended)**\n",
    "- Database generates auto-increment ID (1, 2, 3...)\n",
    "- Convert ID to base62 (a-z, A-Z, 0-9)\n",
    "- Examples:\n",
    "  - ID 1 \u2192 \"1\"\n",
    "  - ID 100 \u2192 \"1C\"\n",
    "  - ID 1,000,000 \u2192 \"4c92\"\n",
    "\n",
    "**Base62 Encoding Logic**:\n",
    "```python\n",
    "BASE62 = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "def encode_base62(num):\n",
    "    if num == 0:\n",
    "        return \"0\"\n",
    "    \n",
    "    result = []\n",
    "    while num > 0:\n",
    "        num, remainder = divmod(num, 62)\n",
    "        result.append(BASE62[remainder])\n",
    "    \n",
    "    return ''.join(reversed(result))\n",
    "\n",
    "def decode_base62(code):\n",
    "    result = 0\n",
    "    for char in code:\n",
    "        result = result * 62 + BASE62.index(char)\n",
    "    return result\n",
    "\n",
    "# Examples\n",
    "print(encode_base62(1000000))  # \"4c92\"\n",
    "print(decode_base62(\"4c92\"))   # 1000000\n",
    "```\n",
    "\n",
    "**Capacity of 6-character codes**:\n",
    "```\n",
    "62^6 = 56.8 billion unique URLs\n",
    "62^7 = 3.5 trillion unique URLs\n",
    "\n",
    "With 100M URLs/month, 6 chars lasts 568 months (~47 years)\n",
    "```\n",
    "\n",
    "**Write Path (Creating Short URL)**:\n",
    "```\n",
    "1. Client sends long_url to POST /shorten\n",
    "2. Application checks if URL already exists (optional deduplication)\n",
    "3. Database inserts new record, gets auto-increment ID\n",
    "4. Application converts ID to base62 short_code\n",
    "5. Update database row with short_code\n",
    "6. Return short_url to client\n",
    "```\n",
    "\n",
    "**Read Path (Redirect)**:\n",
    "```\n",
    "1. Client requests /x7y9z2\n",
    "2. Application checks Redis cache:\n",
    "   - Hit: Return long_url immediately\n",
    "   - Miss: Query database, store in cache, return long_url\n",
    "3. Issue 302 Redirect to long_url\n",
    "4. Async: Increment click count (write to Kafka, batch update DB)\n",
    "```\n",
    "\n",
    "**Why 302 Redirect and not 301?**\n",
    "- **301 (Permanent)**: Browser caches forever. If you change the destination, browsers won't check again.\n",
    "- **302 (Temporary)**: Browser checks every time. Allows updating the long URL later, and allows analytics tracking.\n",
    "\n",
    "### **Deep Dive: Handling the Read-Heavy Traffic**\n",
    "\n",
    "With a 100:1 read-to-write ratio, reads dominate. Here's how to handle 38,000 redirects/second:\n",
    "\n",
    "**Caching Strategy**:\n",
    "- **Cache layer**: Redis cluster with 99% hit rate\n",
    "- **TTL**: 24 hours (or until expiration)\n",
    "- **Cache warming**: Pre-populate cache for popular URLs\n",
    "- **Cache eviction**: LRU (Least Recently Used)\n",
    "\n",
    "**Database Optimization**:\n",
    "- **Read replicas**: 3-5 replicas to distribute read load\n",
    "- **Sharding**: By short_code (consistent hashing) if single DB can't handle load\n",
    "- **Covering index**: Index on (short_code, long_url) to avoid table lookups\n",
    "\n",
    "**CDN for Static Assets**:\n",
    "If serving analytics dashboards or documentation, use CloudFlare/AWS CloudFront.\n",
    "\n",
    "### **Deep Dive: Custom Aliases**\n",
    "\n",
    "If user wants `tinyurl.com/system-design` instead of random code:\n",
    "```\n",
    "1. Check if \"system-design\" already exists\n",
    "2. If not, insert with custom short_code instead of generated one\n",
    "3. Reserve specific keywords in application layer (don't allow \"api\", \"admin\", etc.)\n",
    "```\n",
    "\n",
    "**Collision Handling**:\n",
    "```python\n",
    "def create_short_url(long_url, custom_alias=None):\n",
    "    if custom_alias:\n",
    "        if db.exists(short_code=custom_alias):\n",
    "            raise Error(\"Alias already taken\")\n",
    "        short_code = custom_alias\n",
    "    else:\n",
    "        # Get next ID and encode\n",
    "        id = db.insert(long_url=long_url)\n",
    "        short_code = encode_base62(id)\n",
    "    \n",
    "    return short_code\n",
    "```\n",
    "\n",
    "### **Deep Dive: Analytics at Scale**\n",
    "\n",
    "Tracking 10 billion clicks/month:\n",
    "- Don't write to database synchronously (would kill DB)\n",
    "- Use message queue (Kafka/RabbitMQ)\n",
    "- Consumer batch writes to analytics database (ClickHouse/Druid for OLAP)\n",
    "- Store: timestamp, short_code, user_agent, referrer, geo_location\n",
    "\n",
    "**Data retention**: Raw data 30 days, aggregated data 5 years.\n",
    "\n",
    "### **System Characteristics Summary**\n",
    "\n",
    "| Aspect | Approach |\n",
    "|--------|----------|\n",
    "| Database | Relational (MySQL/Postgres) - strong consistency needed |\n",
    "| Caching | Redis for hot URLs |\n",
    "| Scaling | Horizontal scaling of app servers, read replicas for DB |\n",
    "| Encoding | Base62 of auto-increment ID |\n",
    "| Analytics | Async via message queue |\n",
    "\n",
    "---\n",
    "\n",
    "## **16.2 Design Twitter/X News Feed (Fan-out Problem)**\n",
    "\n",
    "Now we move to a significantly more complex problem: designing a social media feed system where users see posts from people they follow, in real-time.\n",
    "\n",
    "### **Step 1: Scope (Requirements)**\n",
    "\n",
    "**Functional Requirements**:\n",
    "1. **Create tweet**: Users can post tweets (text, images, videos)\n",
    "2. **News feed**: Users see tweets from people they follow, sorted by time (reverse chronological)\n",
    "3. **Follow/unfollow**: Users can follow other users\n",
    "4. **Timeline**: View any user's profile and their tweets\n",
    "\n",
    "**Non-Functional Requirements**:\n",
    "1. **Latency**: News feed should load in < 200ms\n",
    "2. **Availability**: Eventually consistent is acceptable (post may take seconds to appear)\n",
    "3. **Scale**: \n",
    "   - 500 million daily active users (DAU)\n",
    "   - 100 million new tweets per day\n",
    "   - Average user follows 500 people, has 1000 followers\n",
    "   - Some users have 50 million followers (celebrities)\n",
    "\n",
    "**Key Challenge**: The \"Fan-out Problem\"\u2014when a celebrity posts, we must deliver to millions of followers instantly.\n",
    "\n",
    "### **Step 2: Sketch (Back-of-the-Envelope)**\n",
    "\n",
    "**Traffic**:\n",
    "```\n",
    "Tweets: 100M/day = 1,200 tweets/second (average), 12,000/sec (peak)\n",
    "Timeline reads: 500M DAU \u00d7 10 feeds/day = 5B reads/day = 58,000/sec (peak 580,000/sec)\n",
    "```\n",
    "\n",
    "**Storage**:\n",
    "```\n",
    "Tweet metadata: 100 bytes\n",
    "Media: Average 200KB per tweet (5% of tweets have media)\n",
    "Daily storage: \n",
    "  - Metadata: 100M \u00d7 100 bytes = 10 GB\n",
    "  - Media: 5M \u00d7 200KB = 1 TB\n",
    "  \n",
    "5-year storage: 18 PB (media) + 18 TB (metadata)\n",
    "```\n",
    "\n",
    "**Fan-out Analysis**:\n",
    "```\n",
    "Average user: 1,000 followers\n",
    "- Posting tweet: Write to 1,000 timelines = 1,000 writes\n",
    "\n",
    "Celebrity user: 50 million followers\n",
    "- Posting tweet: Write to 50M timelines = 50 million writes!\n",
    "- If 100 celebrities post simultaneously: 5 billion writes\n",
    "```\n",
    "\n",
    "### **Step 3: Solidify (Data Model)**\n",
    "\n",
    "**Tweet Table**:\n",
    "```sql\n",
    "CREATE TABLE tweets (\n",
    "    tweet_id BIGINT PRIMARY KEY,\n",
    "    user_id BIGINT NOT NULL,\n",
    "    content VARCHAR(280),\n",
    "    media_urls JSON,\n",
    "    created_at TIMESTAMP,\n",
    "    likes_count INT DEFAULT 0,\n",
    "    retweets_count INT DEFAULT 0\n",
    ");\n",
    "```\n",
    "\n",
    "**User Table**:\n",
    "```sql\n",
    "CREATE TABLE users (\n",
    "    user_id BIGINT PRIMARY KEY,\n",
    "    username VARCHAR(50) UNIQUE,\n",
    "    email VARCHAR(255),\n",
    "    follower_count BIGINT DEFAULT 0,\n",
    "    following_count BIGINT DEFAULT 0\n",
    ");\n",
    "```\n",
    "\n",
    "**Follow Relationship** (Many-to-Many):\n",
    "```sql\n",
    "CREATE TABLE follows (\n",
    "    follower_id BIGINT,  -- who is following\n",
    "    following_id BIGINT, -- who is being followed\n",
    "    created_at TIMESTAMP,\n",
    "    PRIMARY KEY (follower_id, following_id)\n",
    ");\n",
    "```\n",
    "\n",
    "**News Feed Cache** (Redis):\n",
    "```\n",
    "Key: feed:user_id:{user_id}\n",
    "Value: Sorted Set (zset) of tweet_ids, scored by timestamp\n",
    "TTL: 7 days (older feeds fetched from database)\n",
    "```\n",
    "\n",
    "### **Step 4: Scale (Architecture)**\n",
    "\n",
    "**Two Approaches to News Feed Generation**:\n",
    "\n",
    "#### **Approach 1: Fan-out on Write (Push Model)**\n",
    "\n",
    "When user posts a tweet, immediately push to all followers' feeds.\n",
    "\n",
    "```\n",
    "User posts tweet\n",
    "    \u2502\n",
    "    \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   Tweet      \u2502\n",
    "\u2502   Service    \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "       \u2502\n",
    "       \u251c\u2500\u25ba Save tweet to DB\n",
    "       \u2502\n",
    "       \u251c\u2500\u25ba Get follower list from User Service\n",
    "       \u2502         (User A has 1,000 followers)\n",
    "       \u2502\n",
    "       \u2514\u2500\u25ba Write tweet_id to 1,000 Redis feeds\n",
    "             (fan-out)\n",
    "```\n",
    "\n",
    "**Pros**:\n",
    "- Read is O(1): Just fetch pre-computed feed from Redis\n",
    "- Low latency for timeline reads\n",
    "\n",
    "**Cons**:\n",
    "- Celebrity problem: Writing to 50M followers takes minutes/hours\n",
    "- Waste of resources: Inactive users still get feeds updated\n",
    "\n",
    "#### **Approach 2: Fan-out on Read (Pull Model)**\n",
    "\n",
    "Don't pre-compute feeds. When user opens app, fetch tweets from everyone they follow and merge them.\n",
    "\n",
    "```\n",
    "User requests timeline\n",
    "    \u2502\n",
    "    \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   Timeline   \u2502\n",
    "\u2502   Service    \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "       \u2502\n",
    "       \u251c\u2500\u25ba Get list of 500 people user follows\n",
    "       \u2502\n",
    "       \u251c\u2500\u25ba Fetch recent tweets from each (parallel)\n",
    "       \u2502     - Query 500 database shards\n",
    "       \u2502     - Or query 500 cache keys\n",
    "       \u2502\n",
    "       \u2514\u2500\u25ba Merge and sort by time\n",
    "            Return top 100 tweets\n",
    "```\n",
    "\n",
    "**Pros**:\n",
    "- No celebrity problem\n",
    "- No wasted computation for inactive users\n",
    "\n",
    "**Cons**:\n",
    "- High latency: Querying 500 sources takes time (300-500ms)\n",
    "- Database overload: 500 queries per timeline request\n",
    "\n",
    "#### **Hybrid Approach (The Real Solution)**\n",
    "\n",
    "Twitter uses a hybrid: **Fan-out on Write for normal users, Fan-out on Read for celebrities**.\n",
    "\n",
    "```\n",
    "Define threshold: If user has > 1 million followers, they are \"celebrity\"\n",
    "\n",
    "For Normal User (1,000 followers):\n",
    "    - Push to all followers' Redis feeds immediately\n",
    "    - Read timeline: O(1) fetch from Redis\n",
    "\n",
    "For Celebrity (50M followers):\n",
    "    - Don't push to followers\n",
    "    - When follower requests timeline:\n",
    "        1. Fetch their normal feed from Redis (people they follow)\n",
    "        2. Fetch celebrity tweets separately (recent 100 tweets from each celebrity)\n",
    "        3. Merge results\n",
    "```\n",
    "\n",
    "**Architecture Diagram**:\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   Client    \u2502\u2500\u2500\u2500\u2500\u2500\u2502 Load Balancer\u2502\u2500\u2500\u2500\u2500\u2500\u2502   API       \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                                \u2502\n",
    "                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                    \u2502                             \u2502                             \u2502\n",
    "                    \u25bc                             \u25bc                             \u25bc\n",
    "            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "            \u2502 Tweet Service\u2502            \u2502 Timeline     \u2502              \u2502 User Service \u2502\n",
    "            \u2502 - Post tweet \u2502            \u2502 Service      \u2502              \u2502 - Followers  \u2502\n",
    "            \u2502 - Store media\u2502            \u2502 - Build feed \u2502              \u2502 - Profiles   \u2502\n",
    "            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                   \u2502                           \u2502                             \u2502\n",
    "                   \u25bc                           \u25bc                             \u25bc\n",
    "            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "            \u2502   Database   \u2502            \u2502   Redis      \u2502              \u2502   Database   \u2502\n",
    "            \u2502   (Tweets)   \u2502            \u2502   Cluster    \u2502              \u2502   (Users)    \u2502\n",
    "            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                   \u2502                           \u25b2\n",
    "                   \u2502                           \u2502\n",
    "                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                         Fan-out on Write\n",
    "```\n",
    "\n",
    "### **Deep Dive: The Timeline Generation Algorithm**\n",
    "\n",
    "**For Normal Users**:\n",
    "```python\n",
    "def get_timeline(user_id):\n",
    "    # O(1) operation from Redis\n",
    "    tweet_ids = redis.zrevrange(f\"feed:user_id:{user_id}\", 0, 100)\n",
    "    tweets = fetch_tweet_details(tweet_ids)  # Batch fetch from DB\n",
    "    return tweets\n",
    "```\n",
    "\n",
    "**For Celebrity Content**:\n",
    "```python\n",
    "def get_timeline_hybrid(user_id):\n",
    "    # 1. Get pre-computed feed from Redis (normal users)\n",
    "    normal_tweets = redis.zrevrange(f\"feed:user_id:{user_id}\", 0, 100)\n",
    "    \n",
    "    # 2. Get list of celebrities this user follows\n",
    "    celebrities = get_followed_celebrities(user_id)  # Cached\n",
    "    \n",
    "    # 3. Fetch recent tweets from celebrities (parallel)\n",
    "    celeb_tweets = []\n",
    "    for celeb in celebrities:\n",
    "        tweets = redis.lrange(f\"tweets:user:{celeb}\", 0, 10)\n",
    "        celeb_tweets.extend(tweets)\n",
    "    \n",
    "    # 4. Merge and sort\n",
    "    all_tweets = merge_and_sort(normal_tweets + celeb_tweets)\n",
    "    return all_tweets[:100]\n",
    "```\n",
    "\n",
    "### **Deep Dive: Media Storage**\n",
    "\n",
    "Tweets with images/videos:\n",
    "- **Object Storage**: AWS S3, Google Cloud Storage\n",
    "- **CDN**: CloudFront, CloudFlare for serving images\n",
    "- **Processing Pipeline**: \n",
    "  - Upload \u2192 S3 \u2192 Lambda triggers \u2192 Resize to thumbnails \u2192 Store variants\n",
    "  - Video transcoding: Multiple resolutions (480p, 720p, 1080p)\n",
    "\n",
    "**URL Structure**:\n",
    "```\n",
    "https://media.twitter.com/{user_id}/{tweet_id}/image_1024x768.jpg\n",
    "```\n",
    "\n",
    "### **Deep Dive: Caching Strategy**\n",
    "\n",
    "**Redis Data Structures**:\n",
    "1. **User Feed**: Sorted Set (`zset`) with tweet_id as member, timestamp as score\n",
    "   ```\n",
    "   Key: feed:12345\n",
    "   Value: [(1699123456, tweet_987), (1699123400, tweet_986), ...]\n",
    "   ```\n",
    "\n",
    "2. **Tweet Content**: Hash with tweet details\n",
    "   ```\n",
    "   Key: tweet:987\n",
    "   Value: {content: \"Hello\", user_id: 123, likes: 50, ...}\n",
    "   ```\n",
    "\n",
    "3. **User Profile**: Hash with user info\n",
    "   ```\n",
    "   Key: user:123\n",
    "   Value: {name: \"Alice\", followers: 1000, ...}\n",
    "   ```\n",
    "\n",
    "**Cache Warming**: Pre-populate feeds for active users during low-traffic hours.\n",
    "\n",
    "### **System Characteristics**\n",
    "\n",
    "| Feature | Implementation |\n",
    "|---------|---------------|\n",
    "| Normal tweets | Fan-out on write (push) |\n",
    "| Celebrity tweets | Fan-out on read (pull) |\n",
    "| Feed storage | Redis Sorted Sets |\n",
    "| Media | Object storage (S3) + CDN |\n",
    "| Timeline latency | < 100ms for normal users, < 200ms with celebrities |\n",
    "\n",
    "---\n",
    "\n",
    "## **16.3 Design a Chat Application (WhatsApp/Slack)**\n",
    "\n",
    "Chat systems combine real-time messaging with persistent storage, presence detection, and group management.\n",
    "\n",
    "### **Step 1: Scope**\n",
    "\n",
    "**Functional Requirements**:\n",
    "1. **One-on-one messaging**: Direct messages between users\n",
    "2. **Group messaging**: Chat rooms with multiple participants\n",
    "3. **Online presence**: See who's online/offline\n",
    "4. **Message history**: Access to previous messages\n",
    "5. **Read receipts**: Double checkmarks (delivered/read)\n",
    "6. **Media sharing**: Images, files, voice messages\n",
    "7. **Typing indicators**: \"Alice is typing...\"\n",
    "\n",
    "**Non-Functional Requirements**:\n",
    "1. **Real-time**: Messages delivered in < 500ms\n",
    "2. **Ordered**: Messages appear in correct chronological order\n",
    "3. **Exactly-once delivery**: No duplicate messages\n",
    "4. **Persistence**: Messages stored indefinitely (or user-defined retention)\n",
    "5. **Scale**: 1 billion daily active users, 100 billion messages/day\n",
    "\n",
    "### **Step 2: Sketch**\n",
    "\n",
    "**Traffic**:\n",
    "```\n",
    "100B messages/day = 1.2M messages/second (average)\n",
    "Peak: 10M messages/second\n",
    "\n",
    "Media: 20% of messages include media (20B/day)\n",
    "```\n",
    "\n",
    "**Storage**:\n",
    "```\n",
    "Text message: 200 bytes\n",
    "Media: 1 MB average\n",
    "Daily: (80B \u00d7 200B) + (20B \u00d7 1MB) = 20 TB text + 20 PB media\n",
    "Yearly: 7.3 PB text + 7.3 EB media (exabytes!)\n",
    "```\n",
    "\n",
    "**Connections**:\n",
    "```\n",
    "1B active users, 20% online at once = 200M concurrent connections\n",
    "Each connection maintains persistent WebSocket\n",
    "```\n",
    "\n",
    "### **Step 3: Data Model**\n",
    "\n",
    "**Messages Table** (Cassandra/ScyllaDB - wide column store):\n",
    "```sql\n",
    "CREATE TABLE messages (\n",
    "    chat_id TEXT,           -- user1_user2 for 1:1, group_id for groups\n",
    "    message_id TIMEUUID,    -- contains timestamp, unique\n",
    "    sender_id TEXT,\n",
    "    content TEXT,\n",
    "    media_url TEXT,\n",
    "    created_at TIMESTAMP,\n",
    "    status TEXT,            -- sent, delivered, read\n",
    "    \n",
    "    PRIMARY KEY (chat_id, message_id)\n",
    ") WITH CLUSTERING ORDER BY (message_id DESC);\n",
    "```\n",
    "\n",
    "**Why Cassandra?**\n",
    "- Writes are faster than reads (chat is write-heavy)\n",
    "- Linear scalability\n",
    "- Time-series data fits wide-column model well\n",
    "- Tunable consistency (can trade consistency for availability)\n",
    "\n",
    "**User Sessions** (Redis):\n",
    "```\n",
    "Key: session:{user_id}\n",
    "Value: {server_id: \"ws-server-42\", status: \"online\", last_seen: 1699123456}\n",
    "TTL: 5 minutes (refreshed on activity)\n",
    "```\n",
    "\n",
    "**Recent Chats** (Redis):\n",
    "```\n",
    "Key: recent:{user_id}\n",
    "Value: Sorted Set of chat_ids with last_message_timestamp\n",
    "```\n",
    "\n",
    "### **Step 4: Scale (Architecture)**\n",
    "\n",
    "**High-Level Design**:\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   Mobile    \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502  Load Balancer\u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502   WebSocket \u2502\n",
    "\u2502   Apps      \u2502         \u2502  (Layer 4)    \u2502         \u2502   Servers   \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                                        \u2502\n",
    "                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                    \u2502                                   \u2502                           \u2502\n",
    "                    \u25bc                                   \u25bc                           \u25bc\n",
    "            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "            \u2502   Presence   \u2502                  \u2502   Chat       \u2502              \u2502   Message    \u2502\n",
    "            \u2502   Service    \u2502                  \u2502   Service    \u2502              \u2502   History    \u2502\n",
    "            \u2502   (Redis)    \u2502                  \u2502   (API)      \u2502              \u2502   Service    \u2502\n",
    "            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                                     \u2502                           \u2502\n",
    "                                                     \u25bc                           \u25bc\n",
    "                                             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                                             \u2502   Kafka      \u2502            \u2502   Cassandra  \u2502\n",
    "                                             \u2502   (Queue)    \u2502            \u2502   Cluster    \u2502\n",
    "                                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**WebSocket Connection Flow**:\n",
    "```\n",
    "1. Client authenticates via HTTP API, gets JWT token\n",
    "2. Client connects to WebSocket server with token\n",
    "3. WebSocket server validates token, stores mapping: user_id \u2192 connection\n",
    "4. Heartbeat every 30 seconds to keep connection alive\n",
    "5. On disconnect, mark user as \"offline\" after timeout\n",
    "```\n",
    "\n",
    "**Message Flow (User A sends to User B)**:\n",
    "```\n",
    "User A's Phone\n",
    "     \u2502\n",
    "     \u25bc\n",
    "WebSocket Server (A)\n",
    "     \u2502\n",
    "     \u251c\u2500\u25ba Save message to Cassandra (async)\n",
    "     \u2502\n",
    "     \u251c\u2500\u25ba Check if User B is online (Redis lookup)\n",
    "     \u2502     \u251c\u2500\u25ba Online: Route to WebSocket Server (B) \u2192 Push to User B\n",
    "     \u2502     \u2514\u2500\u25ba Offline: Store for later delivery (Push Notification)\n",
    "     \u2502\n",
    "     \u2514\u2500\u25ba Update recent chats for both users (Redis)\n",
    "```\n",
    "\n",
    "**Handling Message Order**:\n",
    "Problem: Network latency varies. Message 2 might arrive before Message 1.\n",
    "\n",
    "Solutions:\n",
    "1. **Server-side timestamps**: Server assigns timestamp, not client\n",
    "2. **Sequence numbers**: Per-chat incrementing counter\n",
    "3. **Vector clocks**: For distributed systems (complex, usually overkill for chat)\n",
    "\n",
    "**Cassandra handles this naturally**: `message_id` is a TimeUUID (timestamp + random), clustering key sorts by time.\n",
    "\n",
    "### **Deep Dive: Group Chats**\n",
    "\n",
    "**Fan-out in Groups**:\n",
    "- Group has 1,000 members\n",
    "- 1 message sent = 1,000 deliveries needed\n",
    "\n",
    "**Optimization**:\n",
    "- Write once to `messages` table (chat_id = group_id)\n",
    "- Write to `unread` table for each member (lightweight pointer)\n",
    "- Don't fan-out to WebSockets immediately for large groups\n",
    "- Instead, maintain \"last read message_id\" per user\n",
    "\n",
    "**Group Message Table**:\n",
    "```sql\n",
    "CREATE TABLE group_members (\n",
    "    group_id TEXT,\n",
    "    user_id TEXT,\n",
    "    joined_at TIMESTAMP,\n",
    "    role TEXT,  -- admin, member\n",
    "    \n",
    "    PRIMARY KEY (group_id, user_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE unread_messages (\n",
    "    user_id TEXT,\n",
    "    chat_id TEXT,\n",
    "    count INT,\n",
    "    last_message_id TIMEUUID,\n",
    "    \n",
    "    PRIMARY KEY (user_id, chat_id)\n",
    ");\n",
    "```\n",
    "\n",
    "### **Deep Dive: Presence and Typing Indicators**\n",
    "\n",
    "**Presence (Online/Offline)**:\n",
    "- **Heartbeat approach**: Client pings every 30 seconds\n",
    "- **Server updates Redis**: `SET user:123:status online EX 60`\n",
    "- **Broadcast to friends**: When status changes, notify all friends via WebSocket\n",
    "\n",
    "**Optimization**: Don't broadcast to all 1,000 friends immediately. Batch updates or only broadcast to friends currently looking at contact list.\n",
    "\n",
    "**Typing Indicators**:\n",
    "- Client sends \"typing_start\" event\n",
    "- Server broadcasts to chat participants\n",
    "- Debounce: Only send \"typing\" every 3 seconds to prevent spam\n",
    "- Auto-expire: If no \"typing_stop\" received in 10 seconds, clear indicator\n",
    "\n",
    "### **Deep Dive: Media Messages**\n",
    "\n",
    "**Upload Flow**:\n",
    "```\n",
    "1. Client requests upload URL from Media Service\n",
    "2. Media Service generates pre-signed S3 URL (valid 15 minutes)\n",
    "3. Client uploads directly to S3 (bypassing our servers)\n",
    "4. S3 triggers Lambda to generate thumbnail\n",
    "5. Client sends message with S3 URL\n",
    "6. Receivers download directly from S3/CloudFront\n",
    "```\n",
    "\n",
    "**Benefits**:\n",
    "- Our servers don't handle large file uploads (bandwidth savings)\n",
    "- Scales infinitely with S3\n",
    "- Resumable uploads possible\n",
    "\n",
    "### **Deep Dive: Message Delivery Guarantees**\n",
    "\n",
    "**Exactly-Once Delivery**:\n",
    "1. Client generates UUID for message before sending\n",
    "2. Server stores message with UUID as idempotency key\n",
    "3. If client retries (network timeout), server recognizes duplicate UUID\n",
    "4. Acknowledgment: Server sends ACK with server-assigned ID\n",
    "\n",
    "**Offline Delivery**:\n",
    "- Messages stored in Cassandra with TTL (e.g., 30 days)\n",
    "- When user comes online, fetch all messages where `message_id > last_seen_message_id`\n",
    "- Push Notification via Firebase/APNs for critical messages\n",
    "\n",
    "**Read Receipts**:\n",
    "- Client sends \"read\" event with message_id\n",
    "- Server updates `read_at` timestamp\n",
    "- Broadcasts to sender: \"Your message was read\"\n",
    "\n",
    "### **System Characteristics**\n",
    "\n",
    "| Feature | Technology |\n",
    "|---------|-----------|\n",
    "| Real-time transport | WebSockets |\n",
    "| Message storage | Cassandra (write-heavy, time-series) |\n",
    "| Recent chats/Session | Redis |\n",
    "| Media storage | S3 + CloudFront |\n",
    "| Presence | Redis with pub/sub |\n",
    "| Delivery guarantee | Idempotency keys + at-least-once delivery |\n",
    "\n",
    "---\n",
    "\n",
    "## **16.4 Design a Video Streaming Service (YouTube/Netflix)**\n",
    "\n",
    "Video streaming combines massive storage requirements with complex encoding pipelines and adaptive bitrate streaming.\n",
    "\n",
    "### **Step 1: Scope**\n",
    "\n",
    "**Functional Requirements**:\n",
    "1. **Video upload**: Users upload videos in various formats\n",
    "2. **Streaming**: Watch videos with adaptive quality (auto-adjust based on bandwidth)\n",
    "3. **Search**: Find videos by title, description, tags\n",
    "4. **Recommendations**: Suggested videos based on viewing history\n",
    "5. **Subtitles/Captions**: Multi-language support\n",
    "\n",
    "**Non-Functional Requirements**:\n",
    "1. **Latency**: Start playback in < 2 seconds, no buffering\n",
    "2. **Availability**: 99.99% uptime (people binge-watch at 2 AM)\n",
    "3. **Scale**: \n",
    "   - 2 billion users\n",
    "   - 500 hours of video uploaded per minute\n",
    "   - 1 billion hours watched per day\n",
    "\n",
    "**Key Challenge**: Video files are huge. A 10-minute 1080p video is ~500MB. Storage and transmission at scale is the core problem.\n",
    "\n",
    "### **Step 2: Sketch**\n",
    "\n",
    "**Upload Traffic**:\n",
    "```\n",
    "500 hours/minute = 30,000 minutes/hour of video\n",
    "30,000 min \u00d7 60 sec \u00d7 5 Mbps (average bitrate) = 9 TB/hour of raw video\n",
    "```\n",
    "\n",
    "**Streaming Traffic**:\n",
    "```\n",
    "1B hours/day watched\n",
    "Assume average bitrate 2 Mbps (adaptive, varies)\n",
    "1B hours \u00d7 3600 sec \u00d7 2 Mbps = 900 PB/day of outbound traffic\n",
    "Peak traffic: 100 Tbps during evening hours\n",
    "```\n",
    "\n",
    "**Storage**:\n",
    "```\n",
    "Raw uploads: 9 TB/hour \u00d7 24 = 216 TB/day\n",
    "Encoded variants: Each video encoded in 5 qualities (144p to 4K) = 3x storage\n",
    "Yearly raw: 79 PB\n",
    "Yearly encoded: 237 PB\n",
    "```\n",
    "\n",
    "### **Step 3: Data Model**\n",
    "\n",
    "**Video Metadata** (SQL - requires ACID):\n",
    "```sql\n",
    "CREATE TABLE videos (\n",
    "    video_id UUID PRIMARY KEY,\n",
    "    title VARCHAR(255),\n",
    "    description TEXT,\n",
    "    user_id UUID,\n",
    "    status VARCHAR(20),  -- processing, active, deleted\n",
    "    duration INT,        -- seconds\n",
    "    thumbnail_url VARCHAR(255),\n",
    "    upload_date TIMESTAMP,\n",
    "    view_count BIGINT DEFAULT 0,\n",
    "    \n",
    "    INDEX idx_upload_date (upload_date),\n",
    "    INDEX idx_user (user_id)\n",
    ");\n",
    "```\n",
    "\n",
    "**Video Files** (Object Storage):\n",
    "```\n",
    "s3://video-bucket/raw/{video_id}/original.mp4\n",
    "s3://video-bucket/processed/{video_id}/144p.mp4\n",
    "s3://video-bucket/processed/{video_id}/360p.mp4\n",
    "s3://video-bucket/processed/{video_id}/720p.mp4\n",
    "s3://video-bucket/processed/{video_id}/1080p.mp4\n",
    "s3://video-bucket/processed/{video_id}/4k.mp4\n",
    "```\n",
    "\n",
    "**CDN Cache** (Edge locations):\n",
    "```\n",
    "edge-cdn.net/videos/{video_id}/720p/segment_001.ts\n",
    "```\n",
    "\n",
    "### **Step 4: Scale (Architecture)**\n",
    "\n",
    "**Upload Pipeline**:\n",
    "```\n",
    "User uploads video\n",
    "    \u2502\n",
    "    \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   Upload     \u2502\n",
    "\u2502   Service    \u2502\u2500\u2500\u2510\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n",
    "                  \u25bc\n",
    "          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "          \u2502   Raw        \u2502\n",
    "          \u2502   Storage    \u2502\n",
    "          \u2502   (S3)       \u2502\n",
    "          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                 \u2502\n",
    "                 \u25bc\n",
    "          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "          \u2502   Encoding   \u2502\u2500\u2500\u2500\u2500\u2510\n",
    "          \u2502   Queue      \u2502    \u2502\n",
    "          \u2502   (Kafka)    \u2502    \u2502\n",
    "          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n",
    "                              \u25bc\n",
    "                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                       \u2502   Encoding   \u2502\n",
    "                       \u2502   Workers    \u2502\n",
    "                       \u2502   (FFmpeg)   \u2502\n",
    "                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                              \u2502\n",
    "                              \u25bc\n",
    "                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                       \u2502   Processed  \u2502\n",
    "                       \u2502   Storage    \u2502\n",
    "                       \u2502   (S3)       \u2502\n",
    "                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**Streaming Architecture**:\n",
    "```\n",
    "User requests video\n",
    "    \u2502\n",
    "    \u25bc\n",
    "CDN Edge Location (closest to user)\n",
    "    \u2502\n",
    "    \u251c\u2500\u25ba Cache Hit? Serve immediately\n",
    "    \u2502\n",
    "    \u2514\u2500\u25ba Cache Miss? Fetch from Origin\n",
    "            \u2502\n",
    "            \u25bc\n",
    "      Origin Storage (S3)\n",
    "            \u2502\n",
    "            \u25bc\n",
    "      Transcoding on the fly (if needed)\n",
    "```\n",
    "\n",
    "**Adaptive Bitrate Streaming (ABR)**:\n",
    "\n",
    "Instead of one video file, we break it into small chunks (2-10 seconds) at multiple bitrates.\n",
    "\n",
    "```\n",
    "Manifest file (playlist.m3u8):\n",
    "#EXTM3U\n",
    "#EXT-X-STREAM-INF:BANDWIDTH=1280000,RESOLUTION=720x480\n",
    "480p/playlist.m3u8\n",
    "#EXT-X-STREAM-INF:BANDWIDTH=2560000,RESOLUTION=1280x720\n",
    "720p/playlist.m3u8\n",
    "#EXT-X-STREAM-INF:BANDWIDTH=7680000,RESOLUTION=1920x1080\n",
    "1080p/playlist.m3u8\n",
    "\n",
    "480p/playlist.m3u8 contains:\n",
    "segment_001.ts (2 seconds)\n",
    "segment_002.ts\n",
    "segment_003.ts\n",
    "...\n",
    "```\n",
    "\n",
    "**How ABR Works**:\n",
    "```\n",
    "Player starts with lowest quality (fast start)\n",
    "    \u2502\n",
    "    \u25bc\n",
    "Measures download speed:\n",
    "  - If speed > current bitrate \u00d7 1.5 \u2192 switch up\n",
    "  - If speed < current bitrate \u00d7 0.8 \u2192 switch down\n",
    "    \u2502\n",
    "    \u25bc\n",
    "Seamlessly switches quality between segments\n",
    "User sees: \"Auto (720p)\" in settings\n",
    "```\n",
    "\n",
    "**Protocols**:\n",
    "- **HLS (HTTP Live Streaming)**: Apple's protocol, .m3u8 manifests, .ts segments\n",
    "- **DASH (Dynamic Adaptive Streaming)**: MPEG standard, .mpd manifests\n",
    "- **WebRTC**: For live streaming (lower latency)\n",
    "\n",
    "### **Deep Dive: Video Encoding**\n",
    "\n",
    "**Why Encode?**\n",
    "- Raw video from camera: 1 Gbps bitrate (unstreamable)\n",
    "- Encoded 1080p: 5 Mbps (manageable)\n",
    "- Compression ratio: 200:1 using H.264/H.265/AV1\n",
    "\n",
    "**Encoding Ladder**:\n",
    "```\n",
    "Resolution  Bitrate    Use case\n",
    "360p        400 Kbps   Mobile, slow 3G\n",
    "480p        1 Mbps     Mobile, 4G\n",
    "720p        2.5 Mbps   Desktop, good WiFi\n",
    "1080p       5 Mbps     Desktop, fast WiFi\n",
    "4K          20 Mbps    Premium users, fiber\n",
    "```\n",
    "\n",
    "**Encoding Process**:\n",
    "```\n",
    "1. Download raw video from S3\n",
    "2. Extract audio stream\n",
    "3. Create multiple video streams:\n",
    "   - Scale to each resolution\n",
    "   - Compress using H.264 (or VP9, AV1 for better compression but slower)\n",
    "4. Package into HLS/DASH format\n",
    "5. Upload to S3\n",
    "6. Invalidate CDN cache\n",
    "```\n",
    "\n",
    "**Distributed Encoding**:\n",
    "One video split into segments, encoded in parallel by hundreds of servers, then stitched back together.\n",
    "\n",
    "### **Deep Dive: CDN Strategy**\n",
    "\n",
    "**Multi-tier CDN**:\n",
    "```\n",
    "Tier 1 (Edge): 10,000+ locations worldwide\n",
    "  - Cache popular videos (top 1%)\n",
    "  - Serve 95% of traffic\n",
    "\n",
    "Tier 2 (Regional): 100 locations\n",
    "  - Cache long-tail videos\n",
    "  - Fill from Origin when needed\n",
    "\n",
    "Origin (Central): 3-5 data centers\n",
    "  - All videos stored here\n",
    "  - Source of truth\n",
    "```\n",
    "\n",
    "**Cache Eviction**:\n",
    "- **LRU (Least Recently Used)**: Remove videos not watched recently\n",
    "- **LFU (Least Frequently Used)**: Remove videos with few views\n",
    "- **Popular videos**: Pre-positioned on all edge servers (TikTok videos, viral YouTube content)\n",
    "\n",
    "### **Deep Dive: Handling Seek**\n",
    "\n",
    "When user drags progress bar to middle of video:\n",
    "```\n",
    "Player requests manifest for that timestamp\n",
    "    \u2502\n",
    "    \u25bc\n",
    "Manifest contains segment numbers for each timestamp\n",
    "    \u2502\n",
    "    \u25bc\n",
    "Request specific segment (e.g., segment_450.ts)\n",
    "    \u2502\n",
    "    \u25bc\n",
    "If CDN has it \u2192 serve\n",
    "If not \u2192 fetch from origin \u2192 serve \u2192 cache for next user\n",
    "```\n",
    "\n",
    "**Keyframes**: Videos have keyframes every 2-10 seconds. Player can only seek to keyframes. If user seeks to non-keyframe, player seeks to previous keyframe and decodes forward.\n",
    "\n",
    "### **System Characteristics**\n",
    "\n",
    "| Component | Technology |\n",
    "|-----------|-----------|\n",
    "| Raw storage | S3 / GCS |\n",
    "| Encoding | FFmpeg on EC2/Kubernetes |\n",
    "| Streaming | HLS/DASH via CDN |\n",
    "| Metadata | PostgreSQL / Cassandra |\n",
    "| Search | Elasticsearch |\n",
    "| Recommendations | ML Pipeline (TensorFlow) |\n",
    "\n",
    "---\n",
    "\n",
    "## **16.5 Design a Ride-Sharing Service (Uber/Lyft)**\n",
    "\n",
    "Ride-sharing is a real-time, location-heavy system matching drivers with riders using geospatial indexing.\n",
    "\n",
    "### **Step 1: Scope**\n",
    "\n",
    "**Functional Requirements**:\n",
    "1. **Ride request**: Passenger requests ride, sees ETA and price\n",
    "2. **Driver matching**: System finds nearest available driver\n",
    "3. **Real-time tracking**: See driver approaching on map\n",
    "4. **Payment**: Automatic payment after ride\n",
    "5. **Rating**: Rate driver and passenger\n",
    "\n",
    "**Non-Functional Requirements**:\n",
    "1. **Real-time**: Driver location updates every 5 seconds, matching in < 5 seconds\n",
    "2. **Reliability**: Must work during high demand (New Year's Eve, concerts)\n",
    "3. **Scale**: 100 million monthly active users, 20 million trips/day\n",
    "\n",
    "**Key Challenge**: Geospatial queries\u2014finding drivers within 5 miles of a location, fast.\n",
    "\n",
    "### **Step 2: Sketch**\n",
    "\n",
    "**Traffic**:\n",
    "```\n",
    "20M trips/day = 230 trips/second (average), 2,000/sec (peak)\n",
    "\n",
    "Location updates:\n",
    "- 5M drivers online\n",
    "- Update every 5 seconds = 1M updates/second\n",
    "- Each update: driver_id, lat, long, timestamp (50 bytes)\n",
    "- 50 MB/sec of location data\n",
    "```\n",
    "\n",
    "**Storage**:\n",
    "```\n",
    "Trips: 20M/day \u00d7 1KB metadata = 20 GB/day\n",
    "Locations: 1M updates/sec \u00d7 50 bytes \u00d7 1 day retention = 4.3 TB/day (then archived)\n",
    "```\n",
    "\n",
    "### **Step 3: Data Model**\n",
    "\n",
    "**Active Drivers** (Redis with Geospatial indexes):\n",
    "```\n",
    "Redis Geo Commands:\n",
    "GEOADD drivers -122.4194 37.7749 \"driver_123\"  # Add driver at location\n",
    "GEORADIUS drivers -122.4194 37.7749 5 mi       # Find drivers within 5 miles\n",
    "```\n",
    "\n",
    "**Why Redis Geo?**\n",
    "- Built-in geospatial indexing using sorted sets\n",
    "- O(log n) for adding points\n",
    "- O(log n + m) for radius queries (m = number of results)\n",
    "- In-memory = extremely fast (< 10ms)\n",
    "\n",
    "**Trips Table** (PostgreSQL):\n",
    "```sql\n",
    "CREATE TABLE trips (\n",
    "    trip_id UUID PRIMARY KEY,\n",
    "    rider_id UUID NOT NULL,\n",
    "    driver_id UUID,\n",
    "    status VARCHAR(20),  -- requested, accepted, ongoing, completed\n",
    "    pickup_lat DECIMAL(10,8),\n",
    "    pickup_long DECIMAL(11,8),\n",
    "    dropoff_lat DECIMAL(10,8),\n",
    "    dropoff_long DECIMAL(11,8),\n",
    "    requested_at TIMESTAMP,\n",
    "    accepted_at TIMESTAMP,\n",
    "    completed_at TIMESTAMP,\n",
    "    fare DECIMAL(10,2)\n",
    ");\n",
    "```\n",
    "\n",
    "**Driver Locations** (Time-series database, e.g., InfluxDB):\n",
    "```\n",
    "Measurement: driver_location\n",
    "Tags: driver_id\n",
    "Fields: lat, long, speed\n",
    "Timestamp: 2024-01-15T10:30:00Z\n",
    "Retention: 7 days (then aggregated or deleted)\n",
    "```\n",
    "\n",
    "### **Step 4: Scale (Architecture)**\n",
    "\n",
    "**System Components**:\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   Rider App  \u2502      \u2502  Driver App  \u2502      \u2502   Dispatch   \u2502\n",
    "\u2502              \u2502      \u2502              \u2502      \u2502   Service    \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "       \u2502                     \u2502                     \u2502\n",
    "       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                             \u2502\n",
    "                             \u25bc\n",
    "                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                    \u2502  WebSocket      \u2502\n",
    "                    \u2502  Gateway        \u2502\n",
    "                    \u2502  (Location      \u2502\n",
    "                    \u2502   Streaming)    \u2502\n",
    "                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                             \u2502\n",
    "            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "            \u2502                \u2502                \u2502\n",
    "            \u25bc                \u25bc                \u25bc\n",
    "      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "      \u2502  Redis   \u2502    \u2502  Kafka   \u2502    \u2502 PostgreSQL\u2502\n",
    "      \u2502  (Geo    \u2502    \u2502  (Events)\u2502    \u2502 (Trips)   \u2502\n",
    "      \u2502  Index)  \u2502    \u2502          \u2502    \u2502           \u2502\n",
    "      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**The Matching Algorithm**:\n",
    "```\n",
    "Rider requests trip at (lat, long)\n",
    "    \u2502\n",
    "    \u25bc\n",
    "Dispatch Service queries Redis:\n",
    "    GEORADIUS drivers lat long 5 mi WITHDIST\n",
    "    \n",
    "    Returns: [\n",
    "        (\"driver_123\", 0.5 mi),\n",
    "        (\"driver_456\", 1.2 mi),\n",
    "        (\"driver_789\", 2.1 mi)\n",
    "    ]\n",
    "    \u2502\n",
    "    \u25bc\n",
    "Filter out drivers:\n",
    "    - Currently on trip\n",
    "    - Rating below threshold\n",
    "    - Ignoring this area\n",
    "    \n",
    "Select top 3 nearest drivers\n",
    "    \u2502\n",
    "    \u25bc\n",
    "Send push notification to Driver 1 (timeout: 15 seconds)\n",
    "If declined/no response \u2192 Driver 2 \u2192 Driver 3\n",
    "    \u2502\n",
    "    \u25bc\n",
    "When accepted:\n",
    "    - Update trip status in DB\n",
    "    - Notify rider via WebSocket\n",
    "    - Start location streaming\n",
    "```\n",
    "\n",
    "**Surge Pricing** (Dynamic Pricing):\n",
    "```\n",
    "If demand > supply in area:\n",
    "    multiplier = 1.5x, 2x, etc.\n",
    "    \n",
    "Calculation:\n",
    "    requests_per_minute / available_drivers > threshold\n",
    "```\n",
    "\n",
    "**Location Streaming**:\n",
    "```\n",
    "Driver app sends location every 5 seconds:\n",
    "    POST /location\n",
    "    {driver_id, lat, long, timestamp}\n",
    "    \n",
    "Flow:\n",
    "    Driver App \u2192 Load Balancer \u2192 WebSocket Gateway \u2192 Kafka \u2192 Consumers\n",
    "    \n",
    "Consumers:\n",
    "    1. Update Redis Geo index (for matching)\n",
    "    2. Update time-series DB (for analytics)\n",
    "    3. Broadcast to Rider (if on trip): \"Driver is at lat, long\"\n",
    "```\n",
    "\n",
    "### **Deep Dive: Geospatial Indexing**\n",
    "\n",
    "**Why not just SQL?**\n",
    "```sql\n",
    "SELECT * FROM drivers \n",
    "WHERE SQRT(POW(lat - 37.7749, 2) + POW(long - (-122.4194), 2)) < 5;\n",
    "```\n",
    "- Requires full table scan (O(n))\n",
    "- Slow with millions of drivers\n",
    "\n",
    "**Redis GeoHash**:\n",
    "- Earth divided into grid cells\n",
    "- Each cell encoded as hash string\n",
    "- Nearby locations share same hash prefix\n",
    "- Stored in sorted set by hash value\n",
    "- Radius query becomes range query on sorted set\n",
    "\n",
    "**Alternative: Google S2 Geometry**:\n",
    "- Sphere divided into hierarchical cells\n",
    "- Each cell has 64-bit ID\n",
    "- Nearby cells have similar IDs\n",
    "- Can use Bigtable/DynamoDB with cell ID as key\n",
    "\n",
    "### **Deep Dive: Handling Peak Demand**\n",
    "\n",
    "**Problem**: Concert ends, 10,000 people request rides simultaneously in 1 square mile.\n",
    "\n",
    "**Solutions**:\n",
    "1. **Queueing**: Riders enter virtual queue, matched FIFO\n",
    "2. **Radius expansion**: If no drivers in 1 mile, expand to 2 miles, then 5 miles\n",
    "3. **Batch matching**: Collect requests for 10 seconds, optimize matching algorithmically (minimize total distance)\n",
    "4. **Surge pricing**: Reduce demand by increasing price\n",
    "\n",
    "### **System Characteristics**\n",
    "\n",
    "| Component | Technology |\n",
    "|-----------|-----------|\n",
    "| Real-time location | WebSockets |\n",
    "| Geospatial index | Redis Geo |\n",
    "| Matching logic | State machine in application layer |\n",
    "| Event streaming | Kafka |\n",
    "| Trip storage | PostgreSQL |\n",
    "| ETA calculation | ML model + historical traffic data |\n",
    "\n",
    "---\n",
    "\n",
    "## **16.6 Design a Food Delivery App (DoorDash/UberEats)**\n",
    "\n",
    "Food delivery combines ride-sharing's real-time location with inventory management (restaurant menus) and three-sided marketplace (customers, restaurants, drivers).\n",
    "\n",
    "### **Step 1: Scope**\n",
    "\n",
    "**Functional Requirements**:\n",
    "1. **Restaurant browsing**: Search/filter by cuisine, location, rating\n",
    "2. **Menu management**: Restaurants update availability\n",
    "3. **Order placement**: Cart, payment, special instructions\n",
    "4. **Driver assignment**: Match drivers to pick up food\n",
    "5. **Real-time tracking**: Track order status (preparing, picked up, en route)\n",
    "6. **ETA calculation**: When will food arrive?\n",
    "\n",
    "**Non-Functional Requirements**:\n",
    "1. **Consistency**: Orders must not be lost (financial transactions)\n",
    "2. **Real-time**: Status updates within seconds\n",
    "3. **Scale**: 50M orders/month, 500K restaurants, 5M drivers\n",
    "\n",
    "### **Step 2: Sketch**\n",
    "\n",
    "**Traffic**:\n",
    "```\n",
    "50M orders/month = 1.7M orders/day = 20 orders/sec (average), 200/sec (peak)\n",
    "\n",
    "Menu views: 10x orders = 200/sec\n",
    "Location updates: 5M drivers \u00d7 every 10 sec = 500K/sec\n",
    "```\n",
    "\n",
    "**Storage**:\n",
    "```\n",
    "Orders: 50M/month \u00d7 2KB = 100 GB/month\n",
    "Restaurant data: 500K restaurants \u00d7 10MB (menus, images) = 5 TB\n",
    "```\n",
    "\n",
    "### **Step 3: Data Model**\n",
    "\n",
    "**Order State Machine**:\n",
    "```\n",
    "CREATED \u2192 PAID \u2192 CONFIRMED \u2192 PREPARING \u2192 READY_FOR_PICKUP \u2192 \n",
    "PICKED_UP \u2192 EN_ROUTE \u2192 DELIVERED \u2192 COMPLETED\n",
    "```\n",
    "\n",
    "**Orders Table** (ACID required - PostgreSQL):\n",
    "```sql\n",
    "CREATE TABLE orders (\n",
    "    order_id UUID PRIMARY KEY,\n",
    "    customer_id UUID NOT NULL,\n",
    "    restaurant_id UUID NOT NULL,\n",
    "    driver_id UUID,\n",
    "    status VARCHAR(30),\n",
    "    items JSONB,  -- [{item_id, quantity, price, modifications}]\n",
    "    total_amount DECIMAL(10,2),\n",
    "    delivery_address TEXT,\n",
    "    lat DECIMAL(10,8),\n",
    "    long DECIMAL(11,8),\n",
    "    placed_at TIMESTAMP,\n",
    "    estimated_delivery TIMESTAMP,\n",
    "    \n",
    "    INDEX idx_customer (customer_id, placed_at),\n",
    "    INDEX idx_restaurant (restaurant_id, status)\n",
    ");\n",
    "```\n",
    "\n",
    "**Inventory Management** (Redis):\n",
    "```\n",
    "Key: restaurant:{id}:inventory\n",
    "Value: Hash { \"item_123\": 5, \"item_456\": 0 }  -- quantity available\n",
    "\n",
    "Key: restaurant:{id}:menu_version\n",
    "Value: Integer (incremented when menu changes)\n",
    "```\n",
    "\n",
    "### **Step 4: Scale (Architecture)**\n",
    "\n",
    "**Order Flow**:\n",
    "```\n",
    "Customer places order\n",
    "    \u2502\n",
    "    \u25bc\n",
    "Order Service validates:\n",
    "    - Restaurant open?\n",
    "    - Items available? (check Redis inventory)\n",
    "    - Address within delivery range?\n",
    "    \u2502\n",
    "    \u25bc\n",
    "Payment Service processes payment\n",
    "    \u2502\n",
    "    \u25bc\n",
    "Restaurant notified (tablet app/SMS)\n",
    "    \u2502\n",
    "    \u25bc\n",
    "Kitchen Display System shows order\n",
    "    \u2502\n",
    "    \u25bc\n",
    "When food ready (~15-30 min later):\n",
    "    \u251c\u2500\u25ba Find nearest driver (same as Uber)\n",
    "    \u2514\u2500\u25ba Driver picks up and delivers\n",
    "```\n",
    "\n",
    "**ETA Calculation Service**:\n",
    "```\n",
    "Inputs:\n",
    "    - Food prep time (ML model based on restaurant, time of day, current load)\n",
    "    - Driver distance to restaurant (real-time GPS)\n",
    "    - Traffic conditions (Google Maps API or internal data)\n",
    "    - Distance restaurant to customer\n",
    "    \n",
    "Output: \"Your order will arrive in 32-38 minutes\"\n",
    "```\n",
    "\n",
    "**Inventory Management**:\n",
    "```\n",
    "Challenge: Item sells out while customer is browsing\n",
    "\n",
    "Solution:\n",
    "1. Customer opens app \u2192 Cache menu in Redis (TTL: 5 minutes)\n",
    "2. Customer adds to cart \u2192 Reserve inventory for 10 minutes (decrement Redis)\n",
    "3. If not checked out in 10 min \u2192 Release inventory (increment Redis)\n",
    "4. If checked out \u2192 Permanent decrement\n",
    "```\n",
    "\n",
    "**Concurrency Control**:\n",
    "```\n",
    "Two customers try to order last pizza simultaneously:\n",
    "\n",
    "Customer A: Read inventory = 1\n",
    "Customer B: Read inventory = 1 (same time)\n",
    "\n",
    "Both try to decrement:\n",
    "    Optimistic locking: Version number check\n",
    "    OR\n",
    "    Redis INCR/DECR (atomic operations)\n",
    "```\n",
    "\n",
    "**Driver Matching Nuances**:\n",
    "Unlike ride-sharing:\n",
    "- Food must be ready before driver arrives (don't want cold food)\n",
    "- Stack orders: Driver can pick up 2-3 orders from same restaurant\n",
    "- Batch optimization: Route driver to pick up Order A, then Order B, deliver A, then B (traveling salesman problem)\n",
    "\n",
    "### **Deep Dive: The \"Prepare Time\" Problem**\n",
    "\n",
    "**Problem**: If driver arrives too early, food isn't ready (wasted time). If too late, food gets cold.\n",
    "\n",
    "**Solution**:\n",
    "```\n",
    "When order placed:\n",
    "    estimated_prep_time = ML_model(restaurant, items, current_load)\n",
    "    \n",
    "At estimated_prep_time - 5 minutes:\n",
    "    Trigger driver search\n",
    "    \n",
    "Algorithm:\n",
    "    driver_travel_time_to_restaurant \u2248 food_prep_time_remaining\n",
    "```\n",
    "\n",
    "**ML Model Features**:\n",
    "- Restaurant historical prep times\n",
    "- Current number of active orders at restaurant\n",
    "- Day of week/time of day\n",
    "- Item complexity (salad vs. well-done steak)\n",
    "\n",
    "### **Deep Dive: Search and Discovery**\n",
    "\n",
    "**Restaurant Search** (Elasticsearch):\n",
    "```\n",
    "Query: \"Italian food under $30, 4+ stars, within 5 miles\"\n",
    "    \u2502\n",
    "    \u25bc\n",
    "Elasticsearch index:\n",
    "    - Geo-point for location\n",
    "    - Cuisine tags (array)\n",
    "    - Price range (integer 1-4)\n",
    "    - Average rating (float)\n",
    "    - Currently open (boolean)\n",
    "    - Delivery time estimate (integer minutes)\n",
    "```\n",
    "\n",
    "**Ranking Algorithm**:\n",
    "```\n",
    "Score = (distance_weight \u00d7 distance) + \n",
    "        (rating_weight \u00d7 rating) + \n",
    "        (popularity_weight \u00d7 order_count) +\n",
    "        (promoted_weight \u00d7 paid_promotion)\n",
    "```\n",
    "\n",
    "### **Deep Dive: Handling Failures**\n",
    "\n",
    "**Restaurant cancels order** (out of ingredients):\n",
    "1. Refund customer automatically\n",
    "2. Send push notification with apology + coupon\n",
    "3. Suggest similar restaurants\n",
    "\n",
    "**Driver cancels after pickup**:\n",
    "1. Emergency re-assignment to nearest driver\n",
    "2. If food already left restaurant, new driver intercepts en route\n",
    "3. Customer notified of delay\n",
    "\n",
    "**Payment fails**:\n",
    "1. Order held for 5 minutes while customer fixes payment\n",
    "2. If not fixed, release inventory and cancel\n",
    "\n",
    "### **System Characteristics**\n",
    "\n",
    "| Component | Technology |\n",
    "|-----------|-----------|\n",
    "| Order management | PostgreSQL (ACID for payments) |\n",
    "| Real-time location | Redis Geo + WebSockets |\n",
    "| Search | Elasticsearch |\n",
    "| Inventory | Redis (atomic operations) |\n",
    "| ETA/ML | Python microservices |\n",
    "| Notifications | Firebase/APNs + SMS gateway |\n",
    "\n",
    "---\n",
    "\n",
    "## **16.7 Chapter Summary**\n",
    "\n",
    "In this chapter, we designed six production-scale systems, each with unique challenges:\n",
    "\n",
    "1. **URL Shortener**: Taught us about encoding strategies, read-heavy architectures, and the importance of caching. The key decision was base62 encoding of auto-increment IDs.\n",
    "\n",
    "2. **Twitter News Feed**: Introduced the fan-out problem and the hybrid push/pull model. We learned that one size doesn't fit all\u2014treat celebrities differently from normal users.\n",
    "\n",
    "3. **Chat Application**: Covered real-time communication via WebSockets, message ordering guarantees, and handling the \"n-squared\" problem of group chats.\n",
    "\n",
    "4. **Video Streaming**: Demonstrated the complexity of media processing pipelines, adaptive bitrate streaming, and multi-tier CDN strategies for massive files.\n",
    "\n",
    "5. **Ride-Sharing**: Focused on geospatial indexing with Redis Geo, real-time location streaming, and the dispatch matching algorithm.\n",
    "\n",
    "6. **Food Delivery**: Combined elements of ride-sharing with inventory management and three-way marketplace coordination, emphasizing ETA prediction and state machines.\n",
    "\n",
    "**Common Patterns Across All Systems**:\n",
    "- **Caching is crucial**: Redis appears in every design for different use cases\n",
    "- **Asynchronous processing**: Kafka/RabbitMQ for decoupling heavy operations\n",
    "- **Database per use case**: SQL for transactions, NoSQL for scalability, Time-series for metrics\n",
    "- **CDN for static assets**: Offload bandwidth and reduce latency\n",
    "- **Graceful degradation**: When components fail, the system continues operating with reduced functionality\n",
    "\n",
    "**Key Takeaway**: System design is about trade-offs. A URL shortener prioritizes read speed over write speed. Twitter prioritizes read speed for normal users but write speed for celebrities. Chat prioritizes availability over temporary consistency. There are no perfect solutions, only solutions optimized for specific constraints.\n",
    "\n",
    "---\n",
    "\n",
    "**Exercises**:\n",
    "\n",
    "1. **URL Shortener**: How would you modify the design to support URL expiration with automatic cleanup of expired entries?\n",
    "\n",
    "2. **Twitter**: Calculate the storage requirements if we kept the last 1000 tweets for each of 500 million users in Redis. Is this feasible?\n",
    "\n",
    "3. **Chat**: Design a \"message recall\" feature that allows users to delete messages within 5 minutes of sending. What are the consistency challenges?\n",
    "\n",
    "4. **Video Streaming**: How would you design a \"live streaming\" feature (like Twitch) differently from video-on-demand (like YouTube)?\n",
    "\n",
    "5. **Ride-Sharing**: Design an algorithm to detect fraudulent drivers (GPS spoofing, fake trips).\n",
    "\n",
    "6. **Food Delivery**: How would you handle a flash sale where a popular restaurant offers 50% off for one hour, causing a 100x traffic spike?\n",
    "\n",
    "---\n",
    "\n",
    "**Interview Tips**:\n",
    "- Always clarify functional vs. non-functional requirements first\n",
    "- Do the math early (QPS, storage, bandwidth) to guide your design\n",
    "- Identify the \"hardest problem\" in the system (fan-out, geospatial, etc.) and focus your deep dive there\n",
    "- Discuss trade-offs explicitly: \"If we choose X, we get benefits A and B, but drawbacks C and D\"\n",
    "- Never propose a design you can't scale\u2014if you suggest a single database, be ready to explain how to shard it when it fills up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='../5. Architectural_patterns/15. data_intensive_systems.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='17. infrastructure_and_platform_systems.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}