{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb87cc47",
   "metadata": {},
   "source": [
    "# **Chapter 25: Interview Strategy & Communication**\n",
    "\n",
    "The system design interview is fundamentally different from coding interviews. You're not proving you can write a sorting algorithm; you're demonstrating that you can architect complex systems, make trade-offs, and communicate technical decisions effectively. This chapter provides the framework, techniques, and communication strategies to excel in these high-stakes conversations.\n",
    "\n",
    "---\n",
    "\n",
    "## **25.1 The 4S Framework for System Design Interviews**\n",
    "\n",
    "Most candidates fail not because they lack technical knowledge, but because they approach the interview haphazardly. The **4S Framework** provides a structured narrative that guides the interviewer through your thinking process.\n",
    "\n",
    "### **The Framework Overview**\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502  SCOPE  \u2192  SKETCH  \u2192  SOLIDIFY  \u2192  SCALE                     \u2502\n",
    "\u2502  (5 min)   (10 min)    (15 min)     (20 min)                 \u2502\n",
    "\u2502                                                              \u2502\n",
    "\u2502  What to    Rough math    Data model    Deep dives,          \u2502\n",
    "\u2502  build?     & capacity    & API design  trade-offs,          \u2502\n",
    "\u2502             estimates                   bottlenecks          \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### **Phase 1: SCOPE (Requirements Gathering)**\n",
    "\n",
    "**The Goal**: Before designing anything, understand what you're building. A beautiful design for the wrong requirements is worthless.\n",
    "\n",
    "**Functional Requirements (What the system does)**:\n",
    "- **Explicit**: Stated directly in the question\n",
    "- **Implicit**: Assumed but not stated (user authentication, error handling)\n",
    "- **Discovery**: Ask clarifying questions\n",
    "\n",
    "**Non-Functional Requirements (How the system performs)**:\n",
    "- **Scale**: Users, requests per second, data volume\n",
    "- **Performance**: Latency (p50, p99), throughput\n",
    "- **Availability**: Uptime SLA (99.9%, 99.99%)\n",
    "- **Durability**: Data loss tolerance\n",
    "- **Security**: Authentication, encryption, compliance\n",
    "\n",
    "**Example Interview Dialogue**:\n",
    "\n",
    "> **Interviewer**: \"Design a URL shortener like TinyURL.\"\n",
    ">\n",
    "> **Candidate**: \"Before I start designing, let me clarify the requirements. For functional requirements, I'm assuming:\n",
    "> - Users can submit a long URL and get a short alias\n",
    "> - Visiting the short URL redirects to the original\n",
    "> - Users can optionally specify a custom alias\n",
    "> - We should track click analytics\n",
    ">\n",
    "> For non-functional requirements, what scale should I design for? Are we talking hundreds or millions of URLs per day? And what's the expected read-to-write ratio?\"\n",
    ">\n",
    "> **Interviewer**: \"Let's design for 100 million new URLs per month, 10 billion redirects per month. Read-heavy, 100:1 ratio.\"\n",
    ">\n",
    "> **Candidate**: \"Got it. And for latency, I'm assuming sub-100ms for redirects is acceptable? For availability, standard 99.9%?\"\n",
    "\n",
    "**Why This Works**: The candidate demonstrates structured thinking, doesn't make assumptions, and establishes concrete constraints before designing.\n",
    "\n",
    "### **Phase 2: SKETCH (Back-of-the-Envelope Estimation)**\n",
    "\n",
    "**The Goal**: Prove the system is feasible and guide architectural decisions with rough calculations.\n",
    "\n",
    "**Key Numbers to Memorize**:\n",
    "```\n",
    "Latency:\n",
    "- L1 cache reference: 0.5 ns\n",
    "- Main memory reference: 100 ns\n",
    "- SSD read: 100 \u00b5s\n",
    "- Network (same datacenter): 0.5 ms\n",
    "- Network (cross-country): 50 ms\n",
    "- Network (intercontinental): 150 ms\n",
    "\n",
    "Throughput:\n",
    "- Sequential disk read: 200 MB/s\n",
    "- SSD read: 500 MB/s\n",
    "- 1 Gbps network: 125 MB/s\n",
    "- 10 Gbps network: 1.25 GB/s\n",
    "\n",
    "Scale:\n",
    "- 1 million seconds \u2248 11.5 days\n",
    "- 1 billion seconds \u2248 31.7 years\n",
    "```\n",
    "\n",
    "**Estimation Example: URL Shortener**\n",
    "\n",
    "> **Candidate**: \"Let me estimate the scale. We said 100 million new URLs per month, 10 billion redirects.\n",
    ">\n",
    "> **Write throughput**: 100M/month \u00f7 30 days \u00f7 86400 seconds \u2248 40 URLs/second. Peak might be 5x, so 200 writes/second.\n",
    ">\n",
    "> **Read throughput**: 10B/month \u00f7 2.6M seconds \u2248 4000 reads/second. Peak 20,000/second.\n",
    ">\n",
    "> **Storage**: Assuming average URL is 500 bytes (original) + 50 bytes (short URL) + 100 bytes (metadata) = 650 bytes per URL.\n",
    "> 100M URLs/month \u00d7 650 bytes \u00d7 12 months \u00d7 5 years retention = ~4 TB of URL mappings.\n",
    ">\n",
    "> **Bandwidth**: 20,000 redirects/second \u00d7 500 bytes average = 10 MB/s = 80 Mbps. Well within 1 Gbps.\n",
    ">\n",
    "> So we need a system handling 200 writes/second, 20,000 reads/second, storing 4 TB. This is well within single-server capabilities, but for high availability, I'll design for distributed deployment.\"\n",
    "\n",
    "**Why This Matters**: These numbers tell us:\n",
    "- We need caching (20,000 reads/second)\n",
    "- Writes are low enough for any database\n",
    "- Storage is manageable (4 TB fits on one SSD)\n",
    "- We need multiple regions for global latency\n",
    "\n",
    "### **Phase 3: SOLIDIFY (Data Model and API Design)**\n",
    "\n",
    "**The Goal**: Define the contracts\u2014how data is stored and how clients interact with the system.\n",
    "\n",
    "**Database Schema Design**:\n",
    "\n",
    "For the URL shortener:\n",
    "```sql\n",
    "-- URL mappings table\n",
    "CREATE TABLE url_mappings (\n",
    "    short_code VARCHAR(10) PRIMARY KEY,  -- 'abc123'\n",
    "    long_url TEXT NOT NULL,             -- 'https://example.com/very/long/url'\n",
    "    created_at TIMESTAMP DEFAULT NOW(),\n",
    "    expires_at TIMESTAMP,                -- NULL = never expires\n",
    "    user_id UUID,                        -- Who created it\n",
    "    click_count BIGINT DEFAULT 0         -- Cached for fast lookup\n",
    ");\n",
    "\n",
    "-- Analytics table (time-series)\n",
    "CREATE TABLE click_analytics (\n",
    "    id BIGSERIAL PRIMARY KEY,\n",
    "    short_code VARCHAR(10) REFERENCES url_mappings(short_code),\n",
    "    clicked_at TIMESTAMP DEFAULT NOW(),\n",
    "    ip_address INET,\n",
    "    user_agent TEXT,\n",
    "    referrer TEXT,\n",
    "    country_code CHAR(2)\n",
    ");\n",
    "\n",
    "-- Indexes for common queries\n",
    "CREATE INDEX idx_analytics_shortcode_time ON click_analytics(short_code, clicked_at);\n",
    "CREATE INDEX idx_analytics_country ON click_analytics(country_code) WHERE clicked_at > NOW() - INTERVAL '7 days';\n",
    "```\n",
    "\n",
    "**API Design (RESTful)**:\n",
    "\n",
    "```yaml\n",
    "# URL Shortener API\n",
    "\n",
    "POST /api/v1/urls\n",
    "Request:\n",
    "  {\n",
    "    \"long_url\": \"https://example.com/very/long/path?query=param\",\n",
    "    \"custom_alias\": \"mylink\",  # Optional\n",
    "    \"expires_in_days\": 30      # Optional, default 365\n",
    "  }\n",
    "\n",
    "Response 201:\n",
    "  {\n",
    "    \"short_code\": \"mylink\",\n",
    "    \"short_url\": \"https://short.io/mylink\",\n",
    "    \"long_url\": \"https://example.com/very/long/path?query=param\",\n",
    "    \"created_at\": \"2024-01-15T10:30:00Z\",\n",
    "    \"expires_at\": \"2024-02-14T10:30:00Z\"\n",
    "  }\n",
    "\n",
    "Response 409:\n",
    "  {\n",
    "    \"error\": \"Custom alias already exists\",\n",
    "    \"suggested_aliases\": [\"mylink123\", \"mylink2024\"]\n",
    "  }\n",
    "\n",
    "---\n",
    "\n",
    "GET /{short_code}\n",
    "Response 302:\n",
    "  Location: https://example.com/very/long/path?query=param\n",
    "  \n",
    "  (Also logs analytics asynchronously)\n",
    "\n",
    "Response 404:\n",
    "  {\n",
    "    \"error\": \"Short URL not found or expired\"\n",
    "  }\n",
    "\n",
    "---\n",
    "\n",
    "GET /api/v1/urls/{short_code}/analytics\n",
    "Query params:\n",
    "  - start_date: ISO 8601\n",
    "  - end_date: ISO 8601\n",
    "  - granularity: hour | day | month\n",
    "\n",
    "Response:\n",
    "  {\n",
    "    \"short_code\": \"mylink\",\n",
    "    \"total_clicks\": 15420,\n",
    "    \"unique_visitors\": 12300,\n",
    "    \"clicks_by_country\": {\n",
    "      \"US\": 8000,\n",
    "      \"UK\": 3000,\n",
    "      \"DE\": 2000\n",
    "    },\n",
    "    \"clicks_over_time\": [\n",
    "      {\"timestamp\": \"2024-01-15T10:00:00Z\", \"clicks\": 150},\n",
    "      {\"timestamp\": \"2024-01-15T11:00:00Z\", \"clicks\": 230}\n",
    "    ],\n",
    "    \"top_referrers\": [\n",
    "      {\"url\": \"https://twitter.com\", \"clicks\": 5000},\n",
    "      {\"url\": \"https://facebook.com\", \"clicks\": 3000}\n",
    "    ]\n",
    "  }\n",
    "```\n",
    "\n",
    "### **Phase 4: SCALE (High-Level Design and Deep Dives)**\n",
    "\n",
    "**The Goal**: Draw the architecture, identify bottlenecks, and demonstrate how to scale.\n",
    "\n",
    "**High-Level Architecture Diagram**:\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                         DNS                                  \u2502\n",
    "\u2502              (GeoDNS: Route to nearest region)              \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                              \u2193\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                      CDN (CloudFront)                        \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n",
    "\u2502  \u2502 Static Assets\u2502  \u2502 Cached       \u2502  \u2502 Edge         \u2502       \u2502\n",
    "\u2502  \u2502 (JS, CSS)    \u2502  \u2502 Redirects    \u2502  \u2502 Logic        \u2502       \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                              \u2193\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                   Load Balancer (ALB/NGINX)                  \u2502\n",
    "\u2502              Health checks, SSL termination                  \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                              \u2193\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                 Application Servers (Auto-scaling)           \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n",
    "\u2502  \u2502 API      \u2502  \u2502 URL      \u2502  \u2502 Analytics\u2502  \u2502 Health   \u2502     \u2502\n",
    "\u2502  \u2502 Handler  \u2502  \u2502 Generator\u2502  \u2502 Worker   \u2502  \u2502 Check    \u2502     \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n",
    "\u2502                                                              \u2502\n",
    "\u2502  Stateless, horizontal scaling (10-1000 instances)          \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                              \u2193\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    Caching Layer (Redis Cluster)               \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n",
    "\u2502  \u2502 URL Mappings \u2502  \u2502 Rate Limit   \u2502  \u2502 Session      \u2502       \u2502\n",
    "\u2502  \u2502 (short\u2192long) \u2502  \u2502 Counters   \u2502  \u2502 Cache        \u2502       \u2502\n",
    "\u2502  \u2502 TTL: 24h     \u2502  \u2502 TTL: 1h    \u2502  \u2502 TTL: 1h      \u2502       \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n",
    "\u2502                                                              \u2502\n",
    "\u2502  Cache hit: <1ms, Cache miss: Query database                 \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                              \u2193\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                 Primary Database (PostgreSQL/MySQL)          \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n",
    "\u2502  \u2502  URL Mappings Table (sharded by short_code hash)    \u2502    \u2502\n",
    "\u2502  \u2502  - short_code (PK)                                   \u2502    \u2502\n",
    "\u2502  \u2502  - long_url (indexed)                                \u2502    \u2502\n",
    "\u2502  \u2502  - created_at, expires_at                           \u2502    \u2502\n",
    "\u2502  \u2502  - user_id, click_count                               \u2502    \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n",
    "\u2502                                                              \u2502\n",
    "\u2502  Read replicas: 3 (for read scaling)                        \u2502\n",
    "\u2502  Write capacity: 2000 TPS                                   \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                              \u2193\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502              Analytics Pipeline (Kafka \u2192 ClickHouse)         \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n",
    "\u2502  \u2502 Kafka    \u2502 \u2192  \u2502 Flink    \u2502 \u2192  \u2502 ClickHouse\u2502             \u2502\n",
    "\u2502  \u2502 (Raw     \u2502    \u2502 (Enrich, \u2502    \u2502 (Analytics\u2502             \u2502\n",
    "\u2502  \u2502  clicks) \u2502    \u2502  Window) \u2502    \u2502  DB)      \u2502             \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n",
    "\u2502                                                              \u2502\n",
    "\u2502  Real-time dashboards, hourly reports, billing             \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**Deep Dive: Database Sharding Strategy**\n",
    "\n",
    "> **Interviewer**: \"How would you shard the database if you exceed single-node capacity?\"\n",
    "\n",
    "> **Candidate**: \"Currently we're at 4TB with 5 years of data. If we grow 10x, we'd need to shard. I'd use hash-based sharding on `short_code` because:\n",
    "> \n",
    "> 1. **Even distribution**: Short codes are random, so hash mod N gives uniform distribution\n",
    "> 2. **Direct lookup**: Given a short code, we know exactly which shard to query\n",
    "> 3. **No hot spots**: Unlike range sharding on time (recent data is hot), hash spreads load\n",
    "> \n",
    "> Implementation: `shard_id = hash(short_code) % num_shards`\n",
    "> \n",
    "> For cross-shard operations (analytics), we'd aggregate results from all shards or use a separate OLAP database (ClickHouse) fed by CDC (Change Data Capture).\"\n",
    "\n",
    "**Deep Dive: Cache Eviction Strategy**\n",
    "\n",
    "> **Interviewer**: \"What happens when the cache is full and a new popular URL emerges?\"\n",
    "\n",
    "> **Candidate**: \"We'd use an LRU (Least Recently Used) eviction policy with some modifications:\n",
    ">\n",
    "> 1. **Tiered caching**: Hot URLs (top 1%) in L1 (in-memory), warm in L2 (Redis), cold in DB\n",
    "> 2. **TTL variation**: Popular URLs get longer TTL (24h), unpopular shorter (1h)\n",
    "> 3. **Pre-warming**: When cache miss occurs, we don't just cache that one URL; we cache related URLs (same user, same domain) anticipating they'll be accessed\n",
    "> 4. **Write-through**: Database write and cache update happen atomically to prevent inconsistency\"\n",
    "\n",
    "---\n",
    "\n",
    "## **25.2 The Art of Drawing Architecture Diagrams**\n",
    "\n",
    "Your diagrams are your primary communication tool. A good diagram conveys the architecture instantly; a bad one confuses the interviewer.\n",
    "\n",
    "### **Diagramming Principles**\n",
    "\n",
    "**1. Layered Layout**\n",
    "```\n",
    "Top:    Clients (Web, Mobile, Third-party)\n",
    "        \u2193\n",
    "Middle: API Gateway, Load Balancers, Application Logic\n",
    "        \u2193\n",
    "Bottom: Data Layer (Caches, Databases, Storage)\n",
    "```\n",
    "\n",
    "**2. Direction of Flow**\n",
    "- Left-to-right for request flow\n",
    "- Top-to-bottom for dependency hierarchy\n",
    "- Arrows indicate data direction\n",
    "\n",
    "**3. Grouping**\n",
    "- Use boxes to group related components (e.g., \"Availability Zone A\")\n",
    "- Color coding (if digital) or line styles (if whiteboard) for different service types\n",
    "\n",
    "### **Whiteboard Technique**\n",
    "\n",
    "Since most interviews use whiteboards (physical or virtual):\n",
    "\n",
    "**Step 1: Start with the Client**\n",
    "```\n",
    "[User/Browser] \u2192 ?\n",
    "```\n",
    "\n",
    "**Step 2: Add the Entry Point**\n",
    "```\n",
    "[User] \u2192 [DNS] \u2192 [CDN] \u2192 [Load Balancer] \u2192 ?\n",
    "```\n",
    "\n",
    "**Step 3: Build the Core**\n",
    "```\n",
    "... \u2192 [LB] \u2192 [App Servers] \u2192 [Cache] \u2192 [Database]\n",
    "                \u2193\n",
    "           [Message Queue] \u2192 [Workers]\n",
    "```\n",
    "\n",
    "**Step 4: Add Data Flows**\n",
    "- Solid lines: Synchronous requests\n",
    "- Dashed lines: Asynchronous/background\n",
    "- Double arrows: Two-way communication\n",
    "\n",
    "**Step 5: Annotate**\n",
    "Write key metrics next to components:\n",
    "```\n",
    "[Redis Cluster]\n",
    "- 99th percentile: 1ms\n",
    "- Hit rate: 95%\n",
    "- Size: 100GB\n",
    "```\n",
    "\n",
    "### **Common Diagramming Mistakes**\n",
    "\n",
    "1. **The \"Spaghetti\"**: Crossing lines everywhere. Use layers to organize.\n",
    "2. **The \"Monolith\"**: One box labeled \"The System.\" Break it down.\n",
    "3. **Missing Data Stores**: Showing logic but forgetting where data lives.\n",
    "4. **Scale Ambiguity**: Not indicating if components are single instances or clusters.\n",
    "5. **Over-engineering**: Drawing Kubernetes clusters when a single server suffices.\n",
    "\n",
    "---\n",
    "\n",
    "## **25.3 Communication Strategies**\n",
    "\n",
    "### **Thinking Out Loud**\n",
    "\n",
    "Your internal monologue should be external. The interviewer can't read your mind.\n",
    "\n",
    "**Bad**: *Silence for 2 minutes while drawing, then \"So we use a hash ring.\"*\n",
    "\n",
    "**Good**: \"I'm considering how to distribute data across servers. Consistent hashing would work well here because it minimizes data movement when we add nodes. Let me draw that...\"\n",
    "\n",
    "### **Handling Uncertainty**\n",
    "\n",
    "When you don't know something:\n",
    "\n",
    "**Don't**: Guess confidently or pretend you know.\n",
    "**Do**: Acknowledge, reason from first principles, and offer to research.\n",
    "\n",
    "> \"I'm not intimately familiar with Cassandra's compaction strategy, but I know LSM trees generally merge sorted files in the background. For this design, I'd need to verify if Cassandra's write amplification fits our SSD endurance requirements, or if we should consider RocksDB instead. For now, I'll assume we can achieve our write throughput targets.\"\n",
    "\n",
    "### **Managing Time**\n",
    "\n",
    "45-60 minutes goes fast. Check your watch or ask about time.\n",
    "\n",
    "**Time Checkpoints**:\n",
    "- 0-5 min: Requirements complete\n",
    "- 5-15 min: Estimation and high-level design\n",
    "- 15-35 min: Deep dives (database sharding, caching strategy)\n",
    "- 35-50 min: Trade-offs, failure scenarios, monitoring\n",
    "- 50-60 min: Questions for interviewer\n",
    "\n",
    "If running behind: \"I see we have 10 minutes left. Rather than diving into the replication protocol, let me summarize the architecture and discuss how we'd handle a datacenter failure. Does that work?\"\n",
    "\n",
    "---\n",
    "\n",
    "## **25.4 The System Design Checklist**\n",
    "\n",
    "Before saying you're done, verify you've covered:\n",
    "\n",
    "### **Functional Requirements**\n",
    "- [ ] Core features implemented\n",
    "- [ ] API endpoints defined with request/response formats\n",
    "- [ ] Edge cases handled (duplicate requests, invalid inputs)\n",
    "\n",
    "### **Non-Functional Requirements**\n",
    "- [ ] Latency targets met (p50, p99 specified)\n",
    "- [ ] Throughput calculated (QPS, bandwidth)\n",
    "- [ ] Availability SLA (99.9%, 99.99%)\n",
    "- [ ] Durability guarantees (data loss tolerance)\n",
    "\n",
    "### **Data Layer**\n",
    "- [ ] Schema designed (SQL/NoSQL choice justified)\n",
    "- [ ] Sharding strategy (if needed)\n",
    "- [ ] Replication factor and consistency level\n",
    "- [ ] Caching strategy (what to cache, eviction policy)\n",
    "\n",
    "### **Scalability**\n",
    "- [ ] Horizontal scaling path (stateless services)\n",
    "- [ ] Load balancing strategy\n",
    "- [ ] Auto-scaling triggers\n",
    "- [ ] Database scaling (read replicas, sharding)\n",
    "\n",
    "### **Reliability**\n",
    "- [ ] Single points of failure eliminated\n",
    "- [ ] Circuit breakers for external dependencies\n",
    "- [ ] Retry strategies with exponential backoff\n",
    "- [ ] Dead letter queues for failed operations\n",
    "\n",
    "### **Monitoring**\n",
    "- [ ] Metrics to track (QPS, latency, errors)\n",
    "- [ ] Alerting thresholds\n",
    "- [ ] Logging strategy (what to log, retention)\n",
    "- [ ] Distributed tracing for request flow\n",
    "\n",
    "### **Security**\n",
    "- [ ] Authentication (who can access)\n",
    "- [ ] Authorization (what they can do)\n",
    "- [ ] Data encryption (at rest and in transit)\n",
    "- [ ] Input validation and sanitization\n",
    "\n",
    "---\n",
    "\n",
    "## **25.5 Common Pitfalls and How to Avoid Them**\n",
    "\n",
    "### **Pitfall 1: Jumping to Solutions**\n",
    "**Mistake**: Starting with \"We'll use Kubernetes and microservices...\"\n",
    "**Fix**: Always start with requirements. The best architecture depends on constraints.\n",
    "\n",
    "### **Pitfall 2: Over-engineering**\n",
    "**Mistake**: Designing for 1 billion users when the requirement is 1 million.\n",
    "**Fix**: Design for 10x current scale, but mention how to evolve. \"For phase 1, a single PostgreSQL instance handles 10,000 QPS. When we exceed that, we'll shard by user_id...\"\n",
    "\n",
    "### **Pitfall 3: Ignoring Failure Modes**\n",
    "**Mistake**: \"The database never goes down.\"\n",
    "**Fix**: Explicitly discuss failure scenarios. \"If the primary database fails, the replica promotes automatically within 30 seconds. During that window, we serve stale cache data...\"\n",
    "\n",
    "### **Pitfall 4: Neglecting the Data Model**\n",
    "**Mistake**: Detailed discussion of load balancers but vague hand-waving about \"the database.\"\n",
    "**Fix**: Spend time on schema design. Draw the tables, explain primary keys, discuss indexes.\n",
    "\n",
    "### **Pitfall 5: Silent Assumptions**\n",
    "**Mistake**: Assuming the interviewer knows why you chose a technology.\n",
    "**Fix**: Explain trade-offs. \"I'm choosing Cassandra over PostgreSQL because we need write-heavy workload with tunable consistency, though this sacrifices complex query capabilities...\"\n",
    "\n",
    "---\n",
    "\n",
    "## **25.6 Sample Interview Walkthrough**\n",
    "\n",
    "**Question**: \"Design a rate limiter for an API.\"\n",
    "\n",
    "### **SCOPE (5 minutes)**\n",
    "\n",
    "> \"Let me clarify the requirements. For functional requirements, I'm assuming:\n",
    "> - Limit requests per user per time window (e.g., 100 requests/minute)\n",
    "> - Return 429 status when limit exceeded\n",
    "> - Support different limits for different API tiers (free vs. paid)\n",
    "> - Distributed across multiple API servers\n",
    ">\n",
    "> For non-functional:\n",
    "> - Latency: Check should add <1ms overhead\n",
    "> - Accuracy: Can tolerate slight over-limit (sliding window approximation)\n",
    "> - Availability: Rate limiter shouldn't block API if it fails (fail open)\n",
    ">\n",
    "> Does that cover the main requirements, or are there specific algorithms you'd like me to focus on?\"\n",
    "\n",
    "### **SKETCH (10 minutes)**\n",
    "\n",
    "> \"Let me estimate the scale. Assuming:\n",
    "> - 10,000 API servers\n",
    "> - 1 million active users\n",
    "> - Average 10 requests/user/minute = 10 million requests/minute \u2248 170,000 QPS\n",
    ">\n",
    "> Storage: We need to track counters per user per window.\n",
    "> - User ID: 16 bytes\n",
    "> - Window timestamp: 8 bytes\n",
    "> - Counter: 4 bytes\n",
    "> - 1M users \u00d7 28 bytes \u2248 28 MB per time window\n",
    "> - With 1-minute windows and 1-hour retention: 28 MB \u00d7 60 = 1.68 GB\n",
    ">\n",
    "> This fits easily in memory. I'll use Redis for fast counter increments with TTL.\"\n",
    "\n",
    "### **SOLIDIFY (15 minutes)**\n",
    "\n",
    "> \"For the algorithm, I'll use the **Sliding Window Counter** approach for better accuracy than fixed windows, without the memory cost of true sliding windows.\n",
    ">\n",
    "> **Data Model**:\n",
    "> - Key: `rate_limit:{user_id}:{api_tier}:{minute_bucket}`\n",
    "> - Value: counter (integer)\n",
    "> - TTL: 2 minutes (covers current and previous window)\n",
    ">\n",
    "> **API Design**:\n",
    "> ```python\n",
    "> def check_rate_limit(user_id, tier='free'):\n",
    ">     current_minute = time.time() // 60\n",
    ">     current_key = f\"rate_limit:{user_id}:{tier}:{current_minute}\"\n",
    ">     prev_key = f\"rate_limit:{user_id}:{tier}:{current_minute-1}\"\n",
    ">     \n",
    ">     limits = {'free': 100, 'pro': 1000, 'enterprise': 10000}\n",
    ">     limit = limits[tier]\n",
    ">     \n",
    ">     # Get current and previous window counts\n",
    ">     current_count = redis.get(current_key) or 0\n",
    ">     prev_count = redis.get(prev_key) or 0\n",
    ">     \n",
    ">     # Weighted sum: 60% current window + 40% previous\n",
    ">     # This approximates sliding window without storing every request\n",
    ">     estimated = 0.6 * current_count + 0.4 * prev_count\n",
    ">     \n",
    ">     if estimated >= limit:\n",
    ">         return False, 429  # Too many requests\n",
    ">     \n",
    ">     # Increment current window\n",
    ">     pipe = redis.pipeline()\n",
    ">     pipe.incr(current_key)\n",
    ">     pipe.expire(current_key, 120)  # 2 minute TTL\n",
    ">     pipe.execute()\n",
    ">     \n",
    ">     return True, 200\n",
    "> ```\n",
    ">\n",
    "> **Why this works**:\n",
    "> - Redis INCR is atomic (no race conditions)\n",
    "> - Pipeline reduces round trips to 1\n",
    "> - Weighted window prevents burst attacks at window boundaries\n",
    "> - TTL auto-cleans old data\"\n",
    "\n",
    "### **SCALE (20 minutes)**\n",
    "\n",
    "> \"For high availability, I'll deploy Redis in cluster mode with 3 master nodes and 3 replicas. If a master fails, replica promotes automatically.\n",
    ">\n",
    "> **Bottleneck Analysis**:\n",
    "> 1. **Redis CPU**: 170k QPS might saturate single Redis node. I'll shard by user_id hash across 10 Redis clusters.\n",
    "> 2. **Network**: 170k QPS \u00d7 100 bytes = 17 MB/s, well within 1 Gbps.\n",
    "> 3. **Memory**: 1.68 GB per cluster \u00d7 10 = 16.8 GB total, reasonable.\n",
    ">\n",
    "> **Failure Scenarios**:\n",
    "> - **Redis down**: Fail open (allow request) rather than block API. Log for later analysis.\n",
    "> - **Network partition**: Device continues with local cache of rate limits, syncs when reconnected.\n",
    "> - **Hot key**: One user gets huge traffic. Use local in-app caching for rate limit checks to reduce Redis load.\n",
    ">\n",
    "> **Monitoring**:\n",
    "> - Metrics: Rate limit hits/misses, Redis latency, 429 error rate\n",
    "> - Alerts: Redis memory >80%, rate check latency >5ms, sudden spike in 429s (possible attack)\n",
    ">\n",
    "> **Trade-offs**:\n",
    "> - I chose sliding window counter over token bucket for better user experience (no burst allowance at window start), at cost of slightly more memory.\n",
    "> - I chose Redis over in-memory for horizontal scaling, accepting network latency penalty.\n",
    "> - I chose weighted window over true sliding window for O(1) memory vs O(window_size) memory.\"\n",
    "\n",
    "---\n",
    "\n",
    "## **25.7 Key Takeaways**\n",
    "\n",
    "1. **Structure beats improvisation**: The 4S framework (Scope, Sketch, Solidify, Scale) ensures you cover all dimensions systematically.\n",
    "\n",
    "2. **Requirements first, solutions second**: Never start with \"We'll use Kubernetes.\" Start with \"We need to handle 10k QPS with 100ms latency.\"\n",
    "\n",
    "3. **Show your work**: Explain why you chose Redis over Memcached, or sharding over replication. The reasoning matters more than the choice.\n",
    "\n",
    "4. **Estimate confidently**: Use round numbers, state assumptions clearly, and sanity-check results (\"4TB for 5 years of URLs sounds reasonable\").\n",
    "\n",
    "5. **Address the constraints**: Every design has trade-offs. Explicitly discuss consistency vs. availability, latency vs. cost, complexity vs. maintainability.\n",
    "\n",
    "6. **Plan for failure**: The best designs include circuit breakers, fallbacks, and graceful degradation. Never assume 100% uptime.\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "This chapter transformed technical knowledge into interview performance. We established the 4S framework as a narrative structure for any design question. We practiced requirements gathering, back-of-the-envelope calculations, and API design. We walked through a complete rate limiter example, demonstrating how to discuss trade-offs, failure modes, and monitoring.\n",
    "\n",
    "The key insight: The interviewer is evaluating your thought process, not your memory. A candidate who explains why they chose eventual consistency with clear reasoning scores higher than one who recites CAP theorem without context.\n",
    "\n",
    "**Coming up next**: In Chapter 26, we'll put it all together with detailed walkthroughs of 10 classic system design problems, showing exactly how to apply the 4S framework to the most common interview questions.\n",
    "\n",
    "---\n",
    "\n",
    "## **Exercises**\n",
    "\n",
    "1. **Mock Interview Practice**: Record yourself designing a chat application for 15 minutes using the 4S framework. Watch the recording and check:\n",
    "   - Did you ask clarifying questions before designing?\n",
    "   - Did you estimate scale before choosing technologies?\n",
    "   - Did you explain trade-offs when selecting databases?\n",
    "   - Did you discuss failure scenarios?\n",
    "\n",
    "2. **Estimation Drills**: Practice these back-of-the-envelope calculations:\n",
    "   - Design Twitter: 500M daily active users, 500M tweets/day. Calculate storage for 5 years, QPS for home timeline, and cache size.\n",
    "   - Design Uber: 100M monthly users, 10M trips/day. Calculate GPS update frequency, storage for location history, and matching algorithm QPS.\n",
    "\n",
    "3. **Trade-off Analysis**: For each pair, argue for each side:\n",
    "   - SQL vs. NoSQL for a social media feed\n",
    "   - Strong consistency vs. eventual consistency for shopping cart\n",
    "   - Microservices vs. monolith for a startup's MVP\n",
    "   - Kafka vs. RabbitMQ for event streaming\n",
    "\n",
    "4. **Failure Scenario Planning**: Pick any system you've designed. List:\n",
    "   - 3 single points of failure and how to eliminate them\n",
    "   - What happens when the primary database crashes\n",
    "   - How to handle a 10x traffic spike in 5 minutes\n",
    "   - Recovery procedure for a corrupted cache\n",
    "\n",
    "5. **API Design**: Design the API for a distributed rate limiter that works across multiple data centers with shared state. Include endpoints for checking limits, querying current quota, and admin override. Specify request/response formats and error codes.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='../8. Advanced_topics_and_emerging_patterns/24. edge_computing_and_iot.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='26. mock_interviews_and_solutions.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}