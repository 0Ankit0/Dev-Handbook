{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3a3e07",
   "metadata": {},
   "source": [
    "# **Chapter 19: Observability & Monitoring**\n",
    "\n",
    "You cannot fix what you cannot see. In distributed systems, where a single request might traverse fifty microservices across three availability zones, understanding system behavior requires more than checking if a server is \"up.\" Observability—the ability to infer internal system state from external outputs—is the foundation of reliability engineering.\n",
    "\n",
    "This chapter covers the Three Pillars of Observability, modern tooling stacks, and the Site Reliability Engineering (SRE) practices that separate amateur operations from enterprise-grade reliability.\n",
    "\n",
    "---\n",
    "\n",
    "## **19.1 The Three Pillars of Observability**\n",
    "\n",
    "Observability rests on three distinct data types: **Metrics** (numbers over time), **Logs** (discrete events), and **Traces** (request flows). Used together, they transform opaque distributed systems into debuggable, optimizable infrastructure.\n",
    "\n",
    "### **Pillar 1: Metrics—The Numerical Backbone**\n",
    "\n",
    "**What they are**: Time-series numerical data points (e.g., \"CPU usage was 45% at 10:30 AM\").\n",
    "\n",
    "**Key Characteristics**:\n",
    "- **Aggregatable**: You can sum, average, or percentile them\n",
    "- **Low cardinality**: Limited distinct values (hundreds of status codes, not millions of user IDs)\n",
    "- **Efficient**: Cheap to store and query at scale\n",
    "- **Dimensional**: Tagged with metadata (e.g., `http_requests_total{method=\"POST\",status=\"500\",endpoint=\"/api/users\"}`)\n",
    "\n",
    "**The RED Method** (For services—what users experience):\n",
    "```\n",
    "Rate: Requests per second\n",
    "Errors: Percentage of failed requests  \n",
    "Duration: Distribution of request latencies (p50, p95, p99)\n",
    "```\n",
    "\n",
    "**The USE Method** (For resources—what infrastructure experiences):\n",
    "```\n",
    "Utilization: Percentage of resource busy (CPU, memory, disk)\n",
    "Saturation: Queue length or work backlog (threads waiting)\n",
    "Errors: Count of error events (disk failures, network drops)\n",
    "```\n",
    "\n",
    "**Metric Types**:\n",
    "1. **Counters**: Monotonically increasing (total requests, bytes sent)\n",
    "   ```prometheus\n",
    "   # HELP http_requests_total Total HTTP requests\n",
    "   # TYPE http_requests_total counter\n",
    "   http_requests_total{method=\"GET\",status=\"200\"} 1425\n",
    "   http_requests_total{method=\"POST\",status=\"500\"} 3\n",
    "   ```\n",
    "\n",
    "2. **Gauges**: Arbitrary values that go up and down (temperature, queue depth, memory usage)\n",
    "   ```prometheus\n",
    "   # HELP queue_length Current items in processing queue\n",
    "   # TYPE queue_length gauge\n",
    "   queue_length{queue=\"payment\"} 42\n",
    "   ```\n",
    "\n",
    "3. **Histograms**: Distribution of values into buckets (request durations)\n",
    "   ```prometheus\n",
    "   # HELP http_request_duration_seconds Request latency\n",
    "   # TYPE http_request_duration_seconds histogram\n",
    "   http_request_duration_seconds_bucket{le=\"0.1\"} 240\n",
    "   http_request_duration_seconds_bucket{le=\"0.5\"} 489\n",
    "   http_request_duration_seconds_bucket{le=\"1.0\"} 567\n",
    "   http_request_duration_seconds_sum 186.4\n",
    "   http_request_duration_seconds_count 600\n",
    "   ```\n",
    "\n",
    "**Cardinality—The Hidden Killer**:\n",
    "Cardinality = number of unique time series. Each unique combination of labels creates a new series.\n",
    "\n",
    "```\n",
    "Good: http_requests_total{status=\"200\",method=\"GET\"}  // 10s of series\n",
    "Bad:  http_requests_total{user_id=\"12345\",session_id=\"abc\"} // Millions of series\n",
    "```\n",
    "\n",
    "High cardinality (millions of unique label combinations) explodes storage costs and query latency. Never put unbounded dimensions (user IDs, order IDs) in metric labels.\n",
    "\n",
    "---\n",
    "\n",
    "### **Pillar 2: Logs—The Event Narrative**\n",
    "\n",
    "**What they are**: Immutable, timestamped records of discrete events. Logs tell the story of what happened.\n",
    "\n",
    "**Structured vs. Unstructured**:\n",
    "```\n",
    "Unstructured (Hard to query):\n",
    "127.0.0.1 - - [15/Jan/2024:10:30:00 +0000] \"GET /api/users HTTP/1.1\" 200 42\n",
    "\n",
    "Structured (JSON—queryable):\n",
    "{\n",
    "  \"timestamp\": \"2024-01-15T10:30:00Z\",\n",
    "  \"level\": \"INFO\",\n",
    "  \"service\": \"user-service\",\n",
    "  \"trace_id\": \"abc123\",\n",
    "  \"span_id\": \"def456\",\n",
    "  \"http_method\": \"GET\",\n",
    "  \"path\": \"/api/users\",\n",
    "  \"status_code\": 200,\n",
    "  \"duration_ms\": 42,\n",
    "  \"user_agent\": \"Mozilla/5.0...\",\n",
    "  \"message\": \"Request processed successfully\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Log Levels** (Severity hierarchy):\n",
    "- **DEBUG**: Detailed diagnostic information (development only)\n",
    "- **INFO**: Normal operational messages (requests handled, state changes)\n",
    "- **WARN**: Unexpected but handled conditions (retries, degraded performance)\n",
    "- **ERROR**: Failed operations that didn't crash the service (DB connection lost, handled exception)\n",
    "- **FATAL**: Service cannot continue (out of memory, corrupted state)\n",
    "\n",
    "**Correlation IDs** (Distributed Tracing Precursor):\n",
    "Every request gets a unique ID propagated through all services:\n",
    "```\n",
    "Client Request → API Gateway → User Service → Database\n",
    "   [req_abc]      [req_abc]      [req_abc]    [req_abc]\n",
    "   \n",
    "All logs contain: \"trace_id\": \"req_abc\"\n",
    "Query: `trace_id=\"req_abc\"` returns complete request flow across services\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Pillar 3: Traces—The Request Journey**\n",
    "\n",
    "**What they are**: End-to-end latency breakdowns showing exactly where time is spent in distributed systems.\n",
    "\n",
    "**Anatomy of a Trace**:\n",
    "```\n",
    "Trace (User Checkout Request)\n",
    "├── Span 1: API Gateway (Total: 250ms)\n",
    "│   ├── Span 2: Auth Service (15ms)\n",
    "│   ├── Span 3: Cart Service (80ms)\n",
    "│   │   ├── Span 4: Redis (5ms)\n",
    "│   │   └── Span 5: Database (70ms)\n",
    "│   ├── Span 6: Payment Service (120ms)\n",
    "│   │   ├── Span 7: Stripe API (100ms)\n",
    "│   │   └── Span 8: Database Update (15ms)\n",
    "│   └── Span 9: Email Service (30ms)\n",
    "```\n",
    "\n",
    "**Key Concepts**:\n",
    "- **Trace ID**: Unique identifier for the entire request tree\n",
    "- **Span**: A single operation within the trace (has start time, duration, parent reference)\n",
    "- **Baggage**: Context propagated with the trace (user tier, AB test group)\n",
    "- **Sampling**: Only recording 1% or 0.1% of traces to manage volume\n",
    "\n",
    "**Critical Path Analysis**:\n",
    "In the trace above, the critical path is: Gateway → Cart → Payment → Stripe. Optimizing the Email Service (30ms) won't reduce total latency because it likely runs async or in parallel. Optimizing Stripe calls (100ms) or Cart DB (70ms) will.\n",
    "\n",
    "---\n",
    "\n",
    "## **19.2 Monitoring Infrastructure**\n",
    "\n",
    "### **Prometheus—The Metrics Standard**\n",
    "\n",
    "Prometheus is the de facto standard for cloud-native monitoring, using a pull-based model and powerful query language (PromQL).\n",
    "\n",
    "**Architecture**:\n",
    "```\n",
    "┌─────────────┐     ┌──────────────┐     ┌─────────────┐\n",
    "│   Targets   │     │  Prometheus  │     │   Grafana   │\n",
    "│  (Your Apps)│◄────│   Server    │────►│  (Dashboards)│\n",
    "└─────────────┘     └──────────────┘     └─────────────┘\n",
    "       ▲                   │\n",
    "       │                   ▼\n",
    "       │            ┌──────────────┐\n",
    "       └────────────│   Alert      │\n",
    "                    │   Manager    │\n",
    "                    └──────────────┘\n",
    "```\n",
    "\n",
    "**Instrumentation** (Code example):\n",
    "```python\n",
    "from prometheus_client import Counter, Histogram, start_http_server\n",
    "\n",
    "# Metrics definitions\n",
    "REQUEST_COUNT = Counter('http_requests_total', 'Total requests', ['method', 'status'])\n",
    "REQUEST_DURATION = Histogram('http_request_duration_seconds', 'Request latency', ['endpoint'])\n",
    "\n",
    "# Application code\n",
    "@app.route('/api/users')\n",
    "def get_users():\n",
    "    start = time.time()\n",
    "    try:\n",
    "        users = db.query_users()\n",
    "        REQUEST_COUNT.labels(method='GET', status='200').inc()\n",
    "        return jsonify(users)\n",
    "    except Exception as e:\n",
    "        REQUEST_COUNT.labels(method='GET', status='500').inc()\n",
    "        raise\n",
    "    finally:\n",
    "        duration = time.time() - start\n",
    "        REQUEST_DURATION.labels(endpoint='/api/users').observe(duration)\n",
    "\n",
    "# Expose metrics on port 8000\n",
    "start_http_server(8000)\n",
    "```\n",
    "\n",
    "**Service Discovery**:\n",
    "Prometheus doesn't use static configs. It discovers targets via:\n",
    "- **Kubernetes**: Auto-discover pods with specific annotations\n",
    "- **Consul**: Service registry integration\n",
    "- **AWS/GCP/Azure**: Cloud API discovery of instances\n",
    "\n",
    "**PromQL Examples**:\n",
    "```promql\n",
    "# Request rate per second over last 5 minutes\n",
    "rate(http_requests_total[5m])\n",
    "\n",
    "# 95th percentile latency\n",
    "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))\n",
    "\n",
    "# Error rate percentage\n",
    "rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m])\n",
    "\n",
    "# Memory usage percentage\n",
    "100 * (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Grafana—Visualization & Alerting**\n",
    "\n",
    "Grafana transforms Prometheus metrics into actionable dashboards.\n",
    "\n",
    "**Dashboard Design Principles**:\n",
    "1. **The RED Dashboard**: Rate, Errors, Duration for every service\n",
    "2. **The USE Dashboard**: Utilization, Saturation, Errors for infrastructure\n",
    "3. **The Four Golden Signals** (Google SRE):\n",
    "   - Latency (time to serve requests)\n",
    "   - Traffic (demand on system)\n",
    "   - Errors (rate of failed requests)\n",
    "   - Saturation (how \"full\" the service is)\n",
    "\n",
    "**Alerting in Grafana**:\n",
    "```yaml\n",
    "# Example alert rule\n",
    "groups:\n",
    "  - name: api_alerts\n",
    "    rules:\n",
    "      - alert: HighErrorRate\n",
    "        expr: rate(http_requests_total{status=~\"5..\"}[5m]) > 0.05\n",
    "        for: 5m\n",
    "        labels:\n",
    "          severity: critical\n",
    "        annotations:\n",
    "          summary: \"High error rate on {{ $labels.service }}\"\n",
    "          description: \"Error rate is {{ $value }}%\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Jaeger/Zipkin—Distributed Tracing**\n",
    "\n",
    "**Jaeger Architecture**:\n",
    "```\n",
    "┌─────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐\n",
    "│   App   │───►│  Agent   │───►│ Collector│───►│ Storage  │\n",
    "│(Library)│    │  (Daemon)│    │          │    │(Cassandra│\n",
    "└─────────┘    └──────────┘    └──────────┘    │ or ES)   │\n",
    "                                               └──────────┘\n",
    "                                                    │\n",
    "                                               ┌──────────┐\n",
    "                                               │  Jaeger  │\n",
    "                                               │   UI     │\n",
    "                                               └──────────┘\n",
    "```\n",
    "\n",
    "**OpenTelemetry—The Standard**:\n",
    "Modern applications use OpenTelemetry (OTel) as the vendor-neutral instrumentation standard, exporting to Jaeger, Zipkin, or cloud vendors (AWS X-Ray, Google Cloud Trace).\n",
    "\n",
    "**Instrumentation**:\n",
    "```python\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.exporter.jaeger.thrift import JaegerExporter\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "\n",
    "# Initialize tracer\n",
    "trace.set_tracer_provider(TracerProvider())\n",
    "tracer = trace.get_tracer(__name__)\n",
    "\n",
    "# Create spans\n",
    "with tracer.start_as_current_span(\"process_payment\") as span:\n",
    "    span.set_attribute(\"payment.id\", \"pay_123\")\n",
    "    span.set_attribute(\"user.id\", \"user_456\")\n",
    "    \n",
    "    with tracer.start_as_current_span(\"validate_card\"):\n",
    "        # Validation logic\n",
    "        pass\n",
    "        \n",
    "    with tracer.start_as_current_span(\"charge_stripe\"):\n",
    "        # Stripe API call\n",
    "        pass\n",
    "```\n",
    "\n",
    "**Sampling Strategies**:\n",
    "- **Head-based**: Decide at request start (simple, but might sample uninteresting requests)\n",
    "- **Tail-based**: Collect all spans, decide after completion (catches rare errors, expensive)\n",
    "- **Probabilistic**: Fixed percentage (1% of all requests)\n",
    "\n",
    "---\n",
    "\n",
    "## **19.3 Alerting Strategies**\n",
    "\n",
    "### **SLO-Based Alerting (The Google Way)**\n",
    "\n",
    "**Definitions**:\n",
    "- **SLI** (Service Level Indicator): What you measure (e.g., \"latency of homepage requests\")\n",
    "- **SLO** (Service Level Objective): The target (e.g., \"99.9% of requests < 200ms\")\n",
    "- **SLA** (Service Level Agreement): The contract with consequences (e.g., \"99.9% uptime or refund\")\n",
    "\n",
    "**Error Budgets**:\n",
    "If your SLO is 99.9% availability, your **error budget** is 0.1% downtime per month (43 minutes).\n",
    "\n",
    "**Alerting Rules**:\n",
    "1. **Fast Burn**: Will exhaust budget in hours (page immediately)\n",
    "   ```promql\n",
    "   # Burn rate > 10x (consume 2% budget in 1 hour)\n",
    "   job:request_latency:rate1h{job=\"api\"} > 10 * 0.001\n",
    "   ```\n",
    "\n",
    "2. **Slow Burn**: Will exhaust budget in days (ticket, not page)\n",
    "   ```promql\n",
    "   # Burn rate > 2x (consume 5% budget in 3 days)\n",
    "   job:request_latency:rate3d{job=\"api\"} > 2 * 0.001\n",
    "   ```\n",
    "\n",
    "**Alert Fatigue Prevention**:\n",
    "- **Actionable alerts**: If it pages at 3 AM, you must be able to do something\n",
    "- **Symptom-based**: Alert on user pain (latency/errors), not causes (disk usage)\n",
    "- **Severity levels**:\n",
    "  - **P1 (Page)**: Revenue-impacting outage\n",
    "  - **P2 (Ticket)**: Degradation, workaround exists\n",
    "  - **P3 (Log/Monitor)**: Anomaly, investigate during business hours\n",
    "\n",
    "**The \"Wakes You Up\" Test**:\n",
    "Before adding an alert, ask: \"If this wakes me up at 3 AM, will I fix it or just mute it?\" If the latter, don't add it.\n",
    "\n",
    "---\n",
    "\n",
    "## **19.4 Log Aggregation**\n",
    "\n",
    "### **The ELK Stack**\n",
    "\n",
    "**Elasticsearch + Logstash + Kibana** (or **EFK**: Elasticsearch + Fluentd + Kibana)\n",
    "\n",
    "**Architecture**:\n",
    "```\n",
    "┌─────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐\n",
    "│   App   │───►│ Logstash │───►│Elasticsearch│───►│  Kibana  │\n",
    "│ (Logs)  │    │ (Parse)  │    │  (Index)   │    │ (Search) │\n",
    "└─────────┘    └──────────┘    └──────────┘    └──────────┘\n",
    "                                    │\n",
    "                               ┌──────────┐\n",
    "                               │  Archive │\n",
    "                               │  (S3)    │\n",
    "                               └──────────┘\n",
    "```\n",
    "\n",
    "**Logstash Parsing** (Grok patterns):\n",
    "```ruby\n",
    "# Parse Apache logs\n",
    "filter {\n",
    "  grok {\n",
    "    match => { \"message\" => \"%{COMBINEDAPACHELOG}\" }\n",
    "  }\n",
    "  date {\n",
    "    match => [ \"timestamp\", \"dd/MMM/yyyy:HH:mm:ss Z\" ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Elasticsearch Index Strategy**:\n",
    "- **Time-based indices**: `logs-2024.01.15`, `logs-2024.01.16`\n",
    "- **Retention**: Hot (SSD, 7 days), Warm (HDD, 30 days), Cold (Archive, 7 years)\n",
    "- **Sharding**: One shard per 20-50 GB of data\n",
    "\n",
    "**Structured Logging Best Practices**:\n",
    "1. **Use JSON**: Machine-readable, queryable\n",
    "2. **Consistent Schema**: Same field names across services (`user_id`, not `userId` or `user-id`)\n",
    "3. **Contextual Fields**: Every log includes service name, trace ID, version, host\n",
    "4. **Sensitive Data**: Never log passwords, tokens, or PII (use masking)\n",
    "\n",
    "---\n",
    "\n",
    "### **Splunk—Enterprise Alternative**\n",
    "\n",
    "Splunk dominates enterprise due to its powerful search language and indexing, but at significant cost.\n",
    "\n",
    "**Splunk Search Processing Language (SPL)**:\n",
    "```\n",
    "# Find errors with high latency\n",
    "index=web status=500 \n",
    "| stats count by uri \n",
    "| where count > 100 \n",
    "| sort -count\n",
    "\n",
    "# Transaction tracing\n",
    "index=app trace_id=\"abc123\" \n",
    "| transaction trace_id \n",
    "| table _time, service, duration, message\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **19.5 Health Checks & Readiness Probes**\n",
    "\n",
    "**Kubernetes Health Probes**:\n",
    "\n",
    "1. **Liveness Probe**: \"Is the application running?\"\n",
    "   - If fails: Kubernetes restarts the container\n",
    "   - Simple: HTTP GET `/health` returns 200\n",
    "   \n",
    "2. **Readiness Probe**: \"Is the application ready to receive traffic?\"\n",
    "   - If fails: Removed from service endpoints (no traffic)\n",
    "   - Checks: DB connections, cache warmth, feature flags loaded\n",
    "   \n",
    "3. **Startup Probe**: \"Has the application finished starting?\"\n",
    "   - Disables liveness/readiness until successful\n",
    "   - For slow-starting Java apps\n",
    "\n",
    "**Implementation**:\n",
    "```python\n",
    "@app.route('/health')\n",
    "def health():\n",
    "    # Liveness: Just return 200 if process is up\n",
    "    return {'status': 'alive'}, 200\n",
    "\n",
    "@app.route('/ready')\n",
    "def ready():\n",
    "    # Readiness: Check dependencies\n",
    "    if not db.is_connected():\n",
    "        return {'status': 'not ready', 'reason': 'db_connection'}, 503\n",
    "    if not cache.is_warm():\n",
    "        return {'status': 'not ready', 'reason': 'cache_cold'}, 503\n",
    "    return {'status': 'ready'}, 200\n",
    "```\n",
    "\n",
    "**Deep Health Checks**:\n",
    "Don't check external dependencies in liveness probes (you'll restart the whole service if the DB is briefly unavailable). Use readiness probes for dependency checks.\n",
    "\n",
    "---\n",
    "\n",
    "## **19.6 Observability in Practice**\n",
    "\n",
    "### **The Observability Pipeline**\n",
    "\n",
    "```\n",
    "┌─────────────┐    ┌──────────────┐    ┌──────────────┐\n",
    "│   Agents    │───►│   Pipeline   │───►│   Storage    │\n",
    "│ (OTel,      │    │  (Kafka,      │    │ (Prometheus, │\n",
    "│  Fluentd)   │    │   Vector)     │    │  Elasticsearch│\n",
    "└─────────────┘    └──────────────┘    └──────────────┘\n",
    "                                              │\n",
    "                                       ┌──────┴──────┐\n",
    "                                       ▼             ▼\n",
    "                                  ┌─────────┐  ┌─────────┐\n",
    "                                  │ Alerting│  │Dashboards│\n",
    "                                  │(PagerDuty)│ │(Grafana) │\n",
    "                                  └─────────┘  └─────────┘\n",
    "```\n",
    "\n",
    "### **Correlation—The Holy Grail**\n",
    "\n",
    "Link metrics, logs, and traces:\n",
    "```\n",
    "Dashboard: High error rate spike at 10:30 AM\n",
    "    ↓ Click\n",
    "Trace: Representative failed trace showing timeout at Payment Service\n",
    "    ↓ Click\n",
    "Logs: Exact error message \"Connection timeout to payment-db:5432\"\n",
    "    ↓ Click\n",
    "Metric: Database connection pool exhausted at 10:29 AM\n",
    "```\n",
    "\n",
    "**Implementation**:\n",
    "- Trace ID in all logs\n",
    "- Metric timestamps align with log timestamps\n",
    "- Exemplars: Specific trace IDs attached to metric data points\n",
    "\n",
    "---\n",
    "\n",
    "## **19.7 Chapter Summary**\n",
    "\n",
    "Observability transforms debugging from \"print statements and prayer\" into data-driven engineering:\n",
    "\n",
    "1. **Metrics** (RED/USE) tell you *that* something is wrong\n",
    "2. **Logs** tell you *what* happened in detail\n",
    "3. **Traces** tell you *where* the problem originated\n",
    "\n",
    "**Key Takeaways**:\n",
    "- Monitor symptoms (user pain), not causes (disk usage)\n",
    "- Use SLOs and error budgets to balance reliability with feature velocity\n",
    "- High cardinality kills metrics; use logs/traces for high-cardinality data\n",
    "- Alert sparingly—alert fatigue kills teams and systems\n",
    "- Instrument everything with OpenTelemetry for vendor portability\n",
    "\n",
    "**The Observability Maturity Model**:\n",
    "- **Level 1**: Reactive (check logs when users complain)\n",
    "- **Level 2**: Proactive (dashboards, basic alerts)\n",
    "- **Level 3**: Instrumented (distributed tracing, SLOs)\n",
    "- **Level 4**: Intelligent (anomaly detection, automated remediation)\n",
    "\n",
    "---\n",
    "\n",
    "**Exercises**:\n",
    "\n",
    "1. **Cardinality Calculation**: If you have 10 endpoints, 5 HTTP methods, and 10 status codes, how many time series does `http_requests_total` create? What if you add `user_id` (1 million users) as a label?\n",
    "\n",
    "2. **SLO Math**: If your SLO is 99.95% availability, how much downtime is your error budget for a 30-day month? If you have a 2-hour outage on day 1, what percentage of your budget is consumed?\n",
    "\n",
    "3. **Trace Analysis**: A trace shows API Gateway (10ms) → Auth Service (200ms) → Database (5ms). Where is the latency problem? How would you verify?\n",
    "\n",
    "4. **Alert Design**: Design an alert rule for \"Database connection pool exhaustion\" that pages during business hours but creates a ticket at night (assuming manual intervention isn't possible at 3 AM).\n",
    "\n",
    "5. **Log Cost**: Calculate storage costs for 1 TB/day of logs with 90-day retention, comparing hot storage ($0.023/GB) vs. archive ($0.004/GB) for 80% of data.\n",
    "\n",
    "---\n",
    "\n",
    "The next chapter covers **Performance Optimization**—profiling techniques, database tuning, caching strategies, and the systematic approach to making fast systems faster."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
