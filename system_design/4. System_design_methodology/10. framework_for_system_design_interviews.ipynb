{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73cd292a",
   "metadata": {},
   "source": [
    "# Chapter 10: The 4S Framework for System Design Interviews\n",
    "\n",
    "---\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Structure any system design interview conversation using the 4S Framework\n",
    "- Elicit and document functional and non-functional requirements systematically\n",
    "- Perform back-of-the-envelope estimations with confidence\n",
    "- Design data models and APIs that scale\n",
    "- Identify bottlenecks and articulate trade-offs effectively\n",
    "- Draw clear, professional architecture diagrams\n",
    "- Navigate a 45-60 minute system design interview from start to finish\n",
    "\n",
    "---\n",
    "\n",
    "## **Introduction: Why a Framework Matters**\n",
    "\n",
    "Imagine you're an architect. Someone asks you to design a house. Do you start by drawing the bathroom tiles? Of course not. You start by understanding the family's needs, estimate the budget, draw the floor plan, and then dive into the details.\n",
    "\n",
    "System design is the same. Without a framework, you might:\n",
    "- Forget critical requirements\n",
    "- Spend too much time on irrelevant details\n",
    "- Miss the interviewer's hidden expectations\n",
    "- Run out of time before reaching the solution\n",
    "\n",
    "**The 4S Framework** gives you a roadmap. It's used by engineers at Google, Amazon, Meta, Netflix, and many other top companies to structure system design discussions.\n",
    "\n",
    "---\n",
    "\n",
    "## **The 4S Framework Overview**\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                        THE 4S FRAMEWORK                              \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                     \u2502\n",
    "\u2502   1. SCOPE    \u2192  What are we building? (Requirements)              \u2502\n",
    "\u2502                                                                     \u2502\n",
    "\u2502   2. SKETCH   \u2192  How big is this? (Estimations)                    \u2502\n",
    "\u2502                                                                     \u2502\n",
    "\u2502   3. SOLIDIFY \u2192  How does data flow? (Data Model + API)            \u2502\n",
    "\u2502                                                                     \u2502\n",
    "\u2502   4. SCALE    \u2192  How do we make it handle millions? (Design)       \u2502\n",
    "\u2502                                                                     \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "Each 'S' builds on the previous one. You don't jump to the SCALE phase until you've understood the SCOPE, estimated the SKETCH, and SOLIDIFIED the data model.\n",
    "\n",
    "---\n",
    "\n",
    "## **S1: SCOPE \u2014 Understanding Requirements**\n",
    "\n",
    "The SCOPE phase is the foundation. Without clear requirements, you'll design the wrong system.\n",
    "\n",
    "### **What is Scope?**\n",
    "\n",
    "Scope defines:\n",
    "- What you're building\n",
    "- What you're NOT building\n",
    "- How well it needs to perform\n",
    "- What constraints you're working under\n",
    "\n",
    "### **The Requirement Collection Process**\n",
    "\n",
    "Start by asking questions. A good system design interview is a conversation, not a monologue.\n",
    "\n",
    "#### **Step 1: Clarify the Problem**\n",
    "\n",
    "Never assume you understand the problem. Ask clarifying questions:\n",
    "\n",
    "**Example: Design a URL Shortener**\n",
    "\n",
    "```\n",
    "\u274c BAD assumption: \"Okay, I'll design a URL shortener like bit.ly\"\n",
    "\n",
    "\u2705 GOOD approach: \n",
    "\"What kind of URLs are we shortening?\"\n",
    "\"Does the short URL expire?\"\n",
    "\"Do we need custom short URLs?\"\n",
    "\"Is this for public use or internal company use?\"\n",
    "```\n",
    "\n",
    "#### **Step 2: Document Functional Requirements**\n",
    "\n",
    "Functional requirements describe **what the system does**. These are features and behaviors.\n",
    "\n",
    "**How to Document:**\n",
    "\n",
    "1. **List Use Cases**: Who are the users and what do they do?\n",
    "2. **Define Features**: What capabilities does the system have?\n",
    "3. **Identify Input/Output**: What goes in and what comes out?\n",
    "\n",
    "**Example URL Shortener \u2014 Functional Requirements:**\n",
    "\n",
    "| User Action | Description |\n",
    "|-------------|-------------|\n",
    "| Create short URL | User submits a long URL, receives a short URL |\n",
    "| Redirect | User visits short URL, gets redirected to original |\n",
    "| Delete URL | Owner can delete their short URL |\n",
    "| Custom alias | User can choose custom short URL (if available) |\n",
    "| Analytics | Track number of clicks per short URL |\n",
    "\n",
    "**Functional Requirements Summary (Write this down):**\n",
    "```\n",
    "Functional Requirements:\n",
    "- Create and return a unique short URL for any given long URL\n",
    "- When a user accesses a short URL, redirect them to the original long URL\n",
    "- Short URLs should be at most 7 characters long (e.g., abc1234)\n",
    "- Users should be able to optionally specify a custom alias\n",
    "- Track click counts for each short URL\n",
    "```\n",
    "\n",
    "#### **Step 3: Document Non-Functional Requirements**\n",
    "\n",
    "Non-functional requirements describe **how well** the system performs. These are quality attributes.\n",
    "\n",
    "**The Big 5 Non-Functional Requirements:**\n",
    "\n",
    "| Category | What It Means | Example Questions |\n",
    "|----------|---------------|-------------------|\n",
    "| **Scalability** | How many users can it handle? | \"10K concurrent users?\" \"10M URLs total?\" |\n",
    "| **Availability** | How often must it be up? | \"99.9% uptime?\" \"Is downtime acceptable?\" |\n",
    "| **Latency** | How fast must it respond? | \"Redirect in < 200ms?\" \"Create URL in < 100ms?\" |\n",
    "| **Consistency** | How up-to-date must data be? | \"Is eventual consistency okay?\" \"Must reads be latest?\" |\n",
    "| **Durability** | Can we lose data? | \"Can we afford to lose 0.1% of URLs?\" |\n",
    "\n",
    "**Example URL Shortener \u2014 Non-Functional Requirements:**\n",
    "```\n",
    "Non-Functional Requirements:\n",
    "Scalability:\n",
    "  - Support 10 million URL creations per day\n",
    "  - Support 100 million redirects per day\n",
    "  - Store up to 1 billion URLs total\n",
    "\n",
    "Availability:\n",
    "  - 99.9% uptime (redirect service must be highly available)\n",
    "\n",
    "Latency:\n",
    "  - Create URL: < 100ms (p95)\n",
    "  - Redirect: < 50ms (p95)\n",
    "  - Read latency: < 200ms\n",
    "\n",
    "Consistency:\n",
    "  - Strong consistency for URL creation\n",
    "  - Eventual consistency for analytics (click counts)\n",
    "\n",
    "Durability:\n",
    "  - Zero data loss for stored URLs\n",
    "  - Analytics can tolerate slight data loss\n",
    "```\n",
    "\n",
    "#### **Step 4: Define Out of Scope**\n",
    "\n",
    "Explicitly state what you're NOT building. This shows you're managing scope wisely.\n",
    "\n",
    "**Example URL Shortener \u2014 Out of Scope:**\n",
    "```\n",
    "Out of Scope:\n",
    "- User authentication (assume anonymous users)\n",
    "- URL preview (no thumbnail generation)\n",
    "- Social sharing features\n",
    "- QR code generation\n",
    "- Domain-specific shortening\n",
    "- URL expiration (short URLs don't expire)\n",
    "- API rate limiting (for this phase)\n",
    "```\n",
    "\n",
    "### **Pro Tip: The \"Do You Want Me to Consider\" Checklist**\n",
    "\n",
    "After documenting requirements, ask:\n",
    "- \"Do you want me to consider authentication?\"\n",
    "- \"Do you want me to consider caching?\"\n",
    "- \"Do you want me to consider privacy/anonymization?\"\n",
    "\n",
    "This shows you're thinking ahead but deferring to the interviewer's priorities.\n",
    "\n",
    "---\n",
    "\n",
    "## **S2: SKETCH \u2014 Back-of-the-Envelope Estimation**\n",
    "\n",
    "Now that you know WHAT you're building, estimate HOW BIG it needs to be. This is the \"SKETCH\" phase.\n",
    "\n",
    "### **Why Estimation Matters**\n",
    "\n",
    "Estimations help you:\n",
    "- Choose the right technologies\n",
    "- Identify early bottlenecks\n",
    "- Design appropriate data structures\n",
    "- Calculate resource needs (storage, bandwidth, servers)\n",
    "\n",
    "### **What to Estimate**\n",
    "\n",
    "You typically estimate three things:\n",
    "1. **QPS (Queries Per Second)** \u2014 Traffic volume\n",
    "2. **Storage** \u2014 Data size\n",
    "3. **Bandwidth** \u2014 Data transfer rate\n",
    "\n",
    "### **The Estimation Process**\n",
    "\n",
    "#### **Step 1: Start with Daily Volume**\n",
    "\n",
    "Begin with what's given or make reasonable assumptions.\n",
    "\n",
    "**Example URL Shortener:**\n",
    "```\n",
    "Given: 10 million URL creations per day\n",
    "Given: 100 million redirects per day\n",
    "```\n",
    "\n",
    "#### **Step 2: Convert to Peak Per Second**\n",
    "\n",
    "Daily numbers don't help you size for peak. Convert to per-second and add a peak multiplier.\n",
    "\n",
    "**The Formula:**\n",
    "```\n",
    "Peak QPS = (Daily Volume / 86400 seconds) \u00d7 Peak Multiplier\n",
    "\n",
    "Where:\n",
    "- 86400 = 24 hours \u00d7 60 minutes \u00d7 60 seconds\n",
    "- Peak Multiplier = 2 to 10 (depends on traffic pattern)\n",
    "```\n",
    "\n",
    "**Example Calculation:**\n",
    "\n",
    "```\n",
    "URL Creations:\n",
    "  Daily: 10 million\n",
    "  Average QPS = 10,000,000 / 86,400 = 115 QPS\n",
    "  Peak QPS = 115 \u00d7 5 = 575 QPS (peak multiplier of 5)\n",
    "\n",
    "Redirects:\n",
    "  Daily: 100 million\n",
    "  Average QPS = 100,000,000 / 86,400 = 1,157 QPS\n",
    "  Peak QPS = 1,157 \u00d7 10 = 11,570 QPS (peak multiplier of 10)\n",
    "\n",
    "Total Peak QPS = 575 (create) + 11,570 (redirect) = 12,145 QPS\n",
    "```\n",
    "\n",
    "**Pro Tip:** Peak multipliers:\n",
    "- Social media/news: 5-10x (viral spikes)\n",
    "- Business apps: 2-3x (work hours)\n",
    "- E-commerce: 3-5x (events, sales)\n",
    "\n",
    "#### **Step 3: Estimate Storage**\n",
    "\n",
    "Calculate how much data you'll store over the system's lifetime.\n",
    "\n",
    "**The Formula:**\n",
    "```\n",
    "Storage = (Data per item \u00d7 Items stored) + (Growth margin)\n",
    "\n",
    "For multi-year storage:\n",
    "Total Storage = (Data per item \u00d7 Items per year \u00d7 Years)\n",
    "```\n",
    "\n",
    "**Example URL Shortener \u2014 Storage Estimation:**\n",
    "\n",
    "**What do we store per URL?**\n",
    "```\n",
    "Entry: {\n",
    "  short_url: 7 bytes (e.g., \"abc1234\")\n",
    "  long_url: 2000 bytes (average URL length)\n",
    "  creation_time: 8 bytes (Unix timestamp)\n",
    "  click_count: 4 bytes (integer)\n",
    "  user_id: 8 bytes (optional, for future features)\n",
    "}\n",
    "\n",
    "Total per URL \u2248 2,027 bytes \u2248 2 KB per URL\n",
    "```\n",
    "\n",
    "**Storage Calculation:**\n",
    "```\n",
    "Given: 1 billion URLs total\n",
    "\n",
    "Primary Storage:\n",
    "  = 1 billion URLs \u00d7 2 KB\n",
    "  = 2,000,000,000 KB\n",
    "  = 2,000,000 MB\n",
    "  = 2,000 GB\n",
    "  = 2 TB\n",
    "\n",
    "Add 50% for overhead (indexes, metadata):\n",
    "  = 2 TB \u00d7 1.5\n",
    "  = 3 TB total storage\n",
    "```\n",
    "\n",
    "**Analytics Storage (if tracking detailed clicks):**\n",
    "```\n",
    "If we store every click:\n",
    "  Click entry = {\n",
    "    url_id: 8 bytes\n",
    "    timestamp: 8 bytes\n",
    "    ip_address: 4 bytes\n",
    "    user_agent: 50 bytes\n",
    "  } = 70 bytes per click\n",
    "\n",
    "100 million clicks/day \u00d7 70 bytes = 7 GB/day\n",
    "7 GB/day \u00d7 365 days = 2.5 TB/year\n",
    "For 5 years: = 12.5 TB\n",
    "```\n",
    "\n",
    "#### **Step 4: Estimate Bandwidth**\n",
    "\n",
    "Bandwidth is the amount of data flowing in and out of your system per second.\n",
    "\n",
    "**The Formula:**\n",
    "```\n",
    "Bandwidth (GB/s) = (Request size + Response size) \u00d7 Peak QPS / 1,000,000,000\n",
    "```\n",
    "\n",
    "**Example URL Shortener \u2014 Bandwidth Estimation:**\n",
    "\n",
    "**Create URL:**\n",
    "```\n",
    "Request: POST long URL (2000 bytes) + optional alias (7 bytes)\n",
    "       \u2248 2 KB\n",
    "\n",
    "Response: Short URL (7 bytes) + metadata\n",
    "        \u2248 100 bytes\n",
    "\n",
    "Bandwidth (create) = (2 KB + 100 bytes) \u00d7 575 QPS\n",
    "                   = 2,100 bytes \u00d7 575\n",
    "                   = 1,207,500 bytes/second\n",
    "                   \u2248 1.2 MB/s\n",
    "```\n",
    "\n",
    "**Redirect:**\n",
    "```\n",
    "Request: GET short URL (7 bytes)\n",
    "       \u2248 10 bytes with headers\n",
    "\n",
    "Response: 301 Redirect to long URL (2000 bytes)\n",
    "        \u2248 2 KB\n",
    "\n",
    "Bandwidth (redirect) = (10 bytes + 2000 bytes) \u00d7 11,570 QPS\n",
    "                     = 2,010 bytes \u00d7 11,570\n",
    "                     = 23,255,700 bytes/second\n",
    "                     \u2248 23 MB/s\n",
    "```\n",
    "\n",
    "**Total Bandwidth:**\n",
    "```\n",
    "= 1.2 MB/s (create) + 23 MB/s (redirect)\n",
    "= 24.2 MB/s\n",
    "= 0.024 GB/s\n",
    "\n",
    "Per day:\n",
    "  = 0.024 GB/s \u00d7 86,400 s\n",
    "  \u2248 2,074 GB/day\n",
    "  \u2248 2 TB/day bandwidth\n",
    "```\n",
    "\n",
    "### **The Estimation Cheat Sheet**\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    QUICK ESTIMATION RULES                        \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  1 day     = 86,400 seconds                                      \u2502\n",
    "\u2502  1 KB      = 1,024 bytes                                         \u2502\n",
    "\u2502  1 MB      = 1,024 KB                                            \u2502\n",
    "\u2502  1 GB      = 1,024 MB                                            \u2502\n",
    "\u2502  1 TB      = 1,024 GB                                            \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Peak multiplier: 2-10x (use 5x as default)                      \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Average URL length: 200-500 bytes                               \u2502\n",
    "\u2502  Short URL length: 6-8 characters                                \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Typical user record: 1-5 KB                                     \u2502\n",
    "\u2502  Typical transaction: 500 bytes - 2 KB                           \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  1 year of daily data = 365 \u00d7 daily amount                       \u2502\n",
    "\u2502  5 years of daily data \u2248 2,000 \u00d7 daily amount                    \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### **Summary Document \u2014 Sketch Phase**\n",
    "\n",
    "After the SKETCH phase, write down your estimations:\n",
    "\n",
    "```\n",
    "Sketch \u2014 Estimations:\n",
    "\n",
    "Traffic (QPS):\n",
    "  - URL creations: 575 QPS (peak)\n",
    "  - Redirects: 11,570 QPS (peak)\n",
    "  - Total: ~12,145 QPS\n",
    "\n",
    "Storage:\n",
    "  - URL storage: 3 TB (for 1 billion URLs)\n",
    "  - Analytics storage: 12.5 TB (5 years of click data)\n",
    "  - Total: ~15.5 TB\n",
    "\n",
    "Bandwidth:\n",
    "  - Inbound: ~1.2 MB/s\n",
    "  - Outbound: ~23 MB/s\n",
    "  - Total: ~24 MB/s (2 TB/day)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **S3: SOLIDIFY \u2014 Data Model and API Design**\n",
    "\n",
    "Now that you know the scope and scale, design how data flows through the system.\n",
    "\n",
    "### **Data Model Design**\n",
    "\n",
    "The data model defines how you'll store and structure your data.\n",
    "\n",
    "#### **Step 1: Identify Entities**\n",
    "\n",
    "What \"things\" exist in your system?\n",
    "\n",
    "**Example URL Shortener \u2014 Entities:**\n",
    "```\n",
    "Entities:\n",
    "- URL\n",
    "- User (optional, for future features)\n",
    "- Click (for analytics)\n",
    "```\n",
    "\n",
    "#### **Step 2: Define Relationships**\n",
    "\n",
    "How do entities relate to each other?\n",
    "\n",
    "```\n",
    "User  \u2500\u2500\u2500\u2500< creates >\u2500\u2500\u2500\u2500  URL\n",
    "                            \u2502\n",
    "                            \u2502< has many >\n",
    "                            \u2193\n",
    "                          Click\n",
    "```\n",
    "\n",
    "#### **Step 3: Define Attributes per Entity**\n",
    "\n",
    "What properties does each entity have?\n",
    "\n",
    "**URL Entity:**\n",
    "| Attribute | Type | Description |\n",
    "|-----------|------|-------------|\n",
    "| id | VARCHAR(7) | The short URL code (unique, indexed) |\n",
    "| long_url | VARCHAR(2048) | The original URL |\n",
    "| created_at | TIMESTAMP | When it was created |\n",
    "| expires_at | TIMESTAMP | Optional expiration (NULL = never) |\n",
    "| user_id | BIGINT | Optional owner ID |\n",
    "| click_count | INT | Total number of redirects |\n",
    "\n",
    "**Click Entity (for analytics):**\n",
    "| Attribute | Type | Description |\n",
    "|-----------|------|-------------|\n",
    "| id | BIGINT | Auto-increment unique ID |\n",
    "| url_id | VARCHAR(7) | Foreign key to URL |\n",
    "| timestamp | TIMESTAMP | When the click occurred |\n",
    "| ip_address | VARCHAR(45) | IP address of visitor |\n",
    "| user_agent | VARCHAR(255) | Browser/device info |\n",
    "| country | VARCHAR(2) | 2-letter country code |\n",
    "\n",
    "#### **Step 4: Choose Database Type**\n",
    "\n",
    "Based on your data model and requirements:\n",
    "\n",
    "| Factor | Consideration | Decision |\n",
    "|--------|---------------|----------|\n",
    "| Data structure | Simple key-value lookups | Key-Value Store |\n",
    "| Query patterns | Lookup by short URL only | Key-Value Store |\n",
    "| Consistency | Strong consistency required | DynamoDB, Redis, or MySQL with primary key |\n",
    "| Scale | 1 billion URLs | Distributed NoSQL (DynamoDB, Cassandra) |\n",
    "| Analytics | Heavy write load | Separate time-series database |\n",
    "\n",
    "**Recommendation for URL Shortener:**\n",
    "```\n",
    "Primary storage: DynamoDB (AWS) or Redis Cluster\n",
    "  - Key: short_url\n",
    "  - Value: long_url + metadata\n",
    "  - Strong consistency for reads\n",
    "  - Horizontal scaling\n",
    "\n",
    "Analytics storage: Time-series database (TimescaleDB, InfluxDB)\n",
    "  - Optimized for time-series queries\n",
    "  - High write throughput\n",
    "```\n",
    "\n",
    "#### **Step 5: Design Schema (SQL Example)**\n",
    "\n",
    "If using a relational database:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE urls (\n",
    "    id VARCHAR(7) PRIMARY KEY,           -- The short URL code\n",
    "    long_url VARCHAR(2048) NOT NULL,     -- Original URL\n",
    "    created_at TIMESTAMP DEFAULT NOW(),   -- Creation timestamp\n",
    "    user_id BIGINT,                      -- Optional owner\n",
    "    click_count INT DEFAULT 0,           -- Redirect count\n",
    "    INDEX idx_user_id (user_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE clicks (\n",
    "    id BIGINT AUTO_INCREMENT PRIMARY KEY,\n",
    "    url_id VARCHAR(7) NOT NULL,\n",
    "    timestamp TIMESTAMP DEFAULT NOW(),\n",
    "    ip_address VARCHAR(45),\n",
    "    user_agent VARCHAR(255),\n",
    "    country VARCHAR(2),\n",
    "    INDEX idx_url_id (url_id),\n",
    "    INDEX idx_timestamp (timestamp)\n",
    ");\n",
    "\n",
    "-- Foreign key relationship\n",
    "ALTER TABLE clicks\n",
    "ADD FOREIGN KEY (url_id) REFERENCES urls(id);\n",
    "```\n",
    "\n",
    "#### **Step 6: Design Schema (NoSQL Example)**\n",
    "\n",
    "For DynamoDB (document/key-value style):\n",
    "\n",
    "```json\n",
    "// URL Table (Key: short_url)\n",
    "{\n",
    "  \"short_url\": \"abc1234\",\n",
    "  \"long_url\": \"https://example.com/very/long/path\",\n",
    "  \"created_at\": 1709251200,\n",
    "  \"user_id\": null,\n",
    "  \"click_count\": 42,\n",
    "  \"metadata\": {\n",
    "    \"user_agent\": \"Mozilla/5.0...\",\n",
    "    \"ip\": \"192.168.1.1\"\n",
    "  }\n",
    "}\n",
    "\n",
    "// Clicks Table (Partition Key: url_id, Sort Key: timestamp)\n",
    "{\n",
    "  \"url_id\": \"abc1234\",\n",
    "  \"timestamp\": 1709254800,\n",
    "  \"ip_address\": \"192.168.1.2\",\n",
    "  \"user_agent\": \"Mozilla/5.0...\",\n",
    "  \"country\": \"US\"\n",
    "}\n",
    "```\n",
    "\n",
    "### **API Design**\n",
    "\n",
    "The API defines how external systems interact with your system.\n",
    "\n",
    "#### **API Design Principles**\n",
    "\n",
    "1. **Use HTTP Methods Correctly**\n",
    "   - `GET` \u2014 Read data\n",
    "   - `POST` \u2014 Create data\n",
    "   - `PUT` \u2014 Update/replace data\n",
    "   - `DELETE` \u2014 Remove data\n",
    "\n",
    "2. **Use Resource-Based URLs**\n",
    "   - Noun-based, not verb-based\n",
    "   - RESTful conventions\n",
    "\n",
    "3. **Use Appropriate Status Codes**\n",
    "   - `200` \u2014 Success\n",
    "   - `201` \u2014 Created\n",
    "   - `400` \u2014 Bad Request\n",
    "   - `404` \u2014 Not Found\n",
    "   - `500` \u2014 Server Error\n",
    "\n",
    "#### **API Endpoints \u2014 URL Shortener**\n",
    "\n",
    "| Method | Endpoint | Description |\n",
    "|--------|----------|-------------|\n",
    "| POST | `/api/v1/shorten` | Create a new short URL |\n",
    "| GET | `/api/v1/urls/{short_url}` | Get URL details |\n",
    "| GET | `/` | Redirect to original URL |\n",
    "| DELETE | `/api/v1/urls/{short_url}` | Delete a URL |\n",
    "| GET | `/api/v1/stats/{short_url}` | Get analytics for a URL |\n",
    "\n",
    "#### **API Details with Examples**\n",
    "\n",
    "**1. Create Short URL**\n",
    "\n",
    "```http\n",
    "POST /api/v1/shorten HTTP/1.1\n",
    "Host: shortener.example.com\n",
    "Content-Type: application/json\n",
    "\n",
    "{\n",
    "  \"long_url\": \"https://example.com/very/long/path/to/resource\",\n",
    "  \"custom_alias\": null  // Optional: \"my-custom-link\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Success Response:**\n",
    "```http\n",
    "HTTP/1.1 201 Created\n",
    "Content-Type: application/json\n",
    "\n",
    "{\n",
    "  \"short_url\": \"https://short.example.com/abc1234\",\n",
    "  \"long_url\": \"https://example.com/very/long/path/to/resource\",\n",
    "  \"created_at\": \"2024-02-01T00:00:00Z\",\n",
    "  \"expires_at\": null\n",
    "}\n",
    "```\n",
    "\n",
    "**Error Response:**\n",
    "```http\n",
    "HTTP/1.1 400 Bad Request\n",
    "Content-Type: application/json\n",
    "\n",
    "{\n",
    "  \"error\": \"Invalid URL format\",\n",
    "  \"code\": \"INVALID_URL\"\n",
    "}\n",
    "```\n",
    "\n",
    "**2. Redirect to Original URL**\n",
    "\n",
    "```http\n",
    "GET /abc1234 HTTP/1.1\n",
    "Host: shortener.example.com\n",
    "```\n",
    "\n",
    "**Response:**\n",
    "```http\n",
    "HTTP/1.1 301 Moved Permanently\n",
    "Location: https://example.com/very/long/path/to/resource\n",
    "```\n",
    "\n",
    "**3. Get URL Details**\n",
    "\n",
    "```http\n",
    "GET /api/v1/urls/abc1234 HTTP/1.1\n",
    "Host: shortener.example.com\n",
    "```\n",
    "\n",
    "**Response:**\n",
    "```http\n",
    "HTTP/1.1 200 OK\n",
    "Content-Type: application/json\n",
    "\n",
    "{\n",
    "  \"short_url\": \"abc1234\",\n",
    "  \"long_url\": \"https://example.com/very/long/path/to/resource\",\n",
    "  \"created_at\": \"2024-02-01T00:00:00Z\",\n",
    "  \"click_count\": 142,\n",
    "  \"last_accessed\": \"2024-02-05T15:30:00Z\"\n",
    "}\n",
    "```\n",
    "\n",
    "**4. Get Analytics**\n",
    "\n",
    "```http\n",
    "GET /api/v1/stats/abc1234?from=2024-02-01&to=2024-02-05 HTTP/1.1\n",
    "Host: shortener.example.com\n",
    "```\n",
    "\n",
    "**Response:**\n",
    "```http\n",
    "HTTP/1.1 200 OK\n",
    "Content-Type: application/json\n",
    "\n",
    "{\n",
    "  \"short_url\": \"abc1234\",\n",
    "  \"total_clicks\": 142,\n",
    "  \"period\": {\n",
    "    \"from\": \"2024-02-01\",\n",
    "    \"to\": \"2024-02-05\"\n",
    "  },\n",
    "  \"clicks_by_country\": {\n",
    "    \"US\": 85,\n",
    "    \"UK\": 32,\n",
    "    \"DE\": 15,\n",
    "    \"JP\": 10\n",
    "  },\n",
    "  \"clicks_by_day\": [\n",
    "    {\"date\": \"2024-02-01\", \"count\": 30},\n",
    "    {\"date\": \"2024-02-02\", \"count\": 45},\n",
    "    {\"date\": \"2024-02-03\", \"count\": 25},\n",
    "    {\"date\": \"2024-02-04\", \"count\": 20},\n",
    "    {\"date\": \"2024-02-05\", \"count\": 22}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "#### **Code Example \u2014 API Implementation (Python/Flask)**\n",
    "\n",
    "```python\n",
    "from flask import Flask, request, jsonify, redirect\n",
    "import datetime\n",
    "import random\n",
    "import string\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Simulated database (in production, use real DB)\n",
    "url_database = {}\n",
    "\n",
    "def generate_short_url(length=7):\n",
    "    \"\"\"Generate a random short URL code.\"\"\"\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    return ''.join(random.choice(characters) for _ in range(length))\n",
    "\n",
    "@app.route('/api/v1/shorten', methods=['POST'])\n",
    "def shorten_url():\n",
    "    \"\"\"Create a new short URL.\"\"\"\n",
    "    data = request.get_json()\n",
    "    \n",
    "    if not data or 'long_url' not in data:\n",
    "        return jsonify({\n",
    "            \"error\": \"long_url is required\",\n",
    "            \"code\": \"MISSING_URL\"\n",
    "        }), 400\n",
    "    \n",
    "    long_url = data['long_url']\n",
    "    custom_alias = data.get('custom_alias')\n",
    "    \n",
    "    # Validate URL (simplified)\n",
    "    if not long_url.startswith(('http://', 'https://')):\n",
    "        return jsonify({\n",
    "            \"error\": \"Invalid URL format\",\n",
    "            \"code\": \"INVALID_URL\"\n",
    "        }), 400\n",
    "    \n",
    "    # Generate or use custom short URL\n",
    "    if custom_alias:\n",
    "        if custom_alias in url_database:\n",
    "            return jsonify({\n",
    "                \"error\": \"Custom alias already taken\",\n",
    "                \"code\": \"ALIAS_TAKEN\"\n",
    "            }), 409\n",
    "        short_url = custom_alias\n",
    "    else:\n",
    "        # Generate unique short URL\n",
    "        while True:\n",
    "            short_url = generate_short_url()\n",
    "            if short_url not in url_database:\n",
    "                break\n",
    "    \n",
    "    # Store in database\n",
    "    url_database[short_url] = {\n",
    "        \"long_url\": long_url,\n",
    "        \"created_at\": datetime.datetime.now().isoformat(),\n",
    "        \"click_count\": 0,\n",
    "        \"last_accessed\": None\n",
    "    }\n",
    "    \n",
    "    return jsonify({\n",
    "        \"short_url\": f\"https://short.example.com/{short_url}\",\n",
    "        \"long_url\": long_url,\n",
    "        \"created_at\": url_database[short_url][\"created_at\"],\n",
    "        \"expires_at\": None\n",
    "    }), 201\n",
    "\n",
    "@app.route('/<short_url>')\n",
    "def redirect_to_original(short_url):\n",
    "    \"\"\"Redirect to the original URL.\"\"\"\n",
    "    if short_url not in url_database:\n",
    "        return jsonify({\n",
    "            \"error\": \"Short URL not found\",\n",
    "            \"code\": \"NOT_FOUND\"\n",
    "        }), 404\n",
    "    \n",
    "    url_data = url_database[short_url]\n",
    "    \n",
    "    # Update click count\n",
    "    url_data[\"click_count\"] += 1\n",
    "    url_data[\"last_accessed\"] = datetime.datetime.now().isoformat()\n",
    "    \n",
    "    # Redirect\n",
    "    return redirect(url_data[\"long_url\"], code=301)\n",
    "\n",
    "@app.route('/api/v1/urls/<short_url>', methods=['GET'])\n",
    "def get_url_details(short_url):\n",
    "    \"\"\"Get details about a short URL.\"\"\"\n",
    "    if short_url not in url_database:\n",
    "        return jsonify({\n",
    "            \"error\": \"Short URL not found\",\n",
    "            \"code\": \"NOT_FOUND\"\n",
    "        }), 404\n",
    "    \n",
    "    url_data = url_database[short_url]\n",
    "    \n",
    "    return jsonify({\n",
    "        \"short_url\": short_url,\n",
    "        \"long_url\": url_data[\"long_url\"],\n",
    "        \"created_at\": url_data[\"created_at\"],\n",
    "        \"click_count\": url_data[\"click_count\"],\n",
    "        \"last_accessed\": url_data[\"last_accessed\"]\n",
    "    }), 200\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "```\n",
    "\n",
    "### **Summary Document \u2014 Solidify Phase**\n",
    "\n",
    "After the SOLIDIFY phase, you should have:\n",
    "\n",
    "```\n",
    "Solidify \u2014 Data Model:\n",
    "\n",
    "Entities:\n",
    "  - URL: short_url (PK), long_url, created_at, click_count\n",
    "  - Click: id, url_id (FK), timestamp, ip_address, user_agent\n",
    "\n",
    "Database Choice:\n",
    "  - Primary: DynamoDB (strong consistency)\n",
    "  - Analytics: Time-series DB\n",
    "\n",
    "Schema:\n",
    "  [Include your schema diagram or SQL here]\n",
    "\n",
    "Solidify \u2014 API:\n",
    "\n",
    "Endpoints:\n",
    "  POST   /api/v1/shorten          - Create short URL\n",
    "  GET    /{short_url}             - Redirect to original\n",
    "  GET    /api/v1/urls/{short_url} - Get URL details\n",
    "  DELETE /api/v1/urls/{short_url} - Delete URL\n",
    "  GET    /api/v1/stats/{short_url} - Get analytics\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **S4: SCALE \u2014 High-Level Design and Deep Dives**\n",
    "\n",
    "The final phase is where you design the system architecture. This is where most interviewers spend the majority of time.\n",
    "\n",
    "### **The Two-Level Design Approach**\n",
    "\n",
    "System design has two levels:\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    LEVEL 1: HIGH-LEVEL DESIGN                    \u2502\n",
    "\u2502  - Big picture architecture                                      \u2502\n",
    "\u2502  - Component diagram                                             \u2502\n",
    "\u2502  - Data flow                                                     \u2502\n",
    "\u2502  - Key technologies                                              \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                              \u2193\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    LEVEL 2: DEEP DIVE                           \u2502\n",
    "\u2502  - Detailed design of specific components                        \u2502\n",
    "\u2502  - Bottleneck analysis                                          \u2502\n",
    "\u2502  - Trade-off discussion                                          \u2502\n",
    "\u2502  - Alternative approaches                                        \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### **Level 1: High-Level Design**\n",
    "\n",
    "#### **Step 1: Identify Key Components**\n",
    "\n",
    "Based on your requirements and data model, what building blocks do you need?\n",
    "\n",
    "**Example URL Shortener \u2014 Key Components:**\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|---------|\n",
    "| Load Balancer | Distribute traffic across servers |\n",
    "| API Server | Handle HTTP requests |\n",
    "| URL Database | Store URL mappings |\n",
    "| Cache | Speed up redirects |\n",
    "| ID Generator | Create unique short URLs |\n",
    "| Analytics Service | Track clicks |\n",
    "\n",
    "#### **Step 2: Draw the High-Level Architecture**\n",
    "\n",
    "```\n",
    "                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                    \u2502        Client           \u2502\n",
    "                    \u2502  (Browser, Mobile App)  \u2502\n",
    "                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                 \u2502 HTTPS\n",
    "                                 \u2193\n",
    "                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                    \u2502      Load Balancer      \u2502\n",
    "                    \u2502    (AWS ELB / Nginx)    \u2502\n",
    "                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                 \u2502\n",
    "                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                \u2193                \u2193                \u2193\n",
    "    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "    \u2502   API Server 1   \u2502 \u2502 API Server 2 \u2502 \u2502   API Server N   \u2502\n",
    "    \u2502 (Stateless)      \u2502 \u2502 (Stateless)  \u2502 \u2502    (Stateless)    \u2502\n",
    "    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "             \u2502                    \u2502                    \u2502\n",
    "             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                  \u2193\n",
    "                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                    \u2502       Cache Layer       \u2502\n",
    "                    \u2502    (Redis Cluster)      \u2502\n",
    "                    \u2502  - Short URL lookups    \u2502\n",
    "                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                  \u2502 Cache miss\n",
    "                                  \u2193\n",
    "                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                    \u2502    URL Database         \u2502\n",
    "                    \u2502  (DynamoDB / Redis)     \u2502\n",
    "                    \u2502  - Short URL mappings   \u2502\n",
    "                    \u2502  - Strong consistency   \u2502\n",
    "                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                  \u2502\n",
    "                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                    \u2502                           \u2502\n",
    "                    \u2193                           \u2193\n",
    "         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "         \u2502 ID Generator     \u2502        \u2502 Analytics DB     \u2502\n",
    "         \u2502 (Snowflake ID)   \u2502        \u2502 (Time-series)    \u2502\n",
    "         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "#### **Step 3: Explain Data Flow**\n",
    "\n",
    "Walk through the flow for each major operation:\n",
    "\n",
    "**Flow 1: Create Short URL**\n",
    "\n",
    "```\n",
    "1. Client POSTs /api/v1/shorten with long_url\n",
    "2. Load balancer routes to API Server\n",
    "3. API Server calls ID Generator for unique short_url\n",
    "4. API Server writes to URL Database\n",
    "5. API Server writes to Cache (optional)\n",
    "6. API Server returns short_url to client\n",
    "```\n",
    "\n",
    "**Flow 2: Redirect**\n",
    "\n",
    "```\n",
    "1. Client GETs /abc1234\n",
    "2. Load balancer routes to API Server\n",
    "3. API Server checks Cache for short_url\n",
    "4. Cache HIT \u2192 Return long_url immediately\n",
    "5. Cache MISS \u2192 Query URL Database\n",
    "6. URL Database returns long_url\n",
    "7. API Server stores in Cache for next time\n",
    "8. API Server returns 301 redirect to long_url\n",
    "9. API Server triggers analytics update (async)\n",
    "```\n",
    "\n",
    "#### **Step 4: Choose Technologies**\n",
    "\n",
    "Based on your requirements:\n",
    "\n",
    "| Decision | Factor | Choice |\n",
    "|----------|--------|--------|\n",
    "| Load Balancer | HTTP termination, health checks | AWS ALB / Nginx |\n",
    "| API Server | Stateless, auto-scalable | Docker + Kubernetes |\n",
    "| Database | Key-value, high throughput, strong consistency | DynamoDB |\n",
    "| Cache | Fast lookups, distributed | Redis Cluster |\n",
    "| ID Generator | Unique, sortable, collision-free | Snowflake (Twitter's ID generator) |\n",
    "| Analytics | Time-series, high write volume | TimescaleDB / ClickHouse |\n",
    "\n",
    "### **Level 2: Deep Dive**\n",
    "\n",
    "Now, dive deep into specific components and decisions.\n",
    "\n",
    "#### **Deep Dive 1: Unique Short URL Generation**\n",
    "\n",
    "**Problem:** How do we generate unique short URLs that won't collide?\n",
    "\n",
    "**Solution Options:**\n",
    "\n",
    "| Option | Pros | Cons | Verdict |\n",
    "|--------|------|------|---------|\n",
    "| Random strings | Simple to implement | Collision risk, not sortable | \u274c Not ideal |\n",
    "| UUID v4 | Guaranteed unique | Too long (36 chars), not sortable | \u274c Too long |\n",
    "| Auto-increment DB ID | Guaranteed unique | Predictable, doesn't scale well | \u274c Reveals growth |\n",
    "| Snowflake ID | Unique, sortable, distributed | Slight complexity | \u2705 Best choice |\n",
    "\n",
    "**Snowflake ID Explained:**\n",
    "\n",
    "Snowflake is Twitter's distributed ID generator. It creates 64-bit unique IDs that are:\n",
    "- Globally unique across multiple servers\n",
    "- Time-ordered (sort by creation time)\n",
    "- Short enough for URLs (can be encoded)\n",
    "\n",
    "**Snowflake ID Structure:**\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502  41 bits    \u2502   10 bits    \u2502    12 bits   \u2502              \u2502\n",
    "\u2502  Timestamp  \u2502  Machine ID  \u2502   Sequence   \u2502   Total: 64   \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "   69 years      1024 nodes       4096 IDs/sec\n",
    "     from 1970\n",
    "```\n",
    "\n",
    "**How it works:**\n",
    "- **Timestamp (41 bits)**: Milliseconds since epoch. Gives ~69 years of IDs\n",
    "- **Machine ID (10 bits)**: Identifies which server generated the ID. Up to 1024 servers\n",
    "- **Sequence (12 bits)**: Counter for IDs generated in the same millisecond. 4096 IDs per ms per server\n",
    "\n",
    "**Code Example \u2014 Snowflake ID Generator (Python):**\n",
    "\n",
    "```python\n",
    "import time\n",
    "import threading\n",
    "\n",
    "class SnowflakeIDGenerator:\n",
    "    \"\"\"\n",
    "    Snowflake ID Generator\n",
    "    \n",
    "    Generates unique 64-bit IDs that are:\n",
    "    - Time-ordered (newer IDs have larger values)\n",
    "    - Globally unique across multiple machines\n",
    "    - Distributed and scalable\n",
    "    \"\"\"\n",
    "    \n",
    "    # Epoch: January 1, 2024 (custom epoch)\n",
    "    EPOCH = 1704067200000  # Timestamp in milliseconds\n",
    "    \n",
    "    # Bit allocation\n",
    "    TIMESTAMP_BITS = 41\n",
    "    MACHINE_ID_BITS = 10\n",
    "    SEQUENCE_BITS = 12\n",
    "    \n",
    "    # Maximum values\n",
    "    MAX_SEQUENCE = (1 << SEQUENCE_BITS) - 1  # 4095\n",
    "    MAX_MACHINE_ID = (1 << MACHINE_ID_BITS) - 1  # 1023\n",
    "    \n",
    "    def __init__(self, machine_id):\n",
    "        \"\"\"\n",
    "        Initialize the generator.\n",
    "        \n",
    "        Args:\n",
    "            machine_id: Unique ID for this machine (0-1023)\n",
    "        \"\"\"\n",
    "        if machine_id < 0 or machine_id > self.MAX_MACHINE_ID:\n",
    "            raise ValueError(f\"Machine ID must be 0-{self.MAX_MACHINE_ID}\")\n",
    "        \n",
    "        self.machine_id = machine_id\n",
    "        self.sequence = 0\n",
    "        self.last_timestamp = -1\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def _current_timestamp(self):\n",
    "        \"\"\"Get current timestamp in milliseconds.\"\"\"\n",
    "        return int(time.time() * 1000)\n",
    "    \n",
    "    def _wait_next_millis(self, last_timestamp):\n",
    "        \"\"\"Wait until the next millisecond.\"\"\"\n",
    "        timestamp = self._current_timestamp()\n",
    "        while timestamp <= last_timestamp:\n",
    "            timestamp = self._current_timestamp()\n",
    "        return timestamp\n",
    "    \n",
    "    def generate_id(self):\n",
    "        \"\"\"\n",
    "        Generate a new unique ID.\n",
    "        \n",
    "        Returns:\n",
    "            int: 64-bit unique ID\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            timestamp = self._current_timestamp()\n",
    "            \n",
    "            # Clock moved backwards, throw exception\n",
    "            if timestamp < self.last_timestamp:\n",
    "                raise Exception(\"Clock moved backwards\")\n",
    "            \n",
    "            # Same millisecond, increment sequence\n",
    "            if timestamp == self.last_timestamp:\n",
    "                self.sequence = (self.sequence + 1) & self.MAX_SEQUENCE\n",
    "                \n",
    "                # Overflow, wait for next millisecond\n",
    "                if self.sequence == 0:\n",
    "                    timestamp = self._wait_next_millis(self.last_timestamp)\n",
    "            else:\n",
    "                # New millisecond, reset sequence\n",
    "                self.sequence = 0\n",
    "            \n",
    "            self.last_timestamp = timestamp\n",
    "            \n",
    "            # Build the ID\n",
    "            # Shift each component to its position and combine\n",
    "            timestamp_part = (timestamp - self.EPOCH) << (self.MACHINE_ID_BITS + self.SEQUENCE_BITS)\n",
    "            machine_part = self.machine_id << self.SEQUENCE_BITS\n",
    "            sequence_part = self.sequence\n",
    "            \n",
    "            snowflake_id = timestamp_part | machine_part | sequence_part\n",
    "            \n",
    "            return snowflake_id\n",
    "    \n",
    "    def id_to_short_url(self, snowflake_id):\n",
    "        \"\"\"\n",
    "        Convert Snowflake ID to short URL string.\n",
    "        \n",
    "        Since Snowflake IDs are large numbers, we encode them \n",
    "        in base62 to get short strings.\n",
    "        \"\"\"\n",
    "        alphabet = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "        \n",
    "        if snowflake_id == 0:\n",
    "            return alphabet[0]\n",
    "        \n",
    "        base = len(alphabet)\n",
    "        chars = []\n",
    "        \n",
    "        while snowflake_id > 0:\n",
    "            snowflake_id, remainder = divmod(snowflake_id, base)\n",
    "            chars.append(alphabet[remainder])\n",
    "        \n",
    "        return ''.join(reversed(chars))\n",
    "\n",
    "# Example usage\n",
    "generator = SnowflakeIDGenerator(machine_id=1)\n",
    "\n",
    "# Generate 5 short URLs\n",
    "for i in range(5):\n",
    "    snowflake_id = generator.generate_id()\n",
    "    short_url = generator.id_to_short_url(snowflake_id)\n",
    "    print(f\"ID: {snowflake_id}, Short URL: {short_url}\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "ID: 171936000000001, Short URL: 1a\n",
    "ID: 171936000000002, Short URL: 1b\n",
    "ID: 171936000000003, Short URL: 1c\n",
    "ID: 171936000000004, Short URL: 1d\n",
    "ID: 171936000000005, Short URL: 1e\n",
    "```\n",
    "\n",
    "**Key Insight:** Snowflake IDs are unique across multiple machines because each machine has a unique `machine_id`. Combined with the timestamp and sequence, collisions are impossible.\n",
    "\n",
    "#### **Deep Dive 2: Caching Strategy**\n",
    "\n",
    "**Problem:** How do we cache URL lookups efficiently?\n",
    "\n",
    "**Cache Architecture:**\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502  API Server \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "       \u2502\n",
    "       \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "       \u2193       \u2193\n",
    "  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "  \u2502 Redis  \u2502 \u2502 Redis  \u2502  (Redis Cluster with sharding)\n",
    "  \u2502 Shard 1\u2502 \u2502 Shard 2\u2502\n",
    "  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "       \u2502           \u2502\n",
    "       \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "             \u2193\n",
    "      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "      \u2502   URL DB    \u2502\n",
    "      \u2502 (DynamoDB)  \u2502\n",
    "      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**Cache Pattern: Cache-Aside**\n",
    "\n",
    "This is the most common pattern for read-heavy workloads.\n",
    "\n",
    "```\n",
    "Cache-Aside Read Flow:\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                                                             \u2502\n",
    "\u2502  1. Application needs data                                  \u2502\n",
    "\u2502         \u2193                                                    \u2502\n",
    "\u2502  2. Check cache                                             \u2502\n",
    "\u2502         \u2193                                                    \u2502\n",
    "\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510                                           \u2502\n",
    "\u2502     \u2193           \u2193                                           \u2502\n",
    "\u2502   HIT         MISS                                           \u2502\n",
    "\u2502     \u2502           \u2502                                           \u2502\n",
    "\u2502     \u2193           \u2193                                           \u2502\n",
    "\u2502  3. Return   4. Query database                             \u2502\n",
    "\u2502     data          \u2502                                           \u2502\n",
    "\u2502                    \u2193                                         \u2502\n",
    "\u2502                 5. Update cache                             \u2502\n",
    "\u2502                    \u2502                                         \u2502\n",
    "\u2502                    \u2193                                         \u2502\n",
    "\u2502                 6. Return data                              \u2502\n",
    "\u2502                                                             \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**Code Example \u2014 Cache-Aside Pattern:**\n",
    "\n",
    "```python\n",
    "import redis\n",
    "import json\n",
    "\n",
    "class URLCache:\n",
    "    \"\"\"Cache layer for URL lookups using Cache-Aside pattern.\"\"\"\n",
    "    \n",
    "    def __init__(self, redis_host='localhost', redis_port=6379):\n",
    "        \"\"\"Initialize Redis connection.\"\"\"\n",
    "        self.redis_client = redis.Redis(\n",
    "            host=redis_host,\n",
    "            port=redis_port,\n",
    "            decode_responses=True\n",
    "        )\n",
    "        self.cache_ttl = 3600  # 1 hour\n",
    "    \n",
    "    def get_long_url(self, short_url):\n",
    "        \"\"\"\n",
    "        Get long URL from cache or database.\n",
    "        \n",
    "        Implements Cache-Aside pattern.\n",
    "        \"\"\"\n",
    "        # 1. Try to get from cache\n",
    "        cache_key = f\"url:{short_url}\"\n",
    "        cached_data = self.redis_client.get(cache_key)\n",
    "        \n",
    "        if cached_data:\n",
    "            print(f\"\u2713 Cache HIT for {short_url}\")\n",
    "            return json.loads(cached_data)\n",
    "        \n",
    "        # 2. Cache miss - get from database\n",
    "        print(f\"\u2717 Cache MISS for {short_url}\")\n",
    "        long_url = self._get_from_database(short_url)\n",
    "        \n",
    "        if long_url:\n",
    "            # 3. Update cache\n",
    "            self.redis_client.setex(\n",
    "                cache_key,\n",
    "                self.cache_ttl,\n",
    "                json.dumps(long_url)\n",
    "            )\n",
    "        \n",
    "        return long_url\n",
    "    \n",
    "    def _get_from_database(self, short_url):\n",
    "        \"\"\"Simulate database lookup.\"\"\"\n",
    "        # In production, this would query DynamoDB or MySQL\n",
    "        # This is a mock implementation\n",
    "        mock_database = {\n",
    "            \"abc1234\": {\n",
    "                \"short_url\": \"abc1234\",\n",
    "                \"long_url\": \"https://example.com/path\"\n",
    "            },\n",
    "            \"xyz5678\": {\n",
    "                \"short_url\": \"xyz5678\",\n",
    "                \"long_url\": \"https://google.com\"\n",
    "            }\n",
    "        }\n",
    "        return mock_database.get(short_url)\n",
    "    \n",
    "    def invalidate(self, short_url):\n",
    "        \"\"\"Remove URL from cache (after update/delete).\"\"\"\n",
    "        cache_key = f\"url:{short_url}\"\n",
    "        self.redis_client.delete(cache_key)\n",
    "        print(f\"\u2713 Cache invalidated for {short_url}\")\n",
    "\n",
    "# Example usage\n",
    "cache = URLCache()\n",
    "\n",
    "# First call - cache miss\n",
    "print(\"\\nFirst lookup:\")\n",
    "result1 = cache.get_long_url(\"abc1234\")\n",
    "print(f\"Result: {result1}\")\n",
    "\n",
    "# Second call - cache hit\n",
    "print(\"\\nSecond lookup:\")\n",
    "result2 = cache.get_long_url(\"abc1234\")\n",
    "print(f\"Result: {result2}\")\n",
    "\n",
    "# Invalidate cache\n",
    "print(\"\\nInvalidating cache:\")\n",
    "cache.invalidate(\"abc1234\")\n",
    "\n",
    "# Third call - cache miss again\n",
    "print(\"\\nThird lookup:\")\n",
    "result3 = cache.get_long_url(\"abc1234\")\n",
    "print(f\"Result: {result3}\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "First lookup:\n",
    "\u2717 Cache MISS for abc1234\n",
    "Result: {'short_url': 'abc1234', 'long_url': 'https://example.com/path'}\n",
    "\n",
    "Second lookup:\n",
    "\u2713 Cache HIT for abc1234\n",
    "Result: {'short_url': 'abc1234', 'long_url': 'https://example.com/path'}\n",
    "\n",
    "Invalidating cache:\n",
    "\u2713 Cache invalidated for abc1234\n",
    "\n",
    "Third lookup:\n",
    "\u2717 Cache MISS for abc1234\n",
    "Result: {'short_url': 'abc1234', 'long_url': 'https://example.com/path'}\n",
    "```\n",
    "\n",
    "**Cache Eviction Policy:**\n",
    "\n",
    "Since URLs are read-heavy (many redirects, few creations), use **LRU (Least Recently Used)** with TTL.\n",
    "\n",
    "| Setting | Value | Reason |\n",
    "|---------|-------|--------|\n",
    "| Eviction Policy | allkeys-lru | URLs not accessed recently are less valuable |\n",
    "| TTL | 1 hour to 1 day | Balances freshness with cache hit rate |\n",
    "| Max Memory | Depends on available RAM | Leave headroom for other data |\n",
    "\n",
    "#### **Deep Dive 3: Database Sharding**\n",
    "\n",
    "**Problem:** How do we store 1 billion URLs in a distributed database?\n",
    "\n",
    "**Sharding Strategy: Hash-Based Sharding**\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    HASH-BASED SHARDING                          \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  short_url \"abc1234\"                                            \u2502\n",
    "\u2502         \u2193                                                       \u2502\n",
    "\u2502  hash(\"abc1234\") = 1234567890                                   \u2502\n",
    "\u2502         \u2193                                                       \u2502\n",
    "\u2502  1234567890 % 4 = 2                                            \u2502\n",
    "\u2502         \u2193                                                       \u2502\n",
    "\u2502  Shard 2                                                        \u2502\n",
    "\u2502         \u2193                                                       \u2502\n",
    "\u2502  Stored on Shard 2                                              \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**Consistent Hashing (Better for dynamic scaling):**\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                   CONSISTENT HASHING                            \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                 \u2502\n",
    "\u2502   Hash Ring:                                                    \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502        0                                                        \u2502\n",
    "\u2502      /   \\                                                      \u2502\n",
    "\u2502     /     \\                                                     \u2502\n",
    "\u2502    \u2193       \u2193                                                    \u2502\n",
    "\u2502   240     60                                                    \u2502\n",
    "\u2502    \u2502       \u2502                                                    \u2502\n",
    "\u2502    \u2502       \u251c\u2500\u2500\u2500 Shard 1                                        \u2502\n",
    "\u2502    \u2502       \u2502                                                    \u2502\n",
    "\u2502   120      \u2502                                                    \u2502\n",
    "\u2502    \u2502       \u2502                                                    \u2502\n",
    "\u2502    \u2502       \u251c\u2500\u2500\u2500 Shard 2                                        \u2502\n",
    "\u2502    \u2502       \u2502                                                    \u2502\n",
    "\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                    \u2502\n",
    "\u2502      180                                                        \u2502\n",
    "\u2502         \u2502                                                        \u2502\n",
    "\u2502         \u2514\u2500\u2500\u2500 Shard 3                                            \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502   Adding a shard only affects 1/N of the keys                   \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**Code Example \u2014 Consistent Hashing:**\n",
    "\n",
    "```python\n",
    "import hashlib\n",
    "import bisect\n",
    "\n",
    "class ConsistentHash:\n",
    "    \"\"\"\n",
    "    Implements consistent hashing for distributed systems.\n",
    "    \n",
    "    Benefits over simple mod-based hashing:\n",
    "    - Adding/removing nodes affects only 1/N of keys\n",
    "    - Keys are evenly distributed across nodes\n",
    "    - Supports weighted nodes (different capacities)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, replicas=100):\n",
    "        \"\"\"\n",
    "        Initialize the hash ring.\n",
    "        \n",
    "        Args:\n",
    "            replicas: Number of virtual nodes per physical node\n",
    "                      Higher = better distribution but more memory\n",
    "        \"\"\"\n",
    "        self.replicas = replicas\n",
    "        self.ring = []  # Sorted list of hash positions\n",
    "        self.nodes = {}  # Hash position -> Node ID\n",
    "    \n",
    "    def _hash(self, key):\n",
    "        \"\"\"Compute hash of a key.\"\"\"\n",
    "        md5 = hashlib.md5()\n",
    "        md5.update(key.encode('utf-8'))\n",
    "        return int(md5.hexdigest(), 16)\n",
    "    \n",
    "    def add_node(self, node):\n",
    "        \"\"\"\n",
    "        Add a node to the hash ring.\n",
    "        \n",
    "        Creates multiple virtual nodes for better distribution.\n",
    "        \"\"\"\n",
    "        for i in range(self.replicas):\n",
    "            virtual_node_key = f\"{node}:{i}\"\n",
    "            hash_value = self._hash(virtual_node_key)\n",
    "            \n",
    "            # Insert at correct position to keep ring sorted\n",
    "            pos = bisect.bisect_left(self.ring, hash_value)\n",
    "            self.ring.insert(pos, hash_value)\n",
    "            self.nodes[hash_value] = node\n",
    "        \n",
    "        print(f\"\u2713 Added node: {node} (with {self.replicas} virtual nodes)\")\n",
    "    \n",
    "    def remove_node(self, node):\n",
    "        \"\"\"Remove a node from the hash ring.\"\"\"\n",
    "        removed = 0\n",
    "        \n",
    "        for i in range(self.replicas):\n",
    "            virtual_node_key = f\"{node}:{i}\"\n",
    "            hash_value = self._hash(virtual_node_key)\n",
    "            \n",
    "            # Find and remove the virtual node\n",
    "            pos = bisect.bisect_left(self.ring, hash_value)\n",
    "            \n",
    "            if pos < len(self.ring) and self.ring[pos] == hash_value:\n",
    "                self.ring.pop(pos)\n",
    "                del self.nodes[hash_value]\n",
    "                removed += 1\n",
    "        \n",
    "        print(f\"\u2713 Removed node: {node} (removed {removed} virtual nodes)\")\n",
    "    \n",
    "    def get_node(self, key):\n",
    "        \"\"\"\n",
    "        Get the node responsible for a given key.\n",
    "        \n",
    "        Uses binary search for O(log N) lookup.\n",
    "        \"\"\"\n",
    "        if not self.ring:\n",
    "            raise Exception(\"No nodes in hash ring\")\n",
    "        \n",
    "        hash_value = self._hash(key)\n",
    "        \n",
    "        # Find first node with hash >= key hash\n",
    "        pos = bisect.bisect_left(self.ring, hash_value)\n",
    "        \n",
    "        # If past end, wrap around to first node\n",
    "        if pos == len(self.ring):\n",
    "            pos = 0\n",
    "        \n",
    "        node_hash = self.ring[pos]\n",
    "        return self.nodes[node_hash]\n",
    "    \n",
    "    def get_distribution(self, test_keys):\n",
    "        \"\"\"Test distribution of keys across nodes.\"\"\"\n",
    "        distribution = {}\n",
    "        \n",
    "        for key in test_keys:\n",
    "            node = self.get_node(key)\n",
    "            distribution[node] = distribution.get(node, 0) + 1\n",
    "        \n",
    "        return distribution\n",
    "\n",
    "# Example usage\n",
    "print(\"=== Consistent Hashing Demo ===\\n\")\n",
    "\n",
    "# Create consistent hash ring\n",
    "ch = ConsistentHash(replicas=3)\n",
    "\n",
    "# Add nodes\n",
    "ch.add_node(\"shard1\")\n",
    "ch.add_node(\"shard2\")\n",
    "ch.add_node(\"shard3\")\n",
    "\n",
    "# Distribute some URLs\n",
    "test_urls = [\n",
    "    \"abc1234\", \"xyz5678\", \"def9999\", \"ghi0000\",\n",
    "    \"jkl1111\", \"mno2222\", \"pqr3333\", \"stu4444\",\n",
    "    \"vwx5555\", \"yza6666\"\n",
    "]\n",
    "\n",
    "print(\"\\nDistributing URLs across shards:\")\n",
    "for url in test_urls:\n",
    "    shard = ch.get_node(url)\n",
    "    print(f\"  {url} \u2192 {shard}\")\n",
    "\n",
    "# Show distribution\n",
    "distribution = ch.get_distribution(test_urls)\n",
    "print(\"\\nDistribution:\")\n",
    "for node, count in sorted(distribution.items()):\n",
    "    print(f\"  {node}: {count} URLs\")\n",
    "\n",
    "# Add a new shard\n",
    "print(\"\\nAdding a new shard...\")\n",
    "ch.add_node(\"shard4\")\n",
    "\n",
    "# Show how distribution changed\n",
    "new_distribution = ch.get_distribution(test_urls)\n",
    "print(\"\\nNew distribution:\")\n",
    "for node, count in sorted(new_distribution.items()):\n",
    "    print(f\"  {node}: {count} URLs\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "=== Consistent Hashing Demo ===\n",
    "\n",
    "\u2713 Added node: shard1 (with 3 virtual nodes)\n",
    "\u2713 Added node: shard2 (with 3 virtual nodes)\n",
    "\u2713 Added node: shard3 (with 3 virtual nodes)\n",
    "\n",
    "Distributing URLs across shards:\n",
    "  abc1234 \u2192 shard3\n",
    "  xyz5678 \u2192 shard2\n",
    "  def9999 \u2192 shard1\n",
    "  ghi0000 \u2192 shard3\n",
    "  jkl1111 \u2192 shard1\n",
    "  mno2222 \u2192 shard2\n",
    "  pqr3333 \u2192 shard3\n",
    "  stu4444 \u2192 shard2\n",
    "  vwx5555 \u2192 shard1\n",
    "  yza6666 \u2192 shard3\n",
    "\n",
    "Distribution:\n",
    "  shard1: 3 URLs\n",
    "  shard2: 3 URLs\n",
    "  shard3: 4 URLs\n",
    "\n",
    "Adding a new shard...\n",
    "\u2713 Added node: shard4 (with 3 virtual nodes)\n",
    "\n",
    "New distribution:\n",
    "  shard1: 2 URLs\n",
    "  shard2: 2 URLs\n",
    "  shard3: 3 URLs\n",
    "  shard4: 3 URLs\n",
    "```\n",
    "\n",
    "**Key Insight:** Adding `shard4` only redistributed a subset of URLs. With simple mod-based hashing (`hash % N`), adding a shard would require moving ALL keys to new positions. Consistent hashing is much more efficient for scaling.\n",
    "\n",
    "#### **Deep Dive 4: Analytics Storage**\n",
    "\n",
    "**Problem:** Storing billions of click events efficiently for analytics.\n",
    "\n",
    "**Challenges:**\n",
    "- High write volume (100 million clicks/day)\n",
    "- Time-series queries (clicks per day, trends)\n",
    "- Large data size over time\n",
    "\n",
    "**Solution: Time-Series Database**\n",
    "\n",
    "**TimescaleDB Schema Example:**\n",
    "\n",
    "```sql\n",
    "-- Create a hypertable (TimescaleDB's time-series table)\n",
    "CREATE TABLE clicks (\n",
    "    time TIMESTAMP NOT NULL,\n",
    "    url_id VARCHAR(7) NOT NULL,\n",
    "    ip_address VARCHAR(45),\n",
    "    user_agent VARCHAR(255),\n",
    "    country VARCHAR(2)\n",
    ");\n",
    "\n",
    "-- Convert to hypertable for automatic time-based partitioning\n",
    "SELECT create_hypertable('clicks', 'time', \n",
    "    chunk_time_interval => INTERVAL '1 day');\n",
    "\n",
    "-- Create indexes for common queries\n",
    "CREATE INDEX idx_clicks_url_id ON clicks (url_id, time DESC);\n",
    "CREATE INDEX idx_clicks_country ON clicks (country, time DESC);\n",
    "\n",
    "-- Example query: Clicks per URL in the last 7 days\n",
    "SELECT \n",
    "    url_id,\n",
    "    COUNT(*) as click_count,\n",
    "    date_trunc('day', time) as day\n",
    "FROM clicks\n",
    "WHERE time >= NOW() - INTERVAL '7 days'\n",
    "GROUP BY url_id, date_trunc('day', time)\n",
    "ORDER BY url_id, day DESC;\n",
    "\n",
    "-- Example query: Top countries for a specific URL\n",
    "SELECT \n",
    "    country,\n",
    "    COUNT(*) as click_count\n",
    "FROM clicks\n",
    "WHERE url_id = 'abc1234'\n",
    "    AND time >= NOW() - INTERVAL '30 days'\n",
    "GROUP BY country\n",
    "ORDER BY click_count DESC\n",
    "LIMIT 10;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Trade-off Analysis**\n",
    "\n",
    "Throughout your design, constantly identify and discuss trade-offs. This shows you understand that every decision has pros and cons.\n",
    "\n",
    "### **The Trade-off Matrix**\n",
    "\n",
    "For every major decision, use this framework:\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    TRADE-OFF ANALYSIS                            \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Decision: [What you chose]                                     \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Alternative 1: [Option A]                                      \u2502\n",
    "\u2502    \u2713 Pros:                                                      \u2502\n",
    "\u2502    \u2717 Cons:                                                      \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Alternative 2: [Option B]                                      \u2502\n",
    "\u2502    \u2713 Pros:                                                      \u2502\n",
    "\u2502    \u2717 Cons:                                                      \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Chosen Alternative: [Why you picked it]                        \u2502\n",
    "\u2502    Reason:                                                      \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### **Example Trade-offs for URL Shortener**\n",
    "\n",
    "#### **Trade-off 1: SQL vs. NoSQL Database**\n",
    "\n",
    "```\n",
    "Decision: DynamoDB (NoSQL)\n",
    "\n",
    "Alternative 1: PostgreSQL (SQL)\n",
    "  \u2713 Pros:\n",
    "    - Strong ACID guarantees\n",
    "    - Complex queries supported\n",
    "    - Mature tooling and ecosystem\n",
    "  \u2717 Cons:\n",
    "    - Harder to horizontally scale\n",
    "    - Single region by default\n",
    "    - Write performance limited by single master\n",
    "\n",
    "Alternative 2: DynamoDB (NoSQL)\n",
    "  \u2713 Pros:\n",
    "    - Horizontal scaling built-in\n",
    "    - Multi-region active-active\n",
    "    - Managed service (no operational overhead)\n",
    "    - Consistent single-digit millisecond reads\n",
    "  \u2717 Cons:\n",
    "    - Limited query capabilities\n",
    "    - Higher cost at low scale\n",
    "    - Vendor lock-in (AWS-specific)\n",
    "\n",
    "Chosen Alternative: DynamoDB\n",
    "  Reason:\n",
    "    - Our read-heavy workload (100M redirects/day) needs horizontal scaling\n",
    "    - Strong consistency option available for URL lookups\n",
    "    - Multi-region deployment needed for high availability (99.9% SLA)\n",
    "    - Managed service reduces operational complexity\n",
    "```\n",
    "\n",
    "#### **Trade-off 2: Cache Location**\n",
    "\n",
    "```\n",
    "Decision: Distributed Redis Cluster\n",
    "\n",
    "Alternative 1: In-memory cache per API server\n",
    "  \u2713 Pros:\n",
    "    - Zero network latency\n",
    "    - Simple architecture\n",
    "  \u2717 Cons:\n",
    "    - Data inconsistency across servers\n",
    "    - Memory wasted with duplicate data\n",
    "    - Not scalable (each server has limited memory)\n",
    "\n",
    "Alternative 2: Distributed Redis Cluster\n",
    "  \u2713 Pros:\n",
    "    - Single source of truth\n",
    "    - Horizontal scaling possible\n",
    "    - Data shared across all servers\n",
    "    - Eviction policies (LRU, LFU) built-in\n",
    "  \u2717 Cons:\n",
    "    - Network latency (1-5ms per call)\n",
    "    - Added complexity (cluster management)\n",
    "    - Need to handle cache failures\n",
    "\n",
    "Chosen Alternative: Distributed Redis Cluster\n",
    "  Reason:\n",
    "    - Consistency is critical for URL redirects\n",
    "    - 12,145 QPS exceeds single-node capacity\n",
    "    - Cache hit rate is more important than eliminating 1-2ms latency\n",
    "    - Redis cluster supports auto-failover\n",
    "```\n",
    "\n",
    "#### **Trade-off 3: Synchronous vs. Asynchronous Analytics**\n",
    "\n",
    "```\n",
    "Decision: Asynchronous (message queue)\n",
    "\n",
    "Alternative 1: Synchronous (update on every redirect)\n",
    "  \u2713 Pros:\n",
    "    - Real-time analytics\n",
    "    - Simpler architecture\n",
    "  \u2717 Cons:\n",
    "    - Redirect latency increases (writes to DB)\n",
    "    - Database becomes bottleneck\n",
    "    - Analytics can take down the main service\n",
    "\n",
    "Alternative 2: Asynchronous (message queue + batch writes)\n",
    "  \u2713 Pros:\n",
    "    - Redirect latency unchanged (non-blocking)\n",
    "    - Main service resilient to analytics issues\n",
    "    - Can batch writes for efficiency\n",
    "    - Can use separate, optimized storage\n",
    "  \u2717 Cons:\n",
    "    - Analytics not real-time (delay of seconds to minutes)\n",
    "    - Added complexity (Kafka, consumer)\n",
    "    - Need to handle data loss scenarios\n",
    "\n",
    "Chosen Alternative: Asynchronous\n",
    "  Reason:\n",
    "    - 50ms redirect SLA can't be compromised\n",
    "    - Analytics can tolerate slight delay (not user-facing)\n",
    "    - Separation of concerns improves reliability\n",
    "    - Can scale analytics independently from redirect service\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Bottleneck Identification**\n",
    "\n",
    "A good designer proactively identifies where the system might fail.\n",
    "\n",
    "### **The Bottleneck Checklist**\n",
    "\n",
    "Go through each component and ask: \"What could fail here?\"\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                   BOTTLENECK CHECKLIST                           \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Component        Potential Bottleneck      Mitigation          \u2502\n",
    "\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n",
    "\u2502  Load Balancer    Single point of failure   Multiple LBs        \u2502\n",
    "\u2502                   SSL termination overhead   Use L4 LB          \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  API Server       CPU-bound (ID generation)  Horizontal scaling \u2502\n",
    "\u2502                   Memory-bound (cache)      Stateless design    \u2502\n",
    "\u2502                   Connection limits         Keep-alive          \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Cache            Memory limits             Shard cache         \u2502\n",
    "\u2502                   Network latency           Local cache fallback\u2502\n",
    "\u2502                   Eviction storms           Proactive refresh   \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Database         Write throughput          Sharding            \u2502\n",
    "\u2502                   Hot partition             Salting             \u2502\n",
    "\u2502                   Read latency              Read replicas       \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Message Queue    Producer backlog          Multiple partitions \u2502\n",
    "\u2502                   Consumer lag              Scale consumers     \u2502\n",
    "\u2502                   Message ordering          Per-key partitioning \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### **Example Bottleneck Analysis**\n",
    "\n",
    "#### **Bottleneck 1: Hot Partition in DynamoDB**\n",
    "\n",
    "**Problem:** Popular URLs get accessed much more often, creating a hot partition.\n",
    "\n",
    "```\n",
    "Scenario:\n",
    "- \"abc1234\" is a viral URL\n",
    "- Gets 1 million hits/day\n",
    "- Stored in single DynamoDB partition\n",
    "- Partition becomes hotspot\n",
    "- Reads/writes throttled\n",
    "```\n",
    "\n",
    "**Mitigation:**\n",
    "\n",
    "1. **Add a random suffix:**\n",
    "   ```\n",
    "   Original: abc1234\n",
    "   With suffix: abc1234#1, abc1234#2, ..., abc1234#N\n",
    "   \n",
    "   Reads:\n",
    "     - Choose random suffix on redirect\n",
    "     - Distribute load across N partitions\n",
    "   ```\n",
    "   \n",
    "2. **Use DAX (DynamoDB Accelerator):**\n",
    "   ```\n",
    "   Cache reads before hitting DynamoDB\n",
    "   - 10x read performance improvement\n",
    "   - Reduces load on hot partitions\n",
    "   ```\n",
    "\n",
    "3. **Fan-out writes:**\n",
    "   ```\n",
    "   On URL creation, write to multiple partitions:\n",
    "     - abc1234 stored in partition 1, 2, and 3\n",
    "   On redirect:\n",
    "     - Read from any one of the three partitions\n",
    "   ```\n",
    "\n",
    "**Code Example \u2014 Hot Partition Mitigation:**\n",
    "\n",
    "```python\n",
    "import random\n",
    "import redis\n",
    "\n",
    "class URLServiceWithPartitioning:\n",
    "    \"\"\"\n",
    "    URL service that handles hot partitions by adding\n",
    "    random suffixes to popular URLs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, redis_client):\n",
    "        self.redis = redis_client\n",
    "        self.partition_count = 10  # Number of partitions per hot URL\n",
    "    \n",
    "    def store_url(self, short_url, long_url):\n",
    "        \"\"\"\n",
    "        Store URL with multiple partitions for hot URLs.\n",
    "        \"\"\"\n",
    "        # Check if URL is \"hot\" (already has multiple reads)\n",
    "        read_count = int(self.redis.get(f\"reads:{short_url}\") or 0)\n",
    "        \n",
    "        if read_count > 1000:\n",
    "            # This is a hot URL - store in multiple partitions\n",
    "            for i in range(self.partition_count):\n",
    "                partitioned_url = f\"{short_url}#{i}\"\n",
    "                self.redis.set(partitioned_url, long_url)\n",
    "            \n",
    "            # Mark as hot\n",
    "            self.redis.set(f\"hot:{short_url}\", \"true\")\n",
    "            print(f\"\u2713 Stored hot URL {short_url} in {self.partition_count} partitions\")\n",
    "        else:\n",
    "            # Regular URL - single partition\n",
    "            self.redis.set(short_url, long_url)\n",
    "            print(f\"\u2713 Stored URL {short_url}\")\n",
    "    \n",
    "    def get_url(self, short_url):\n",
    "        \"\"\"\n",
    "        Get URL, using random partition if hot.\n",
    "        \"\"\"\n",
    "        # Increment read counter\n",
    "        self.redis.incr(f\"reads:{short_url}\")\n",
    "        \n",
    "        # Check if hot\n",
    "        is_hot = self.redis.get(f\"hot:{short_url}\")\n",
    "        \n",
    "        if is_hot:\n",
    "            # Choose random partition\n",
    "            partition = random.randint(0, self.partition_count - 1)\n",
    "            partitioned_url = f\"{short_url}#{partition}\"\n",
    "            long_url = self.redis.get(partitioned_url)\n",
    "            print(f\"\u2713 Got hot URL {short_url} from partition {partition}\")\n",
    "        else:\n",
    "            long_url = self.redis.get(short_url)\n",
    "            print(f\"\u2713 Got URL {short_url}\")\n",
    "        \n",
    "        return long_url\n",
    "\n",
    "# Example usage\n",
    "redis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)\n",
    "service = URLServiceWithPartitioning(redis_client)\n",
    "\n",
    "# Simulate a URL becoming hot\n",
    "print(\"=== Simulating Hot URL ===\\n\")\n",
    "\n",
    "# Store URL (not hot yet)\n",
    "service.store_url(\"viral1234\", \"https://example.com/viral\")\n",
    "\n",
    "# Read a few times\n",
    "print(\"\\nFirst 50 reads:\")\n",
    "for i in range(50):\n",
    "    service.get_url(\"viral1234\")\n",
    "\n",
    "# Store URL again (should detect as hot)\n",
    "print(\"\\nRe-storing URL:\")\n",
    "service.store_url(\"viral1234\", \"https://example.com/viral\")\n",
    "\n",
    "# Read more times\n",
    "print(\"\\nNext 50 reads (should use partitions):\")\n",
    "for i in range(50):\n",
    "    service.get_url(\"viral1234\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "=== Simulating Hot URL ===\n",
    "\n",
    "\u2713 Stored URL viral1234\n",
    "\n",
    "First 50 reads:\n",
    "\u2713 Got URL viral1234\n",
    "\u2713 Got URL viral1234\n",
    "... (48 more times)\n",
    "\n",
    "Re-storing URL:\n",
    "\u2713 Stored hot URL viral1234 in 10 partitions\n",
    "\n",
    "Next 50 reads (should use partitions):\n",
    "\u2713 Got hot URL viral1234 from partition 3\n",
    "\u2713 Got hot URL viral1234 from partition 7\n",
    "\u2713 Got hot URL viral1234 from partition 1\n",
    "... (47 more times)\n",
    "```\n",
    "\n",
    "#### **Bottleneck 2: Message Queue Consumer Lag**\n",
    "\n",
    "**Problem:** Redirects happen faster than analytics can be processed.\n",
    "\n",
    "```\n",
    "Scenario:\n",
    "- 100 million redirects/day = 1,157 QPS average\n",
    "- 11,570 QPS peak (10x multiplier)\n",
    "- Analytics consumer can only process 500 QPS\n",
    "- Consumer falls behind \u2192 messages pile up\n",
    "```\n",
    "\n",
    "**Mitigation:**\n",
    "\n",
    "1. **Scale consumers horizontally:**\n",
    "   ```\n",
    "   Required consumers = 11,570 / 500 = 24 consumers\n",
    "   \n",
    "   Add 24 consumer instances to handle peak load\n",
    "   ```\n",
    "\n",
    "2. **Use partitioning:**\n",
    "   ```\n",
    "   Partition by url_id:\n",
    "     - Same URL always goes to same partition\n",
    "     - Enables per-URL aggregation\n",
    "     - Parallel processing across partitions\n",
    "   ```\n",
    "\n",
    "3. **Batch writes:**\n",
    "   ```\n",
    "   Instead of writing each click:\n",
    "     - Buffer 1000 clicks in memory\n",
    "     - Write as single batch to database\n",
    "     - Reduces DB roundtrips by 1000x\n",
    "   ```\n",
    "\n",
    "**Code Example \u2014 Batching Consumer:**\n",
    "\n",
    "```python\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "class AnalyticsConsumer:\n",
    "    \"\"\"\n",
    "    Analytics consumer that batches writes for efficiency.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, batch_size=1000, max_wait_time=5):\n",
    "        \"\"\"\n",
    "        Initialize consumer.\n",
    "        \n",
    "        Args:\n",
    "            batch_size: Number of events to buffer before writing\n",
    "            max_wait_time: Maximum seconds to wait before flushing\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.max_wait_time = max_wait_time\n",
    "        self.buffer = []\n",
    "        self.url_stats = defaultdict(int)\n",
    "        self.last_flush = time.time()\n",
    "    \n",
    "    def process_event(self, event):\n",
    "        \"\"\"\n",
    "        Process a single click event.\n",
    "        \n",
    "        Adds to buffer and flushes if necessary.\n",
    "        \"\"\"\n",
    "        self.buffer.append(event)\n",
    "        self.url_stats[event['url_id']] += 1\n",
    "        \n",
    "        # Check if we should flush\n",
    "        should_flush = (\n",
    "            len(self.buffer) >= self.batch_size or\n",
    "            time.time() - self.last_flush >= self.max_wait_time\n",
    "        )\n",
    "        \n",
    "        if should_flush:\n",
    "            self.flush()\n",
    "    \n",
    "    def flush(self):\n",
    "        \"\"\"\n",
    "        Write buffered events to database.\n",
    "        \"\"\"\n",
    "        if not self.buffer:\n",
    "            return\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # In production, this would be a bulk insert to DB\n",
    "        print(f\"Flushing {len(self.buffer)} events...\")\n",
    "        \n",
    "        # Simulate batch write (aggregated by URL)\n",
    "        for url_id, count in self.url_stats.items():\n",
    "            # Update analytics for this URL\n",
    "            print(f\"  {url_id}: +{count} clicks\")\n",
    "        \n",
    "        # Clear buffer\n",
    "        self.buffer = []\n",
    "        self.url_stats = defaultdict(int)\n",
    "        self.last_flush = time.time()\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Flush completed in {elapsed:.2f}s\\n\")\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Flush any remaining events before shutdown.\"\"\"\n",
    "        print(\"Closing consumer...\")\n",
    "        self.flush()\n",
    "\n",
    "# Example usage\n",
    "print(\"=== Batching Consumer Demo ===\\n\")\n",
    "\n",
    "consumer = AnalyticsConsumer(batch_size=5, max_wait_time=10)\n",
    "\n",
    "# Simulate stream of events\n",
    "events = [\n",
    "    {\"url_id\": \"abc1234\", \"timestamp\": 1709251200},\n",
    "    {\"url_id\": \"abc1234\", \"timestamp\": 1709251201},\n",
    "    {\"url_id\": \"xyz5678\", \"timestamp\": 1709251202},\n",
    "    {\"url_id\": \"abc1234\", \"timestamp\": 1709251203},\n",
    "    {\"url_id\": \"def9999\", \"timestamp\": 1709251204},  # Triggers flush (5 events)\n",
    "    {\"url_id\": \"xyz5678\", \"timestamp\": 1709251205},\n",
    "    {\"url_id\": \"abc1234\", \"timestamp\": 1709251206},\n",
    "]\n",
    "\n",
    "for event in events:\n",
    "    print(f\"Processing: {event['url_id']}\")\n",
    "    consumer.process_event(event)\n",
    "    time.sleep(0.1)  # Simulate processing delay\n",
    "\n",
    "# Force final flush\n",
    "consumer.close()\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "=== Batching Consumer Demo ===\n",
    "\n",
    "Processing: abc1234\n",
    "Processing: abc1234\n",
    "Processing: xyz5678\n",
    "Processing: abc1234\n",
    "Processing: def9999\n",
    "Flushing 5 events...\n",
    "  abc1234: +3 clicks\n",
    "  xyz5678: +1 clicks\n",
    "  def9999: +1 clicks\n",
    "Flush completed in 0.00s\n",
    "\n",
    "Processing: xyz5678\n",
    "Processing: abc1234\n",
    "Closing consumer...\n",
    "Flushing 2 events...\n",
    "  xyz5678: +1 clicks\n",
    "  abc1234: +1 clicks\n",
    "Flush completed in 0.00s\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **The Art of Drawing Architecture Diagrams**\n",
    "\n",
    "A picture is worth a thousand words. Good diagrams communicate complex systems clearly.\n",
    "\n",
    "### **Diagramming Best Practices**\n",
    "\n",
    "#### **Rule 1: Start Simple, Add Detail**\n",
    "\n",
    "Don't draw everything at once. Build up your diagram progressively.\n",
    "\n",
    "```\n",
    "Step 1: Client \u2192 Server (basic flow)\n",
    "Step 2: Add Load Balancer\n",
    "Step 3: Add Cache Layer\n",
    "Step 4: Add Database\n",
    "Step 5: Add Message Queue\n",
    "Step 6: Add Analytics\n",
    "```\n",
    "\n",
    "#### **Rule 2: Use Standard Symbols**\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    ARCHITECTURE SYMBOLS                         \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Client:          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502\n",
    "\u2502                   \u2502      \ud83d\udcf1          \u2502                           \u2502\n",
    "\u2502                   \u2502    Browser/App   \u2502                           \u2502\n",
    "\u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Load Balancer:   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502\n",
    "\u2502                   \u2502  \u2696\ufe0f  Load Bal.   \u2502                           \u2502\n",
    "\u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Server:          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502\n",
    "\u2502                   \u2502  \ud83d\udda5\ufe0f  API Server  \u2502                           \u2502\n",
    "\u2502                   \u2502    (Stateless)   \u2502                           \u2502\n",
    "\u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Cache:           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502\n",
    "\u2502                   \u2502   \ud83d\udcbe  Cache      \u2502                           \u2502\n",
    "\u2502                   \u2502    (Redis)       \u2502                           \u2502\n",
    "\u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Database:        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502\n",
    "\u2502                   \u2502   \ud83d\uddc4\ufe0f  Database   \u2502                           \u2502\n",
    "\u2502                   \u2502   (DynamoDB)     \u2502                           \u2502\n",
    "\u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Message Queue:   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502\n",
    "\u2502                   \u2502   \ud83d\udce8  MQ         \u2502                           \u2502\n",
    "\u2502                   \u2502   (Kafka)        \u2502                           \u2502\n",
    "\u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  External:        \u2601\ufe0f  External Service                         \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Data Flow:       \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 (Unidirectional)                \u2502\n",
    "\u2502  Bidirectional:   \u2190\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 (Both ways)                      \u2502\n",
    "\u2502  Async:           \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192> (Async)                         \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "#### **Rule 3: Label Everything**\n",
    "\n",
    "Every box, arrow, and connection should have a label.\n",
    "\n",
    "```\n",
    "\u2717 BAD (no labels):\n",
    "\u250c\u2500\u2500\u2500\u2500\u2510   \u2192   \u250c\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502 LB \u2502       \u2502 API \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "\u2713 GOOD (labeled):\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         HTTPS (443)          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   Load      \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\u2502      API        \u2502\n",
    "\u2502  Balancer   \u2502\u2190\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500|    Server       \u2502\n",
    "\u2502  (ALB)      \u2502      Response (200 OK)       \u2502   (K8s Pod)     \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "#### **Rule 4: Show Data Flow**\n",
    "\n",
    "Don't just draw boxes. Show how data moves through the system.\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                     REQUEST FLOW DIAGRAM                         \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  Client                                                         \u2502\n",
    "\u2502    \u2502                                                            \u2502\n",
    "\u2502    \u2502  1. POST /api/v1/shorten                                   \u2502\n",
    "\u2502    \u2502     { \"long_url\": \"https://...\" }                          \u2502\n",
    "\u2502    \u2193                                                            \u2502\n",
    "\u2502  Load Balancer                                                  \u2502\n",
    "\u2502    \u2502                                                            \u2502\n",
    "\u2502    \u2502  2. Route to healthy server                                \u2502\n",
    "\u2502    \u2193                                                            \u2502\n",
    "\u2502  API Server                                                     \u2502\n",
    "\u2502    \u2502                                                            \u2502\n",
    "\u2502    \u2502  3. Generate short URL (Snowflake ID)                      \u2502\n",
    "\u2502    \u2502                                                            \u2502\n",
    "\u2502    \u2502  4. Write to DynamoDB                                      \u2502\n",
    "\u2502    \u2193                                                            \u2502\n",
    "\u2502  DynamoDB                                                       \u2502\n",
    "\u2502    \u2502                                                            \u2502\n",
    "\u2502    \u2502  5. Store: { \"abc1234\": \"https://...\" }                    \u2502\n",
    "\u2502    \u2502                                                            \u2502\n",
    "\u2502    \u2502  6. ACK success                                            \u2502\n",
    "\u2502    \u2191                                                            \u2502\n",
    "\u2502  API Server                                                     \u2502\n",
    "\u2502    \u2502                                                            \u2502\n",
    "\u2502    \u2502  7. Cache in Redis (optional)                              \u2502\n",
    "\u2502    \u2502                                                            \u2502\n",
    "\u2502    \u2502  8. Return: { \"short_url\": \"https://short.url/abc1234\" }   \u2502\n",
    "\u2502    \u2191                                                            \u2502\n",
    "\u2502  Load Balancer                                                  \u2502\n",
    "\u2502    \u2502                                                            \u2502\n",
    "\u2502    \u2502  9. Response (201 Created)                                 \u2502\n",
    "\u2502    \u2191                                                            \u2502\n",
    "\u2502  Client                                                         \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "#### **Rule 5: Indicate Scale**\n",
    "\n",
    "Show when components have multiple instances.\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                   MULTI-INSTANCE DIAGRAM                         \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                 \u2502\n",
    "\u2502                     Load Balancer                                \u2502\n",
    "\u2502                           \u2502                                      \u2502\n",
    "\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n",
    "\u2502     \u2193                     \u2193                     \u2193               \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\n",
    "\u2502  \u2502 API-1  \u2502           \u2502 API-2  \u2502           \u2502 API-N  \u2502           \u2502\n",
    "\u2502  \u2502 (K8s)  \u2502           \u2502 (K8s)  \u2502           \u2502 (K8s)  \u2502           \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\n",
    "\u2502     \u2502                     \u2502                     \u2502               \u2502\n",
    "\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n",
    "\u2502                           \u2502                                      \u2502\n",
    "\u2502                     Redis Cluster                                \u2502\n",
    "\u2502                   (Master + 3 Slaves)                            \u2502\n",
    "\u2502                           \u2502                                      \u2502\n",
    "\u2502                     \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510                                \u2502\n",
    "\u2502                     \u2193           \u2193                                \u2502\n",
    "\u2502                  Shard-1     Shard-2                             \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### **Drawing Order for Interviews**\n",
    "\n",
    "When drawing during an interview, follow this sequence:\n",
    "\n",
    "```\n",
    "1. Draw the client and first server (5 seconds)\n",
    "   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "   \u2502User  \u2502\u2500\u2500\u2500\u2192\u2502  Server  \u2502\n",
    "   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "2. Add load balancer (10 seconds)\n",
    "   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "   \u2502User  \u2502\u2500\u2500\u2500\u2192\u2502    LB    \u2502\u2500\u2500\u2500\u2192\u2502  Server  \u2502\n",
    "   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "3. Add database (15 seconds)\n",
    "   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "   \u2502User  \u2502\u2500\u2500\u2500\u2192\u2502    LB    \u2502\u2500\u2500\u2500\u2192\u2502  Server  \u2502\u2500\u2500\u2500\u2192\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502  DB     \u2502\n",
    "                                            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "4. Add cache (20 seconds)\n",
    "   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "   \u2502User  \u2502\u2500\u2500\u2500\u2192\u2502    LB    \u2502\u2500\u2500\u2500\u2192\u2502  Server  \u2502\u2500\u2500\u2500\u2192\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502  DB     \u2502\n",
    "                                           \u2191  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                           \u2502\n",
    "                                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                                      \u2502  Cache  \u2502\n",
    "                                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "5. Add message queue (30 seconds)\n",
    "   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "   \u2502User  \u2502\u2500\u2500\u2500\u2192\u2502    LB    \u2502\u2500\u2500\u2500\u2192\u2502  Server  \u2502\u2500\u2500\u2500\u2192\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502  DB     \u2502\n",
    "                              \u2502                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                              \u2193\n",
    "                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                         \u2502   MQ    \u2502\n",
    "                         \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n",
    "                              \u2193\n",
    "                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                         \u2502Consumer \u2502\n",
    "                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "6. Add multiple instances (final diagram)\n",
    "   (See complete architecture diagram above)\n",
    "```\n",
    "\n",
    "### **Diagramming Tools**\n",
    "\n",
    "**For Interviews:**\n",
    "- **Whiteboard** \u2014 Most common in on-site interviews\n",
    "- **Excalidraw** \u2014 Free online tool (hand-drawn style)\n",
    "- **Draw.io** \u2014 Free, feature-rich\n",
    "- **Lucidchart** \u2014 Paid, very popular\n",
    "\n",
    "**For Documentation:**\n",
    "- **Mermaid** \u2014 Code-based diagrams (great for Git)\n",
    "- **PlantUML** \u2014 Code-based UML diagrams\n",
    "- **Cloudcraft** \u2014 AWS-specific diagrams\n",
    "\n",
    "**Example Mermaid Code:**\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    User[User] -->|HTTPS| LB[Load Balancer]\n",
    "    LB -->|Route| API1[API Server 1]\n",
    "    LB -->|Route| API2[API Server 2]\n",
    "    LB -->|Route| APIN[API Server N]\n",
    "    \n",
    "    API1 -->|Read/Write| Cache[Redis Cluster]\n",
    "    API2 -->|Read/Write| Cache\n",
    "    APIN -->|Read/Write| Cache\n",
    "    \n",
    "    API1 -->|Write| DB[DynamoDB]\n",
    "    API2 -->|Write| DB\n",
    "    APIN -->|Write| DB\n",
    "    \n",
    "    API1 -->|Publish| MQ[Kafka]\n",
    "    API2 -->|Publish| MQ\n",
    "    APIN -->|Publish| MQ\n",
    "    \n",
    "    MQ -->|Consume| Consumer[Analytics Consumer]\n",
    "    Consumer -->|Write| Analytics[TimescaleDB]\n",
    "    \n",
    "    style LB fill:#f9f,stroke:#333,stroke-width:2px\n",
    "    style Cache fill:#bbf,stroke:#333,stroke-width:2px\n",
    "    style DB fill:#bfb,stroke:#333,stroke-width:2px\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Putting It All Together: The 4S Interview Flow**\n",
    "\n",
    "Here's how you would use the 4S framework in a 45-minute interview:\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                   45-MINUTE INTERVIEW TIMELINE                   \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  0-5 min:     SCOPE                                             \u2502\n",
    "\u2502                 \u2022 Clarify the problem                           \u2502\n",
    "\u2502                 \u2022 Ask questions                                  \u2502\n",
    "\u2502                 \u2022 Define functional requirements                \u2502\n",
    "\u2502                 \u2022 Define non-functional requirements             \u2502\n",
    "\u2502                 \u2022 Define out-of-scope                           \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  5-10 min:    SKETCH                                            \u2502\n",
    "\u2502                 \u2022 Calculate QPS (peak and average)              \u2502\n",
    "\u2502                 \u2022 Estimate storage                              \u2502\n",
    "\u2502                 \u2022 Estimate bandwidth                            \u2502\n",
    "\u2502                 \u2022 Identify scale constraints                    \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  10-15 min:   SOLIDIFY                                          \u2502\n",
    "\u2502                 \u2022 Identify entities                             \u2502\n",
    "\u2502                 \u2022 Design data model                              \u2502\n",
    "\u2502                 \u2022 Choose database type                          \u2502\n",
    "\u2502                 \u2022 Design API endpoints                          \u2502\n",
    "\u2502                 \u2022 Define request/response formats               \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  15-35 min:   SCALE \u2014 High-Level Design                        \u2502\n",
    "\u2502                 \u2022 Identify key components                       \u2502\n",
    "\u2502                 \u2022 Draw high-level architecture                  \u2502\n",
    "\u2502                 \u2022 Explain data flow                             \u2502\n",
    "\u2502                 \u2022 Choose technologies                           \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2502  35-45 min:   SCALE \u2014 Deep Dive                                \u2502\n",
    "\u2502                 \u2022 Dive into 2-3 critical components             \u2502\n",
    "\u2502                 \u2022 Analyze bottlenecks                           \u2502\n",
    "\u2502                 \u2022 Discuss trade-offs                            \u2502\n",
    "\u2502                 \u2022 Propose alternatives                          \u2502\n",
    "\u2502                 \u2022 Handle follow-up questions                     \u2502\n",
    "\u2502                                                                 \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### **Sample Interview Script**\n",
    "\n",
    "**Interviewer:** \"Design a URL shortener.\"\n",
    "\n",
    "**You (SCOPE - 0-5 min):**\n",
    "\n",
    "```\n",
    "You: \"Great! Let me clarify a few things first:\n",
    "\n",
    "1. Is this for public use or internal company use?\n",
    "   Int: Public use.\n",
    "\n",
    "2. Should short URLs expire, or do they last forever?\n",
    "   Int: They don't expire.\n",
    "\n",
    "3. Can users specify custom aliases?\n",
    "   Int: Yes, if available.\n",
    "\n",
    "4. Do we need analytics (click tracking, geo location)?\n",
    "   Int: Yes, basic click counts.\n",
    "\n",
    "5. What's the expected scale?\n",
    "   Int: 10 million URL creations per day, 100 million redirects per day.\n",
    "\n",
    "Based on that, here are my requirements:\n",
    "\n",
    "Functional Requirements:\n",
    "- Create and return unique short URLs (\u22647 characters)\n",
    "- Redirect short URLs to original long URLs\n",
    "- Optional custom aliases\n",
    "- Track click counts per URL\n",
    "\n",
    "Non-Functional Requirements:\n",
    "- Support 10M URL creations/day, 100M redirects/day\n",
    "- 99.9% availability\n",
    "- Create URL: <100ms, Redirect: <50ms\n",
    "- Strong consistency for URL lookups\n",
    "- Zero data loss for URLs\n",
    "\n",
    "Out of Scope:\n",
    "- User authentication (assume anonymous)\n",
    "- URL preview thumbnails\n",
    "- Social sharing features\n",
    "- QR code generation\n",
    "\n",
    "Does this sound right to you?\"\n",
    "```\n",
    "\n",
    "**You (SKETCH - 5-10 min):**\n",
    "\n",
    "```\n",
    "You: \"Now let me estimate the scale:\n",
    "\n",
    "Traffic (QPS):\n",
    "- URL creations: 10M/day = 115 QPS avg, 575 QPS peak (5x multiplier)\n",
    "- Redirects: 100M/day = 1,157 QPS avg, 11,570 QPS peak (10x multiplier)\n",
    "- Total: ~12,145 QPS peak\n",
    "\n",
    "Storage:\n",
    "- Per URL: short_url (7B) + long_url (2KB) + metadata = ~2KB\n",
    "- 1 billion URLs \u00d7 2KB = 2TB\n",
    "- With 50% overhead: ~3TB\n",
    "\n",
    "Bandwidth:\n",
    "- Create: 2KB req + 100B res \u00d7 575 QPS = 1.2 MB/s\n",
    "- Redirect: 10B req + 2KB res \u00d7 11,570 QPS = 23 MB/s\n",
    "- Total: ~24 MB/s (2TB/day)\n",
    "\n",
    "This tells me we need a horizontally scalable database and \n",
    "distributed caching to handle the 11K+ QPS for redirects.\"\n",
    "```\n",
    "\n",
    "**You (SOLIDIFY - 10-15 min):**\n",
    "\n",
    "```\n",
    "You: \"Let me design the data model:\n",
    "\n",
    "Entities:\n",
    "- URL: short_url (PK), long_url, created_at, click_count\n",
    "- Click: id, url_id (FK), timestamp, ip_address\n",
    "\n",
    "I'll use DynamoDB for the main URL storage:\n",
    "- Key: short_url (7 chars)\n",
    "- Strong consistency for redirects\n",
    "- Horizontal scaling for 1B+ URLs\n",
    "\n",
    "For analytics, I'll use a time-series database:\n",
    "- TimescaleDB for click events\n",
    "- Optimized for time-series queries\n",
    "\n",
    "API Design:\n",
    "- POST /api/v1/shorten - Create short URL\n",
    "- GET /{short_url} - Redirect (301)\n",
    "- GET /api/v1/urls/{short_url} - Get details\n",
    "- GET /api/v1/stats/{short_url} - Get analytics\n",
    "\n",
    "The redirect endpoint needs to be ultra-fast, so we'll \n",
    "cache heavily at that layer.\"\n",
    "```\n",
    "\n",
    "**You (SCALE - High-Level - 15-25 min):**\n",
    "\n",
    "```\n",
    "You: [Draws diagram]\n",
    "\n",
    "\"Here's the high-level architecture:\n",
    "\n",
    "[Draws and explains each component]\n",
    "\n",
    "Key components:\n",
    "1. Load Balancer - Distributes traffic\n",
    "2. API Servers - Stateless, horizontally scalable\n",
    "3. Redis Cluster - Cache for fast redirects\n",
    "4. DynamoDB - Primary storage for URLs\n",
    "5. Snowflake ID Generator - Unique, sortable IDs\n",
    "6. Kafka - Async analytics pipeline\n",
    "7. TimescaleDB - Analytics storage\n",
    "\n",
    "Data flow for redirect:\n",
    "1. Client GETs /abc1234\n",
    "2. Load balancer routes to API server\n",
    "3. API server checks Redis cache\n",
    "4. Cache HIT \u2192 Return redirect immediately\n",
    "5. Cache MISS \u2192 Query DynamoDB\n",
    "6. Update cache for next time\n",
    "7. Async publish click event to Kafka\n",
    "\n",
    "For URL creation:\n",
    "1. Client POSTs to /api/v1/shorten\n",
    "2. API server generates Snowflake ID\n",
    "3. Encodes to short URL\n",
    "4. Writes to DynamoDB\n",
    "5. Returns short URL to client\"\n",
    "```\n",
    "\n",
    "**You (SCALE - Deep Dive - 25-40 min):**\n",
    "\n",
    "```\n",
    "You: \"Let me dive deeper into a few critical areas:\n",
    "\n",
    "1. Short URL Generation:\n",
    "   I'm using Snowflake IDs because:\n",
    "   - Globally unique across servers\n",
    "   - Time-ordered (sortable)\n",
    "   - No collisions\n",
    "   - Base62 encoding keeps URLs short\n",
    "   \n",
    "   [Explains Snowflake structure and shows code]\n",
    "\n",
    "2. Caching Strategy:\n",
    "   Using Cache-Aside pattern with Redis Cluster:\n",
    "   - Cache hit reduces latency from ~50ms to ~5ms\n",
    "   - LRU eviction with 1-hour TTL\n",
    "   - Consistent hashing for distribution\n",
    "   \n",
    "   [Shows cache-aside code]\n",
    "\n",
    "3. Hot Partition Mitigation:\n",
    "   Viral URLs could create hot partitions in DynamoDB.\n",
    "   Solution:\n",
    "   - Add random suffix to popular URLs\n",
    "   - Store in multiple partitions\n",
    "   - Use DAX for caching\n",
    "   \n",
    "   [Shows mitigation code]\n",
    "\n",
    "Trade-offs I considered:\n",
    "\n",
    "DynamoDB vs PostgreSQL:\n",
    "   Chose DynamoDB for horizontal scaling and multi-region\n",
    "   PostgreSQL would be simpler but doesn't scale as well\n",
    "\n",
    "Synchronous vs Asynchronous Analytics:\n",
    "   Chose async (Kafka) to not impact redirect latency\n",
    "   Synchronous would be simpler but violates 50ms SLA\"\n",
    "```\n",
    "\n",
    "**Interviewer:** \"What if the cache fails?\"\n",
    "\n",
    "**You (40-45 min):**\n",
    "\n",
    "```\n",
    "You: \"Good question. If Redis fails:\n",
    "\n",
    "1. Immediate fallback:\n",
    "   - API server detects cache failure\n",
    "   - Directly queries DynamoDB\n",
    "   - Latency increases to ~50ms (still within SLA)\n",
    "\n",
    "2. Failover:\n",
    "   - Redis Cluster has automatic failover\n",
    "   - One replica becomes master\n",
    "   - Service restored in seconds\n",
    "\n",
    "3. Local cache:\n",
    "   - Each API server has local LRU cache\n",
    "   - Temporary buffer until Redis recovers\n",
    "   - Reduces load on DynamoDB during outage\n",
    "\n",
    "4. Degradation mode:\n",
    "   - If both caches fail and DB is overloaded\n",
    "   - Serve 503 with Retry-After header\n",
    "   - Better than serving stale/wrong data\n",
    "\n",
    "This defense in depth ensures 99.9% availability even \n",
    "with cache failures.\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "### **Key Takeaways**\n",
    "\n",
    "| Concept | Summary |\n",
    "|---------|---------|\n",
    "| **4S Framework** | Structured approach: Scope \u2192 Sketch \u2192 Solidify \u2192 Scale |\n",
    "| **Scope** | Define functional/non-functional requirements and out-of-scope |\n",
    "| **Sketch** | Estimate QPS, storage, and bandwidth using simple math |\n",
    "| **Solidify** | Design data model, choose database, define APIs |\n",
    "| **Scale** | Draw architecture, explain data flow, deep-dive into components |\n",
    "| **Trade-offs** | Every decision has pros and cons\u2014discuss them explicitly |\n",
    "| **Bottlenecks** | Proactively identify potential failure points and mitigations |\n",
    "| **Diagrams** | Draw progressively, label everything, show data flow |\n",
    "\n",
    "### **Common Mistakes to Avoid**\n",
    "\n",
    "| Mistake | Why It's Bad | How to Fix It |\n",
    "|---------|--------------|---------------|\n",
    "| Jumping straight to design | You might solve the wrong problem | Always start with SCOPE and clarifying questions |\n",
    "| Ignoring estimations | You'll under- or over-engineer | Always do back-of-the-envelope calculations |\n",
    "| Over-complicating early | Wastes time and confuses interviewer | Start simple, add complexity only if needed |\n",
    "| No trade-off discussion | Shows you don't understand alternatives | Always discuss 2-3 options and your reasoning |\n",
    "| Forgetting bottlenecks | System might fail at scale | Proactively identify and mitigate bottlenecks |\n",
    "| Poor diagramming | Harder for interviewer to follow | Use clear labels, standard symbols, show data flow |\n",
    "\n",
    "### **4S Framework Checklist**\n",
    "\n",
    "Use this during your interview:\n",
    "\n",
    "```\n",
    "\u25a1 SCOPE:\n",
    "  \u25a1 Clarified the problem\n",
    "  \u25a1 Asked relevant questions\n",
    "  \u25a1 Documented functional requirements\n",
    "  \u25a1 Documented non-functional requirements\n",
    "  \u25a1 Defined out-of-scope\n",
    "\n",
    "\u25a1 SKETCH:\n",
    "  \u25a1 Calculated QPS (peak and average)\n",
    "  \u25a1 Estimated storage\n",
    "  \u25a1 Estimated bandwidth\n",
    "  \u25a1 Identified scale constraints\n",
    "\n",
    "\u25a1 SOLIDIFY:\n",
    "  \u25a1 Identified entities\n",
    "  \u25a1 Designed data model\n",
    "  \u25a1 Chose database type\n",
    "  \u25a1 Defined API endpoints\n",
    "  \u25a1 Specified request/response formats\n",
    "\n",
    "\u25a1 SCALE:\n",
    "  \u25a1 Identified key components\n",
    "  \u25a1 Drew high-level architecture\n",
    "  \u25a1 Explained data flow\n",
    "  \u25a1 Chose technologies with reasoning\n",
    "  \u25a1 Dived into 2-3 critical components\n",
    "  \u25a1 Identified bottlenecks\n",
    "  \u25a1 Discussed trade-offs\n",
    "  \u25a1 Proposed alternatives\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Exercises**\n",
    "\n",
    "### **Exercise 1: Apply 4S to a New Problem**\n",
    "\n",
    "Apply the 4S framework to \"Design a chat application.\"\n",
    "\n",
    "**Hint:** Consider:\n",
    "- Real-time messaging (WebSockets)\n",
    "- Message ordering\n",
    "- Offline message delivery\n",
    "- Read receipts\n",
    "- Group chats vs. direct messages\n",
    "\n",
    "### **Exercise 2: Estimation Practice**\n",
    "\n",
    "Calculate QPS, storage, and bandwidth for:\n",
    "\n",
    "- A photo-sharing app with 1M users, each uploading 5 photos/day\n",
    "- Average photo size: 2MB\n",
    "- Each photo viewed 10 times on average\n",
    "- Assume 5x peak multiplier\n",
    "\n",
    "**Solution:**\n",
    "```\n",
    "Daily uploads: 1M users \u00d7 5 photos = 5M photos/day\n",
    "Upload QPS: 5M / 86,400 = 58 QPS avg, 290 QPS peak\n",
    "Daily views: 5M \u00d7 10 = 50M views/day\n",
    "View QPS: 50M / 86,400 = 578 QPS avg, 2,890 QPS peak\n",
    "\n",
    "Storage per day: 5M photos \u00d7 2MB = 10GB/day\n",
    "Per year: 10GB \u00d7 365 = 3.65TB/year\n",
    "5 years: ~18TB\n",
    "\n",
    "Upload bandwidth: 2MB \u00d7 290 QPS = 580 MB/s\n",
    "View bandwidth: 2MB \u00d7 2,890 QPS = 5.78 GB/s\n",
    "Total: ~6.3 GB/s\n",
    "```\n",
    "\n",
    "### **Exercise 3: Trade-off Analysis**\n",
    "\n",
    "For each decision, list 2 alternatives and explain your choice:\n",
    "\n",
    "1. SQL vs. NoSQL for photo metadata\n",
    "2. Blob storage (S3) vs. database for photo files\n",
    "3. CDN vs. direct storage for serving photos\n",
    "\n",
    "---\n",
    "\n",
    "## **Further Reading**\n",
    "\n",
    "| Resource | Description |\n",
    "|----------|-------------|\n",
    "| [System Design Primer](https://github.com/donnemartin/system-design-primer) | Comprehensive GitHub repo with diagrams |\n",
    "| [Designing Data-Intensive Applications](https://dataintensive.net/) | Martin Kleppmann's book on distributed systems |\n",
    "| [DDIA - Chapter 5](https://www.oreilly.com/library/view/designing-data-intensive-applications/9781491903119/) | Replication, partitioning, transactions |\n",
    "| [Google File System Paper](https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf) | Classic distributed file system paper |\n",
    "| [Dynamo Paper](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf) | Amazon's key-value store design |\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** In Chapter 11, we'll dive deep into **Reliability & Fault Tolerance**, exploring how to design systems that survive failures, disasters, and unexpected events. We'll cover redundancy patterns, retry strategies, chaos engineering, and disaster recovery planning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='../3. Distributes_systems_fundamentals/9. scalability_patterns.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='11. reliability_and_fault_tolerance.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}