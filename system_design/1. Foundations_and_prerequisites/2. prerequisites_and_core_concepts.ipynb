{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec185f5c",
   "metadata": {},
   "source": [
    "# **Chapter 2: Prerequisites & Core Concepts**\n",
    "\n",
    "Before we can design systems that scale to millions of users, we need to understand the fundamental building blocks that make distributed systems possible. This chapter covers the essential concepts that form the bedrock of system design knowledge.\n",
    "\n",
    "---\n",
    "\n",
    "## **2.1 Networking Fundamentals**\n",
    "\n",
    "Understanding how computers communicate over networks is crucial because, in distributed systems, almost every operation involves network communication. Your application is rarely faster than the network allows it to be.\n",
    "\n",
    "### **The OSI Model Simplified**\n",
    "\n",
    "The Open Systems Interconnection (OSI) model conceptualizes how network communication works. While you won't memorize all 7 layers, understanding which layer your protocols operate on is essential for debugging performance issues.\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502 Layer 7: Application                    \u2502 \u2190 HTTP, HTTPS, SMTP, DNS, SSH\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Layer 6: Presentation                    \u2502 \u2190 TLS/SSL, JSON/XML serialization\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Layer 5: Session                         \u2502 \u2190 TCP/UDP ports\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Layer 4: Transport                       \u2502 \u2190 TCP (reliable), UDP (fast)\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Layer 3: Network                         \u2502 \u2190 IP addressing, routing\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Layer 2: Data Link                       \u2502 \u2190 MAC addresses, Ethernet\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502 Layer 1: Physical                        \u2502 \u2190 Cables, radio waves\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "**Key Insight**: In system design, we mostly care about Layers 3-7. You don't need to understand physical cables to design distributed systems, but you do need to understand how TCP/IP works.\n",
    "\n",
    "### **TCP vs. UDP: The Transport Layer Trade-off**\n",
    "\n",
    "**TCP (Transmission Control Protocol)**: The reliable option. Like certified mail\u2014you get delivery confirmation.\n",
    "\n",
    "**Characteristics**:\n",
    "- **Connection-oriented**: Three-way handshake before data transfer\n",
    "- **Reliable delivery**: Retransmits lost packets, acknowledges successful delivery\n",
    "- **Ordered delivery**: Guarantees packets arrive in sequence\n",
    "- **Flow control**: Prevents overwhelming the receiver\n",
    "\n",
    "**Three-way handshake visualization**:\n",
    "```\n",
    "Client                              Server\n",
    "  \u2502                                   \u2502\n",
    "  \u2502\u2500\u2500 SYN (Synchronize) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502 \"Can I connect?\"\n",
    "  \u2502                                   \u2502\n",
    "  \u2502<\u2500\u2500 SYN-ACK (Synchronize-Ack) \u2500\u2500\u2500\u2500\u2500\u2524 \"Yes, can I confirm?\"\n",
    "  \u2502                                   \u2502\n",
    "  \u2502\u2500\u2500 ACK (Acknowledgment) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502 \"Confirmed! Let's talk.\"\n",
    "  \u2502                                   \u2502\n",
    "  \u25bc                                   \u25bc\n",
    "Connection Established\n",
    "```\n",
    "\n",
    "**Use cases**: Web browsing (HTTP/HTTPS), email (SMTP), file transfers (SFTP), databases (MySQL, PostgreSQL connections).\n",
    "\n",
    "**UDP (User Datagram Protocol)**: The fast option. Like shouting in a crowded room\u2014you speak, but there's no guarantee anyone heard you.\n",
    "\n",
    "**Characteristics**:\n",
    "- **Connectionless**: No setup, no teardown\n",
    "- **Unreliable**: No guarantees\u2014packets may be lost, duplicated, or arrive out of order\n",
    "- **Fast**: No overhead from acknowledgments or retransmissions\n",
    "- **Minimal headers**: Smaller packet size\n",
    "\n",
    "**Use cases**: Video streaming, online gaming, DNS queries, VoIP calls.\n",
    "\n",
    "**System Design Decision**: Use TCP for anything where data integrity matters more than speed (transactions, user data). Use UDP where speed matters more than occasional data loss (live video, real-time gaming where a dropped frame is acceptable).\n",
    "\n",
    "### **HTTP Versions: Evolution of Web Communication**\n",
    "\n",
    "**HTTP/1.1 (1997)**: The foundation of the modern web.\n",
    "\n",
    "**How it works**: Text-based protocol. Each request opens a new TCP connection, sends the request, and closes the connection. Multiple requests can be pipelined, but responses arrive in order.\n",
    "\n",
    "**Request Example**:\n",
    "```http\n",
    "GET /api/users/123 HTTP/1.1\n",
    "Host: api.example.com\n",
    "User-Agent: Mozilla/5.0\n",
    "Accept: application/json\n",
    "\n",
    "Response:\n",
    "HTTP/1.1 200 OK\n",
    "Content-Type: application/json\n",
    "Content-Length: 142\n",
    "\n",
    "{\"id\": 123, \"name\": \"Alice\", \"email\": \"alice@example.com\"}\n",
    "```\n",
    "\n",
    "**Problems**: \n",
    "- **Head-of-line blocking**: The response for the first request must complete before the second request starts (even if the second could be served faster)\n",
    "- **Inefficient headers**: Repeated headers with every request\n",
    "- **Connection overhead**: TCP handshake for each request (despite Keep-Alive, still has limitations)\n",
    "\n",
    "**HTTP/2 (2015)**: Binary protocol for efficiency.\n",
    "\n",
    "**Key Features**:\n",
    "- **Multiplexing**: Multiple streams over a single TCP connection (no head-of-line blocking)\n",
    "- **Binary framing**: More efficient parsing (not text-based like HTTP/1.1)\n",
    "- **Header compression**: HPACK compression reduces header size by up to 90%\n",
    "- **Server push**: Server can proactively send resources (e.g., CSS file along with HTML)\n",
    "\n",
    "**Visualization**:\n",
    "```\n",
    "HTTP/1.1:                            HTTP/2:\n",
    "Request 1 \u2500\u2510                        Stream 1 \u2500\u2500\u2510\n",
    "Response 1\u2500\u2524                        Stream 2 \u2500\u2500\u2524 \u2192 All on 1 connection\n",
    "Request 2 \u2500\u2524 (Serial)               Stream 3 \u2500\u2500\u2524 (Parallel)\n",
    "Response 2\u2500\u2524                        Stream 4 \u2500\u2500\u2518\n",
    "Request 3 \u2500\u2518\n",
    "Response 3\u2500\u2518\n",
    "```\n",
    "\n",
    "**HTTP/3 (2022)**: Replaces TCP with QUIC (UDP-based).\n",
    "\n",
    "**Key Innovation**: HTTP/3 runs on QUIC, which is built on UDP (not TCP). This eliminates TCP-level head-of-line blocking\u2014if one packet is lost, only that stream is affected, not all streams.\n",
    "\n",
    "**When to use each**:\n",
    "- **HTTP/1.1**: Still widely supported, simpler, adequate for most use cases\n",
    "- **HTTP/2**: Better for browsers loading multiple resources from a single domain\n",
    "- **HTTP/3**: Best for high-latency networks (mobile, satellite), unreliable connections\n",
    "\n",
    "### **gRPC: RPC for the Modern Era**\n",
    "\n",
    "**RPC (Remote Procedure Call)**: Code that calls a function on another computer as if it were local. You write `user = getUser(123)` and the call happens over the network.\n",
    "\n",
    "**gRPC (Google Remote Procedure Call)**: High-performance RPC framework using Protocol Buffers (protobuf) for serialization and HTTP/2 for transport.\n",
    "\n",
    "**Why it's superior to REST**:\n",
    "1. **Smaller payloads**: Protobuf binary is 3-10x smaller than JSON\n",
    "2. **Faster serialization**: Protobuf encoding/decoding is significantly faster\n",
    "3. **Strongly typed**: Schema-first approach catches errors at compile time\n",
    "4. **Bidirectional streaming**: Both client and server can send messages continuously\n",
    "\n",
    "**Comparison Example**:\n",
    "\n",
    "**REST + JSON**:\n",
    "```json\n",
    "// Request\n",
    "GET /api/users/123\n",
    "\n",
    "// Response (450 bytes)\n",
    "{\n",
    "  \"id\": 123,\n",
    "  \"name\": \"Alice Johnson\",\n",
    "  \"email\": \"alice@example.com\",\n",
    "  \"created_at\": \"2024-01-15T08:30:00Z\"\n",
    "}\n",
    "```\n",
    "\n",
    "**gRPC + Protobuf**:\n",
    "```protobuf\n",
    "// Schema definition (.proto file)\n",
    "syntax = \"proto3\";\n",
    "\n",
    "message User {\n",
    "  int32 id = 1;\n",
    "  string name = 2;\n",
    "  string email = 3;\n",
    "  int64 created_at = 4;\n",
    "}\n",
    "\n",
    "service UserService {\n",
    "  rpc GetUser(GetUserRequest) returns (User);\n",
    "}\n",
    "```\n",
    "```go\n",
    "// Binary request/response (~80 bytes, 5x smaller)\n",
    "// And 10x faster to serialize/deserialize\n",
    "```\n",
    "\n",
    "**Use cases**: Microservices communication (Google uses it extensively), mobile-to-backend communication, browser-to-backend communication (via gRPC-Web).\n",
    "\n",
    "### **WebSockets: Real-Time Bidirectional Communication**\n",
    "\n",
    "HTTP was designed for request-response. What if you need the server to send messages to the client without being asked?\n",
    "\n",
    "**WebSocket**: A persistent, bidirectional communication channel over a single TCP connection.\n",
    "\n",
    "**Handshake Process**:\n",
    "```\n",
    "Client                                          Server\n",
    "  \u2502                                               \u2502\n",
    "  \u2502\u2500\u2500 HTTP GET (Upgrade: websocket) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500>\u2502\n",
    "  \u2502  \"I want a WebSocket connection\"             \u2502\n",
    "  \u2502                                               \u2502\n",
    "  \u2502<\u2500\u2500 HTTP 101 (Switching Protocols) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "  \u2502  \"Switching to WebSocket protocol\"           \u2502\n",
    "  \u2502                                               \u2502\n",
    "  \u25bc                                               \u25bc\n",
    "           Persistent bidirectional connection\n",
    "              (No new HTTP requests needed)\n",
    "```\n",
    "\n",
    "**Key Features**:\n",
    "- **Full-duplex**: Both client and server can send messages anytime\n",
    "- **Low overhead**: Only 2-14 bytes per message (compared to HTTP headers)\n",
    "- **Persistent**: Connection stays open until either party closes it\n",
    "- **Efficient for real-time**: Perfect for chat, notifications, live updates\n",
    "\n",
    "**Code Example** (JavaScript Client):\n",
    "```javascript\n",
    "// Establish WebSocket connection\n",
    "const socket = new WebSocket('wss://api.example.com/notifications');\n",
    "\n",
    "// Listen for messages from server\n",
    "socket.onmessage = (event) => {\n",
    "  const notification = JSON.parse(event.data);\n",
    "  showNotification(notification);\n",
    "};\n",
    "\n",
    "// Send message to server\n",
    "socket.send(JSON.stringify({\n",
    "  type: 'subscribe',\n",
    "  channel: 'user-updates'\n",
    "}));\n",
    "\n",
    "// Handle connection close\n",
    "socket.onclose = () => {\n",
    "  console.log('WebSocket closed. Reconnecting...');\n",
    "  setTimeout(reconnect, 1000);\n",
    "};\n",
    "```\n",
    "\n",
    "**Use cases**: Chat applications (Slack, WhatsApp), live collaboration (Google Docs), real-time notifications (GitHub, Jira), live sports scores, multiplayer games.\n",
    "\n",
    "---\n",
    "\n",
    "## **2.2 Latency Numbers Every Programmer Should Know**\n",
    "\n",
    "In system design, having an intuitive sense of how long different operations take helps you make better decisions. These numbers, popularized by Jeff Dean (Google engineer), should be memorized.\n",
    "\n",
    "### **The Hierarchy of Speed**\n",
    "\n",
    "```\n",
    "Operation                          Time (approx)  Human Scale\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "CPU L1 cache access                1 ns            Light travels 30 cm\n",
    "CPU L2 cache access                4 ns            Light travels 1.2 m\n",
    "CPU L3 cache access                10 ns           Light travels 3 m\n",
    "Main memory RAM access             100 ns          Light travels 30 m\n",
    "Context switch (OS)                10,000 ns       100x slower than RAM\n",
    "SSD random read                    100,000 ns      1,000x slower than RAM\n",
    "Read from network (same DC)        250,000 ns      2,500x slower than RAM\n",
    "Read from network (global)         150,000,000 ns  1.5 million x slower than RAM\n",
    "SSD sequential read                1,000,000 ns    10,000x slower than RAM\n",
    "Disk (HDD) random read             10,000,000 ns   100,000x slower than RAM\n",
    "Disk (HDD) sequential read         50,000,000 ns   500,000x slower than RAM\n",
    "```\n",
    "\n",
    "**Key Insight**: RAM is about **10-100x faster than SSD**, and **SSD is about 10-100x faster than HDD**. Network calls are **1,000-1,000,000x slower** than RAM operations.\n",
    "\n",
    "### **Practical Implications**\n",
    "\n",
    "**1. The Caching Imperative**\n",
    "\n",
    "If a database query takes 100ms, but reading from RAM takes 0.1ms, caching can make your application 1,000x faster. This is why distributed systems heavily invest in caching layers.\n",
    "\n",
    "**2. The Network Is the Enemy**\n",
    "\n",
    "Every network call is an eternity in computer time. A single network round-trip to a database in another data center takes 150ms\u2014enough time to:\n",
    "- Read from L1 cache 150 million times\n",
    "- Read from RAM 1.5 million times\n",
    "- Switch CPU contexts 15,000 times\n",
    "\n",
    "**Design consequence**: Minimize network calls. Batch operations, use in-memory data when possible, and cache aggressively.\n",
    "\n",
    "**3. Memory vs. Disk Trade-offs**\n",
    "\n",
    "If you can fit your working set in RAM, do it. Even an expensive database server with 1TB of RAM is cheaper than the engineering cost of optimizing disk access.\n",
    "\n",
    "### **Scaling These Numbers Over Time**\n",
    "\n",
    "**Network Latency**:\n",
    "- Same data center: 0.1-0.5 ms\n",
    "- Same city: 5-10 ms\n",
    "- East Coast US to West Coast US: 40-50 ms\n",
    "- US to Europe: 80-100 ms\n",
    "- US to Asia: 150-200 ms\n",
    "- US to South America: 100-120 ms\n",
    "\n",
    "**Why this matters for global systems**:\n",
    "- A user in Tokyo waiting for data from US servers experiences 200ms latency\n",
    "- If you do 10 database calls per request, that's 2 seconds just in network latency\n",
    "- This is why companies deploy data centers globally\n",
    "\n",
    "**Optimization Techniques**:\n",
    "- **CDN (Content Delivery Network)**: Serve static assets from edge locations (~10ms globally)\n",
    "- **Read replicas**: Database replicas in each region (local reads)\n",
    "- **Edge computing**: Run application logic close to users (AWS CloudFront Functions, Cloudflare Workers)\n",
    "\n",
    "---\n",
    "\n",
    "## **2.3 Data Structures for System Design**\n",
    "\n",
    "General-purpose data structures you learned in computer science (arrays, hash maps, trees) have specialized variants optimized for distributed systems. These are the building blocks of scalable systems.\n",
    "\n",
    "### **Hash Functions & Consistent Hashing**\n",
    "\n",
    "**Hash Function**: A mathematical function that maps data of arbitrary size to fixed-size values.\n",
    "\n",
    "```\n",
    "hash(\"hello\") \u2192 8c7d9b...\n",
    "hash(\"hello\") \u2192 8c7d9b... (always the same result)\n",
    "hash(\"world\") \u2192 2d4f6a... (different result)\n",
    "```\n",
    "\n",
    "**Properties of Good Hash Functions**:\n",
    "- **Deterministic**: Same input always produces same output\n",
    "- **Uniform distribution**: Inputs are spread evenly across output space\n",
    "- **Avalanche effect**: Small input changes produce completely different outputs\n",
    "- **Fast**: Computationally inexpensive to calculate\n",
    "\n",
    "**Simple Hash Example**:\n",
    "```python\n",
    "def simple_hash(key, num_servers):\n",
    "    return sum(ord(c) for c in key) % num_servers\n",
    "\n",
    "# This determines which server stores the data\n",
    "server_id = simple_hash(\"user_123\", 10)  # Returns 0-9\n",
    "```\n",
    "\n",
    "**Problem with Simple Hashing**: What happens when we add or remove servers?\n",
    "\n",
    "```python\n",
    "# Initially 10 servers\n",
    "server_id = simple_hash(\"user_123\", 10)  # Returns 7 (data on server 7)\n",
    "\n",
    "# We add a new server (now 11 servers)\n",
    "server_id = simple_hash(\"user_123\", 11)  # Returns 3 (data moved to server 3)\n",
    "```\n",
    "\n",
    "**The Rehashing Problem**: Adding one server causes all keys to be reassigned to different servers. In a system with 1 billion keys, this means moving billions of records\u2014a catastrophic operation.\n",
    "\n",
    "**Consistent Hashing**: Solves this by hashing both servers and keys onto the same ring.\n",
    "\n",
    "```\n",
    "           Key: \"user_123\"\n",
    "                  \u2193\n",
    "    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "    \u2502     \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Ring \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba     \u2502\n",
    "    \u2502                                \u2502\n",
    "    \u2502  Key: \"user_456\"    Server C  \u2502\n",
    "    \u2502       \u2193                \u2191       \u2502\n",
    "    \u2502  Server A \u2500\u2500\u2500\u25ba Server B \u2500\u2500\u2500\u25ba  \u2502\n",
    "    \u2502      \u2191                   \u2193     \u2502\n",
    "    \u2502  Key: \"user_789\"   Key: \"user_000\"\n",
    "    \u2502                                \u2502\n",
    "    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "Key assignment rule: Each key is assigned to the next server clockwise.\n",
    "```\n",
    "\n",
    "**Key Advantages**:\n",
    "1. **Minimal disruption**: Adding a server only moves ~1/N of keys (N = number of servers)\n",
    "2. **Automatic scaling**: Can add/remove servers without massive data movement\n",
    "3. **Load balancing**: Even distribution of keys across servers\n",
    "\n",
    "**Virtual Nodes**: In practice, each physical server is represented by multiple virtual nodes on the ring (e.g., 100-1000) to ensure even distribution when the number of servers is small.\n",
    "\n",
    "**Code Example** (Conceptual):\n",
    "```python\n",
    "class ConsistentHash:\n",
    "    def __init__(self, num_virtual_nodes=100):\n",
    "        self.ring = []\n",
    "        self.num_virtual_nodes = num_virtual_nodes\n",
    "        \n",
    "    def add_server(self, server):\n",
    "        # Add virtual nodes for this server\n",
    "        for i in range(self.num_virtual_nodes):\n",
    "            hash_value = hash(f\"{server}_{i}\")\n",
    "            self.ring.append((hash_value, server))\n",
    "        self.ring.sort()  # Sort by hash value\n",
    "        \n",
    "    def get_server(self, key):\n",
    "        hash_value = hash(key)\n",
    "        # Find first server clockwise from this hash\n",
    "        for node_hash, server in self.ring:\n",
    "            if node_hash >= hash_value:\n",
    "                return server\n",
    "        # Wrap around to first server\n",
    "        return self.ring[0][1]\n",
    "```\n",
    "\n",
    "**Use cases**: \n",
    "- **Distributed caches**: Memcached clusters\n",
    "- **Distributed databases**: Cassandra, Riak\n",
    "- **Load balancing**: Deterministic routing of requests\n",
    "\n",
    "---\n",
    "\n",
    "### **Bloom Filters: Space-Efficient Probabilistic Data Structures**\n",
    "\n",
    "**Question**: How can you efficiently check if an element is in a very large set without storing the entire set?\n",
    "\n",
    "**Answer**: Bloom filters\u2014space-efficient probabilistic data structures that test whether an element is a member of a set.\n",
    "\n",
    "**Properties**:\n",
    "- **Space-efficient**: 1-2 bytes per element (vs. 20+ bytes for hash maps)\n",
    "- **False positives possible**: Might say \"yes\" when answer is \"no\"\n",
    "- **False negatives impossible**: If it says \"no\", element is definitely not in set\n",
    "- **No deletion**: Standard bloom filters don't support deletion (though variants do)\n",
    "\n",
    "**How It Works**:\n",
    "```\n",
    "1. Choose k hash functions and a bit array of m bits\n",
    "2. To add an element, compute k hash values and set those bits to 1\n",
    "3. To check membership, compute k hash values; if all bits are 1, element might be in set\n",
    "```\n",
    "\n",
    "**Visualization**:\n",
    "```\n",
    "Initial state (m=10 bits):\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "Add \"alice\":\n",
    "hash1(\"alice\") = 2 \u2192 set bit[2] = 1\n",
    "hash2(\"alice\") = 5 \u2192 set bit[5] = 1\n",
    "hash3(\"alice\") = 9 \u2192 set bit[9] = 1\n",
    "\n",
    "Result:\n",
    "[0, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
    "\n",
    "Check \"bob\":\n",
    "hash1(\"bob\") = 2 \u2192 bit[2] = 1 \u2713\n",
    "hash2(\"bob\") = 3 \u2192 bit[3] = 0 \u2717 \u2192 Definitely not in set\n",
    "\n",
    "Check \"charlie\":\n",
    "hash1(\"charlie\") = 2 \u2192 bit[2] = 1 \u2713\n",
    "hash2(\"charlie\") = 5 \u2192 bit[5] = 1 \u2713\n",
    "hash3(\"charlie\") = 9 \u2192 bit[9] = 1 \u2713\n",
    "\u2192 Possibly in set (might be false positive)\n",
    "```\n",
    "\n",
    "**False Positive Rate**:\n",
    "```\n",
    "P(false positive) \u2248 (1 - e^(-kn/m))^k\n",
    "\n",
    "Where:\n",
    "- n = number of elements in set\n",
    "- m = size of bit array\n",
    "- k = number of hash functions\n",
    "```\n",
    "\n",
    "**Optimal Configuration**:\n",
    "- For given n and m, optimal k \u2248 (m/n) * ln(2)\n",
    "- For 1% false positive rate, need ~10 bits per element\n",
    "- For 0.1% false positive rate, need ~15 bits per element\n",
    "\n",
    "**Code Example**:\n",
    "```python\n",
    "import mmh3  # MurmurHash3, a fast non-cryptographic hash\n",
    "from bitarray import bitarray\n",
    "\n",
    "class BloomFilter:\n",
    "    def __init__(self, size, hash_count):\n",
    "        self.size = size\n",
    "        self.hash_count = hash_count\n",
    "        self.bit_array = bitarray(size)\n",
    "        self.bit_array.setall(0)\n",
    "        \n",
    "    def add(self, item):\n",
    "        for i in range(self.hash_count):\n",
    "            # Different seed for each hash function\n",
    "            index = mmh3.hash(str(item), i) % self.size\n",
    "            self.bit_array[index] = 1\n",
    "            \n",
    "    def might_contain(self, item):\n",
    "        for i in range(self.hash_count):\n",
    "            index = mmh3.hash(str(item), i) % self.size\n",
    "            if not self.bit_array[index]:\n",
    "                return False  # Definitely not in set\n",
    "        return True  # Possibly in set\n",
    "```\n",
    "\n",
    "**Real-World Use Cases**:\n",
    "- **Google Chrome**: \"Do not show this website's notifications again\" (10MB filter for billions of domains)\n",
    "- **Databases**: Query optimization (bloom filter before reading from disk)\n",
    "- **Bitcoin**: Lightweight clients can check if a transaction exists without storing entire blockchain\n",
    "- **Web crawlers**: Avoid re-crawling URLs\n",
    "- **Spell checkers**: Quickly determine if a word might be misspelled\n",
    "\n",
    "**System Design Pattern**:\n",
    "```\n",
    "Request \u2192 Bloom Filter Check\n",
    "    \u251c\u2500\u2192 Negative (definitely not in DB) \u2192 Return 404\n",
    "    \u2514\u2500\u2192 Positive (might be in DB) \u2192 Query Database \u2192 Return result\n",
    "```\n",
    "\n",
    "This prevents 99% of unnecessary database queries for non-existent keys.\n",
    "\n",
    "---\n",
    "\n",
    "### **Skip Lists: Probabilistic Search Structures**\n",
    "\n",
    "**Problem**: Sorted arrays support O(1) access by index and O(log n) search but O(n) insertion/deletion. Balanced trees support O(log n) operations but are complex to implement and maintain. What if we want something simpler?\n",
    "\n",
    "**Skip Lists**: Probabilistic data structures that provide O(log n) search, insertion, and deletion with simpler implementation than balanced trees.\n",
    "\n",
    "**How It Works**: A multi-level linked list where higher levels skip many elements, similar to how you might look at the chapter titles before reading paragraphs.\n",
    "\n",
    "**Visualization**:\n",
    "```\n",
    "Level 2:      1 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 10 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 30\n",
    "Level 1:      1 \u2500\u2500\u2500\u2500\u2192 5 \u2500\u2500\u2500\u2500\u2192 10 \u2500\u2500\u2500\u2500\u2192 20 \u2500\u2500\u2192 30\n",
    "Level 0: 0 \u2500\u2500\u2192 1 \u2500\u2500\u2192 5 \u2500\u2500\u2192 8 \u2500\u2500\u2192 10 \u2500\u2500\u2192 20 \u2500\u2500\u2192 30 \u2500\u2500\u2192 \u221e\n",
    "```\n",
    "\n",
    "**Search for 20**:\n",
    "1. Start at Level 2: 1 \u2192 10 \u2192 30 (20 is between 10 and 30)\n",
    "2. Drop to Level 1: 10 \u2192 20 (found!)\n",
    "3. Only 4 node visits instead of 6 in Level 0\n",
    "\n",
    "**Insertion Process**:\n",
    "```\n",
    "1. Insert node into Level 0 (like normal linked list)\n",
    "2. Randomly decide whether to promote to Level 1 (usually 50% chance)\n",
    "3. If promoted to Level 1, randomly decide whether to promote to Level 2 (25% chance)\n",
    "4. Continue until node isn't promoted or reaches max level\n",
    "```\n",
    "\n",
    "**Why This Works**: The probability distribution ensures that higher levels have exponentially fewer nodes, mimicking the structure of balanced trees.\n",
    "\n",
    "**Code Example** (Conceptual):\n",
    "```python\n",
    "import random\n",
    "\n",
    "class SkipListNode:\n",
    "    def __init__(self, value, levels):\n",
    "        self.value = value\n",
    "        self.next = [None] * levels\n",
    "\n",
    "class SkipList:\n",
    "    def __init__(self, max_levels=16, probability=0.5):\n",
    "        self.max_levels = max_levels\n",
    "        self.probability = probability\n",
    "        self.head = SkipListNode(-float('inf'), max_levels)\n",
    "        \n",
    "    def random_level(self):\n",
    "        level = 1\n",
    "        while random.random() < self.probability and level < self.max_levels:\n",
    "            level += 1\n",
    "        return level\n",
    "        \n",
    "    def search(self, value):\n",
    "        current = self.head\n",
    "        for level in reversed(range(self.max_levels)):\n",
    "            while current.next[level] and current.next[level].value < value:\n",
    "                current = current.next[level]\n",
    "        current = current.next[0]\n",
    "        return current and current.value == value\n",
    "        \n",
    "    def insert(self, value):\n",
    "        update = [None] * self.max_levels\n",
    "        current = self.head\n",
    "        \n",
    "        for level in reversed(range(self.max_levels)):\n",
    "            while current.next[level] and current.next[level].value < value:\n",
    "                current = current.next[level]\n",
    "            update[level] = current\n",
    "            \n",
    "        new_level = self.random_level()\n",
    "        new_node = SkipListNode(value, new_level)\n",
    "        \n",
    "        for level in range(new_level):\n",
    "            new_node.next[level] = update[level].next[level]\n",
    "            update[level].next[level] = new_node\n",
    "```\n",
    "\n",
    "**Real-World Use Cases**:\n",
    "- **Redis**: Implementing sorted sets (ZSET) data structure\n",
    "- **Apache Cassandra**: SSTable indexing (memtable-sstable)\n",
    "- **LevelDB/RocksDB**: Memtable structure\n",
    "\n",
    "**Advantages over Balanced Trees**:\n",
    "- Simpler to implement correctly\n",
    "- Better cache locality (linked lists vs. tree nodes scattered in memory)\n",
    "- No need for rebalancing rotations\n",
    "- Efficient concurrent access (lock levels individually)\n",
    "\n",
    "---\n",
    "\n",
    "### **Bitmasks: Efficient Flag Storage**\n",
    "\n",
    "**Problem**: How do you efficiently store and check multiple boolean flags for millions of items?\n",
    "\n",
    "**Answer**: Bitmasks\u2014using individual bits within integers to represent boolean values.\n",
    "\n",
    "**Basic Concept**: A 64-bit integer can store 64 boolean flags.\n",
    "```\n",
    "Integer:  0000 0001 0100 1000 (binary)\n",
    "Meaning:  \u2514\u252c\u2500\u2518 \u2514\u252c\u2500\u2518 \u2514\u252c\u2500\u2518 \u2514\u252c\u2500\u2518\n",
    "         Flag  Flag  Flag  Flag\n",
    "           0     3     6     9\n",
    "         \n",
    "Bit 0 = 1 \u2192 Flag 0 is True\n",
    "Bit 3 = 1 \u2192 Flag 3 is True\n",
    "Bit 6 = 1 \u2192 Flag 6 is True\n",
    "Bit 9 = 1 \u2192 Flag 9 is True\n",
    "All other bits = 0 \u2192 Other flags are False\n",
    "```\n",
    "\n",
    "**Bitwise Operations**:\n",
    "\n",
    "**Set a bit** (turn flag on):\n",
    "```python\n",
    "flags = 0b00001010  # Initial flags\n",
    "flags |= 0b00000100  # Set bit 2 (| is OR)\n",
    "# Result: 0b00001110\n",
    "```\n",
    "\n",
    "**Clear a bit** (turn flag off):\n",
    "```python\n",
    "flags = 0b00001110\n",
    "flags &= ~0b00000100  # Clear bit 2 (& is AND, ~ is NOT)\n",
    "# Result: 0b00001010\n",
    "```\n",
    "\n",
    "**Check a bit** (is flag set?):\n",
    "```python\n",
    "flags = 0b00001110\n",
    "is_set = bool(flags & 0b00000100)  # Check bit 2\n",
    "# Result: True\n",
    "```\n",
    "\n",
    "**Toggle a bit** (flip flag):\n",
    "```python\n",
    "flags = 0b00001110\n",
    "flags ^= 0b00000100  # Toggle bit 2 (^ is XOR)\n",
    "# Result: 0b00001010\n",
    "```\n",
    "\n",
    "**Real-World Example: File Permissions in Unix/Linux**:\n",
    "```python\n",
    "# Unix file permissions (rwxrwxrwx)\n",
    "# Read = 4 (100), Write = 2 (010), Execute = 1 (001)\n",
    "\n",
    "# Owner permissions: read + write = 4 + 2 = 6 (110)\n",
    "# Group permissions: read only = 4 (100)\n",
    "# Others: no permissions = 0 (000)\n",
    "\n",
    "permissions = 0o640  # Octal notation\n",
    "\n",
    "# Check if owner can write\n",
    "owner_can_write = bool((permissions >> 6) & 0o2)  # True\n",
    "\n",
    "# Check if group can execute\n",
    "group_can_execute = bool((permissions >> 3) & 0o1)  # False\n",
    "\n",
    "# Grant execute permission to others\n",
    "permissions |= 0o1  # Now 0o641\n",
    "```\n",
    "\n",
    "**System Design Use Cases**:\n",
    "- **User permissions**: Store 64+ permission flags in single integer per user\n",
    "- **Feature flags**: Efficient A/B testing and gradual rollout\n",
    "- **Caching**: Dirty bits indicating which cache entries need to be written to disk\n",
    "- **Compression**: Bitmap indices for databases\n",
    "\n",
    "**Performance Advantage**:\n",
    "- 64 flags stored in 8 bytes\n",
    "- All operations are CPU-native (single instruction)\n",
    "- Can test all flags simultaneously with bitmask comparisons\n",
    "\n",
    "---\n",
    "\n",
    "## **2.4 Concurrency Basics**\n",
    "\n",
    "In distributed systems, multiple operations often happen simultaneously. Understanding concurrency is essential for designing correct and performant systems.\n",
    "\n",
    "### **Processes vs. Threads: Understanding the Hierarchy**\n",
    "\n",
    "**Process**: An instance of a running program. Each process has its own memory space, file descriptors, and resources.\n",
    "\n",
    "**Characteristics**:\n",
    "- **Isolated memory**: One process cannot directly access another's memory\n",
    "- **Heavyweight**: Creating a process copies the entire memory space\n",
    "- **Communication**: Requires IPC (Inter-Process Communication) mechanisms\n",
    "- **Safety**: Process crashes don't affect other processes (usually)\n",
    "\n",
    "**Thread**: The smallest unit of execution within a process. Threads share the same memory space and resources.\n",
    "\n",
    "**Characteristics**:\n",
    "- **Shared memory**: All threads in a process share the same memory\n",
    "- **Lightweight**: Creating a thread is much faster than creating a process\n",
    "- **Direct communication**: Can access shared variables directly\n",
    "- **Vulnerable**: One thread can corrupt memory for all threads\n",
    "\n",
    "**Visualization**:\n",
    "```\n",
    "Process A                          Process B\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                         \u2502       \u2502                         \u2502\n",
    "\u2502  Memory Space           \u2502       \u2502  Memory Space           \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502       \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n",
    "\u2502  \u2502 Thread 1            \u2502\u2502       \u2502  \u2502 Thread 1            \u2502\u2502\n",
    "\u2502  \u2502 (Shared memory)     \u2502\u2502       \u2502  \u2502 (Shared memory)     \u2502\u2502\n",
    "\u2502  \u2502                     \u2502\u2502       \u2502  \u2502                     \u2502\u2502\n",
    "\u2502  \u2502 Thread 2            \u2502\u2502       \u2502  \u2502 Thread 2            \u2502\u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502       \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n",
    "\u2502                         \u2502       \u2502                         \u2502\n",
    "\u2502  File Descriptors       \u2502       \u2502  File Descriptors       \u2502\n",
    "\u2502  Network Sockets        \u2502       \u2502  Network Sockets        \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "No direct access between processes\n",
    "```\n",
    "\n",
    "**Performance Comparison**:\n",
    "```\n",
    "Operation                    Time (approx)\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "Process creation            10-50 ms\n",
    "Thread creation             0.1-1 ms\n",
    "Context switch (same proc)  1-5 \u00b5s\n",
    "Context switch (diff proc)  10-100 \u00b5s\n",
    "```\n",
    "\n",
    "**Use Cases**:\n",
    "- **Multi-process**: Separate services (web server, database, cache), isolation (browser tabs), CPU-bound parallelism\n",
    "- **Multi-thread**: Shared data structures, responsive UI (background tasks), I/O-bound work (handling multiple connections)\n",
    "\n",
    "---\n",
    "\n",
    "### **Race Conditions and Data Races**\n",
    "\n",
    "**Race Condition**: The behavior of software depends on the relative timing of events. Results are non-deterministic.\n",
    "\n",
    "**Example**: The \"Bank Account Problem\"\n",
    "```python\n",
    "# Shared balance variable\n",
    "balance = 1000\n",
    "\n",
    "# Thread 1: Deposit $100\n",
    "def deposit():\n",
    "    global balance\n",
    "    temp = balance      # Read: 1000\n",
    "    time.sleep(0.001)   # Context switch happens here!\n",
    "    balance = temp + 100\n",
    "\n",
    "# Thread 2: Deposit $200\n",
    "def deposit_large():\n",
    "    global balance\n",
    "    temp = balance      # Read: 1000 (stale value!)\n",
    "    balance = temp + 200\n",
    "\n",
    "# Expected: balance = 1300\n",
    "# Actual: balance = 1200 (Thread 2 overwrites Thread 1's update)\n",
    "```\n",
    "\n",
    "**Timeline of the Race**:\n",
    "```\n",
    "Time  Thread 1          Thread 2          Balance\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "0     Read 1000                           1000\n",
    "1                       Read 1000          1000\n",
    "2     Write 1100                          1100\n",
    "3                       Write 1200         1200  \u2190 Wrong!\n",
    "```\n",
    "\n",
    "**Types of Race Conditions**:\n",
    "1. **Check-then-act**: Check a condition, then act (but condition changed)\n",
    "2. **Read-modify-write**: Read value, modify, write (race between read and write)\n",
    "3. **Lost update**: Multiple threads update same value based on stale reads\n",
    "\n",
    "---\n",
    "\n",
    "### **Synchronization Mechanisms: Preventing Race Conditions**\n",
    "\n",
    "**Mutex (Mutual Exclusion)**: Ensures only one thread can access shared resource at a time.\n",
    "\n",
    "**Concept**:\n",
    "```\n",
    "Room (shared resource) with one key (mutex)\n",
    "\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                 \u2502\n",
    "\u2502   Thread 1      \u2502 \u2190 Has key, enters room\n",
    "\u2502   \ud83d\udd11 Key        \u2502   (Other threads wait)\n",
    "\u2502                 \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "When Thread 1 leaves, it returns the key.\n",
    "Next waiting thread gets the key and enters.\n",
    "```\n",
    "\n",
    "**Code Example**:\n",
    "```python\n",
    "import threading\n",
    "\n",
    "balance = 1000\n",
    "balance_lock = threading.Lock()  # Mutex\n",
    "\n",
    "def deposit(amount):\n",
    "    global balance\n",
    "    with balance_lock:  # Acquire lock\n",
    "        temp = balance\n",
    "        time.sleep(0.001)  # Even with delay, no race condition\n",
    "        balance = temp + amount\n",
    "    # Lock automatically released when exiting 'with' block\n",
    "\n",
    "# Now threads execute sequentially, not concurrently\n",
    "```\n",
    "\n",
    "**Performance Impact**:\n",
    "- Locks introduce overhead (tens to hundreds of nanoseconds)\n",
    "- Contention (threads waiting for locks) can become bottleneck\n",
    "- Deadlock risk if locks are held incorrectly\n",
    "\n",
    "**Best Practices**:\n",
    "- Hold locks for minimal time\n",
    "- Avoid holding locks while calling unknown functions\n",
    "- Use lock ordering to prevent deadlocks\n",
    "- Consider lock-free data structures for high-contention scenarios\n",
    "\n",
    "---\n",
    "\n",
    "### **Semaphores: Counting Resources**\n",
    "\n",
    "**Semaphore**: A more general synchronization primitive that allows multiple threads to access a resource up to a limit.\n",
    "\n",
    "**Binary Semaphore**: Acts like a mutex (limit = 1).\n",
    "\n",
    "**Counting Semaphore**: Allows up to N threads to access resource simultaneously.\n",
    "\n",
    "**Example**: Database Connection Pool\n",
    "```python\n",
    "import threading\n",
    "\n",
    "class ConnectionPool:\n",
    "    def __init__(self, max_connections):\n",
    "        self.max_connections = max_connections\n",
    "        self.semaphore = threading.Semaphore(max_connections)\n",
    "        \n",
    "    def get_connection(self):\n",
    "        self.semaphore.acquire()  # Decrements semaphore\n",
    "        # If semaphore = 0, blocks until a connection is released\n",
    "        return create_database_connection()\n",
    "        \n",
    "    def return_connection(self, connection):\n",
    "        connection.close()\n",
    "        self.semaphore.release()  # Increments semaphore\n",
    "\n",
    "# Usage\n",
    "pool = ConnectionPool(max_connections=10)\n",
    "\n",
    "# Up to 10 threads can have connections simultaneously\n",
    "# 11th thread blocks until a connection is returned\n",
    "```\n",
    "\n",
    "**Use Cases**:\n",
    "- **Resource pools**: Database connections, thread pools\n",
    "- **Rate limiting**: Limit concurrent API calls\n",
    "- **Producer-consumer**: Bounded buffer synchronization\n",
    "\n",
    "---\n",
    "\n",
    "### **Deadlocks: When Threads Wait Forever**\n",
    "\n",
    "**Deadlock**: A situation where multiple threads are blocked waiting for each other, resulting in no progress.\n",
    "\n",
    "**Example**: The \"Dining Philosophers Problem\"\n",
    "```\n",
    "Philosopher 1: Fork A \u2192 Fork B  (waiting for Fork B)\n",
    "Philosopher 2: Fork B \u2192 Fork A  (waiting for Fork A)\n",
    "\n",
    "Both are waiting for the other to release their fork.\n",
    "Neither can proceed. Deadlock!\n",
    "```\n",
    "\n",
    "**Four Necessary Conditions for Deadlock** (Coffman conditions):\n",
    "1. **Mutual exclusion**: Resources cannot be shared\n",
    "2. **Hold and wait**: Thread holds a resource while waiting for another\n",
    "3. **No preemption**: Resources cannot be forcibly taken\n",
    "4. **Circular wait**: Thread A waits for Thread B, which waits for Thread A...\n",
    "\n",
    "**Prevention Strategies**:\n",
    "\n",
    "**1. Lock Ordering**: Always acquire locks in a consistent order.\n",
    "```python\n",
    "def transfer(account1, account2, amount):\n",
    "    # Always lock the account with the smaller ID first\n",
    "    if account1.id < account2.id:\n",
    "        account1.lock.acquire()\n",
    "        account2.lock.acquire()\n",
    "    else:\n",
    "        account2.lock.acquire()\n",
    "        account1.lock.acquire()\n",
    "    \n",
    "    # Perform transfer\n",
    "    account2.lock.release()\n",
    "    account1.lock.release()\n",
    "```\n",
    "\n",
    "**2. Timeouts**: Give up if lock acquisition takes too long.\n",
    "```python\n",
    "def transfer_with_timeout(account1, account2, amount):\n",
    "    if account1.lock.acquire(timeout=1.0):\n",
    "        try:\n",
    "            if account2.lock.acquire(timeout=1.0):\n",
    "                try:\n",
    "                    # Perform transfer\n",
    "                    pass\n",
    "                finally:\n",
    "                    account2.lock.release()\n",
    "        finally:\n",
    "            account1.lock.release()\n",
    "    else:\n",
    "        raise TimeoutError(\"Could not acquire lock\")\n",
    "```\n",
    "\n",
    "**3. Try-Lock**: Attempt to acquire all locks; if any fails, release all and retry.\n",
    "```python\n",
    "def transfer_try_lock(account1, account2, amount):\n",
    "    acquired = False\n",
    "    try:\n",
    "        acquired = account1.lock.acquire(blocking=False) and \\\n",
    "                   account2.lock.acquire(blocking=False)\n",
    "        if acquired:\n",
    "            # Perform transfer\n",
    "            pass\n",
    "    finally:\n",
    "        if acquired:\n",
    "            account2.lock.release()\n",
    "            account1.lock.release()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **The Event Loop: Asynchronous I/O Without Threads**\n",
    "\n",
    "**Problem**: Threads have overhead (stack memory, context switching). What if we want to handle thousands of concurrent connections with minimal overhead?\n",
    "\n",
    "**Solution**: Event loop + asynchronous I/O\u2014single thread handles all I/O operations.\n",
    "\n",
    "**How It Works**:\n",
    "```\n",
    "1. Event loop maintains a queue of tasks\n",
    "2. When task performs I/O (network read, disk write), it yields control\n",
    "3. Event loop schedules next task from queue\n",
    "4. When I/O completes, original task is resumed\n",
    "```\n",
    "\n",
    "**Comparison**:\n",
    "```\n",
    "Threaded Model:              Event Loop Model:\n",
    "Thread 1:                    Task 1:  I/O wait \u2192 yield\n",
    "  Handle Request 1                  Task 2:  Handle Request 2\n",
    "  Read from DB                      Task 3:  Handle Request 3\n",
    "  Write response                    ...\n",
    "Thread 2:                           I/O completes \u2192 Task 1 resumed\n",
    "  Handle Request 2                  Task 1:  Write response\n",
    "  Read from DB\n",
    "  Write response\n",
    "... (1000 threads)\n",
    "```\n",
    "\n",
    "**Memory Usage**:\n",
    "```\n",
    "Threaded (1000 threads, 2MB stack per thread): ~2GB memory\n",
    "Event Loop (1 thread, task objects): ~50MB memory\n",
    "```\n",
    "\n",
    "**Code Example (Node.js/JavaScript)**:\n",
    "```javascript\n",
    "// Node.js uses an event loop by default\n",
    "const fs = require('fs');\n",
    "\n",
    "// Non-blocking file read\n",
    "fs.readFile('large_file.txt', (err, data) => {\n",
    "  // This callback runs when file is read\n",
    "  console.log('File read complete!');\n",
    "});\n",
    "\n",
    "console.log('This prints BEFORE file read completes');\n",
    "\n",
    "// Output:\n",
    "// \"This prints BEFORE file read completes\"\n",
    "// \"File read complete!\"\n",
    "```\n",
    "\n",
    "**Code Example (Python asyncio)**:\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def fetch_data(url):\n",
    "    print(f\"Fetching {url}...\")\n",
    "    await asyncio.sleep(2)  # Simulate network call\n",
    "    print(f\"Data from {url} received!\")\n",
    "    return f\"Data from {url}\"\n",
    "\n",
    "async def main():\n",
    "    # Execute three fetches concurrently\n",
    "    tasks = [\n",
    "        fetch_data('http://api1.com'),\n",
    "        fetch_data('http://api2.com'),\n",
    "        fetch_data('http://api3.com')\n",
    "    ]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "# Total time: 2 seconds (not 6 seconds!)\n",
    "asyncio.run(main())\n",
    "```\n",
    "\n",
    "**Use Cases**:\n",
    "- **High-concurrency web servers**: Node.js, Python asyncio\n",
    "- **Real-time applications**: Chat servers, multiplayer games\n",
    "- **Microservices**: API gateways, proxy servers\n",
    "\n",
    "**Trade-offs**:\n",
    "- **Pros**: Low memory usage, no lock contention, efficient I/O handling\n",
    "- **Cons**: CPU-bound tasks block entire event loop, requires async-compatible libraries, steeper learning curve\n",
    "\n",
    "---\n",
    "\n",
    "## **2.5 Basic Math for Capacity Planning**\n",
    "\n",
    "System design often requires back-of-the-envelope calculations to make quick decisions. You don't need complex math, but you do need to understand the basics of estimating capacity.\n",
    "\n",
    "### **Throughput and QPS (Queries Per Second)**\n",
    "\n",
    "**QPS**: Number of queries/requests processed per second.\n",
    "\n",
    "**Basic Calculation**:\n",
    "```\n",
    "QPS = Total Users \u00d7 Requests per User / Time Window\n",
    "\n",
    "Example:\n",
    "- 1 million daily active users (DAU)\n",
    "- Each user makes 10 requests per day\n",
    "- Total daily requests = 10 million\n",
    "- Peak hour has 20% of traffic = 2 million requests\n",
    "- Peak QPS = 2,000,000 / 3600 = 555 requests/second\n",
    "```\n",
    "\n",
    "**Real-World QPS Estimates**:\n",
    "```\n",
    "Service              Peak QPS\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "Twitter              30,000+ (tweets per second)\n",
    "Google Search        70,000+\n",
    "YouTube              100,000+ (video starts per second)\n",
    "AWS                  1,000,000+ (API calls)\n",
    "Small SaaS app       10-100\n",
    "Medium app           1,000-10,000\n",
    "Large app            10,000-100,000\n",
    "```\n",
    "\n",
    "**Server Capacity Planning**:\n",
    "```\n",
    "If each server can handle 1,000 QPS:\n",
    "- Required for 5,000 QPS: 5 servers\n",
    "- Required for 50,000 QPS: 50 servers\n",
    "- Required for 500,000 QPS: 500 servers\n",
    "\n",
    "Add buffer for:\n",
    "- Peak traffic (2-5x average)\n",
    "- Server failures (1-2 extra servers)\n",
    "- Maintenance capacity (another 10-20%)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Storage Estimation**\n",
    "\n",
    "**Formula**: Storage = Records \u00d7 Size per Record\n",
    "\n",
    "**Example: Social Media Posts**\n",
    "```\n",
    "Assumptions:\n",
    "- Post ID: 8 bytes (64-bit integer)\n",
    "- User ID: 8 bytes\n",
    "- Timestamp: 8 bytes\n",
    "- Content: 1,000 bytes (500 characters, 2 bytes each)\n",
    "- Metadata: 100 bytes\n",
    "\n",
    "Total per post: ~1,124 bytes\n",
    "\n",
    "Daily posts:\n",
    "- 1 million users\n",
    "- 2 posts per user per day\n",
    "- 2 million posts per day\n",
    "\n",
    "Daily storage: 2,000,000 \u00d7 1,124 bytes \u2248 2.2 GB\n",
    "Yearly storage: 2.2 GB \u00d7 365 \u2248 800 GB\n",
    "\n",
    "5-year storage: 4 TB (plus ~20% overhead = 5 TB)\n",
    "```\n",
    "\n",
    "**Example: Chat Messages**\n",
    "```\n",
    "Assumptions:\n",
    "- Message ID: 16 bytes (UUID)\n",
    "- Sender ID: 8 bytes\n",
    "- Recipient ID: 8 bytes\n",
    "- Timestamp: 8 bytes\n",
    "- Message text: 200 bytes\n",
    "- Metadata: 50 bytes\n",
    "\n",
    "Total per message: ~290 bytes\n",
    "\n",
    "Daily messages:\n",
    "- 500,000 users\n",
    "- 50 messages per user per day\n",
    "- 25 million messages per day\n",
    "\n",
    "Daily storage: 25,000,000 \u00d7 290 bytes \u2248 7.25 GB\n",
    "Yearly storage: 7.25 GB \u00d7 365 \u2248 2.6 TB\n",
    "```\n",
    "\n",
    "**Database Storage Overhead**:\n",
    "- Add 20-30% for database overhead (indexes, page headers)\n",
    "- Add 50-100% for replicas (3 replicas = 3x storage)\n",
    "- Add 50% for backups (incremental backups reduce this)\n",
    "\n",
    "**Compression Savings**:\n",
    "- Text: 50-70% reduction (gzip, LZ4)\n",
    "- Images: 50-90% reduction (WebP, AVIF)\n",
    "- Video: 90-99% reduction (H.264, VP9, AV1)\n",
    "\n",
    "---\n",
    "\n",
    "### **Network Bandwidth**\n",
    "\n",
    "**Formula**: Bandwidth = Throughput \u00d7 Average Response Size\n",
    "\n",
    "**Example: Image Serving**\n",
    "```\n",
    "Assumptions:\n",
    "- 10,000 image requests per second\n",
    "- Average image size: 500 KB\n",
    "\n",
    "Bandwidth: 10,000 \u00d7 500 KB = 5 GB/s = 40 Gbps\n",
    "\n",
    "Network requirements:\n",
    "- 40 Gbps of bandwidth\n",
    "- With redundancy: 2 \u00d7 40 Gbps = 80 Gbps total\n",
    "- For 3 availability zones: 3 \u00d7 80 Gbps = 240 Gbps\n",
    "```\n",
    "\n",
    "**Example: API Response Bandwidth**\n",
    "```\n",
    "Assumptions:\n",
    "- 5,000 API requests per second\n",
    "- Average response size: 10 KB\n",
    "\n",
    "Bandwidth: 5,000 \u00d7 10 KB = 50 MB/s = 400 Mbps\n",
    "\n",
    "With CDN:\n",
    "- 80% of bandwidth served from CDN (cached responses)\n",
    "- 20% served from origin\n",
    "- Origin bandwidth: 400 Mbps \u00d7 0.2 = 80 Mbps\n",
    "```\n",
    "\n",
    "**Cost Estimation** (AWS us-east-1, approximate):\n",
    "```\n",
    "Data Transfer Out:\n",
    "- First 10 TB/month: Free\n",
    "- Next 40 TB/month: $0.09/GB\n",
    "- Next 100 TB/month: $0.085/GB\n",
    "- Beyond: Tiered pricing\n",
    "\n",
    "Example: 1 TB/month data transfer\n",
    "= 10 TB free + 40 TB \u00d7 $0.09 + 950 TB \u00d7 $0.085\n",
    "\u2248 $81,550/month (high traffic!)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Latency Budget**\n",
    "\n",
    "**Latency Budget**: Maximum acceptable time for each component.\n",
    "\n",
    "**Example: 200ms Total Budget**\n",
    "```\n",
    "Component                Budget     Actual    Status\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "Client processing       10 ms      8 ms      \u2713\n",
    "Network (CDN edge)      30 ms      25 ms     \u2713\n",
    "CDN cache lookup        20 ms      15 ms     \u2713\n",
    "Application processing  50 ms      45 ms     \u2713\n",
    "Database query          40 ms      60 ms     \u2717 (over budget)\n",
    "Cache fallback          10 ms      5 ms      \u2713\n",
    "Response serialization   10 ms      8 ms      \u2713\n",
    "Network return          30 ms      25 ms     \u2713\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "Total                   200 ms     191 ms    \u2713\n",
    "\n",
    "If database exceeds budget, options:\n",
    "1. Add more read replicas\n",
    "2. Optimize queries and add indexes\n",
    "3. Increase cache hit rate\n",
    "4. Denormalize data\n",
    "```\n",
    "\n",
    "**P99 Latency Calculation**:\n",
    "```\n",
    "If 99% of requests are under 200ms, but 1% take 5 seconds:\n",
    "- Average latency: ~200ms (misleading!)\n",
    "- P50 latency: ~150ms\n",
    "- P95 latency: ~250ms\n",
    "- P99 latency: ~5,000ms (users notice!)\n",
    "- P99.9 latency: ~10,000ms (users give up!)\n",
    "\n",
    "Always track P99, not just averages.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2.6 Key Takeaways**\n",
    "\n",
    "1. **Networking is the slowest component**: Network calls are 1,000-1,000,000x slower than memory operations. Minimize them.\n",
    "\n",
    "2. **Protocol selection matters**: Use TCP for reliability, UDP for speed. Use HTTP/2 for efficiency, HTTP/3 for reliability over unreliable networks.\n",
    "\n",
    "3. **Data structure selection is critical**: Bloom filters for membership testing, consistent hashing for distribution, skip lists for efficient indexing.\n",
    "\n",
    "4. **Concurrency is complex**: Understand race conditions, deadlocks, and synchronization. Choose threads vs. event loops based on your workload.\n",
    "\n",
    "5. **Back-of-the-envelope calculations**: Quick math (QPS, storage, bandwidth) guides architectural decisions and prevents costly mistakes.\n",
    "\n",
    "6. **Measure first, optimize second**: Before optimizing, know your baseline. 80% of optimization efforts are wasted on non-bottlenecks.\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "In this chapter, we built the foundation for system design by understanding networking fundamentals, the hierarchy of speed, specialized data structures, concurrency concepts, and capacity planning math.\n",
    "\n",
    "We learned that network latency is the enemy of performance, that different protocols serve different needs, and that specialized data structures like Bloom filters and consistent hashing are essential for distributed systems.\n",
    "\n",
    "We explored concurrency from processes to event loops, understanding how to prevent race conditions and deadlocks. Finally, we learned to calculate requirements quickly using basic math\u2014skills that will guide our architectural decisions in every subsequent chapter.\n",
    "\n",
    "**Coming up next**: In Chapter 3, we'll dive deep into databases\u2014the heart of most systems. We'll explore relational and NoSQL databases, indexing strategies, sharding, and the CAP theorem in detail.\n",
    "\n",
    "---\n",
    "\n",
    "**Exercises**:\n",
    "\n",
    "1. **Network Latency**: Calculate the total latency for a request that:\n",
    "   - Travels from user in London to server in New York (80ms round-trip)\n",
    "   - Makes 3 database queries (each 10ms)\n",
    "   - Processes 50ms of business logic\n",
    "   - What's the total? Where would you optimize?\n",
    "\n",
    "2. **Bloom Filter Design**: You need a bloom filter for 1 billion URLs with 1% false positive rate. How many bits do you need? How many hash functions?\n",
    "\n",
    "3. **Capacity Planning**: You're building a video streaming service with 1 million users, each watching 2 hours of video per day (average 3 Mbps). Calculate:\n",
    "   - Daily storage requirements\n",
    "   - Peak bandwidth requirements (assuming 20% of users watch during peak hour)\n",
    "   - How many 10 Gbps network connections do you need?\n",
    "\n",
    "4. **Concurrency**: Identify the race condition in this code and fix it:\n",
    "```python\n",
    "counter = 0\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    temp = counter\n",
    "    time.sleep(0.001)\n",
    "    counter = temp + 1\n",
    "\n",
    "# What happens if 10 threads call increment() simultaneously?\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='1. introduction_to_system_design.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='../2. The_building_blocks/3. databases.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}