{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11: Iterators, Generators, and Decorators\n",
    "\n",
    "Python's elegance lies not just in its readable syntax, but in its sophisticated protocols that enable memory-efficient data processing and clean separation of concerns. Three features\u2014iterators, generators, and decorators\u2014form the backbone of advanced Python programming, allowing you to handle infinite data streams, create lazy evaluation pipelines, and inject cross-cutting functionality without cluttering business logic.\n",
    "\n",
    "This chapter explores the iterator protocol that powers Python's `for` loops, the generator functions that enable memory-efficient data processing, and the decorator pattern that modifies function behavior. These tools are essential for writing Pythonic code that scales from kilobytes to gigabytes of data while maintaining clean, reusable architectures.\n",
    "\n",
    "## 11.1 Iterators: The Iterator Protocol\n",
    "\n",
    "An **iterator** is an object that represents a stream of data, returning one element at a time when requested. Understanding iterators is fundamental because they underpin every `for` loop, comprehension, and iterable operation in Python.\n",
    "\n",
    "### The Iterator Protocol\n",
    "\n",
    "Python's iterator protocol consists of two methods:\n",
    "1.  `__iter__()`: Returns the iterator object itself (required for iterables)\n",
    "2.  `__next__()`: Returns the next value or raises `StopIteration` when exhausted\n",
    "\n",
    "```python\n",
    "from typing import Iterator, Iterable, Self\n",
    "\n",
    "class Countdown:\n",
    "    \"\"\"\n",
    "    Custom iterator counting down from start to 0.\n",
    "    \n",
    "    Demonstrates the iterator protocol explicitly.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, start: int) -> None:\n",
    "        if start < 0:\n",
    "            raise ValueError(\"Start must be non-negative\")\n",
    "        self.start: int = start\n",
    "        self.current: int = start\n",
    "    \n",
    "    def __iter__(self) -> Self:\n",
    "        \"\"\"\n",
    "        Return the iterator object itself.\n",
    "        \n",
    "        This makes the class both an iterable (has __iter__) \n",
    "        and an iterator (has __next__).\n",
    "        \"\"\"\n",
    "        self.current = self.start  # Reset for reuse\n",
    "        return self\n",
    "    \n",
    "    def __next__(self) -> int:\n",
    "        \"\"\"\n",
    "        Return next value or raise StopIteration.\n",
    "        \n",
    "        StopIteration signals to the for loop that iteration is complete.\n",
    "        \"\"\"\n",
    "        if self.current < 0:\n",
    "            raise StopIteration\n",
    "        \n",
    "        num: int = self.current\n",
    "        self.current -= 1\n",
    "        return num\n",
    "\n",
    "# Usage\n",
    "counter: Countdown = Countdown(5)\n",
    "\n",
    "# Manual iteration\n",
    "iterator: Iterator[int] = iter(counter)  # Calls __iter__\n",
    "print(next(iterator))  # 5 (calls __next__)\n",
    "print(next(iterator))  # 4\n",
    "print(next(iterator))  # 3\n",
    "\n",
    "# For loop iteration (automatic protocol)\n",
    "for num in Countdown(3):\n",
    "    print(num)  # 3, 2, 1, 0\n",
    "```\n",
    "\n",
    "**Key Insight:** The `for` loop is syntactic sugar for:\n",
    "```python\n",
    "iterator = iter(obj)  # Calls __iter__()\n",
    "while True:\n",
    "    try:\n",
    "        item = next(iterator)  # Calls __next__()\n",
    "    except StopIteration:\n",
    "        break\n",
    "    # Process item\n",
    "```\n",
    "\n",
    "### Iterable vs. Iterator\n",
    "\n",
    "Critical distinction:\n",
    "*   **Iterable**: Object with `__iter__()` method (can be looped over). Examples: `list`, `str`, `dict`, file objects.\n",
    "*   **Iterator**: Object with `__next__()` method (stateful, produces values on demand). Iterators are also iterables (they return themselves from `__iter__`).\n",
    "\n",
    "```python\n",
    "from typing import Iterable, Iterator\n",
    "\n",
    "# List is iterable but not an iterator\n",
    "numbers: list[int] = [1, 2, 3]\n",
    "print(hasattr(numbers, '__iter__'))  # True (iterable)\n",
    "print(hasattr(numbers, '__next__'))  # False (not iterator)\n",
    "\n",
    "# Getting iterator from iterable\n",
    "it: Iterator[int] = iter(numbers)  # Calls numbers.__iter__()\n",
    "print(hasattr(it, '__next__'))     # True (now it's an iterator)\n",
    "\n",
    "# Iterators are consumed (one-shot)\n",
    "print(list(it))  # [1, 2, 3]\n",
    "print(list(it))  # [] (exhausted, cannot rewind)\n",
    "```\n",
    "\n",
    "### Custom Iterables (Separating Iterable from Iterator)\n",
    "\n",
    "For complex iterators, separate the iterable (factory) from the iterator (state machine):\n",
    "\n",
    "```python\n",
    "from typing import Iterator, Optional\n",
    "import hashlib\n",
    "\n",
    "class FileLineIterable:\n",
    "    \"\"\"\n",
    "    Iterable that yields lines from a file matching a pattern.\n",
    "    \n",
    "    Iterable: Represents the collection/resource\n",
    "    Iterator: Maintains state during iteration\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filepath: str, pattern: str) -> None:\n",
    "        self.filepath: str = filepath\n",
    "        self.pattern: str = pattern\n",
    "    \n",
    "    def __iter__(self) -> 'FileLineIterator':\n",
    "        # Return fresh iterator each time\n",
    "        return FileLineIterator(self.filepath, self.pattern)\n",
    "\n",
    "class FileLineIterator:\n",
    "    \"\"\"Iterator with state (file handle, current position).\"\"\"\n",
    "    \n",
    "    def __init__(self, filepath: str, pattern: str) -> None:\n",
    "        self.filepath: str = filepath\n",
    "        self.pattern: str = pattern\n",
    "        self.file_handle: Optional[object] = None\n",
    "        self.line_number: int = 0\n",
    "    \n",
    "    def __iter__(self) -> Self:\n",
    "        return self\n",
    "    \n",
    "    def __next__(self) -> str:\n",
    "        if self.file_handle is None:\n",
    "            self.file_handle = open(self.filepath, 'r', encoding='utf-8')\n",
    "        \n",
    "        while True:\n",
    "            line: str = self.file_handle.readline()\n",
    "            self.line_number += 1\n",
    "            \n",
    "            if not line:  # EOF\n",
    "                self.file_handle.close()\n",
    "                self.file_handle = None\n",
    "                raise StopIteration\n",
    "            \n",
    "            if self.pattern in line:\n",
    "                return line.strip()\n",
    "\n",
    "# Usage - iterable can be reused, iterator maintains state\n",
    "log_lines: FileLineIterable = FileLineIterable(\"app.log\", \"ERROR\")\n",
    "\n",
    "# First iteration\n",
    "for line in log_lines:\n",
    "    print(f\"Found: {line}\")\n",
    "\n",
    "# Second iteration (fresh iterator created automatically)\n",
    "for line in log_lines:  # Works because __iter__ returns new iterator\n",
    "    print(f\"Found again: {line}\")\n",
    "```\n",
    "\n",
    "### The `collections.abc` Abstract Base Classes\n",
    "\n",
    "Use abstract base classes to properly type-check iterables:\n",
    "\n",
    "```python\n",
    "from collections.abc import Iterator, Iterable, Generator\n",
    "\n",
    "def process_stream(data: Iterable[int]) -> None:\n",
    "    \"\"\"\n",
    "    Accepts any iterable (list, tuple, generator, custom iterator).\n",
    "    \n",
    "    Using Iterable[int] indicates we only need to loop once.\n",
    "    \"\"\"\n",
    "    total: int = 0\n",
    "    for item in data:\n",
    "        total += item\n",
    "    print(f\"Total: {total}\")\n",
    "\n",
    "def get_stream() -> Iterator[int]:\n",
    "    \"\"\"\n",
    "    Returns iterator (stateful, single-pass).\n",
    "    \n",
    "    Using Iterator indicates this can only be consumed once.\n",
    "    \"\"\"\n",
    "    return iter([1, 2, 3])\n",
    "```\n",
    "\n",
    "## 11.2 Generators: Lazy Evaluation with yield\n",
    "\n",
    "**Generators** are a special type of iterator that simplify the iterator protocol using the `yield` keyword. They automatically implement `__iter__` and `__next__`, maintain local variable state between calls, and raise `StopIteration` automatically when the function returns.\n",
    "\n",
    "### Basic Generator Functions\n",
    "\n",
    "```python\n",
    "from typing import Generator\n",
    "\n",
    "def fibonacci(n: int) -> Generator[int, None, None]:\n",
    "    \"\"\"\n",
    "    Generate first n Fibonacci numbers.\n",
    "    \n",
    "    Generator function: contains yield, returns generator iterator.\n",
    "    Type hint: Generator[YieldType, SendType, ReturnType]\n",
    "    \"\"\"\n",
    "    a: int = 0\n",
    "    b: int = 1\n",
    "    count: int = 0\n",
    "    \n",
    "    while count < n:\n",
    "        yield a  # Suspends here, returns a to caller\n",
    "        # Resumes here on next iteration\n",
    "        a, b = b, a + b\n",
    "        count += 1\n",
    "    # Implicit StopIteration when function returns\n",
    "\n",
    "# Usage\n",
    "fib_gen: Generator[int, None, None] = fibonacci(10)\n",
    "\n",
    "# Convert to list (eager evaluation - consumes generator)\n",
    "numbers: list[int] = list(fibonacci(5))  # [0, 1, 1, 2, 3]\n",
    "\n",
    "# Lazy evaluation (memory efficient)\n",
    "for num in fibonacci(1000000):  # Doesn't store million numbers in memory\n",
    "    if num > 1000:\n",
    "        break\n",
    "    print(num)\n",
    "```\n",
    "\n",
    "**Generator Lifecycle:**\n",
    "1.  Calling `fibonacci(10)` returns a generator object (doesn't execute code yet)\n",
    "2.  Calling `next()` starts/resumes execution until `yield`\n",
    "3.  State (local variables `a`, `b`, `count`) is frozen between calls\n",
    "4.  When function returns (or raises), `StopIteration` is raised automatically\n",
    "\n",
    "### Generator State and Memory Efficiency\n",
    "\n",
    "Generators excel at processing large datasets that don't fit in memory:\n",
    "\n",
    "```python\n",
    "from typing import Generator\n",
    "import csv\n",
    "\n",
    "def read_large_csv(filepath: str) -> Generator[dict[str, str], None, None]:\n",
    "    \"\"\"\n",
    "    Lazily yield rows from a large CSV file.\n",
    "    \n",
    "    Memory usage remains constant regardless of file size.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r', newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            yield row  # Only one row in memory at a time\n",
    "\n",
    "# Process 10GB file with minimal memory\n",
    "for row in read_large_csv('huge_dataset.csv'):\n",
    "    if float(row['value']) > 1000:\n",
    "        process_row(row)\n",
    "```\n",
    "\n",
    "**Comparison:**\n",
    "*   **List approach**: `return [row for row in reader]` \u2192 Memory = size of entire file\n",
    "*   **Generator approach**: `yield row` \u2192 Memory = size of one row\n",
    "\n",
    "### Bidirectional Communication: send(), throw(), close()\n",
    "\n",
    "Generators can receive data from the caller, enabling coroutine-like behavior:\n",
    "\n",
    "```python\n",
    "from typing import Generator\n",
    "\n",
    "def running_average() -> Generator[float, float, None]:\n",
    "    \"\"\"\n",
    "    Generator that receives values and yields running average.\n",
    "    \n",
    "    Type: Generator[YieldType, SendType, ReturnType]\n",
    "    \"\"\"\n",
    "    total: float = 0.0\n",
    "    count: int = 0\n",
    "    average: float = 0.0\n",
    "    \n",
    "    while True:\n",
    "        # yield sends out current average, receives new value via send()\n",
    "        new_value: float = yield average\n",
    "        total += new_value\n",
    "        count += 1\n",
    "        average = total / count\n",
    "\n",
    "# Usage\n",
    "avg: Generator[float, float, None] = running_average()\n",
    "next(avg)  # Prime the generator (advance to first yield)\n",
    "\n",
    "print(avg.send(10))  # 10.0\n",
    "print(avg.send(20))  # 15.0\n",
    "print(avg.send(30))  # 20.0\n",
    "\n",
    "# Exception injection\n",
    "avg.throw(ValueError, \"Invalid input\")  # Can be caught inside generator\n",
    "\n",
    "# Cleanup\n",
    "avg.close()  # Raises GeneratorExit inside generator\n",
    "```\n",
    "\n",
    "**Practical Example: Stateful Logger**\n",
    "```python\n",
    "from typing import Generator\n",
    "from datetime import datetime\n",
    "\n",
    "def log_processor() -> Generator[None, str, None]:\n",
    "    \"\"\"Accumulate log messages and batch write.\"\"\"\n",
    "    buffer: list[str] = []\n",
    "    \n",
    "    while True:\n",
    "        message: str = yield\n",
    "        timestamp: str = datetime.now().isoformat()\n",
    "        buffer.append(f\"[{timestamp}] {message}\")\n",
    "        \n",
    "        if len(buffer) >= 10:\n",
    "            write_to_disk(buffer)\n",
    "            buffer.clear()\n",
    "\n",
    "logger = log_processor()\n",
    "next(logger)  # Prime\n",
    "\n",
    "logger.send(\"User logged in\")\n",
    "logger.send(\"Database connection established\")\n",
    "```\n",
    "\n",
    "### Delegation with yield from (Sub-generators)\n",
    "\n",
    "`yield from` delegates iteration to another iterable, transparently passing values and exceptions:\n",
    "\n",
    "```python\n",
    "from typing import Generator\n",
    "\n",
    "def sub_generator(start: int, end: int) -> Generator[int, None, None]:\n",
    "    \"\"\"Yield range of numbers.\"\"\"\n",
    "    for i in range(start, end):\n",
    "        yield i\n",
    "\n",
    "def main_generator() -> Generator[int, None, None]:\n",
    "    \"\"\"Delegate to sub-generators.\"\"\"\n",
    "    print(\"Phase 1\")\n",
    "    yield from sub_generator(1, 3)\n",
    "    \n",
    "    print(\"Phase 2\")\n",
    "    yield from sub_generator(10, 13)\n",
    "    \n",
    "    print(\"Done\")\n",
    "\n",
    "# Output: Phase 1, 1, 2, Phase 2, 10, 11, 12, Done\n",
    "for val in main_generator():\n",
    "    print(val)\n",
    "```\n",
    "\n",
    "**Benefits of `yield from`:**\n",
    "*   Eliminates boilerplate `for item in sub_gen: yield item`\n",
    "*   Propagates `send()` and `throw()` to sub-generator\n",
    "*   Returns value from sub-generator (Python 3.3+)\n",
    "\n",
    "```python\n",
    "def sub_gen() -> Generator[int, None, str]:\n",
    "    yield 1\n",
    "    yield 2\n",
    "    return \"Finished\"\n",
    "\n",
    "def main_gen() -> Generator[int, None, None]:\n",
    "    result: str = yield from sub_gen()\n",
    "    print(result)  # \"Finished\"\n",
    "    yield 3\n",
    "```\n",
    "\n",
    "## 11.3 Generator Expressions: Memory-Efficient Comprehensions\n",
    "\n",
    "**Generator expressions** provide a concise, memory-efficient way to create generators using syntax similar to list comprehensions but with parentheses instead of brackets.\n",
    "\n",
    "### Syntax and Behavior\n",
    "\n",
    "```python\n",
    "from typing import Generator\n",
    "import sys\n",
    "\n",
    "# List comprehension (eager, stores all values in memory)\n",
    "squares_list: list[int] = [x**2 for x in range(1000000)]\n",
    "print(f\"List size: {sys.getsizeof(squares_list)} bytes\")  # ~8MB\n",
    "\n",
    "# Generator expression (lazy, stores only iterator)\n",
    "squares_gen: Generator[int, None, None] = (x**2 for x in range(1000000))\n",
    "print(f\"Generator size: {sys.getsizeof(squares_gen)} bytes\")  # ~112 bytes\n",
    "\n",
    "# Generator expressions are single-use\n",
    "gen = (x for x in range(5))\n",
    "print(list(gen))  # [0, 1, 2, 3, 4]\n",
    "print(list(gen))  # [] (exhausted)\n",
    "```\n",
    "\n",
    "### Chaining Generators (Pipelines)\n",
    "\n",
    "Generator expressions excel at creating data processing pipelines without intermediate memory allocation:\n",
    "\n",
    "```python\n",
    "from typing import Generator\n",
    "import re\n",
    "\n",
    "def read_lines(filename: str) -> Generator[str, None, None]:\n",
    "    \"\"\"Yield lines from file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            yield line.strip()\n",
    "\n",
    "# Pipeline: File -> Filter -> Transform -> Aggregate\n",
    "# Without storing intermediate lists\n",
    "\n",
    "log_lines: Generator[str, None, None] = read_lines('server.log')\n",
    "\n",
    "# Filter: Only ERROR lines\n",
    "errors: Generator[str, None, None] = (line for line in log_lines if 'ERROR' in line)\n",
    "\n",
    "# Transform: Extract timestamp and message\n",
    "pattern = re.compile(r'(\\d{4}-\\d{2}-\\d{2}) (.*)')\n",
    "parsed: Generator[tuple[str, str], None, None] = (\n",
    "    (match.group(1), match.group(2)) \n",
    "    for line in errors \n",
    "    if (match := pattern.search(line))\n",
    ")\n",
    "\n",
    "# Execute pipeline (lazy evaluation happens here)\n",
    "for date, message in parsed:\n",
    "    print(f\"[{date}] {message}\")\n",
    "\n",
    "# Memory usage remains constant regardless of file size\n",
    "```\n",
    "\n",
    "**Performance Comparison:**\n",
    "```python\n",
    "# Approach 1: Nested lists (high memory, intermediate storage)\n",
    "result = [process(x) for x in [filter(y) for y in huge_list]]\n",
    "\n",
    "# Approach 2: Generator pipeline (low memory, streaming)\n",
    "result = (process(x) for x in (filter(y) for y in huge_list))\n",
    "```\n",
    "\n",
    "### When to Use What\n",
    "\n",
    "| Feature | Syntax | Memory | Use Case |\n",
    "|---------|--------|--------|----------|\n",
    "| List Comprehension | `[x for x in data]` | High (all data) | Need random access, multiple iterations, or len() |\n",
    "| Generator Expression | `(x for x in data)` | Low (iterator) | Single pass, large datasets, pipelining |\n",
    "| Generator Function | `def gen(): yield x` | Low (iterator) | Complex logic, stateful iteration, reuse |\n",
    "\n",
    "**Best Practice:** Use generator expressions for simple transformations, generator functions for complex logic requiring multiple statements.\n",
    "\n",
    "## 11.4 Decorators: Modifying Function Behavior\n",
    "\n",
    "**Decorators** are functions that take another function or class as input, extend or alter its behavior, and return a modified function. They enable separation of cross-cutting concerns (logging, authentication, caching) from business logic.\n",
    "\n",
    "### Function Decorators Fundamentals\n",
    "\n",
    "```python\n",
    "from typing import Callable, Any\n",
    "from functools import wraps\n",
    "import time\n",
    "\n",
    "def timer_decorator(func: Callable[..., Any]) -> Callable[..., Any]:\n",
    "    \"\"\"\n",
    "    Decorator that measures function execution time.\n",
    "    \n",
    "    Args:\n",
    "        func: The function to be decorated\n",
    "        \n",
    "    Returns:\n",
    "        Wrapped function with timing logic\n",
    "    \"\"\"\n",
    "    @wraps(func)  # Preserves metadata (__name__, __doc__)\n",
    "    def wrapper(*args: Any, **kwargs: Any) -> Any:\n",
    "        start_time: float = time.time()\n",
    "        result: Any = func(*args, **kwargs)\n",
    "        end_time: float = time.time()\n",
    "        print(f\"{func.__name__} executed in {end_time - start_time:.4f}s\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Application using @ syntax (syntactic sugar)\n",
    "@timer_decorator\n",
    "def slow_function(n: int) -> int:\n",
    "    \"\"\"Calculate sum of range (simulated slow operation).\"\"\"\n",
    "    time.sleep(0.1)\n",
    "    return sum(range(n))\n",
    "\n",
    "# Equivalent to: slow_function = timer_decorator(slow_function)\n",
    "\n",
    "result: int = slow_function(100000)  # Prints timing info\n",
    "```\n",
    "\n",
    "**Without `@wraps`:**\n",
    "*   `slow_function.__name__` becomes \"wrapper\"\n",
    "*   `slow_function.__doc__` becomes None\n",
    "*   Introspection breaks\n",
    "\n",
    "**With `@wraps(func)`:**\n",
    "*   Metadata is copied from original function to wrapper\n",
    "*   Debugging and documentation remain intact\n",
    "\n",
    "### Decorators with Arguments (Decorator Factories)\n",
    "\n",
    "To accept arguments, create a decorator factory that returns the actual decorator:\n",
    "\n",
    "```python\n",
    "from typing import Callable, Any\n",
    "from functools import wraps\n",
    "\n",
    "def retry(max_attempts: int = 3, delay: float = 1.0) -> Callable:\n",
    "    \"\"\"\n",
    "    Decorator factory that creates retry logic.\n",
    "    \n",
    "    Args:\n",
    "        max_attempts: Maximum number of retry attempts\n",
    "        delay: Seconds to wait between retries\n",
    "    \"\"\"\n",
    "    def decorator(func: Callable[..., Any]) -> Callable[..., Any]:\n",
    "        @wraps(func)\n",
    "        def wrapper(*args: Any, **kwargs: Any) -> Any:\n",
    "            attempts: int = 0\n",
    "            while attempts < max_attempts:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    attempts += 1\n",
    "                    if attempts == max_attempts:\n",
    "                        raise\n",
    "                    print(f\"Attempt {attempts} failed: {e}. Retrying...\")\n",
    "                    time.sleep(delay)\n",
    "            return None  # Unreachable but satisfies type checker\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# Usage with arguments\n",
    "@retry(max_attempts=5, delay=2.0)\n",
    "def unreliable_api_call() -> dict:\n",
    "    \"\"\"Simulate flaky API.\"\"\"\n",
    "    if random.random() < 0.7:\n",
    "        raise ConnectionError(\"Network timeout\")\n",
    "    return {\"status\": \"success\"}\n",
    "\n",
    "# Equivalent to: unreliable_api_call = retry(max_attempts=5)(unreliable_api_call)\n",
    "```\n",
    "\n",
    "### Preserving Function Signatures with inspect\n",
    "\n",
    "For type-safe decorators that preserve exact signatures:\n",
    "\n",
    "```python\n",
    "from typing import TypeVar, ParamSpec\n",
    "from functools import wraps\n",
    "import logging\n",
    "\n",
    "P = ParamSpec('P')  # Captures parameter specification\n",
    "R = TypeVar('R')    # Captures return type\n",
    "\n",
    "def log_call(func: Callable[P, R]) -> Callable[P, R]:\n",
    "    \"\"\"\n",
    "    Type-safe decorator preserving function signature.\n",
    "    \n",
    "    Uses ParamSpec (Python 3.10+) to maintain parameter types.\n",
    "    \"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:\n",
    "        logging.info(f\"Calling {func.__name__} with args={args}, kwargs={kwargs}\")\n",
    "        result: R = func(*args, **kwargs)\n",
    "        logging.info(f\"{func.__name__} returned {result}\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@log_call\n",
    "def add(x: int, y: int) -> int:\n",
    "    return x + y\n",
    "\n",
    "# Type checker knows: add(x: int, y: int) -> int\n",
    "reveal_type(add)  # Revealed type is \"def (x: int, y: int) -> int\"\n",
    "```\n",
    "\n",
    "### Class Decorators\n",
    "\n",
    "Decorators can also modify classes, adding methods, registering subclasses, or enforcing invariants:\n",
    "\n",
    "```python\n",
    "from typing import Type, TypeVar, Callable\n",
    "import json\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def auto_repr(cls: Type[T]) -> Type[T]:\n",
    "    \"\"\"\n",
    "    Class decorator that automatically adds __repr__ method.\n",
    "    \n",
    "    Generates representation showing class name and attributes.\n",
    "    \"\"\"\n",
    "    def __repr__(self: T) -> str:\n",
    "        attributes: str = ', '.join(\n",
    "            f\"{k}={v!r}\" \n",
    "            for k, v in self.__dict__.items() \n",
    "            if not k.startswith('_')\n",
    "        )\n",
    "        return f\"{self.__class__.__name__}({attributes})\"\n",
    "    \n",
    "    cls.__repr__ = __repr__\n",
    "    return cls\n",
    "\n",
    "def json_serializable(cls: Type[T]) -> Type[T]:\n",
    "    \"\"\"\n",
    "    Add to_json method to class.\n",
    "    \"\"\"\n",
    "    def to_json(self: T) -> str:\n",
    "        return json.dumps(self.__dict__, default=str)\n",
    "    \n",
    "    cls.to_json = to_json\n",
    "    return cls\n",
    "\n",
    "@auto_repr\n",
    "@json_serializable\n",
    "class User:\n",
    "    def __init__(self, name: str, email: str) -> None:\n",
    "        self.name: str = name\n",
    "        self.email: str = email\n",
    "\n",
    "user = User(\"Alice\", \"alice@example.com\")\n",
    "print(user)  # User(name='Alice', email='alice@example.com')\n",
    "print(user.to_json())  # {\"name\": \"Alice\", \"email\": \"alice@example.com\"}\n",
    "```\n",
    "\n",
    "### Stacking Decorators\n",
    "\n",
    "Multiple decorators are applied bottom-up (closest to function first):\n",
    "\n",
    "```python\n",
    "@decorator_a\n",
    "@decorator_b\n",
    "@decorator_c\n",
    "def func():\n",
    "    pass\n",
    "\n",
    "# Equivalent to: func = decorator_a(decorator_b(decorator_c(func)))\n",
    "```\n",
    "\n",
    "**Execution Order:**\n",
    "1.  `decorator_c` wraps original function\n",
    "2.  `decorator_b` wraps result of step 1\n",
    "3.  `decorator_a` wraps result of step 2\n",
    "4.  When called: `decorator_a` logic runs first (outer), then `decorator_b`, then `decorator_c`, then original function, then unwinds back up\n",
    "\n",
    "### Practical Decorator Patterns\n",
    "\n",
    "**1. Caching/Memoization:**\n",
    "```python\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def fibonacci(n: int) -> int:\n",
    "    \"\"\"LRU cache decorator stores recent results.\"\"\"\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "# First call: computed\n",
    "# Subsequent calls with same n: returned from cache\n",
    "```\n",
    "\n",
    "**2. Access Control:**\n",
    "```python\n",
    "from typing import Callable\n",
    "from functools import wraps\n",
    "\n",
    "def require_auth(func: Callable) -> Callable:\n",
    "    \"\"\"Decorator ensuring user is authenticated.\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        if not getattr(self, 'is_authenticated', False):\n",
    "            raise PermissionError(\"Authentication required\")\n",
    "        return func(self, *args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "class AdminPanel:\n",
    "    @require_auth\n",
    "    def delete_user(self, user_id: int) -> None:\n",
    "        \"\"\"Protected method.\"\"\"\n",
    "        pass\n",
    "```\n",
    "\n",
    "**3. Rate Limiting:**\n",
    "```python\n",
    "import time\n",
    "from collections import deque\n",
    "from typing import Callable\n",
    "\n",
    "def rate_limit(max_calls: int, period: int) -> Callable:\n",
    "    \"\"\"Limit function calls to max_calls per period seconds.\"\"\"\n",
    "    def decorator(func: Callable) -> Callable:\n",
    "        calls: deque[float] = deque()\n",
    "        \n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            now: float = time.time()\n",
    "            \n",
    "            # Remove calls outside the time window\n",
    "            while calls and now - calls[0] > period:\n",
    "                calls.popleft()\n",
    "            \n",
    "            if len(calls) >= max_calls:\n",
    "                raise RuntimeError(f\"Rate limit exceeded: {max_calls} calls per {period}s\")\n",
    "            \n",
    "            calls.append(now)\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@rate_limit(max_calls=5, period=60)\n",
    "def api_request() -> dict:\n",
    "    \"\"\"Limited to 5 calls per minute.\"\"\"\n",
    "    return fetch_data()\n",
    "```\n",
    "\n",
    "## Summary\n",
    "\n",
    "Advanced Python features enable you to write code that is both efficient and elegant. You have mastered the **iterator protocol** (`__iter__` and `__next__`), understanding how Python's `for` loops work under the hood and how to create custom data streams. **Generators** and **generator expressions** provide memory-efficient lazy evaluation, allowing you to process infinite or massive datasets with constant memory usage while maintaining clean, imperative syntax through `yield`.\n",
    "\n",
    "You have explored bidirectional generator communication with `send()` and sub-generator delegation with `yield from`. **Decorators** allow you to extract cross-cutting concerns\u2014logging, retry logic, caching, authentication\u2014into reusable, composable components that modify function behavior without altering source code. Using `functools.wraps` and `ParamSpec`, you ensure decorators preserve function metadata and type signatures.\n",
    "\n",
    "These patterns separate *what* code does from *how* it does it, creating systems that are modular, testable, and resource-efficient. However, data processing requires persistence. In the next chapter, we explore Python's facilities for interacting with the file system, handling various data formats, and ensuring resources are properly managed through context managers.\n",
    "\n",
    "**Next Chapter**: Chapter 12: File I/O and Data Persistence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='../4. professional_development_practices/10. testing_and_quality_assurance.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='12. file_io_and_data_persistence.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}