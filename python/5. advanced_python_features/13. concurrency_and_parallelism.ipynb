{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13: Concurrency and Parallelism\n",
    "\n",
    "Modern applications must handle multiple tasks simultaneously—serving thousands of web clients, processing large datasets, or maintaining responsive UIs during intensive operations. Python offers three distinct concurrency models: **threading** for I/O-bound concurrency, **multiprocessing** for CPU-bound parallelism, and **asyncio** for high-performance asynchronous I/O. Understanding when and how to apply each is essential for building scalable systems.\n",
    "\n",
    "This chapter examines the Global Interpreter Lock (GIL) that shapes Python's concurrency landscape, thread safety and synchronization primitives, process-based parallelism that bypasses the GIL, and the async/await syntax for cooperative multitasking. We emphasize the critical distinction between I/O-bound and CPU-bound workloads, providing decision frameworks for selecting the appropriate concurrency model.\n",
    "\n",
    "## 13.1 Understanding Concurrency vs. Parallelism\n",
    "\n",
    "Before implementing concurrent code, understand the fundamental distinction:\n",
    "\n",
    "**Concurrency** (Threading/Asyncio): Handling multiple tasks by interleaving execution. Tasks make progress within the same time period but not necessarily simultaneously. Ideal for I/O-bound operations (network requests, disk I/O) where the program waits for external resources.\n",
    "\n",
    "**Parallelism** (Multiprocessing): Executing multiple tasks simultaneously on multiple CPU cores. Tasks truly run at the same time. Required for CPU-bound operations (heavy computation, data processing) that fully utilize processor cycles.\n",
    "\n",
    "```python\n",
    "import time\n",
    "import threading\n",
    "import multiprocessing\n",
    "from typing import Callable\n",
    "import requests\n",
    "\n",
    "def io_bound_task(url: str) -> None:\n",
    "    \"\"\"\n",
    "    I/O-bound: Most time spent waiting for network.\n",
    "    CPU usage is low during execution.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    print(f\"Fetched {len(response.content)} bytes\")\n",
    "\n",
    "def cpu_bound_task(n: int) -> int:\n",
    "    \"\"\"\n",
    "    CPU-bound: Constant computation, no waiting.\n",
    "    CPU usage is 100% during execution.\n",
    "    \"\"\"\n",
    "    count: int = 0\n",
    "    for i in range(n):\n",
    "        count += i ** 2\n",
    "    return count\n",
    "```\n",
    "\n",
    "**The Global Interpreter Lock (GIL):**\n",
    "CPython's memory management isn't thread-safe. The GIL is a mutex that prevents multiple threads from executing Python bytecode simultaneously. This means:\n",
    "*   **Threading**: Only one thread executes Python code at a time (but threads can wait for I/O simultaneously)\n",
    "*   **Multiprocessing**: Each process has its own Python interpreter and GIL, enabling true parallelism\n",
    "\n",
    "## 13.2 Threading: Concurrent I/O Operations\n",
    "\n",
    "The `threading` module provides threads that share memory space but are limited by the GIL. Despite the GIL, threading excels for I/O-bound tasks because threads release the GIL when waiting for I/O operations.\n",
    "\n",
    "### Basic Thread Creation\n",
    "\n",
    "```python\n",
    "import threading\n",
    "from typing import List\n",
    "import time\n",
    "\n",
    "def download_file(file_id: int) -> None:\n",
    "    \"\"\"Simulate downloading a file.\"\"\"\n",
    "    print(f\"[Thread {threading.current_thread().name}] Starting download {file_id}\")\n",
    "    time.sleep(1)  # Simulating network I/O\n",
    "    print(f\"[Thread {threading.current_thread().name}] Finished download {file_id}\")\n",
    "\n",
    "def basic_threading() -> None:\n",
    "    \"\"\"Create and manage threads manually.\"\"\"\n",
    "    threads: List[threading.Thread] = []\n",
    "    \n",
    "    # Create 5 threads\n",
    "    for i in range(5):\n",
    "        thread = threading.Thread(\n",
    "            target=download_file,\n",
    "            args=(i,),\n",
    "            name=f\"Worker-{i}\"\n",
    "        )\n",
    "        threads.append(thread)\n",
    "        thread.start()  # Begin thread execution\n",
    "    \n",
    "    # Wait for all threads to complete\n",
    "    for thread in threads:\n",
    "        thread.join()  # Block until thread finishes\n",
    "    \n",
    "    print(\"All downloads complete\")\n",
    "\n",
    "# Timing: Sequential would take 5 seconds\n",
    "# Threading takes ~1 second (limited by slowest download)\n",
    "```\n",
    "\n",
    "### Thread Safety and Race Conditions\n",
    "\n",
    "When multiple threads access shared data, race conditions occur:\n",
    "\n",
    "```python\n",
    "import threading\n",
    "from typing import List\n",
    "\n",
    "class UnsafeCounter:\n",
    "    \"\"\"Demonstrates race condition - not thread-safe.\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        self.value: int = 0\n",
    "    \n",
    "    def increment(self) -> None:\n",
    "        \"\"\"Read-modify-write operation is not atomic.\"\"\"\n",
    "        current = self.value      # Read\n",
    "        time.sleep(0.000001)      # Simulate processing (context switch happens here)\n",
    "        self.value = current + 1  # Write\n",
    "\n",
    "def demonstrate_race_condition() -> None:\n",
    "    \"\"\"Show data corruption without synchronization.\"\"\"\n",
    "    counter = UnsafeCounter()\n",
    "    threads: List[threading.Thread] = []\n",
    "    \n",
    "    def worker() -> None:\n",
    "        for _ in range(1000):\n",
    "            counter.increment()\n",
    "    \n",
    "    # Create 10 threads\n",
    "    for _ in range(10):\n",
    "        t = threading.Thread(target=worker)\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "    \n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    \n",
    "    # Expected: 10000, Actual: Less (due to lost updates)\n",
    "    print(f\"Final count: {counter.value}\")  # Likely < 10000\n",
    "```\n",
    "\n",
    "### Synchronization Primitives\n",
    "\n",
    "Protect shared data with locks and other synchronization tools:\n",
    "\n",
    "```python\n",
    "import threading\n",
    "from typing import Optional\n",
    "import time\n",
    "\n",
    "class SafeCounter:\n",
    "    \"\"\"Thread-safe counter using Lock.\"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        self.value: int = 0\n",
    "        self._lock: threading.Lock = threading.Lock()\n",
    "    \n",
    "    def increment(self) -> None:\n",
    "        \"\"\"Atomic increment with explicit lock.\"\"\"\n",
    "        with self._lock:  # Acquires lock, releases automatically\n",
    "            self.value += 1\n",
    "    \n",
    "    def get_value(self) -> int:\n",
    "        with self._lock:\n",
    "            return self.value\n",
    "\n",
    "# Alternative: Using RLock (reentrant, same thread can acquire multiple times)\n",
    "class ReentrantExample:\n",
    "    def __init__(self) -> None:\n",
    "        self._lock: threading.RLock = threading.RLock()\n",
    "        self.data: dict = {}\n",
    "    \n",
    "    def process(self) -> None:\n",
    "        with self._lock:\n",
    "            self.modify()\n",
    "    \n",
    "    def modify(self) -> None:\n",
    "        with self._lock:  # Would deadlock with regular Lock\n",
    "            self.data['key'] = 'value'\n",
    "\n",
    "# Semaphore: Limit concurrent access (e.g., connection pools)\n",
    "class ConnectionPool:\n",
    "    def __init__(self, max_connections: int = 5) -> None:\n",
    "        self._semaphore: threading.Semaphore = threading.Semaphore(max_connections)\n",
    "        self._connections: List[object] = []\n",
    "    \n",
    "    def acquire_connection(self) -> Optional[object]:\n",
    "        \"\"\"Block if max connections reached.\"\"\"\n",
    "        if self._semaphore.acquire(timeout=5):  # Wait max 5 seconds\n",
    "            # Return connection from pool\n",
    "            return object()  # Placeholder\n",
    "        return None\n",
    "\n",
    "# Event: One-shot signaling between threads\n",
    "def wait_for_event() -> None:\n",
    "    event: threading.Event = threading.Event()\n",
    "    \n",
    "    def waiter() -> None:\n",
    "        print(\"Waiting for event...\")\n",
    "        event.wait()  # Blocks until set()\n",
    "        print(\"Event received!\")\n",
    "    \n",
    "    def setter() -> None:\n",
    "        time.sleep(2)\n",
    "        print(\"Setting event\")\n",
    "        event.set()\n",
    "    \n",
    "    threading.Thread(target=waiter).start()\n",
    "    threading.Thread(target=setter).start()\n",
    "\n",
    "# Condition: Complex coordination (producer-consumer pattern)\n",
    "class ThreadSafeQueue:\n",
    "    def __init__(self, max_size: int = 10) -> None:\n",
    "        self._queue: List[int] = []\n",
    "        self._condition: threading.Condition = threading.Condition()\n",
    "        self._max_size: int = max_size\n",
    "    \n",
    "    def put(self, item: int) -> None:\n",
    "        with self._condition:\n",
    "            while len(self._queue) >= self._max_size:\n",
    "                self._condition.wait()  # Wait until space available\n",
    "            self._queue.append(item)\n",
    "            self._condition.notify_all()  # Notify consumers\n",
    "    \n",
    "    def get(self) -> int:\n",
    "        with self._condition:\n",
    "            while not self._queue:\n",
    "                self._condition.wait()  # Wait until items available\n",
    "            item = self._queue.pop(0)\n",
    "            self._condition.notify_all()  # Notify producers\n",
    "            return item\n",
    "```\n",
    "\n",
    "### Thread-Local Storage\n",
    "\n",
    "Each thread needs its own isolated data:\n",
    "\n",
    "```python\n",
    "import threading\n",
    "from typing import Any\n",
    "\n",
    "# Thread-local storage\n",
    "thread_local: threading.local = threading.local()\n",
    "\n",
    "def process_request(request_id: int) -> None:\n",
    "    \"\"\"Each thread has its own request_id.\"\"\"\n",
    "    thread_local.request_id = request_id\n",
    "    thread_local.db_connection = create_connection()\n",
    "    \n",
    "    # Process...\n",
    "    print(f\"Thread {threading.current_thread().name} handling request {thread_local.request_id}\")\n",
    "    \n",
    "    # Clean up\n",
    "    thread_local.db_connection.close()\n",
    "\n",
    "def create_connection() -> Any:\n",
    "    return object()\n",
    "```\n",
    "\n",
    "### ThreadPoolExecutor: High-Level Interface\n",
    "\n",
    "For most threading needs, use the high-level executor API:\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import List, Dict\n",
    "import requests\n",
    "\n",
    "def fetch_url(url: str) -> Dict[str, Any]:\n",
    "    \"\"\"Fetch single URL.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        return {'url': url, 'status': response.status_code, 'size': len(response.content)}\n",
    "    except Exception as e:\n",
    "        return {'url': url, 'error': str(e)}\n",
    "\n",
    "def concurrent_downloads(urls: List[str], max_workers: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Download multiple URLs concurrently using thread pool.\n",
    "    \n",
    "    Args:\n",
    "        urls: List of URLs to fetch\n",
    "        max_workers: Maximum concurrent threads\n",
    "        \n",
    "    Returns:\n",
    "        Results as they complete\n",
    "    \"\"\"\n",
    "    results: List[Dict] = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_url: Dict[Future, str] = {\n",
    "            executor.submit(fetch_url, url): url \n",
    "            for url in urls\n",
    "        }\n",
    "        \n",
    "        # Process results as they complete\n",
    "        for future in as_completed(future_to_url):\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "                results.append(data)\n",
    "            except Exception as exc:\n",
    "                print(f\"{url} generated exception: {exc}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Usage\n",
    "urls = ['https://api.example.com/data'] * 20\n",
    "results = concurrent_downloads(urls, max_workers=10)\n",
    "```\n",
    "\n",
    "## 13.3 Multiprocessing: True Parallelism\n",
    "\n",
    "The `multiprocessing` module creates separate processes with their own memory space and Python interpreter, bypassing the GIL for CPU-bound tasks.\n",
    "\n",
    "### Process Creation\n",
    "\n",
    "```python\n",
    "import multiprocessing as mp\n",
    "from typing import List\n",
    "import time\n",
    "import os\n",
    "\n",
    "def cpu_intensive_task(n: int) -> int:\n",
    "    \"\"\"\n",
    "    Heavy computation that fully utilizes CPU.\n",
    "    Runs in separate process with its own GIL.\n",
    "    \"\"\"\n",
    "    print(f\"Process {os.getpid()} handling task {n}\")\n",
    "    total: int = 0\n",
    "    for i in range(n):\n",
    "        total += i ** 2\n",
    "    return total\n",
    "\n",
    "def basic_multiprocessing() -> None:\n",
    "    \"\"\"Create processes manually.\"\"\"\n",
    "    processes: List[mp.Process] = []\n",
    "    \n",
    "    for i in range(4):\n",
    "        # Args must be pickleable (sent to new process)\n",
    "        p = mp.Process(target=cpu_intensive_task, args=(1000000,))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "    \n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    print(\"All processes complete\")\n",
    "\n",
    "# Safety check required on Windows/macOS\n",
    "if __name__ == '__main__':\n",
    "    basic_multiprocessing()\n",
    "```\n",
    "\n",
    "### Sharing Data Between Processes\n",
    "\n",
    "Processes don't share memory by default. Use explicit shared memory or managers:\n",
    "\n",
    "```python\n",
    "import multiprocessing as mp\n",
    "from typing import List\n",
    "\n",
    "def shared_memory_example() -> None:\n",
    "    \"\"\"Share data using Value and Array (shared memory).\"\"\"\n",
    "    # Shared value (synchronized with lock)\n",
    "    counter: mp.Value = mp.Value('i', 0)  # 'i' = signed int\n",
    "    \n",
    "    # Shared array\n",
    "    shared_array: mp.Array = mp.Array('d', [0.0, 0.0, 0.0])  # 'd' = double\n",
    "    \n",
    "    def worker(counter: mp.Value, arr: mp.Array, index: int) -> None:\n",
    "        \"\"\"Modify shared memory.\"\"\"\n",
    "        with counter.get_lock():  # Acquire lock\n",
    "            counter.value += 1\n",
    "        \n",
    "        arr[index] = index * 2.0\n",
    "    \n",
    "    processes: List[mp.Process] = []\n",
    "    for i in range(3):\n",
    "        p = mp.Process(target=worker, args=(counter, shared_array, i))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "    \n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    print(f\"Counter: {counter.value}\")  # 3\n",
    "    print(f\"Array: {list(shared_array)}\")  # [0.0, 2.0, 4.0]\n",
    "\n",
    "def queue_communication() -> None:\n",
    "    \"\"\"Use Queue for process-safe communication.\"\"\"\n",
    "    def producer(queue: mp.Queue) -> None:\n",
    "        for i in range(5):\n",
    "            queue.put(f\"Message {i}\")\n",
    "            time.sleep(0.1)\n",
    "        queue.put(None)  # Sentinel value\n",
    "    \n",
    "    def consumer(queue: mp.Queue) -> None:\n",
    "        while True:\n",
    "            item = queue.get()\n",
    "            if item is None:\n",
    "                break\n",
    "            print(f\"Consumed: {item}\")\n",
    "    \n",
    "    queue: mp.Queue = mp.Queue()\n",
    "    \n",
    "    p1 = mp.Process(target=producer, args=(queue,))\n",
    "    p2 = mp.Process(target=consumer, args=(queue,))\n",
    "    \n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "```\n",
    "\n",
    "### ProcessPoolExecutor\n",
    "\n",
    "Like ThreadPoolExecutor but for processes:\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing as mp\n",
    "\n",
    "def parallel_map(data: List[int], func: Callable[[int], int]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Map function over data using process pool.\n",
    "    \n",
    "    Automatically distributes work across CPU cores.\n",
    "    \"\"\"\n",
    "    # Default: uses os.cpu_count() processes\n",
    "    with ProcessPoolExecutor(max_workers=mp.cpu_count()) as executor:\n",
    "        # executor.map preserves order\n",
    "        results: List[int] = list(executor.map(func, data))\n",
    "        \n",
    "        # Or submit individual tasks\n",
    "        futures = [executor.submit(func, x) for x in data]\n",
    "        results = [f.result() for f in futures]\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Usage\n",
    "if __name__ == '__main__':\n",
    "    data = range(100)\n",
    "    results = parallel_map(data, cpu_intensive_task)\n",
    "```\n",
    "\n",
    "## 13.4 Asyncio: Asynchronous Programming\n",
    "\n",
    "`asyncio` provides single-threaded concurrent I/O using an event loop and cooperative multitasking. It's ideal for high-concurrency network operations (thousands of simultaneous connections).\n",
    "\n",
    "### Core Concepts\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "from typing import Coroutine, List\n",
    "\n",
    "async def fetch_data(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Coroutine: async function that can suspend execution.\n",
    "    \n",
    "    When awaiting, control returns to event loop to run other tasks.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching {url}\")\n",
    "    await asyncio.sleep(1)  # Non-blocking sleep (yields control)\n",
    "    return f\"Data from {url}\"\n",
    "\n",
    "async def main() -> None:\n",
    "    \"\"\"Entry point for asyncio program.\"\"\"\n",
    "    # Await single coroutine\n",
    "    result = await fetch_data(\"https://api.example.com\")\n",
    "    \n",
    "    # Run multiple concurrently\n",
    "    urls = [\"url1\", \"url2\", \"url3\"]\n",
    "    tasks: List[Coroutine] = [fetch_data(url) for url in urls]\n",
    "    \n",
    "    # asyncio.gather runs them concurrently\n",
    "    results: List[str] = await asyncio.gather(*tasks)\n",
    "    print(results)\n",
    "\n",
    "# Run the event loop\n",
    "if __name__ == '__main__':\n",
    "    asyncio.run(main())  # Python 3.7+\n",
    "```\n",
    "\n",
    "### Event Loop Mechanics\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "def event_loop_example() -> None:\n",
    "    \"\"\"Manual event loop control (rarely needed in modern Python).\"\"\"\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    \n",
    "    try:\n",
    "        result = loop.run_until_complete(fetch_data(\"test\"))\n",
    "        print(result)\n",
    "    finally:\n",
    "        loop.close()\n",
    "```\n",
    "\n",
    "### Task Management\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "from typing import Set\n",
    "\n",
    "async def task_management() -> None:\n",
    "    \"\"\"Create and manage tasks explicitly.\"\"\"\n",
    "    # Create task (scheduled immediately)\n",
    "    task1 = asyncio.create_task(fetch_data(\"api1.com\"))\n",
    "    task2 = asyncio.create_task(fetch_data(\"api2.com\"))\n",
    "    \n",
    "    # Wait for specific task\n",
    "    result = await task1\n",
    "    \n",
    "    # Wait with timeout\n",
    "    try:\n",
    "        result = await asyncio.wait_for(task2, timeout=5.0)\n",
    "    except asyncio.TimeoutError:\n",
    "        print(\"Task timed out\")\n",
    "    \n",
    "    # Wait for multiple with return_when options\n",
    "    pending: Set[asyncio.Task] = {\n",
    "        asyncio.create_task(fetch_data(f\"api{i}.com\")) \n",
    "        for i in range(10)\n",
    "    }\n",
    "    \n",
    "    while pending:\n",
    "        done, pending = await asyncio.wait(\n",
    "            pending,\n",
    "            return_when=asyncio.FIRST_COMPLETED  # Or ALL_COMPLETED\n",
    "        )\n",
    "        for task in done:\n",
    "            print(f\"Completed: {task.result()}\")\n",
    "\n",
    "async def cancellation() -> None:\n",
    "    \"\"\"Cancel running tasks.\"\"\"\n",
    "    task = asyncio.create_task(asyncio.sleep(10))\n",
    "    await asyncio.sleep(1)\n",
    "    \n",
    "    task.cancel()\n",
    "    try:\n",
    "        await task\n",
    "    except asyncio.CancelledError:\n",
    "        print(\"Task was cancelled\")\n",
    "```\n",
    "\n",
    "### Real-World Asyncio: aiohttp Example\n",
    "\n",
    "```python\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from typing import List\n",
    "\n",
    "async def fetch_session(\n",
    "    session: aiohttp.ClientSession, \n",
    "    url: str\n",
    ") -> dict:\n",
    "    \"\"\"Fetch using aiohttp (async HTTP client).\"\"\"\n",
    "    async with session.get(url) as response:\n",
    "        return {\n",
    "            'url': url,\n",
    "            'status': response.status,\n",
    "            'content': await response.text()\n",
    "        }\n",
    "\n",
    "async def fetch_all(urls: List[str]) -> List[dict]:\n",
    "    \"\"\"Fetch all URLs concurrently.\"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_session(session, url) for url in urls]\n",
    "        return await asyncio.gather(*tasks)\n",
    "\n",
    "# Usage: Fetch 100 URLs concurrently in single thread\n",
    "urls = ['https://example.com'] * 100\n",
    "results = asyncio.run(fetch_all(urls))\n",
    "```\n",
    "\n",
    "### Async Context Managers and Iterators\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "from typing import AsyncIterator\n",
    "\n",
    "class AsyncDatabaseConnection:\n",
    "    \"\"\"Async context manager.\"\"\"\n",
    "    async def __aenter__(self) -> 'AsyncDatabaseConnection':\n",
    "        await self.connect()\n",
    "        return self\n",
    "    \n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:\n",
    "        await self.disconnect()\n",
    "    \n",
    "    async def connect(self) -> None:\n",
    "        await asyncio.sleep(0.1)  # Simulated async operation\n",
    "    \n",
    "    async def disconnect(self) -> None:\n",
    "        await asyncio.sleep(0.1)\n",
    "\n",
    "async def use_connection() -> None:\n",
    "    async with AsyncDatabaseConnection() as conn:\n",
    "        print(\"Using connection\")\n",
    "\n",
    "class AsyncRange:\n",
    "    \"\"\"Async iterator.\"\"\"\n",
    "    def __init__(self, start: int, end: int) -> None:\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.current = start\n",
    "    \n",
    "    def __aiter__(self) -> AsyncIterator[int]:\n",
    "        return self\n",
    "    \n",
    "    async def __anext__(self) -> int:\n",
    "        if self.current >= self.end:\n",
    "            raise StopAsyncIteration\n",
    "        await asyncio.sleep(0.01)  # Simulated async work\n",
    "        value = self.current\n",
    "        self.current += 1\n",
    "        return value\n",
    "\n",
    "async def iterate_async() -> None:\n",
    "    async for i in AsyncRange(0, 5):\n",
    "        print(i)\n",
    "```\n",
    "\n",
    "## 13.5 Choosing the Right Concurrency Model\n",
    "\n",
    "| Scenario | Solution | Reason |\n",
    "|----------|----------|--------|\n",
    "| Multiple I/O operations (HTTP, DB) | **Asyncio** | Thousands of concurrent connections, single-threaded |\n",
    "| Few I/O operations, existing sync code | **Threading** | Simple, works with blocking libraries |\n",
    "| CPU-intensive (math, data processing) | **Multiprocessing** | Bypasses GIL, uses multiple cores |\n",
    "| Mixed I/O and CPU | **Asyncio + ProcessPoolExecutor** | Async for I/O, processes for CPU |\n",
    "| Simple parallel tasks | **concurrent.futures** | High-level, easy to use |\n",
    "\n",
    "### Decision Flowchart\n",
    "\n",
    "```\n",
    "Is it I/O bound (waiting for network/disk)?\n",
    "├── Yes: Is it many connections (1000s)?\n",
    "│   ├── Yes: Use Asyncio\n",
    "│   └── No: Use Threading\n",
    "└── No (CPU bound): Use Multiprocessing\n",
    "```\n",
    "\n",
    "### Combining Approaches\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing as mp\n",
    "\n",
    "async def hybrid_approach() -> None:\n",
    "    \"\"\"\n",
    "    Use asyncio for I/O, process pool for CPU work.\n",
    "    \n",
    "    Example: Web server that handles requests (asyncio)\n",
    "    but offloads image processing to processes.\n",
    "    \"\"\"\n",
    "    loop = asyncio.get_running_loop()\n",
    "    \n",
    "    # Run CPU-bound function in process pool\n",
    "    with ProcessPoolExecutor() as pool:\n",
    "        result = await loop.run_in_executor(\n",
    "            pool,\n",
    "            cpu_intensive_task,\n",
    "            1000000\n",
    "        )\n",
    "        print(f\"Result from process: {result}\")\n",
    "    \n",
    "    # Continue with async I/O\n",
    "    await asyncio.sleep(1)\n",
    "```\n",
    "\n",
    "## Summary\n",
    "\n",
    "Concurrency transforms sequential bottlenecks into scalable systems, but choosing the wrong model degrades performance. You understand the **Global Interpreter Lock** and its implications: threading provides concurrent I/O handling but not parallelism, while multiprocessing achieves true parallelism at the cost of memory overhead and serialization complexity.\n",
    "\n",
    "You have mastered **threading** synchronization primitives—Locks, Semaphores, Conditions, and Events—that prevent race conditions in shared-memory concurrency. **ThreadPoolExecutor** provides a high-level interface for I/O-bound workloads without manual thread lifecycle management.\n",
    "\n",
    "For CPU-intensive tasks, **multiprocessing** bypasses the GIL through separate processes, using shared memory (Value, Array), Queues, and Managers for inter-process communication. **ProcessPoolExecutor** distributes computational work across available CPU cores.\n",
    "\n",
    "**Asyncio** represents Python's modern approach to high-concurrency I/O, using coroutines (`async def`), the event loop, and cooperative multitasking to handle thousands of simultaneous connections in a single thread. You understand that `await` yields control to the event loop, enabling efficient resource utilization during I/O waits.\n",
    "\n",
    "However, concurrent code introduces complexity that demands rigorous testing and debugging. In the next chapter, we explore the ecosystem of web development—building APIs and services that leverage these concurrency models to serve users at scale.\n",
    "\n",
    "**Next Chapter**: Chapter 14: Web Development and APIs (FastAPI, Flask, and HTTP Fundamentals)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
