{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 17: The Data Science Stack\n",
    "\n",
    "Python's rise to prominence in the software industry is inextricably linked to its dominance in data science. From experimental prototyping to production-grade machine learning pipelines, Python offers a unified ecosystem for numerical computing, data manipulation, and visualization. This ecosystem is built on three pillars: **NumPy** for efficient numerical operations, **Pandas** for structured data analysis, and visualization libraries for communicating insights.\n",
    "\n",
    "This chapter explores these foundational tools. You will learn to leverage vectorization for performance that rivals compiled languages, manipulate datasets with expressive syntax, and generate publication-quality visualizations. We emphasize the patterns that differentiate data science code from general-purpose scripting: array-oriented thinking, the split-apply-combine strategy, and the grammar of graphics.\n",
    "\n",
    "## 17.1 NumPy: N-Dimensional Arrays\n",
    "\n",
    "**NumPy** (Numerical Python) is the foundation of the scientific Python stack. It provides the `ndarray`—a multidimensional array object that enables vectorized operations, broadcasting, and memory-efficient storage.\n",
    "\n",
    "### The ndarray: Memory and Performance\n",
    "\n",
    "Unlike Python lists, which store references to scattered objects, NumPy arrays store homogeneous data in a contiguous memory block. This enables CPU cache optimization and SIMD (Single Instruction, Multiple Data) operations.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import time\n",
    "\n",
    "# Comparing Python lists vs. NumPy arrays\n",
    "def performance_comparison() -> None:\n",
    "    \"\"\"Demonstrate NumPy's performance advantage.\"\"\"\n",
    "    size: int = 10_000_000\n",
    "    \n",
    "    # Python lists\n",
    "    list_a = list(range(size))\n",
    "    list_b = list(range(size))\n",
    "    \n",
    "    start = time.time()\n",
    "    # Element-wise operation requires loop\n",
    "    list_c = [a + b for a, b in zip(list_a, list_b)]\n",
    "    list_time = time.time() - start\n",
    "    \n",
    "    # NumPy arrays\n",
    "    array_a = np.arange(size)\n",
    "    array_b = np.arange(size)\n",
    "    \n",
    "    start = time.time()\n",
    "    # Vectorized operation (no explicit loop)\n",
    "    array_c = array_a + array_b\n",
    "    numpy_time = time.time() - start\n",
    "    \n",
    "    print(f\"Python List: {list_time:.4f}s\")\n",
    "    print(f\"NumPy Array: {numpy_time:.6f}s\")\n",
    "    print(f\"Speedup: {list_time / numpy_time:.0f}x\")\n",
    "\n",
    "# Array creation\n",
    "arr_1d = np.array([1, 2, 3, 4, 5])\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Special constructors\n",
    "zeros = np.zeros((3, 4))           # 3x4 matrix of 0s\n",
    "ones = np.ones((2, 3), dtype=np.float64)\n",
    "identity = np.eye(3)               # 3x3 identity matrix\n",
    "random = np.random.randn(2, 2)     # Standard normal distribution\n",
    "linspace = np.linspace(0, 10, 5)   # [0., 2.5, 5., 7.5, 10.]\n",
    "```\n",
    "\n",
    "### Array Attributes and Indexing\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "arr = np.random.randint(0, 100, (3, 4, 5))  # 3D array: 3 blocks, 4 rows, 5 cols\n",
    "\n",
    "# Attributes\n",
    "print(f\"Shape: {arr.shape}\")       # (3, 4, 5)\n",
    "print(f\"Dimensions: {arr.ndim}\")   # 3\n",
    "print(f\"Size: {arr.size}\")         # 60 total elements\n",
    "print(f\"Dtype: {arr.dtype}\")       # int64\n",
    "\n",
    "# Indexing (0-based)\n",
    "print(arr[0, 1, 2])                # First block, second row, third column\n",
    "\n",
    "# Slicing\n",
    "print(arr[:, 0, :])                # All blocks, first row, all columns\n",
    "print(arr[::2])                    # Every other block (step=2)\n",
    "print(arr[..., -1])                # Last column of all blocks (ellipsis)\n",
    "\n",
    "# Boolean Indexing (Filtering)\n",
    "data = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "mask = data > 4\n",
    "filtered = data[mask]              # [5, 6, 7, 8]\n",
    "\n",
    "# Fancy Indexing (Integer array indexing)\n",
    "indices = np.array([0, 2, 5])\n",
    "selected = data[indices]           # [1, 3, 6]\n",
    "```\n",
    "\n",
    "### Vectorization and Broadcasting\n",
    "\n",
    "**Broadcasting** describes how NumPy treats arrays with different shapes during arithmetic operations. Smaller arrays are \"broadcast\" across larger ones without copying data.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Broadcasting rules:\n",
    "# 1. Compare shapes right-to-left\n",
    "# 2. Dimensions are compatible if equal or one is 1\n",
    "# 3. Missing dimensions are treated as 1\n",
    "\n",
    "# Example 1: Scalar + Array\n",
    "arr = np.array([1, 2, 3])\n",
    "result = arr + 5                   # [6, 7, 8] (Scalar broadcast to shape (3,))\n",
    "\n",
    "# Example 2: 2D + 1D\n",
    "matrix = np.ones((3, 3))           # Shape (3, 3)\n",
    "row = np.array([1, 2, 3])          # Shape (3,)\n",
    "result = matrix + row              # Row broadcast across each row of matrix\n",
    "\n",
    "# Example 3: Column + Row\n",
    "col = np.array([[1], [2], [3]])    # Shape (3, 1)\n",
    "row = np.array([1, 2, 3])          # Shape (3,)\n",
    "result = col + row                 # Outer product: Shape (3, 3)\n",
    "\n",
    "# Visualizing Broadcasting\n",
    "\"\"\"\n",
    "(3, 1) + (3,) -> (3, 3)\n",
    "[[1],          [1, 2, 3]    [[1+1, 1+2, 1+3],\n",
    " [2],      +            =   [2+1, 2+2, 2+3],\n",
    " [3]]                        [3+1, 3+2, 3+3]]\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### Universal Functions (ufuncs)\n",
    "\n",
    "NumPy provides vectorized wrappers for mathematical functions:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "arr = np.array([1, 4, 9, 16, 25])\n",
    "\n",
    "# Mathematical functions\n",
    "np.sqrt(arr)                       # [1., 2., 3., 4., 5.]\n",
    "np.exp(arr)\n",
    "np.log(arr)\n",
    "np.sin(arr)\n",
    "\n",
    "# Statistical aggregations\n",
    "arr = np.random.randn(1000)\n",
    "np.mean(arr)\n",
    "np.std(arr)\n",
    "np.min(arr), np.max(arr)\n",
    "np.sum(arr)\n",
    "\n",
    "# Axis-based operations (for multi-dimensional arrays)\n",
    "matrix = np.random.rand(3, 4)\n",
    "np.sum(matrix, axis=0)             # Sum each column (result shape: (4,))\n",
    "np.sum(matrix, axis=1)             # Sum each row (result shape: (3,))\n",
    "np.mean(matrix, axis=1, keepdims=True)  # Keep dimension (shape: (3, 1))\n",
    "```\n",
    "\n",
    "### Linear Algebra\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from numpy.linalg import inv, eig, svd\n",
    "\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "# Matrix multiplication\n",
    "C = A @ B                         # Preferred (Python 3.5+)\n",
    "C = np.matmul(A, B)               # Equivalent\n",
    "\n",
    "# Element-wise multiplication\n",
    "D = A * B\n",
    "\n",
    "# Transpose\n",
    "A_T = A.T\n",
    "\n",
    "# Inverse\n",
    "A_inv = inv(A)\n",
    "\n",
    "# Eigenvalues and Eigenvectors\n",
    "eigenvalues, eigenvectors = eig(A)\n",
    "\n",
    "# Singular Value Decomposition\n",
    "U, S, Vh = svd(A)\n",
    "```\n",
    "\n",
    "## 17.2 Pandas: Data Manipulation and Analysis\n",
    "\n",
    "**Pandas** builds on NumPy to provide labeled, tabular data structures. It handles heterogeneous data types, missing values, and time series functionality that NumPy alone cannot provide.\n",
    "\n",
    "### Core Data Structures\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "\n",
    "# Series: 1D labeled array\n",
    "series = pd.Series(\n",
    "    [10, 20, 30, 40],\n",
    "    index=['a', 'b', 'c', 'd'],\n",
    "    name='values'\n",
    ")\n",
    "print(series['b'])                 # 20 (label-based indexing)\n",
    "print(series.iloc[1])              # 20 (position-based indexing)\n",
    "\n",
    "# DataFrame: 2D labeled table (dict of Series)\n",
    "data: Dict[str, List] = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
    "    'age': [25, 30, 35, 28],\n",
    "    'city': ['NY', 'LA', 'NY', 'Chicago'],\n",
    "    'salary': [50000, 60000, 75000, np.nan]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Attributes\n",
    "print(df.shape)                    # (4, 4)\n",
    "print(df.columns)                  # Index(['name', 'age', 'city', 'salary'])\n",
    "print(df.dtypes)                   # Data types per column\n",
    "print(df.info())                   # Summary including memory usage\n",
    "print(df.describe())               # Statistical summary of numeric columns\n",
    "```\n",
    "\n",
    "### Data Loading and Persistence\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# CSV\n",
    "df = pd.read_csv('data.csv', sep=',', header=0, index_col=0)\n",
    "df.to_csv('output.csv', index=False)\n",
    "\n",
    "# Excel (requires openpyxl or xlrd)\n",
    "df = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
    "df.to_excel('output.xlsx', sheet_name='Results')\n",
    "\n",
    "# JSON\n",
    "df = pd.read_json('data.json', orient='records')\n",
    "df.to_json('output.json', indent=2)\n",
    "\n",
    "# SQL (requires SQLAlchemy)\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://user:password@localhost/db')\n",
    "df = pd.read_sql('SELECT * FROM users', engine)\n",
    "df.to_sql('users_copy', engine, if_exists='replace', index=False)\n",
    "\n",
    "# Large files: Chunking\n",
    "chunk_iter = pd.read_csv('huge_file.csv', chunksize=10000)\n",
    "for chunk in chunk_iter:\n",
    "    process_chunk(chunk)\n",
    "```\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "Real-world data is messy. Pandas provides robust tools for handling issues:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [5, np.nan, np.nan, 8, 10],\n",
    "    'C': ['apple', 'banana', 'apple', np.nan, 'banana'],\n",
    "    'D': [10, 20, 30, 40, 50]\n",
    "})\n",
    "\n",
    "# Handling Missing Data\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Drop columns with missing values\n",
    "df_clean_cols = df.dropna(axis=1)\n",
    "\n",
    "# Fill missing values\n",
    "df_filled = df.fillna(0)           # Fill all with 0\n",
    "df_ffill = df.fillna(method='ffill')  # Forward fill\n",
    "\n",
    "# Column-specific filling\n",
    "values = {'A': df['A'].mean(), 'B': 0, 'C': 'unknown'}\n",
    "df_filled_custom = df.fillna(values)\n",
    "\n",
    "# Duplicates\n",
    "df_deduped = df.drop_duplicates(subset=['C'], keep='first')\n",
    "\n",
    "# Type Conversion\n",
    "df['D'] = df['D'].astype(float)\n",
    "df['D'] = pd.to_numeric(df['D'], errors='coerce')  # Invalid -> NaN\n",
    "\n",
    "# String Operations (accessed via .str)\n",
    "df['C_upper'] = df['C'].str.upper()\n",
    "df['C_len'] = df['C'].str.len()\n",
    "df['is_apple'] = df['C'].str.contains('apple', na=False)\n",
    "\n",
    "# Applying Functions\n",
    "# Element-wise\n",
    "df['D_squared'] = df['D'].apply(lambda x: x ** 2)\n",
    "\n",
    "# Row-wise\n",
    "def categorize(row):\n",
    "    if row['age'] < 30:\n",
    "        return 'Young'\n",
    "    elif row['age'] < 50:\n",
    "        return 'Adult'\n",
    "    return 'Senior'\n",
    "\n",
    "# Vectorized string operations (faster than .apply)\n",
    "df['C_first'] = df['C'].str[0]     # First character\n",
    "```\n",
    "\n",
    "### Data Transformation: Split-Apply-Combine\n",
    "\n",
    "The `groupby` operation is Pandas' most powerful analytical tool, implementing the split-apply-combine pattern:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "df = pd.DataFrame({\n",
    "    'department': ['Sales', 'Sales', 'IT', 'IT', 'HR', 'HR'],\n",
    "    'employee': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank'],\n",
    "    'salary': [50000, 60000, 70000, 80000, 45000, 55000],\n",
    "    'years_experience': [2, 5, 8, 10, 1, 3]\n",
    "})\n",
    "\n",
    "# Grouping\n",
    "grouped = df.groupby('department')\n",
    "\n",
    "# Aggregations\n",
    "print(grouped['salary'].mean())    # Average salary per department\n",
    "print(grouped['salary'].agg(['mean', 'min', 'max']))\n",
    "\n",
    "# Multiple columns\n",
    "print(grouped.agg({\n",
    "    'salary': 'mean',\n",
    "    'years_experience': 'max'\n",
    "}))\n",
    "\n",
    "# Custom aggregation\n",
    "def salary_range(series):\n",
    "    return series.max() - series.min()\n",
    "\n",
    "print(grouped['salary'].agg(salary_range))\n",
    "\n",
    "# Named aggregations (cleaner syntax)\n",
    "result = df.groupby('department').agg(\n",
    "    avg_salary=('salary', 'mean'),\n",
    "    total_experience=('years_experience', 'sum'),\n",
    "    employee_count=('employee', 'count')\n",
    ")\n",
    "\n",
    "# Transformation (return same shape as input)\n",
    "# Standardize within group\n",
    "df['salary_normalized'] = df.groupby('department')['salary'].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "\n",
    "# Filtering groups\n",
    "# Keep only departments with avg salary > 60000\n",
    "high_paid = df.groupby('department').filter(\n",
    "    lambda g: g['salary'].mean() > 60000\n",
    ")\n",
    "```\n",
    "\n",
    "### Merging and Joining\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "employees = pd.DataFrame({\n",
    "    'emp_id': [1, 2, 3, 4],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
    "    'dept_id': [10, 20, 10, 30]\n",
    "})\n",
    "\n",
    "departments = pd.DataFrame({\n",
    "    'dept_id': [10, 20, 40],\n",
    "    'dept_name': ['Sales', 'IT', 'Marketing']\n",
    "})\n",
    "\n",
    "# Inner Join (intersection)\n",
    "inner = pd.merge(employees, departments, on='dept_id', how='inner')\n",
    "# Only emp_id 1, 2, 3 remain (dept 30 not in departments, dept 40 has no employees)\n",
    "\n",
    "# Left Join (keep all employees)\n",
    "left = pd.merge(employees, departments, on='dept_id', how='left')\n",
    "# Diana (dept 30) has NaN for dept_name\n",
    "\n",
    "# Outer Join (union)\n",
    "outer = pd.merge(employees, departments, on='dept_id', how='outer')\n",
    "\n",
    "# Concatenation\n",
    "df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
    "\n",
    "vertical = pd.concat([df1, df2], ignore_index=True)\n",
    "horizontal = pd.concat([df1, df2], axis=1)\n",
    "```\n",
    "\n",
    "## 17.3 Data Visualization: Matplotlib and Seaborn\n",
    "\n",
    "Visualization transforms numbers into narratives. **Matplotlib** provides low-level control, while **Seaborn** offers high-level abstractions for statistical graphics.\n",
    "\n",
    "### Matplotlib Fundamentals\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "x = np.linspace(0, 10, 100)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.cos(x)\n",
    "\n",
    "# Figure and Axes (Object-Oriented Approach - Recommended)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plotting\n",
    "ax.plot(x, y1, label='sin(x)', color='blue', linestyle='-', linewidth=2)\n",
    "ax.plot(x, y2, label='cos(x)', color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "# Customization\n",
    "ax.set_xlabel('X Axis')\n",
    "ax.set_ylabel('Y Axis')\n",
    "ax.set_title('Trigonometric Functions')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotations\n",
    "ax.annotate(\n",
    "    'Local Max', \n",
    "    xy=(np.pi/2, 1), \n",
    "    xytext=(np.pi/2, 1.5),\n",
    "    arrowprops=dict(facecolor='black', shrink=0.05)\n",
    ")\n",
    "\n",
    "# Saving the figure\n",
    "fig.savefig('trig_functions.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Display (in interactive environments)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Multiple Subplots\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create 2x2 grid of subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Multiple Plot Types', fontsize=16)\n",
    "\n",
    "# Flatten axes array for easy iteration\n",
    "axes = axes.ravel()\n",
    "\n",
    "# 1. Line plot\n",
    "x = np.linspace(0, 10, 50)\n",
    "axes[0].plot(x, np.sin(x), 'b-')\n",
    "axes[0].set_title('Line Plot')\n",
    "\n",
    "# 2. Scatter plot\n",
    "axes[1].scatter(np.random.rand(50), np.random.rand(50), c='green', alpha=0.6)\n",
    "axes[1].set_title('Scatter Plot')\n",
    "\n",
    "# 3. Bar chart\n",
    "categories = ['A', 'B', 'C', 'D']\n",
    "values = [23, 45, 12, 67]\n",
    "axes[2].bar(categories, values, color='purple')\n",
    "axes[2].set_title('Bar Chart')\n",
    "\n",
    "# 4. Histogram\n",
    "axes[3].hist(np.random.randn(1000), bins=30, color='orange', edgecolor='black')\n",
    "axes[3].set_title('Histogram')\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Seaborn: Statistical Visualization\n",
    "\n",
    "Seaborn simplifies creating attractive statistical graphics and integrates seamlessly with Pandas DataFrames.\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set aesthetic style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Sample dataset\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "print(tips.head())\n",
    "\n",
    "# 1. Distribution Plots\n",
    "# Histogram with Kernel Density Estimate (KDE)\n",
    "sns.histplot(data=tips, x=\"total_bill\", kde=True, bins=20)\n",
    "plt.title(\"Distribution of Total Bill\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Categorical Plots\n",
    "# Box plot (shows quartiles and outliers)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=tips, x=\"day\", y=\"total_bill\", hue=\"smoker\")\n",
    "plt.title(\"Total Bill by Day and Smoking Status\")\n",
    "plt.show()\n",
    "\n",
    "# Violin plot (combines box plot with KDE)\n",
    "sns.violinplot(data=tips, x=\"day\", y=\"total_bill\", hue=\"time\", split=True)\n",
    "plt.show()\n",
    "\n",
    "# 3. Relational Plots\n",
    "# Scatter plot with regression line\n",
    "sns.lmplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"smoker\", height=6, aspect=1.5)\n",
    "plt.title(\"Tip vs Total Bill with Regression\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot with semantic mapping\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=tips, \n",
    "    x=\"total_bill\", \n",
    "    y=\"tip\", \n",
    "    hue=\"time\",    # Color by time\n",
    "    style=\"sex\",   # Marker style by sex\n",
    "    size=\"size\",   # Marker size by party size\n",
    "    sizes=(50, 200)\n",
    ")\n",
    "plt.title(\"Multi-dimensional Scatter Plot\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Pairwise Relationships (Exploratory Data Analysis)\n",
    "# Plots pairwise relationships in a dataset\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "sns.pairplot(iris, hue=\"species\", corner=True)  # corner=True removes upper triangle\n",
    "plt.show()\n",
    "\n",
    "# 5. Heatmaps (Correlation Matrices)\n",
    "# Select only numeric columns for correlation\n",
    "numeric_tips = tips.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numeric_tips.corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    correlation_matrix, \n",
    "    annot=True,       # Show values\n",
    "    cmap='coolwarm',  # Color map\n",
    "    center=0,         # Center colormap at 0\n",
    "    square=True\n",
    ")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# 6. Faceting (Plotting on multiple axes based on data subsets)\n",
    "g = sns.FacetGrid(tips, col=\"time\", row=\"smoker\", height=3, aspect=1.5)\n",
    "g.map_dataframe(sns.scatterplot, x=\"total_bill\", y=\"tip\")\n",
    "g.add_legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Best Practices for Visualization\n",
    "\n",
    "1.  **Choose the Right Plot Type:**\n",
    "    *   **Distribution**: Histogram, KDE, Box Plot\n",
    "    *   **Relationship**: Scatter Plot, Line Plot\n",
    "    *   **Comparison**: Bar Chart, Violin Plot\n",
    "    *   **Composition**: Stacked Bar, Pie Chart (use sparingly)\n",
    "    \n",
    "2.  **Declutter (Data-Ink Ratio):**\n",
    "    Remove chart junk (excessive grid lines, 3D effects, distracting backgrounds) that doesn't add information.\n",
    "\n",
    "3.  **Label Clearly:**\n",
    "    Titles, axis labels, and legends must be unambiguous. Units should be included in labels.\n",
    "\n",
    "4.  **Color Blindness Accessibility:**\n",
    "    Use palettes that are distinguishable for color-blind users (Seaborn's default is generally good; avoid red-green combinations).\n",
    "\n",
    "## Summary\n",
    "\n",
    "Data science in Python is built on a powerful stack of libraries that transform raw data into actionable insights. **NumPy** provides the computational engine with its N-dimensional arrays, enabling vectorized operations that are orders of magnitude faster than Python loops. You understand broadcasting and the memory efficiency of contiguous arrays.\n",
    "\n",
    "**Pandas** brings data to life through DataFrames and Series, offering intuitive tools for cleaning, transforming, and analyzing tabular data. You have mastered the split-apply-combine pattern through `groupby`, handled missing data gracefully, and joined datasets with SQL-like flexibility.\n",
    "\n",
    "**Visualization** with Matplotlib and Seaborn allows you to communicate findings effectively. Matplotlib provides low-level control over every element of a plot, while Seaborn offers high-level abstractions for statistical visualization that integrate seamlessly with Pandas data structures.\n",
    "\n",
    "These tools form the basis for analysis, but they are also the stepping stones to automation. In the next chapter, we apply Python to system administration and task automation—writing scripts to interact with the operating system, scrape the web, and schedule routine work.\n",
    "\n",
    "**Next Chapter**: Chapter 18: Automation and Scripting."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
