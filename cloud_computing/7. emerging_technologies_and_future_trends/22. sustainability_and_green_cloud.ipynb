{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 22: Sustainability and Green Cloud**\n",
    "\n",
    "## Introduction: The Environmental Cost of Digital Infinity\n",
    "\n",
    "Cloud computing promises infinite scale—a marketing abstraction that materializes as vast data centers sprawling across the globe, consuming prodigious amounts of energy and water. The digital world is not ethereal; it is anchored in physical reality. Every Google search, every Netflix stream, every model trained on millions of parameters, requires electrons flowing through servers, cooling systems humming to dissipate heat, and network infrastructure bridging continents.\n",
    "\n",
    "The ICT (Information and Communication Technology) sector currently accounts for approximately 2-4% of global greenhouse gas emissions, a figure rivaling the aviation industry. As AI workloads explode—training a single large language model can emit as much carbon as five cars over their lifetimes—the imperative for sustainable computing intensifies. Cloud providers, facing pressure from investors, regulators, and environmentally conscious customers, are racing to decarbonize their operations.\n",
    "\n",
    "However, sustainability is not solely the provider's responsibility. Cloud consumers dictate *what* runs and *how* efficiently it runs. Architectural decisions—selecting a compute region, choosing a programming language, optimizing database queries—have direct environmental consequences. \"GreenOps\" or \"Sustainable Cloud Engineering\" extends the FinOps discipline of financial accountability to environmental accountability, optimizing workloads for carbon efficiency alongside cost and performance.\n",
    "\n",
    "This chapter equips you with the knowledge to architect sustainable cloud systems. We will analyze the carbon footprint of cloud operations, distinguishing between operational emissions (electricity) and embodied emissions (hardware manufacturing). We will evaluate the sustainability commitments of major cloud providers, learning to navigate their carbon reporting tools. Finally, we will implement practical strategies for carbon-aware computing—architecting workloads that shift execution to times and places where renewable energy is abundant, optimizing resource utilization to minimize waste, and measuring the environmental impact of our technical decisions.\n",
    "\n",
    "---\n",
    "\n",
    "## 22.1 The Carbon Footprint of Computing\n",
    "\n",
    "Understanding the environmental impact requires decomposing where emissions originate in the cloud value chain.\n",
    "\n",
    "### 22.1.1 Operational Carbon vs. Embodied Carbon\n",
    "\n",
    "**Concept Explanation:**\n",
    "\n",
    "**1. Operational Carbon (Use Phase):**\n",
    "Emissions generated from the electricity consumed by data centers during operation.\n",
    "- **Sources:** Servers (CPU/GPU/Memory), Storage (SSD/HDD), Networking (Routers/Switches), and Cooling (HVAC systems, water usage).\n",
    "- **Key Metric:** Carbon Intensity (grams of CO₂ equivalent per kilowatt-hour, gCO₂eq/kWh). This varies by the local power grid. A data center in Iceland (geothermal/hydro) has near-zero operational carbon; one in a region powered by coal has high carbon intensity.\n",
    "\n",
    "**2. Embodied Carbon (Embedded Emissions):**\n",
    "The carbon emitted during the manufacturing, transportation, and eventual disposal of hardware.\n",
    "- **Sources:** Mining raw materials (rare earth metals), semiconductor fabrication (extremely energy-intensive), assembly, shipping, and end-of-life recycling.\n",
    "- **Impact:** A server's embodied carbon might equal 3-5 years of its operational carbon. Extending hardware lifespan is a key sustainability strategy.\n",
    "\n",
    "**Implication for Cloud Architects:**\n",
    "Cloud providers maximize server utilization (running workloads on shared hardware), amortizing embodied carbon across many customers—often more efficiently than on-premises servers running at 20% capacity. However, provisioning new resources (e.g., launching a new cluster) still \"activates\" embodied carbon demand. Optimization (using fewer resources) reduces both operational and embodied impact.\n",
    "\n",
    "### 22.1.2 Metrics for Sustainability\n",
    "\n",
    "**PUE (Power Usage Effectiveness):**\n",
    "Measures data center energy efficiency.\n",
    "$$\n",
    "\\text{PUE} = \\frac{\\text{Total Facility Energy}}{\\text{IT Equipment Energy}}\n",
    "$$\n",
    "- **Ideal:** 1.0 (all energy goes to compute, none to cooling/overhead).\n",
    "- **Industry Average:** ~1.5-1.6.\n",
    "- **Hyperscalers:** Google and Microsoft achieve PUEs of 1.10-1.20 via advanced cooling (evaporative, liquid cooling) and AI-driven climate control.\n",
    "\n",
    "**CUE (Carbon Usage Effectiveness):**\n",
    "Measures carbon emissions relative to compute.\n",
    "$$\n",
    "\\text{CUE} = \\frac{\\text{Total CO₂ Emissions (Scope 1+2)}}{\\text{IT Equipment Energy}}\n",
    "$$\n",
    "Lower CUE indicates a greener facility, largely dependent on the local grid's energy mix.\n",
    "\n",
    "---\n",
    "\n",
    "## 22.2 Cloud Provider Sustainability Efforts\n",
    "\n",
    "Hyperscalers are the world's largest purchasers of renewable energy. Their commitments vary in scope and ambition.\n",
    "\n",
    "### 22.2.1 Comparative Sustainability Goals\n",
    "\n",
    "| Provider | Goal | Target Date | Strategy |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Google Cloud** | **Carbon Neutral** | Achieved (2007) | Offsets for remaining emissions. |\n",
    "| | **24/7 Carbon-Free Energy** | 2030 | Matching electricity consumption with clean energy every hour of every day in every region. |\n",
    "| **Microsoft Azure** | **Carbon Negative** | 2030 | Removing more carbon than emitted. |\n",
    "| | **Zero Waste** | 2030 | 90% diversion from landfills for data centers. |\n",
    "| **AWS** | **Net-Zero Carbon** | 2040 | 10 years ahead of Paris Agreement. 100% renewable energy by 2025. |\n",
    "\n",
    "**The Concept of \"Additionality\":**\n",
    "Purchasing \"unbundled\" Renewable Energy Credits (RECs) allows companies to claim green status even if their data center draws power from a coal grid. Leaders like Google now focus on **Additionality**—investing in *new* renewable projects (wind/solar farms) that directly power their data centers, ensuring their consumption actually increases global renewable capacity.\n",
    "\n",
    "### 22.2.2 Carbon Reporting Tools\n",
    "\n",
    "**AWS Customer Carbon Footprint Tool:**\n",
    "Provides estimates of the carbon emissions associated with your AWS usage.\n",
    "- **Data:** Monthly emissions by service and region.\n",
    "- **Projection:** Estimates emissions avoided by using AWS vs. on-premises data centers.\n",
    "- **Access:** Enabled via AWS Billing Console.\n",
    "\n",
    "**Google Cloud Carbon Footprint:**\n",
    "Integrated into the Cloud Console.\n",
    "- **Granularity:** Project-level and region-level emissions.\n",
    "- **Export:** Data export to BigQuery for custom analysis.\n",
    "- **Actionable:** Direct integration with recommendations for optimization.\n",
    "\n",
    "**Microsoft Sustainability Calculator:**\n",
    "Provides emissions insights for Azure usage and the broader supply chain.\n",
    "\n",
    "**Implementation: Querying GCP Carbon Footprint Data (BigQuery):**\n",
    "\n",
    "```sql\n",
    "-- Analyze carbon emissions by service in the last month\n",
    "SELECT\n",
    "  usage_start_time,\n",
    "  project_id,\n",
    "  location,\n",
    "  service_description,\n",
    "  usage_amount,\n",
    "  usage_unit,\n",
    "  carbon_footprint_kg_co2e -- Kilograms of CO2 equivalent\n",
    "FROM\n",
    "  `project-id.region`.carbon_footprint_usage_data\n",
    "WHERE\n",
    "  usage_start_time >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 MONTH)\n",
    "ORDER BY\n",
    "  carbon_footprint_kg_co2e DESC;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 22.3 Sustainable Cloud Practices: The GreenOps Playbook\n",
    "\n",
    "Architects and developers can actively reduce the environmental impact of their workloads through targeted strategies.\n",
    "\n",
    "### 22.3.1 Region Selection: The Geography of Carbon\n",
    "\n",
    "**Concept Explanation:**\n",
    "Not all cloud regions are equal. The carbon intensity of the local grid varies dramatically based on the energy mix (coal vs. wind/solar/nuclear/hydro).\n",
    "\n",
    "**Strategy:**\n",
    "For workloads that are not latency-sensitive (e.g., overnight batch processing, data analytics, model training), prioritize regions with lower carbon intensity.\n",
    "\n",
    "**Carbon Intensity Examples (Approximate):**\n",
    "- **Low Carbon:** Finland (Hydro/Nuclear), Montreal (Hydro), Norway (Hydro), Oregon (Hydro).\n",
    "- **High Carbon:** Singapore (Natural Gas), Virginia (Mixed/Grid), Hong Kong (Natural Gas/Coal).\n",
    "\n",
    "**Implementation: Carbon-Aware Region Selector (Python):**\n",
    "\n",
    "```python\n",
    "# Pseudo-code for carbon-aware region selection\n",
    "# Uses an external API like ElectricityMaps or Cloud Provider metadata\n",
    "\n",
    "import requests\n",
    "\n",
    "def get_greenest_region(workload_type, candidate_regions):\n",
    "    \"\"\"\n",
    "    Selects the region with the lowest current carbon intensity.\n",
    "    \"\"\"\n",
    "    # Example API call to ElectricityMaps (commercial API)\n",
    "    # Or use internal cloud provider carbon intensity APIs if available\n",
    "    \n",
    "    carbon_data = []\n",
    "    \n",
    "    for region in candidate_regions:\n",
    "        # In reality, you would call an API here\n",
    "        # response = requests.get(f\"https://api.electricitymap.org/v3/carbon-intensity/latest?zone={region_zone}\")\n",
    "        \n",
    "        # Mock data for demonstration\n",
    "        mock_intensity = {\n",
    "            'us-east-1': 450,  # gCO2eq/kWh (High)\n",
    "            'us-west-2': 150,  # gCO2eq/kWh (Lower - Hydro)\n",
    "            'eu-north-1': 50,  # gCO2eq/kWh (Very Low - Nordic grid)\n",
    "            'asia-southeast-1': 500\n",
    "        }\n",
    "        \n",
    "        intensity = mock_intensity.get(region, 400)\n",
    "        carbon_data.append({'region': region, 'intensity': intensity})\n",
    "    \n",
    "    # Sort by intensity (lowest first)\n",
    "    sorted_regions = sorted(carbon_data, key=lambda x: x['intensity'])\n",
    "    \n",
    "    print(f\"Recommended region for {workload_type}: {sorted_regions[0]['region']}\")\n",
    "    print(f\"Current Carbon Intensity: {sorted_regions[0]['intensity']} gCO2eq/kWh\")\n",
    "    \n",
    "    return sorted_regions[0]['region']\n",
    "\n",
    "# Usage: Selecting region for a non-urgent training job\n",
    "candidates = ['us-east-1', 'us-west-2', 'eu-north-1']\n",
    "best_region = get_greenest_region('ml-training', candidates)\n",
    "```\n",
    "\n",
    "### 22.3.2 Temporal Shifting: Carbon-Aware Computing\n",
    "\n",
    "**Concept Explanation:**\n",
    "Renewable energy is intermittent. Solar peaks at midday; wind peaks at night. Grids often have \"dirty\" periods (high carbon) when demand peaks and renewable supply is low. Carbon-aware computing shifts flexible workloads to times when the grid is greenest.\n",
    "\n",
    "**Architecture Pattern:**\n",
    "Instead of running a batch job at 09:00 AM every day, check the forecast for carbon intensity. If the grid is currently high-carbon, wait 4 hours until solar output increases.\n",
    "\n",
    "**Implementation: Carbon-Aware Batch Scheduler (Lambda + EventBridge):**\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"\n",
    "    Checks carbon intensity before triggering a heavy batch job.\n",
    "    If intensity is high, delays execution.\n",
    "    \"\"\"\n",
    "    # 1. Get current carbon intensity for the region (Mock)\n",
    "    current_intensity = get_current_intensity('us-west-2')\n",
    "    threshold = 200  # gCO2eq/kWh\n",
    "    \n",
    "    if current_intensity < threshold:\n",
    "        # Conditions are green: Run the job\n",
    "        print(f\"Carbon intensity is low ({current_intensity}). Starting job.\")\n",
    "        trigger_batch_job()\n",
    "        return {'status': 'EXECUTED', 'intensity': current_intensity}\n",
    "    else:\n",
    "        # Conditions are dirty: Reschedule for later\n",
    "        print(f\"Carbon intensity is high ({current_intensity}). Rescheduling.\")\n",
    "        \n",
    "        # Reschedule via EventBridge Scheduler\n",
    "        scheduler = boto3.client('scheduler')\n",
    "        \n",
    "        # Schedule for 4 hours later\n",
    "        schedule_time = datetime.utcnow() + timedelta(hours=4)\n",
    "        \n",
    "        scheduler.create_schedule(\n",
    "            Name=f'carbon-aware-retry-{context.aws_request_id}',\n",
    "            ScheduleExpression=f'at({schedule_time.strftime(\"%Y-%m-%dT%H:%M:%S\")})',\n",
    "            FlexibleTimeWindow={'Mode': 'OFF'},\n",
    "            Target={\n",
    "                'Arn': 'arn:aws:lambda:us-west-2:123456789012:function:carbon-aware-trigger',\n",
    "                'RoleArn': 'arn:aws:iam::123456789012:role/scheduler-role'\n",
    "            },\n",
    "            ActionAfterCompletion='DELETE'  # Clean up one-time schedule\n",
    "        )\n",
    "        \n",
    "        return {'status': 'RESCHEDULED', 'intensity': current_intensity, 'retry_at': schedule_time.isoformat()}\n",
    "\n",
    "def get_current_intensity(region):\n",
    "    # Mock logic - integrate with ElectricityMaps or similar\n",
    "    # Simulate fluctuation\n",
    "    hour = datetime.utcnow().hour\n",
    "    if 10 <= hour <= 16:  # Solar peak\n",
    "        return 100  # Low carbon\n",
    "    else:\n",
    "        return 350  # High carbon\n",
    "\n",
    "def trigger_batch_job():\n",
    "    # Trigger Glue job, Batch job, or Step Function\n",
    "    glue = boto3.client('glue')\n",
    "    glue.start_job_run(JobName='data-lake-etl')\n",
    "```\n",
    "\n",
    "### 22.3.3 Architectural Efficiency\n",
    "\n",
    "**1. Serverless and Scale-to-Zero:**\n",
    "Idle servers consume energy without delivering value. Serverless architectures (Lambda, Fargate) scale to zero when not in use, eliminating idle energy consumption.\n",
    "- **Impact:** A VM running 24/7 at 5% utilization wastes 95% of its energy. A serverless function only consumes energy during execution.\n",
    "\n",
    "**2. Spot Instances:**\n",
    "Spot instances utilize \"spare\" cloud capacity. By consuming these spare resources, you increase the overall utilization of the cloud provider's data center, effectively sharing the embodied carbon of that hardware more efficiently.\n",
    "\n",
    "**3. Software Efficiency:**\n",
    "Efficient code reduces CPU cycles.\n",
    "- **Algorithms:** Optimizing an algorithm from O(n²) to O(n log n) saves compute time and energy.\n",
    "- **Languages:** Compiled languages (Rust, C++, Go) are generally more energy-efficient than interpreted languages (Python, Ruby) for CPU-intensive tasks. A study showed Rust consumed roughly 50% less energy than Python for similar tasks.\n",
    "- **Libraries:** Using optimized libraries (e.g., NumPy for Python) leverages compiled C backends, improving efficiency.\n",
    "\n",
    "**Implementation: Identifying Inefficient Code (Profiler):**\n",
    "\n",
    "```python\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# Profile a function to find energy-intensive bottlenecks\n",
    "def process_large_dataset():\n",
    "    # Inefficient loop\n",
    "    data = range(1000000)\n",
    "    result = []\n",
    "    for i in data:\n",
    "        result.append(i * i)\n",
    "    return result\n",
    "\n",
    "# Run profiler\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "process_large_dataset()\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "stats.print_stats(10)\n",
    "\n",
    "# Output will show time-consuming functions.\n",
    "# Optimizing these reduces energy consumption.\n",
    "```\n",
    "\n",
    "### 22.3.4 Hardware Lifecycle and Right-Sizing\n",
    "\n",
    "**Right-Sizing (FinOps + GreenOps):**\n",
    "Oversized instances (e.g., running a light web server on a 64-core machine) waste both money and energy. Right-sizing ensures hardware resources match the workload requirements, maximizing the useful work per watt.\n",
    "\n",
    "**Hardware Generation:**\n",
    "Newer hardware is typically more energy-efficient. For example, AWS Graviton3 processors offer better performance per watt than previous generations. Selecting modern instance types often aligns with sustainability goals.\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary and Transition to Module VIII\n",
    "\n",
    "This chapter positioned sustainability as a critical non-functional requirement for modern cloud architecture, integral to the responsible operation of global-scale systems. We dissected the carbon footprint of computing, differentiating between operational carbon (electricity usage) and embodied carbon (manufacturing), and introduced metrics like PUE and CUE to quantify efficiency.\n",
    "\n",
    "We examined the aggressive sustainability commitments of hyperscalers—Google's 24/7 carbon-free energy, Microsoft's carbon-negative goals, and AWS's net-zero path—and learned to leverage their carbon reporting tools (AWS Customer Carbon Footprint Tool, GCP Carbon Footprint) to gain visibility into our environmental impact.\n",
    "\n",
    "Practical GreenOps strategies provided actionable pathways: selecting low-carbon regions for flexible workloads, implementing carbon-aware computing that shifts execution to times of high renewable availability, and prioritizing architectural patterns like serverless and spot instances that maximize hardware utilization. We concluded that software efficiency is environmental efficiency—optimizing code reduces CPU cycles, which directly reduces energy consumption.\n",
    "\n",
    "Having traversed the technical landscape from foundational cloud concepts through security, DevOps, data, AI, and emerging technologies like edge and quantum computing, and finally grounding ourselves in sustainable practices, we have assembled the complete toolkit of the modern cloud architect. Theory, however, remains abstract without application. In **Module VIII: Capstone Project and Career Development**, we transition from learning to doing. **Chapter 23: End-to-End Cloud Project** presents a comprehensive architectural challenge that synthesizes the concepts covered throughout this handbook. You will design a scalable, secure, and cost-optimized system, applying the principles of IAM, networking, compute, storage, and observability to a real-world scenario, effectively bridging the gap between knowledge and professional execution."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
