{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 19: Edge Computing**\n",
    "\n",
    "## Introduction: Extending the Cloud to Where Data Lives\n",
    "\n",
    "Cloud computing centralized infrastructure in hyperscale data centers, achieving unprecedented economies of scale. However, this centralization introduces a fundamental constraint: the speed of light. A round-trip between a user in Tokyo and a data center in Virginia takes approximately 120 milliseconds\u2014not including processing time. For applications like autonomous vehicles (requiring sub-10ms response times), remote surgery, or high-frequency industrial automation, this latency is unacceptable. Furthermore, the sheer volume of data generated at the network edge strains bandwidth: a single autonomous vehicle produces 4 terabytes of data per day, while a smart factory with 1,000 sensors might generate 5 petabytes annually. Transferring all this data to the cloud for processing is cost-prohibitive and technically infeasible.\n",
    "\n",
    "Edge computing decentralizes compute and storage resources, placing them physically closer to data sources and end users\u2014at cell towers, factory floors, retail stores, and embedded in devices themselves. This does not replace the cloud; rather, it creates a **cloud-edge continuum** where workloads dynamically execute where most appropriate. The cloud remains the hub for model training, data aggregation, and deep analytics, while the edge handles real-time inference, local data reduction, and immediate action.\n",
    "\n",
    "This chapter explores the architectural patterns, technologies, and operational practices for extending cloud capabilities to the edge. We will examine the continuum from centralized cloud to far-edge devices, implement data synchronization strategies that handle intermittent connectivity, deploy machine learning models for local inference, and manage fleets of thousands of edge nodes using platforms like AWS IoT Greengrass, Azure IoT Edge, and Anthos. By the chapter's end, you will possess the knowledge to architect hybrid systems that leverage the scale of the cloud and the responsiveness of the edge.\n",
    "\n",
    "---\n",
    "\n",
    "## 19.1 Core Concepts: Why Compute at the Edge?\n",
    "\n",
    "Edge computing addresses fundamental limitations of centralized cloud architectures. Understanding these drivers is essential for evaluating when edge deployment is necessary.\n",
    "\n",
    "### 19.1.1 Latency and Response Time\n",
    "\n",
    "**Concept Explanation:**\n",
    "Latency encompasses three components:\n",
    "1. **Propagation Delay:** Time for signals to travel distance (limited by physics\u2014light in fiber travels ~200,000 km/s)\n",
    "2. **Transmission Delay:** Time to push data onto the wire (dependent on bandwidth)\n",
    "3. **Processing Delay:** Time for computation at the destination\n",
    "\n",
    "Edge computing eliminates propagation delay for time-critical decisions by placing compute within meters of the data source.\n",
    "\n",
    "**Latency Thresholds by Use Case:**\n",
    "| Application | Acceptable Latency | Cloud Feasibility |\n",
    "|-------------|-------------------|-------------------|\n",
    "| Video streaming (adaptive bitrate) | 2-5 seconds | Cloud (via CDN) |\n",
    "| Voice assistants | 200-500 ms | Cloud acceptable |\n",
    "| Industrial automation (PLC control) | 5-10 ms | **Edge required** |\n",
    "| Autonomous vehicle braking | 1-5 ms | **Far-edge (in-vehicle) required** |\n",
    "| Augmented reality | < 20 ms | **Edge required** |\n",
    "\n",
    "**Calculation Example:**\n",
    "A manufacturing robot detects a defect and must stop the assembly line within 10 ms. The control system is 50 km from the factory:\n",
    "$$\n",
    "\\text{Propagation delay} = \\frac{50 \\text{ km} \\times 2 \\text{ (round-trip)}}{200,000 \\text{ km/s}} = 0.5 \\text{ ms}\n",
    "$$\n",
    "Adding network queuing, serialization, and processing, round-trip time is typically 10-30 ms\u2014exceeding the safety threshold. Edge compute on the factory floor reduces this to <1 ms.\n",
    "\n",
    "### 19.1.2 Bandwidth Cost and Data Volume\n",
    "\n",
    "**Concept Explanation:**\n",
    "Transmitting raw data to the cloud incurs ongoing bandwidth costs and requires robust connectivity. Edge processing performs **data reduction**\u2014filtering, aggregating, or analyzing data locally\u2014transmitting only valuable insights.\n",
    "\n",
    "**Cost-Benefit Analysis:**\n",
    "A smart building with 500 HVAC sensors generates 1 KB of data per sensor per second:\n",
    "$$\n",
    "500 \\text{ sensors} \\times 1 \\text{ KB/s} \\times 86,400 \\text{ s/day} = 43.2 \\text{ GB/day}\n",
    "$$\n",
    "Cloud ingestion cost (AWS): $0.09/GB \u00d7 43.2 GB = **$3.89/day ($1,420/year)**\n",
    "\n",
    "With edge processing analyzing data locally and uploading only anomalies (5% of data):\n",
    "$$\n",
    "43.2 \\text{ GB} \\times 0.05 = 2.16 \\text{ GB/day} \\rightarrow \\$0.19/\\text{day} (\\$69/\\text{year})\n",
    "$$\n",
    "**Annual savings: $1,351** (plus reduced cloud storage costs).\n",
    "\n",
    "### 19.1.3 Resilience and Intermittent Connectivity\n",
    "\n",
    "**Concept Explanation:**\n",
    "Many edge environments (ships, oil rigs, remote mining sites, moving vehicles) have unreliable internet connectivity. Edge computing enables **offline operation**, queuing data for synchronization when connectivity resumes.\n",
    "\n",
    "**Implementation Pattern: Store-and-Forward:**\n",
    "```python\n",
    "# Edge device: Store-and-forward data synchronization\n",
    "import json\n",
    "import time\n",
    "import sqlite3\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from threading import Thread\n",
    "\n",
    "class EdgeSyncManager:\n",
    "    def __init__(self, db_path, cloud_endpoint, max_retries=5):\n",
    "        self.db_path = db_path\n",
    "        self.cloud_endpoint = cloud_endpoint\n",
    "        self.max_retries = max_retries\n",
    "        self._init_db()\n",
    "        \n",
    "    def _init_db(self):\n",
    "        \"\"\"Initialize local queue database\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        conn.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS event_queue (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                event_type TEXT NOT NULL,\n",
    "                payload TEXT NOT NULL,\n",
    "                timestamp TEXT NOT NULL,\n",
    "                retry_count INTEGER DEFAULT 0,\n",
    "                status TEXT DEFAULT 'pending'\n",
    "            )\n",
    "        ''')\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def store_event(self, event_type, payload):\n",
    "        \"\"\"Store event locally (always succeeds even if offline)\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        conn.execute(\n",
    "            'INSERT INTO event_queue (event_type, payload, timestamp) VALUES (?, ?, ?)',\n",
    "            (event_type, json.dumps(payload), datetime.utcnow().isoformat())\n",
    "        )\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        print(f\"Event stored locally: {event_type}\")\n",
    "    \n",
    "    def sync_loop(self):\n",
    "        \"\"\"Background thread to sync pending events when connected\"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                self._attempt_sync()\n",
    "            except Exception as e:\n",
    "                print(f\"Sync failed: {e}\")\n",
    "            time.sleep(30)  # Check every 30 seconds\n",
    "    \n",
    "    def _attempt_sync(self):\n",
    "        \"\"\"Try to upload pending events\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Get pending events (oldest first)\n",
    "        cursor.execute('''\n",
    "            SELECT id, event_type, payload, retry_count \n",
    "            FROM event_queue \n",
    "            WHERE status = 'pending' AND retry_count < ?\n",
    "            ORDER BY timestamp ASC\n",
    "            LIMIT 50\n",
    "        ''', (self.max_retries,))\n",
    "        \n",
    "        events = cursor.fetchall()\n",
    "        \n",
    "        if not events:\n",
    "            return\n",
    "        \n",
    "        for event_id, event_type, payload, retry_count in events:\n",
    "            try:\n",
    "                # Attempt to send to cloud\n",
    "                response = requests.post(\n",
    "                    f\"{self.cloud_endpoint}/{event_type}\",\n",
    "                    json=json.loads(payload),\n",
    "                    timeout=10\n",
    "                )\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    # Mark as synced\n",
    "                    conn.execute(\n",
    "                        'UPDATE event_queue SET status = ? WHERE id = ?',\n",
    "                        ('synced', event_id)\n",
    "                    )\n",
    "                    print(f\"Synced event {event_id}\")\n",
    "                else:\n",
    "                    raise Exception(f\"HTTP {response.status_code}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                # Increment retry count\n",
    "                conn.execute(\n",
    "                    'UPDATE event_queue SET retry_count = retry_count + 1 WHERE id = ?',\n",
    "                    (event_id,)\n",
    "                )\n",
    "                print(f\"Failed to sync event {event_id}: {e}\")\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def start_background_sync(self):\n",
    "        \"\"\"Start synchronization thread\"\"\"\n",
    "        thread = Thread(target=self.sync_loop, daemon=True)\n",
    "        thread.start()\n",
    "        return thread\n",
    "\n",
    "# Usage on edge device\n",
    "sync_manager = EdgeSyncManager(\n",
    "    db_path='/data/edge_queue.db',\n",
    "    cloud_endpoint='https://api.company.com/iot/events'\n",
    ")\n",
    "sync_manager.start_background_sync()\n",
    "\n",
    "# Application code generates events\n",
    "def sensor_reading_handler(sensor_id, temperature, humidity):\n",
    "    event = {\n",
    "        'sensor_id': sensor_id,\n",
    "        'temperature': temperature,\n",
    "        'humidity': humidity,\n",
    "        'timestamp': datetime.utcnow().isoformat(),\n",
    "        'location': 'Factory-Floor-1'\n",
    "    }\n",
    "    \n",
    "    # Store locally (instant, works offline)\n",
    "    sync_manager.store_event('sensor_reading', event)\n",
    "```\n",
    "\n",
    "### 19.1.4 Data Sovereignty and Privacy\n",
    "\n",
    "**Concept Explanation:**\n",
    "Regulations (GDPR, CCPA, HIPAA) restrict where certain data can be processed and stored. Edge computing keeps sensitive data (patient health records, customer video feeds) within physical boundaries, transmitting only anonymized or aggregated insights to the cloud.\n",
    "\n",
    "**Architecture Pattern:**\n",
    "A retail store uses in-store cameras for customer analytics:\n",
    "- **Edge Processing:** Detect faces, analyze demographics, track movement patterns\u2014all locally\n",
    "- **Cloud Upload:** Only aggregated metrics (daily footfall, average dwell time, demographic distribution)\n",
    "- **Compliance:** No facial images leave the premises, satisfying privacy regulations without explicit consent for cloud processing\n",
    "\n",
    "---\n",
    "\n",
    "## 19.2 The Cloud-Edge Continuum Architecture\n",
    "\n",
    "Edge computing is not a separate domain but an extension of cloud infrastructure. Effective architectures define clear responsibilities and seamless data flows across the continuum.\n",
    "\n",
    "### 19.2.1 Architectural Layers\n",
    "\n",
    "**Layer 1: Far Edge (Device/Embedded)**\n",
    "- **Characteristics:** Highly constrained resources (microcontrollers, embedded Linux), battery-powered, real-time requirements\n",
    "- **Examples:** Industrial sensors, wearable devices, vehicle ECUs, smart meters\n",
    "- **Responsibilities:** Data acquisition, signal conditioning, time-sensitive control loops\n",
    "\n",
    "**Layer 2: Near Edge (Gateway/On-Premises)**\n",
    "- **Characteristics:** Moderate compute (ARM processors, small GPUs), stable power, local networking\n",
    "- **Examples:** Factory servers, retail point-of-sale systems, cell tower micro-data centers\n",
    "- **Responsibilities:** Local data aggregation, stream processing, ML inference, short-term storage\n",
    "\n",
    "**Layer 3: Regional Edge (CDN Points of Presence, Metro Data Centers)**\n",
    "- **Characteristics:** Substantial compute and storage, low-latency connectivity to users\n",
    "- **Examples:** AWS Wavelength, Azure Edge Zones, Google Cloud Edge\n",
    "- **Responsibilities:** User-facing applications, real-time analytics, content caching\n",
    "\n",
    "**Layer 4: Central Cloud (Hyperscale Regions)**\n",
    "- **Characteristics:** Unlimited scale, global services, advanced capabilities\n",
    "- **Examples:** AWS us-east-1, Azure East US, GCP us-central1\n",
    "- **Responsibilities:** Model training, long-term analytics, cross-region aggregation, system of record\n",
    "\n",
    "### 19.2.2 Workload Orchestration Across the Continuum\n",
    "\n",
    "**Concept Explanation:**\n",
    "Workloads should dynamically execute where most appropriate. Orchestration platforms manage deployment and lifecycle across layers.\n",
    "\n",
    "**Decision Framework:**\n",
    "\n",
    "| Criterion | Far Edge | Near Edge | Regional Edge | Central Cloud |\n",
    "|-----------|----------|-----------|---------------|---------------|\n",
    "| Latency Requirement | <10 ms | 10-100 ms | 50-200 ms | >200 ms |\n",
    "| Data Volume (generated) | Tiny (bytes) | Moderate (MB/GB) | Large (TB) | Unlimited |\n",
    "| Connectivity | Intermittent | Sometimes intermittent | Always connected | Always connected |\n",
    "| Compute Power | Very limited | Moderate | Substantial | Unlimited |\n",
    "| Management Complexity | High (fleet) | Medium | Medium | Low |\n",
    "| Example | Sensor calibration | Video analytics | User session management | ML model training |\n",
    "\n",
    "**Implementation: Kubernetes-Native Edge Orchestration (KubeEdge/K3s):**\n",
    "\n",
    "```yaml\n",
    "# Kubernetes deployment with node selectors for edge placement\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: video-analytics\n",
    "  labels:\n",
    "    app: video-processor\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: video-processor\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: video-processor\n",
    "    spec:\n",
    "      nodeSelector:\n",
    "        node-type: edge-gateway  # Schedule on edge nodes only\n",
    "        \n",
    "      containers:\n",
    "        - name: inference-engine\n",
    "          image: company/video-inference:v2.1\n",
    "          resources:\n",
    "            limits:\n",
    "              memory: \"512Mi\"\n",
    "              cpu: \"1000m\"\n",
    "            requests:\n",
    "              memory: \"256Mi\"\n",
    "              cpu: \"500m\"\n",
    "          \n",
    "          env:\n",
    "            - name: CLOUD_SYNC_ENDPOINT\n",
    "              value: \"https://api.company.com/edge-ingest\"\n",
    "            - name: OFFLINE_MODE\n",
    "              value: \"true\"\n",
    "            - name: MODEL_PATH\n",
    "              value: \"/models/detection.tflite\"\n",
    "          \n",
    "          volumeMounts:\n",
    "            - name: model-storage\n",
    "              mountPath: /models\n",
    "            - name: local-cache\n",
    "              mountPath: /data/cache\n",
    "      \n",
    "      volumes:\n",
    "        - name: model-storage\n",
    "          configMap:\n",
    "            name: ml-models  # Models distributed via ConfigMap\n",
    "        - name: local-cache\n",
    "          emptyDir:\n",
    "            sizeLimit: 5Gi\n",
    "---\n",
    "# Edge-specific ConfigMap for model distribution\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: ml-models\n",
    "  namespace: edge-ns\n",
    "data:\n",
    "  detection.tflite: |\n",
    "    # Binary model data (or use initContainer to download)\n",
    "---\n",
    "# Node labeling for edge identification (applied during provisioning)\n",
    "# kubectl label node edge-gateway-01 node-type=edge-gateway\n",
    "# kubectl label node edge-gateway-01 region=factory-floor-1\n",
    "```\n",
    "\n",
    "### 19.2.3 Data Synchronization Patterns\n",
    "\n",
    "**Pattern 1: Event Sourcing with Conflict Resolution:**\n",
    "Edge devices generate events that must eventually reconcile with cloud state. Conflict-free Replicated Data Types (CRDTs) enable eventual consistency without coordination.\n",
    "\n",
    "**Pattern 2: Delta Sync:**\n",
    "Instead of transmitting full state, transmit only changes (deltas) since last sync. Requires versioning or timestamp tracking.\n",
    "\n",
    "**Pattern 3: Tiered Storage:**\n",
    "Hot data on edge (last 24 hours), warm data on regional edge (last 30 days), cold data in central cloud (archive). Automated lifecycle policies move data based on age and access patterns.\n",
    "\n",
    "**Architecture Diagram:**\n",
    "\n",
    "```\n",
    "[Far Edge Sensors] --(MQTT)--> [Near Edge Gateway] --(AMQP/HTTPS)--> [Cloud IoT Hub]\n",
    "      |                              |                              |\n",
    "  Local Action               Local Inference              Global Aggregation\n",
    "  (Real-time)               (Minutes-Hours)              (Days-Months)\n",
    "      |                              |                              |\n",
    "  TinyDB (RAM)                SQLite (SSD)                 DynamoDB/BigQuery\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 19.3 Primary Use Cases and Implementation Patterns\n",
    "\n",
    "Edge computing solves specific problems where cloud alone falls short. Three dominant use cases demonstrate the architecture in practice.\n",
    "\n",
    "### 19.3.1 Industrial IoT (IIoT) and Smart Manufacturing\n",
    "\n",
    "**Scenario:**\n",
    "A manufacturing plant monitors 500 machines for predictive maintenance. Each machine has vibration, temperature, and pressure sensors. The goal is to detect anomalies indicating impending failure before breakdowns occur.\n",
    "\n",
    "**Architecture:**\n",
    "- **Far Edge:** Sensors on each machine sample at 10 kHz, performing initial signal processing (Fast Fourier Transform) to extract features\n",
    "- **Near Edge:** Gateway server on factory floor runs ML model (trained in cloud) to detect anomalies, triggering alerts within 50 ms\n",
    "- **Cloud:** Aggregates anomaly reports across 50 factories, retrains models monthly, provides dashboards for maintenance planning\n",
    "\n",
    "**Implementation: AWS IoT Greengrass for Predictive Maintenance:**\n",
    "\n",
    "```python\n",
    "# Greengrass Lambda function running on edge gateway\n",
    "import greengrasssdk\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "\n",
    "# Initialize\n",
    "gg_client = greengrasssdk.client('iot-data')\n",
    "model = tf.lite.Interpreter(model_path='/opt/ml/model.tflite')\n",
    "model.allocate_tensors()\n",
    "\n",
    "# Ring buffer for time-series window\n",
    "window_size = 100\n",
    "data_buffer = {\n",
    "    'vibration': deque(maxlen=window_size),\n",
    "    'temperature': deque(maxlen=window_size)\n",
    "}\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"\n",
    "    Process incoming sensor data from local MQTT broker\n",
    "    Event structure: {'machine_id': 'M-101', 'vibration': 0.45, 'temperature': 78.2}\n",
    "    \"\"\"\n",
    "    machine_id = event['machine_id']\n",
    "    \n",
    "    # Append to buffer\n",
    "    data_buffer['vibration'].append(event['vibration'])\n",
    "    data_buffer['temperature'].append(event['temperature'])\n",
    "    \n",
    "    # Wait for full window\n",
    "    if len(data_buffer['vibration']) < window_size:\n",
    "        return\n",
    "    \n",
    "    # Prepare input tensor\n",
    "    input_data = np.array([\n",
    "        list(data_buffer['vibration']),\n",
    "        list(data_buffer['temperature'])\n",
    "    ], dtype=np.float32).T.reshape(1, window_size, 2)\n",
    "    \n",
    "    # Run inference\n",
    "    input_details = model.get_input_details()\n",
    "    output_details = model.get_output_details()\n",
    "    model.set_tensor(input_details[0]['index'], input_data)\n",
    "    model.invoke()\n",
    "    prediction = model.get_tensor(output_details[0]['index'])[0]\n",
    "    \n",
    "    # prediction: [normal_prob, anomaly_prob]\n",
    "    anomaly_score = prediction[1]\n",
    "    \n",
    "    if anomaly_score > 0.8:\n",
    "        # CRITICAL: Trigger immediate local alert (factory floor display)\n",
    "        gg_client.publish(\n",
    "            topic='factory/alerts/critical',\n",
    "            payload=json.dumps({\n",
    "                'machine_id': machine_id,\n",
    "                'anomaly_score': float(anomaly_score),\n",
    "                'timestamp': event['timestamp'],\n",
    "                'recommendation': 'SCHEDULE_MAINTENANCE_IMMEDIATELY'\n",
    "            })\n",
    "        )\n",
    "        \n",
    "        # Also send to cloud for global tracking (will queue if offline)\n",
    "        gg_client.publish(\n",
    "            topic='cloud/factory/anomaly',\n",
    "            payload=json.dumps({\n",
    "                'factory_id': 'FACTORY-01',\n",
    "                'machine_id': machine_id,\n",
    "                'anomaly_score': float(anomaly_score),\n",
    "                'sensor_snapshot': {\n",
    "                    'vibration': list(data_buffer['vibration'])[-10:],\n",
    "                    'temperature': list(data_buffer['temperature'])[-10:]\n",
    "                }\n",
    "            })\n",
    "        )\n",
    "    else:\n",
    "        # Send health heartbeat (less frequent)\n",
    "        gg_client.publish(\n",
    "            topic='cloud/factory/heartbeat',\n",
    "            payload=json.dumps({\n",
    "                'machine_id': machine_id,\n",
    "                'health_score': float(prediction[0])\n",
    "            })\n",
    "        )\n",
    "```\n",
    "\n",
    "**Terraform: AWS IoT Greengrass Group Definition:**\n",
    "\n",
    "```hcl\n",
    "resource \"aws_iot_thing\" \"edge_gateway\" {\n",
    "  name = \"factory-01-gateway\"\n",
    "  \n",
    "  attributes = {\n",
    "    location = \"factory-floor-1\"\n",
    "    type     = \"greengrass-core\"\n",
    "  }\n",
    "}\n",
    "\n",
    "resource \"aws_iot_thing_group\" \"factory_fleet\" {\n",
    "  name = \"factory-01-devices\"\n",
    "  \n",
    "  properties {\n",
    "    attribute_payload {\n",
    "      attributes = {\n",
    "        factory_id = \"FACTORY-01\"\n",
    "        region     = \"midwest\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "resource \"aws_iot_topic_rule\" \"anomaly_to_cloud\" {\n",
    "  name        = \"AnomalyToCloudProcessing\"\n",
    "  description = \"Forward anomaly events to cloud processing pipeline\"\n",
    "  enabled     = true\n",
    "  \n",
    "  sql         = \"SELECT * FROM 'cloud/factory/anomaly'\"\n",
    "  sql_version = \"2016-03-23\"\n",
    "  \n",
    "  lambda {\n",
    "    function_arn = aws_lambda_function.anomaly_processor.arn\n",
    "  }\n",
    "}\n",
    "\n",
    "resource \"aws_greengrass_group\" \"factory_edge\" {\n",
    "  name = \"factory-01-edge-group\"\n",
    "  \n",
    "  role_arn = aws_iam_role.greengrass_service_role.arn\n",
    "  \n",
    "  default_function_definition_version_arn = aws_greengrass_function_definition_version.ml_inference.arn\n",
    "}\n",
    "\n",
    "resource \"aws_greengrass_function_definition_version\" \"ml_inference\" {\n",
    "  function_definition_id = aws_greengrass_function_definition.main.id\n",
    "  \n",
    "  function {\n",
    "    id            = \"predictive-maintenance-ml\"\n",
    "    function_arn  = aws_lambda_function.edge_inference.arn\n",
    "    function_name = \"edge-predictive-maintenance\"\n",
    "    \n",
    "    run_as_config {\n",
    "      uid = 1000\n",
    "      gid = 1000\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### 19.3.2 Real-Time Video Analytics\n",
    "\n",
    "**Scenario:**\n",
    "A retail chain wants to analyze customer behavior in 500 stores using existing security cameras. Requirements: real-time occupancy counting, queue length detection, and heat map generation.\n",
    "\n",
    "**Architecture:**\n",
    "- **Edge:** NVIDIA Jetson Nano or equivalent GPU device per store runs object detection model\n",
    "- **Processing:** 1080p video stream processed locally at 15 FPS, only metadata (counts, coordinates) uploaded\n",
    "- **Cloud:** Aggregates metadata across stores, generates daily reports, retrains models with new product layouts\n",
    "\n",
    "**Bandwidth Savings Calculation:**\n",
    "- Raw video: 1080p @ 15 FPS = ~15 Mbps per camera\n",
    "- Metadata only: ~50 Kbps per camera (counts + bounding boxes)\n",
    "- **Reduction: 99.7%** bandwidth savings\n",
    "\n",
    "**Implementation: Docker Container for Edge Inference:**\n",
    "\n",
    "```dockerfile\n",
    "# Dockerfile for edge video analytics\n",
    "FROM nvcr.io/nvidia/l4t-pytorch:r35.1.0-pth1.12-py3\n",
    "\n",
    "# Install OpenCV and dependencies\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    libopencv-dev \\\n",
    "    python3-opencv \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Install Python packages\n",
    "RUN pip3 install \\\n",
    "    paho-mqtt \\\n",
    "    redis \\\n",
    "    numpy\n",
    "\n",
    "# Copy inference code\n",
    "COPY inference.py /app/inference.py\n",
    "COPY models/yolov8n.pt /app/models/\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Entry point\n",
    "CMD [\"python3\", \"inference.py\"]\n",
    "```\n",
    "\n",
    "```python\n",
    "# inference.py - Edge video analytics\n",
    "import cv2\n",
    "import paho.mqtt.client as mqtt\n",
    "import json\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class EdgeVideoAnalytics:\n",
    "    def __init__(self, camera_id, mqtt_broker, model_path):\n",
    "        self.camera_id = camera_id\n",
    "        self.model = YOLO(model_path)\n",
    "        \n",
    "        # Connect to local MQTT broker (Greengrass or Mosquitto)\n",
    "        self.mqtt_client = mqtt.Client(client_id=f\"edge-{camera_id}\")\n",
    "        self.mqtt_client.connect(mqtt_broker, 1883, 60)\n",
    "        self.mqtt_client.loop_start()\n",
    "        \n",
    "        # Configuration\n",
    "        self.frame_skip = 2  # Process every 2nd frame\n",
    "        self.confidence_threshold = 0.5\n",
    "        self.classes_of_interest = [0]  # 0 = person in COCO dataset\n",
    "        \n",
    "    def process_stream(self, rtsp_url):\n",
    "        cap = cv2.VideoCapture(rtsp_url)\n",
    "        frame_count = 0\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Skip frames for performance\n",
    "            if frame_count % self.frame_skip != 0:\n",
    "                continue\n",
    "            \n",
    "            # Run inference\n",
    "            results = self.model(\n",
    "                frame,\n",
    "                classes=self.classes_of_interest,\n",
    "                conf=self.confidence_threshold,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Extract metadata\n",
    "            detections = []\n",
    "            for r in results:\n",
    "                for box in r.boxes:\n",
    "                    detections.append({\n",
    "                        'class': int(box.cls[0]),\n",
    "                        'confidence': float(box.conf[0]),\n",
    "                        'bbox': box.xywh[0].tolist()  # [x, y, width, height]\n",
    "                    })\n",
    "            \n",
    "            # Generate analytics\n",
    "            people_count = len(detections)\n",
    "            \n",
    "            # Queue detection (simple: people in bottom third of frame)\n",
    "            queue_count = len([\n",
    "                d for d in detections \n",
    "                if d['bbox'][1] > frame.shape[0] * 0.66  # y > 2/3 height\n",
    "            ])\n",
    "            \n",
    "            # Publish to local MQTT (and sync to cloud)\n",
    "            payload = {\n",
    "                'camera_id': self.camera_id,\n",
    "                'timestamp': time.time(),\n",
    "                'people_count': people_count,\n",
    "                'queue_length': queue_count,\n",
    "                'detections': detections[:10]  # Limit payload size\n",
    "            }\n",
    "            \n",
    "            self.mqtt_client.publish(\n",
    "                topic='retail/analytics/metadata',\n",
    "                payload=json.dumps(payload),\n",
    "                qos=1\n",
    "            )\n",
    "            \n",
    "            # Optional: Draw and display locally (for debugging)\n",
    "            # annotated_frame = results[0].plot()\n",
    "            # cv2.imshow('Edge Analytics', annotated_frame)\n",
    "            \n",
    "        cap.release()\n",
    "\n",
    "# Run\n",
    "analytics = EdgeVideoAnalytics(\n",
    "    camera_id='STORE-001-CAM-05',\n",
    "    mqtt_broker='localhost',  # Local Greengrass broker\n",
    "    model_path='/app/models/yolov8n.pt'\n",
    ")\n",
    "analytics.process_stream('rtsp://admin:pass@192.168.1.100:554/stream1')\n",
    "```\n",
    "\n",
    "### 19.3.3 Content Delivery and Edge Caching\n",
    "\n",
    "**Scenario:**\n",
    "A media company serves live sports streams to 10 million concurrent viewers. Viewers expect sub-second startup time and no buffering.\n",
    "\n",
    "**Architecture:**\n",
    "- **Origin Cloud:** Live encoder in cloud region (aws, gcp)\n",
    "- **CDN Edge:** Content cached at 200+ Points of Presence globally (CloudFront, Akamai, Cloudflare)\n",
    "- **Edge Compute:** Origin shield and manifest manipulation at edge for personalized ad insertion\n",
    "\n",
    "**Implementation: CloudFront Functions for Edge Logic:**\n",
    "\n",
    "```javascript\n",
    "// CloudFront Function: Edge-based geo-blocking and personalization\n",
    "function handler(event) {\n",
    "    var request = event.request;\n",
    "    var response = event.response;\n",
    "    \n",
    "    // Get viewer country from CloudFront headers\n",
    "    var country = request.headers['cloudfront-viewer-country'] ? \n",
    "                  request.headers['cloudfront-viewer-country'].value : 'US';\n",
    "    \n",
    "    // Geo-blocking for licensing restrictions\n",
    "    var blockedCountries = ['XX', 'YY'];  // Example country codes\n",
    "    \n",
    "    if (blockedCountries.includes(country)) {\n",
    "        return {\n",
    "            statusCode: 403,\n",
    "            statusDescription: 'Forbidden',\n",
    "            headers: {\n",
    "                'content-type': { value: 'application/json' }\n",
    "            },\n",
    "            body: JSON.stringify({\n",
    "                error: 'Content not available in your region',\n",
    "                code: 'GEO_BLOCKED'\n",
    "            })\n",
    "        };\n",
    "    }\n",
    "    \n",
    "    // Continue with request\n",
    "    return request;\n",
    "}\n",
    "\n",
    "// Edge logic for ad insertion (modify m3u8 manifest)\n",
    "function modifyManifest(event) {\n",
    "    var response = event.response;\n",
    "    var uri = request.uri;\n",
    "    \n",
    "    // If requesting master manifest\n",
    "    if (uri.endsWith('.m3u8')) {\n",
    "        var body = response.body;\n",
    "        \n",
    "        // Insert edge-determined ad break based on viewer segment\n",
    "        var adTag = '#EXT-X-DATERANGE:ID=\"ad-' + Date.now() + \n",
    "                    '\",CLASS=\"com.apple.hls.interstitial\",START-DATE=\"' + \n",
    "                    new Date().toISOString() + '\",DURATION=30.0';\n",
    "        \n",
    "        body = body.replace('#EXT-X-PLAYLIST-TYPE:EVENT', \n",
    "                           '#EXT-X-PLAYLIST-TYPE:EVENT\\n' + adTag);\n",
    "        \n",
    "        response.body = body;\n",
    "    }\n",
    "    \n",
    "    return response;\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 19.4 Edge Platforms: Managed Services for Fleet Management\n",
    "\n",
    "Managing thousands of edge devices requires platforms that handle provisioning, deployment, monitoring, and updates at scale.\n",
    "\n",
    "### 19.4.1 AWS IoT Greengrass\n",
    "\n",
    "**Overview:**\n",
    "AWS IoT Greengrass extends AWS services to edge devices, enabling local compute, messaging, and sync capabilities. Devices run the Greengrass Core software, which manages local Lambda functions, Docker containers, and native processes.\n",
    "\n",
    "**Key Features:**\n",
    "- **Local Lambda execution:** Run Lambda functions locally with same programming model\n",
    "- **Local messaging:** MQTT broker for device-to-device communication\n",
    "- **Stream Manager:** Managed data streams to cloud (Kinesis, IoT Analytics)\n",
    "- **Secrets Manager integration:** Securely deploy credentials to edge\n",
    "- **Over-the-air (OTA) updates:** Fleet updates via AWS Jobs\n",
    "\n",
    "**Deployment Workflow:**\n",
    "\n",
    "1. **Develop:** Write Lambda function or Docker container\n",
    "2. **Package:** Create Greengrass component (recipe + artifacts)\n",
    "3. **Deploy:** Create deployment targeting thing group\n",
    "4. **Monitor:** Logs shipped to CloudWatch; metrics to IoT FleetWise\n",
    "\n",
    "**Terraform: Complete Greengrass Deployment:**\n",
    "\n",
    "```hcl\n",
    "# Greengrass V2 Component Definition\n",
    "resource \"aws_greengrassv2_component_version\" \"sensor_processor\" {\n",
    "  component_name = \"com.company.sensors.processor\"\n",
    "  \n",
    "  inline_recipe = jsonencode({\n",
    "    RecipeFormatVersion = \"2020-01-25\"\n",
    "    ComponentName       = \"SensorProcessor\"\n",
    "    ComponentVersion    = \"2.0.0\"\n",
    "    ComponentDescription = \"Processes sensor data at edge\"\n",
    "    ComponentPublisher  = \"Company\"\n",
    "    ComponentConfiguration = {\n",
    "      DefaultConfiguration = {\n",
    "        sampling_interval_ms = 1000\n",
    "        buffer_size          = 100\n",
    "        cloud_sync_topic     = \"cloud/sensors/data\"\n",
    "      }\n",
    "    }\n",
    "    Manifests = [{\n",
    "      Platform = {\n",
    "        os   = \"linux\"\n",
    "        arch = \"amd64\"\n",
    "      }\n",
    "      Lifecycle = {\n",
    "        Run = \"python3 -u {artifacts:path}/sensor_processor.py\"\n",
    "      }\n",
    "      Artifacts = [{\n",
    "        Uri = \"s3://${aws_s3_bucket.greengrass_artifacts.bucket}/components/sensor_processor.py\"\n",
    "        Permission = \"READ\"\n",
    "      }]\n",
    "    }]\n",
    "  })\n",
    "}\n",
    "\n",
    "# Deployment to fleet\n",
    "resource \"aws_greengrassv2_deployment\" \"factory_fleet\" {\n",
    "  components = {\n",
    "    \"com.company.sensors.processor\" = {\n",
    "      component_version = aws_greengrassv2_component_version.sensor_processor.component_version\n",
    "      configuration_update = jsonencode({\n",
    "        sampling_interval_ms = 500\n",
    "      })\n",
    "    }\n",
    "    \n",
    "    \"aws.greengrass.Nucleus\" = {\n",
    "      component_version = \"2.11.0\"\n",
    "      configuration_update = jsonencode({\n",
    "        logging = {\n",
    "          level = \"INFO\"\n",
    "        }\n",
    "      })\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  iot_job_configuration = {\n",
    "    job_executions_rollout_config = {\n",
    "      exponential_rate = {\n",
    "        base_rate_per_minute = 10\n",
    "        increment_factor      = 2.0\n",
    "        rate_increase_criteria = {\n",
    "          number_of_notified things = 100\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  target_arn = aws_iot_thing_group.factory_fleet.arn\n",
    "}\n",
    "```\n",
    "\n",
    "### 19.4.2 Azure IoT Edge\n",
    "\n",
    "**Overview:**\n",
    "Azure IoT Edge deploys containerized modules to edge devices, managed via IoT Hub. It integrates tightly with Azure services (Stream Analytics, Cognitive Services) as pre-built modules.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **IoT Hub:** Cloud gateway for device management and routing\n",
    "- **Edge Modules:** Docker containers running on edge device\n",
    "- **Edge Runtime:** Manages module lifecycle and communication\n",
    "- **Deployment Manifest:** JSON defining desired modules and routes\n",
    "\n",
    "**Deployment Manifest Example:**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"modulesContent\": {\n",
    "    \"$edgeAgent\": {\n",
    "      \"properties.desired\": {\n",
    "        \"schemaVersion\": \"1.1\",\n",
    "        \"runtime\": {\n",
    "          \"type\": \"docker\",\n",
    "          \"settings\": {\n",
    "            \"minDockerVersion\": \"v1.25\",\n",
    "            \"loggingOptions\": \"\"\n",
    "          }\n",
    "        },\n",
    "        \"systemModules\": {\n",
    "          \"edgeAgent\": {\n",
    "            \"type\": \"docker\",\n",
    "            \"settings\": {\n",
    "              \"image\": \"mcr.microsoft.com/azureiotedge-agent:1.4\",\n",
    "              \"createOptions\": \"{}\"\n",
    "            }\n",
    "          },\n",
    "          \"edgeHub\": {\n",
    "            \"type\": \"docker\",\n",
    "            \"settings\": {\n",
    "              \"image\": \"mcr.microsoft.com/azureiotedge-hub:1.4\",\n",
    "              \"createOptions\": \"{\\\"HostConfig\\\":{\\\"PortBindings\\\":{\\\"8883/tcp\\\":[{\\\"HostPort\\\":\\\"8883\\\"}],\\\"443/tcp\\\":[{\\\"HostPort\\\":\\\"443\\\"}]}}}\"\n",
    "            },\n",
    "            \"env\": {\n",
    "              \"OptimizeForPerformance\": { \"value\": \"true\" }\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        \"modules\": {\n",
    "          \"TemperatureSensor\": {\n",
    "            \"version\": \"1.0\",\n",
    "            \"type\": \"docker\",\n",
    "            \"status\": \"running\",\n",
    "            \"restartPolicy\": \"always\",\n",
    "            \"settings\": {\n",
    "              \"image\": \"${CONTAINER_REGISTRY}/temperature-sensor:v1.0\",\n",
    "              \"createOptions\": \"{}\"\n",
    "            }\n",
    "          },\n",
    "          \"AnomalyDetection\": {\n",
    "            \"version\": \"1.0\",\n",
    "            \"type\": \"docker\",\n",
    "            \"status\": \"running\",\n",
    "            \"restartPolicy\": \"on-failure\",\n",
    "            \"env\": {\n",
    "              \"MODEL_URL\": { \"value\": \"https://storageaccount.blob.core.windows.net/models/anomaly.onnx\" }\n",
    "            },\n",
    "            \"settings\": {\n",
    "              \"image\": \"${CONTAINER_REGISTRY}/anomaly-module:v2.1\",\n",
    "              \"createOptions\": \"{\\\"HostConfig\\\":{\\\"Memory\\\":536870912}}\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"$edgeHub\": {\n",
    "      \"properties.desired\": {\n",
    "        \"schemaVersion\": \"1.1\",\n",
    "        \"routes\": {\n",
    "          \"sensorToAnomaly\": \"FROM /messages/modules/TemperatureSensor/outputs/* INTO BrokeredEndpoint(\\\"/modules/AnomalyDetection/inputs/input1\\\")\",\n",
    "          \"anomalyToCloud\": \"FROM /messages/modules/AnomalyDetection/outputs/* INTO $upstream\"\n",
    "        },\n",
    "        \"storeAndForwardConfiguration\": {\n",
    "          \"timeToLiveSecs\": 7200\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### 19.4.3 Google Anthos and Edge Kubernetes\n",
    "\n",
    "**Overview:**\n",
    "Anthos extends GKE (Google Kubernetes Engine) to on-premises and edge locations. For edge scenarios, Anthos clusters run on minimal hardware (single-node deployments) and maintain connectivity to the Google Cloud control plane.\n",
    "\n",
    "**Architecture:**\n",
    "- **Anthos Clusters:** Kubernetes clusters running on edge hardware\n",
    "- **Anthos Config Management:** GitOps-based configuration sync\n",
    "- **Connect Agent:** Secure tunnel to Google Cloud for management\n",
    "\n",
    "**Key Advantage:** Consistent Kubernetes API across cloud and edge\u2014applications can be deployed identically.\n",
    "\n",
    "**Configuration: Anthos Edge Deployment:**\n",
    "\n",
    "```yaml\n",
    "# Anthos Config Management: ClusterSelector for edge clusters\n",
    "apiVersion: configmanagement.gke.io/v1\n",
    "kind: ClusterSelector\n",
    "metadata:\n",
    "  name: edge-factories-selector\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      env: edge\n",
    "      type: factory\n",
    "---\n",
    "# Namespace for edge application\n",
    "apiVersion: v1\n",
    "kind: Namespace\n",
    "metadata:\n",
    "  name: factory-processing\n",
    "  labels:\n",
    "    configsync.gke.io/cluster-name-selector: edge-factories-selector\n",
    "---\n",
    "# Deployment tailored for edge resources\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: edge-processor\n",
    "  namespace: factory-processing\n",
    "spec:\n",
    "  replicas: 1  # Single replica for single-node edge\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: edge-processor\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: edge-processor\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: processor\n",
    "          image: gcr.io/project-id/edge-processor:v3.2\n",
    "          resources:\n",
    "            limits:\n",
    "              memory: \"1Gi\"\n",
    "              cpu: \"500m\"\n",
    "            requests:\n",
    "              memory: \"512Mi\"\n",
    "              cpu: \"250m\"\n",
    "          env:\n",
    "            - name: GOOGLE_CLOUD_PROJECT\n",
    "              valueFrom:\n",
    "                fieldRef:\n",
    "                  fieldPath: metadata.namespace\n",
    "            - name: EDGE_LOCATION\n",
    "              valueFrom:\n",
    "                fieldRef:\n",
    "                  fieldPath: spec.nodeName\n",
    "          volumeMounts:\n",
    "            - name: local-storage\n",
    "              mountPath: /data\n",
    "      volumes:\n",
    "        - name: local-storage\n",
    "          hostPath:\n",
    "            path: /mnt/edge-data\n",
    "            type: DirectoryOrCreate\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 19.5 Security at the Edge\n",
    "\n",
    "Edge environments introduce unique security challenges: devices are physically accessible, network perimeters are porous, and centralized security tooling cannot inspect traffic in real-time.\n",
    "\n",
    "### 19.5.1 Zero Trust for Edge\n",
    "\n",
    "**Principles:**\n",
    "1. **Device Identity:** Every edge device has a hardware-backed identity (TPM, secure enclave)\n",
    "2. **Mutual TLS:** All communication authenticated and encrypted\n",
    "3. **Least Privilege:** Devices access only resources they need\n",
    "4. **Continuous Verification:** Device health attestation before granting access\n",
    "\n",
    "**Implementation: AWS IoT Device Defender and Certificate Management:**\n",
    "\n",
    "```hcl\n",
    "# IoT Thing with certificate-based authentication\n",
    "resource \"aws_iot_thing\" \"edge_device\" {\n",
    "  name = \"edge-gateway-${var.device_id}\"\n",
    "  \n",
    "  attributes = {\n",
    "    device_id = var.device_id\n",
    "    location  = var.location\n",
    "  }\n",
    "}\n",
    "\n",
    "resource \"aws_iot_certificate\" \"edge_cert\" {\n",
    "  active = true\n",
    "}\n",
    "\n",
    "resource \"aws_iot_thing_principal_attachment\" \"attach_cert\" {\n",
    "  thing      = aws_iot_thing.edge_device.name\n",
    "  principal  = aws_iot_certificate.edge_cert.arn\n",
    "}\n",
    "\n",
    "# Restrictive IoT Policy\n",
    "resource \"aws_iot_policy\" \"edge_policy\" {\n",
    "  name = \"edge-device-policy-${var.device_id}\"\n",
    "  \n",
    "  policy = jsonencode({\n",
    "    Version = \"2012-10-17\"\n",
    "    Statement = [\n",
    "      {\n",
    "        Effect = \"Allow\"\n",
    "        Action = [\n",
    "          \"iot:Connect\"\n",
    "        ]\n",
    "        Resource = [\n",
    "          \"arn:aws:iot:${var.region}:${var.account_id}:client/edge-${var.device_id}\"\n",
    "        ]\n",
    "        Condition = {\n",
    "          Bool = {\n",
    "            \"iot:Connection.Thing.IsAttached\" = \"true\"\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        Effect = \"Allow\"\n",
    "        Action = [\n",
    "          \"iot:Publish\"\n",
    "        ]\n",
    "        Resource = [\n",
    "          \"arn:aws:iot:${var.region}:${var.account_id}:topic/factory/${var.device_id}/*\",\n",
    "          \"arn:aws:iot:${var.region}:${var.account_id}:topic/$aws/things/edge-${var.device_id}/*\"\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        Effect = \"Allow\"\n",
    "        Action = [\n",
    "          \"iot:Subscribe\"\n",
    "        ]\n",
    "        Resource = [\n",
    "          \"arn:aws:iot:${var.region}:${var.account_id}:topicfilter/factory/${var.device_id}/commands\"\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  })\n",
    "}\n",
    "\n",
    "# Device Defender audit\n",
    "resource \"aws_iot_role_alias\" \"defender\" {\n",
    "  alias    = \"DefenderAuditRole\"\n",
    "  role_arn = aws_iam_role.device_defender.arn\n",
    "}\n",
    "\n",
    "# Security profile for anomaly detection\n",
    "resource \"aws_iot_security_profile\" \"edge_security\" {\n",
    "  name = \"edge-device-security-profile\"\n",
    "  \n",
    "  target_arns = [\n",
    "    \"arn:aws:iot:${var.region}:${var.account_id}:all/things\"\n",
    "  ]\n",
    "  \n",
    "  behaviors {\n",
    "    name                = \"max-message-size\"\n",
    "    metric              = \"aws:message-byte-size\"\n",
    "    comparison_operator = \"greater-than\"\n",
    "    value {\n",
    "      count = 8192  # Alert if messages exceed 8KB\n",
    "    }\n",
    "    \n",
    "    name                = \"auth-failures\"\n",
    "    metric              = \"aws:num-authorization-failures\"\n",
    "    comparison_operator = \"greater-than\"\n",
    "    value {\n",
    "      count = 5\n",
    "    }\n",
    "    duration_seconds = 300  # In 5 minutes\n",
    "  }\n",
    "  \n",
    "  alert_targets {\n",
    "    alert_target_arn = aws_sns_topic.security_alerts.arn\n",
    "    role_arn         = aws_iam_role.device_defender.arn\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### 19.5.2 Physical Security and Secure Boot\n",
    "\n",
    "**Chain of Trust:**\n",
    "1. **Hardware Root of Trust:** TPM (Trusted Platform Module) or HSM (Hardware Security Module) embedded in device\n",
    "2. **Secure Boot:** Device firmware validates bootloader signature before execution\n",
    "3. **Measured Boot:** Each boot stage records measurements (hashes) in TPM\n",
    "4. **Remote Attestation:** Device proves its software state to cloud before accessing resources\n",
    "\n",
    "**Implementation Consideration:**\n",
    "Edge devices should use hardware security modules to store private keys, preventing extraction even if the device is physically stolen. AWS IoT Greengrass and Azure IoT Edge support PKCS#11 integration for HSM-backed key storage.\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary and Transition to Chapter 20\n",
    "\n",
    "This chapter extended the cloud paradigm to the network edge, addressing the fundamental constraints of latency, bandwidth, and connectivity that limit purely centralized architectures. We explored the cloud-edge continuum, defining architectural layers from far-edge embedded devices (microcontrollers, sensors) through near-edge gateways (industrial PCs, retail servers) to regional edge locations (CDN nodes, metro data centers) and finally to the central cloud. This layered approach matches workload placement to technical requirements: sub-millisecond control loops execute on far-edge hardware, local inference and aggregation occur on near-edge gateways, and model training and global analytics reside in the central cloud.\n",
    "\n",
    "We examined three primary use cases demonstrating edge architecture in practice: Industrial IoT for predictive maintenance, where edge ML inference detects anomalies in milliseconds while cloud analytics optimize models across factories; real-time video analytics, where edge processing reduces bandwidth by 99% by transmitting only metadata; and content delivery, where edge caching ensures sub-second startup times for global audiences.\n",
    "\n",
    "Platform selection requires evaluating the ecosystem: AWS IoT Greengrass for deep AWS integration, Azure IoT Edge for Azure-centric environments with pre-built cognitive service modules, and Google Anthos for Kubernetes-consistent deployments across cloud and edge. Each provides fleet management, OTA updates, and local compute orchestration at scale.\n",
    "\n",
    "Security at the edge demands zero-trust principles: hardware-backed device identities, mutual TLS for all communication, and continuous attestation. Unlike centralized data centers, edge devices are physically accessible, requiring secure boot chains and hardware security modules to protect cryptographic material.\n",
    "\n",
    "As edge devices proliferate\u2014driven by IoT adoption, 5G deployment, and autonomous systems\u2014they generate unprecedented volumes of data and decision-making requirements. Artificial Intelligence becomes essential for processing this data and enabling autonomous operation. In **Chapter 20: AI-Native Cloud Computing**, we will explore how AI transforms from an add-on service to a foundational cloud capability. You will learn to architect AI-native applications that leverage specialized hardware (GPUs, TPUs, Inferentia), implement MLOps pipelines for continuous model training and deployment, integrate vector databases for semantic search and retrieval-augmented generation (RAG), and optimize inference costs through model compression and hardware acceleration. We will examine how cloud providers are building AI infrastructure from silicon to services, and how to leverage these capabilities to build intelligent, autonomous systems that operate across the cloud-edge continuum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='../6. cloud_financial_management_and_operations/18. cloud_observability_and_site_reliability_engineering.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='20. ai_native_cloud_computing.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}