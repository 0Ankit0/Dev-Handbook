{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 14: Securing Cloud Infrastructure**\n",
    "\n",
    "## Introduction: Defense in Depth for the Cloud Native Era\n",
    "\n",
    "While Chapter 13 established identity as the primary security perimeter, robust cloud security requires comprehensive protection of the underlying infrastructure\u2014compute instances, container orchestration platforms, storage systems, and network configurations that host applications and data. Identity controls determine *who* can access resources, but infrastructure security ensures *what* they access is hardened against exploitation, monitored for anomalies, and resilient against attack.\n",
    "\n",
    "The cloud's programmatic nature creates both opportunities and challenges for infrastructure security. On one hand, infrastructure as code enables security policies to be codified, tested, and enforced before deployment, eliminating the configuration drift that plagues traditional data centers. On the other hand, the speed of cloud provisioning and the complexity of distributed architectures create expansive attack surfaces where misconfigurations\u2014exposed storage buckets, overly permissive security groups, or unpatched container images\u2014can be exploited within minutes of deployment.\n",
    "\n",
    "This chapter implements defense-in-depth strategies across the infrastructure stack. We will architect network security controls that move beyond simple perimeter defense to micro-segmentation, harden compute resources against emerging threats through automated vulnerability management and configuration baselines, protect sensitive data through comprehensive encryption and secrets management, and establish observable security postures through centralized logging, behavioral analytics, and automated remediation. These controls transform the theoretical security architecture of Chapter 12 into operational reality.\n",
    "\n",
    "---\n",
    "\n",
    "## 14.1 Network Security Architecture: Beyond the Perimeter\n",
    "\n",
    "Traditional network security relied on a hard exterior shell with soft interior\u2014once past the firewall, attackers had lateral freedom. Cloud-native network security implements zero-trust networking where every packet is inspected, every connection is authenticated, and segmentation occurs at the workload level.\n",
    "\n",
    "### 14.1.1 Virtual Private Cloud (VPC) Design Patterns\n",
    "\n",
    "**Segmented VPC Architecture:**\n",
    "Isolating workloads by function and sensitivity level prevents lateral movement and limits blast radius.\n",
    "\n",
    "**Terraform Implementation: Multi-Tier VPC with Network Segmentation**\n",
    "\n",
    "```hcl\n",
    "# Comprehensive VPC architecture with security zones\n",
    "module \"vpc\" {\n",
    "  source  = \"terraform-aws-modules/vpc/aws\"\n",
    "  version = \"~> 5.0\"\n",
    "\n",
    "  name = \"production-vpc\"\n",
    "  cidr = \"10.0.0.0/16\"\n",
    "\n",
    "  azs             = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n",
    "  \n",
    "  # Public tier: Load balancers and bastion hosts only\n",
    "  public_subnets  = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"]\n",
    "  \n",
    "  # Private tier: Application workloads\n",
    "  private_subnets = [\"10.0.4.0/24\", \"10.0.5.0/24\", \"10.0.6.0/24\"]\n",
    "  \n",
    "  # Database tier: Highly restricted\n",
    "  database_subnets = [\"10.0.7.0/24\", \"10.0.8.0/24\", \"10.0.9.0/24\"]\n",
    "\n",
    "  # Network ACLs for defense in depth\n",
    "  public_subnet_tags = {\n",
    "    Tier = \"public\"\n",
    "    Compliance = \"standard\"\n",
    "  }\n",
    "  \n",
    "  private_subnet_tags = {\n",
    "    Tier = \"private\"\n",
    "    Compliance = \"sensitive\"\n",
    "  }\n",
    "\n",
    "  database_subnet_tags = {\n",
    "    Tier = \"restricted\"\n",
    "    Compliance = \"critical\"\n",
    "  }\n",
    "\n",
    "  # VPC Flow Logs for traffic analysis\n",
    "  enable_flow_log                      = true\n",
    "  create_flow_log_cloudwatch_iam_role  = true\n",
    "  create_flow_log_cloudwatch_log_group = true\n",
    "  flow_log_max_aggregation_interval    = 60\n",
    "  \n",
    "  # DNS security\n",
    "  enable_dns_hostnames = true\n",
    "  enable_dns_support   = true\n",
    "  \n",
    "  # VPC Endpoints for private AWS service access (no internet traversal)\n",
    "  enable_ec2_endpoint              = true\n",
    "  ec2_endpoint_private_dns_enabled = true\n",
    "  ec2_endpoint_security_group_ids  = [aws_security_group.vpc_endpoints.id]\n",
    "}\n",
    "\n",
    "# Transit Gateway for multi-VPC connectivity with inspection\n",
    "resource \"aws_ec2_transit_gateway\" \"main\" {\n",
    "  description                     = \"Centralized routing hub\"\n",
    "  auto_accept_shared_attachments  = \"disable\"\n",
    "  default_route_table_association = \"disable\"\n",
    "  default_route_table_propagation = \"disable\"\n",
    "  \n",
    "  # Enable appliance mode for stateful inspection\n",
    "  vpn_ecmp_support = \"disable\"\n",
    "  \n",
    "  tags = {\n",
    "    Name = \"security-tgw\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# Transit Gateway Route Table for traffic inspection\n",
    "resource \"aws_ec2_transit_gateway_route_table\" \"inspection\" {\n",
    "  transit_gateway_id = aws_ec2_transit_gateway.main.id\n",
    "  \n",
    "  tags = {\n",
    "    Name = \"inspection-rt\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# Route all inter-VPC traffic through Network Firewall\n",
    "resource \"aws_ec2_transit_gateway_route\" \"to_firewall\" {\n",
    "  destination_cidr_block         = \"10.0.0.0/8\"\n",
    "  transit_gateway_route_table_id = aws_ec2_transit_gateway_route_table.inspection.id\n",
    "  transit_gateway_attachment_id  = aws_ec2_transit_gateway_vpc_attachment.firewall.id\n",
    "}\n",
    "```\n",
    "\n",
    "**Security Controls Implemented:**\n",
    "- **Subnet Isolation:** Database subnets have no internet gateway route, requiring all access through application tier\n",
    "- **DNS Security:** Private DNS ensures internal service names resolve without public internet exposure\n",
    "- **VPC Endpoints:** Private connectivity to AWS services prevents data from traversing public internet\n",
    "- **Transit Gateway:** Centralized routing enables traffic inspection between VPCs without complex peering\n",
    "\n",
    "### 14.1.2 Security Groups and Network ACLs: Stateful vs. Stateless\n",
    "\n",
    "**Security Groups (Stateful):**\n",
    "Operate at the instance level, automatically allowing return traffic. They serve as virtual firewalls controlling inbound and outbound traffic.\n",
    "\n",
    "**Network ACLs (Stateless):**\n",
    "Operate at the subnet level, providing an additional layer of defense. Require explicit rules for both request and response traffic.\n",
    "\n",
    "**Defense in Depth Implementation:**\n",
    "\n",
    "```hcl\n",
    "# Application tier security group - restrictive by default\n",
    "resource \"aws_security_group\" \"application_tier\" {\n",
    "  name_prefix = \"app-tier-\"\n",
    "  description = \"Security group for application servers\"\n",
    "  vpc_id      = module.vpc.vpc_id\n",
    "\n",
    "  # Only accept HTTPS from load balancer\n",
    "  ingress {\n",
    "    description     = \"HTTPS from ALB only\"\n",
    "    from_port       = 443\n",
    "    to_port         = 443\n",
    "    protocol        = \"tcp\"\n",
    "    security_groups = [aws_security_group.alb.id]\n",
    "  }\n",
    "\n",
    "  # Application health checks\n",
    "  ingress {\n",
    "    description = \"Health checks from ALB\"\n",
    "    from_port   = 8080\n",
    "    to_port     = 8080\n",
    "    protocol    = \"tcp\"\n",
    "    security_groups = [aws_security_group.alb.id]\n",
    "  }\n",
    "\n",
    "  # Outbound to database tier only\n",
    "  egress {\n",
    "    description     = \"PostgreSQL to DB tier\"\n",
    "    from_port       = 5432\n",
    "    to_port         = 5432\n",
    "    protocol        = \"tcp\"\n",
    "    cidr_blocks     = [module.vpc.database_subnets_cidr_blocks[0]]  # Specific subnet only\n",
    "  }\n",
    "\n",
    "  # Outbound to AWS APIs via VPC endpoint\n",
    "  egress {\n",
    "    description     = \"HTTPS to VPC endpoints\"\n",
    "    from_port       = 443\n",
    "    to_port         = 443\n",
    "    protocol        = \"tcp\"\n",
    "    prefix_list_ids = [aws_vpc_endpoint.s3.prefix_list_id]\n",
    "  }\n",
    "\n",
    "  tags = {\n",
    "    Name = \"application-tier-sg\"\n",
    "    Tier = \"application\"\n",
    "  }\n",
    "\n",
    "  lifecycle {\n",
    "    create_before_destroy = true\n",
    "  }\n",
    "}\n",
    "\n",
    "# Network ACL for database subnets - additional subnet-level protection\n",
    "resource \"aws_network_acl\" \"database\" {\n",
    "  vpc_id     = module.vpc.vpc_id\n",
    "  subnet_ids = module.vpc.database_subnets\n",
    "\n",
    "  # Explicit deny of common attack ports at subnet level\n",
    "  egress {\n",
    "    protocol   = \"tcp\"\n",
    "    rule_no    = 100\n",
    "    action     = \"deny\"\n",
    "    cidr_block = \"0.0.0.0/0\"\n",
    "    from_port  = 22    # SSH should never leave database tier\n",
    "    to_port    = 22\n",
    "  }\n",
    "\n",
    "  # Allow PostgreSQL from application tier only\n",
    "  ingress {\n",
    "    protocol   = \"tcp\"\n",
    "    rule_no    = 100\n",
    "    action     = \"allow\"\n",
    "    cidr_block = module.vpc.private_subnets_cidr_blocks[0]  # App tier CIDR\n",
    "    from_port  = 5432\n",
    "    to_port    = 5432\n",
    "  }\n",
    "\n",
    "  # Allow return traffic (stateless requirement)\n",
    "  egress {\n",
    "    protocol   = \"tcp\"\n",
    "    rule_no    = 200\n",
    "    action     = \"allow\"\n",
    "    cidr_block = module.vpc.private_subnets_cidr_blocks[0]\n",
    "    from_port  = 1024\n",
    "    to_port    = 65535  # Ephemeral ports\n",
    "  }\n",
    "\n",
    "  # Explicit deny all other ingress\n",
    "  ingress {\n",
    "    protocol   = \"-1\"\n",
    "    rule_no    = 32766\n",
    "    action     = \"deny\"\n",
    "    cidr_block = \"0.0.0.0/0\"\n",
    "    from_port  = 0\n",
    "    to_port    = 0\n",
    "  }\n",
    "\n",
    "  tags = {\n",
    "    Name = \"database-nacl\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Key Security Principles:**\n",
    "- **Security Group References:** Instead of CIDR blocks, reference other security group IDs\u2014if the ALB changes IP, the rule remains valid\n",
    "- **Minimal Outbound:** Application servers can only reach the database subnet on port 5432 and AWS services via VPC endpoints\u2014no general internet access\n",
    "- **NACL as Safety Net:** Even if a security group is misconfigured to allow 0.0.0.0/0, the NACL provides subnet-level blocking\n",
    "\n",
    "### 14.1.3 Web Application Firewall (WAF) and DDoS Protection\n",
    "\n",
    "**AWS WAFv2 with Managed Rules:**\n",
    "\n",
    "```hcl\n",
    "resource \"aws_wafv2_web_acl\" \"main\" {\n",
    "  name        = \"production-protection\"\n",
    "  description = \"WAF rules for production application\"\n",
    "  scope       = \"REGIONAL\"\n",
    "\n",
    "  default_action {\n",
    "    block {}  # Default deny - must explicitly allow\n",
    "  }\n",
    "\n",
    "  # AWS Managed Rules - Core Rule Set (OWASP Top 10)\n",
    "  rule {\n",
    "    name     = \"AWSManagedRulesCommonRuleSet\"\n",
    "    priority = 1\n",
    "\n",
    "    override_action {\n",
    "      none {}\n",
    "    }\n",
    "\n",
    "    statement {\n",
    "      managed_rule_group_statement {\n",
    "        name        = \"AWSManagedRulesCommonRuleSet\"\n",
    "        vendor_name = \"AWS\"\n",
    "        \n",
    "        rule_action_override {\n",
    "          action_to_use {\n",
    "            count {}  # Monitor only for this rule initially\n",
    "          }\n",
    "          name = \"SizeRestrictions_BODY\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    visibility_config {\n",
    "      cloudwatch_metrics_enabled = true\n",
    "      metric_name                = \"AWSManagedRulesCommonRuleSetMetric\"\n",
    "      sampled_requests_enabled   = true\n",
    "    }\n",
    "  }\n",
    "\n",
    "  # Rate Limiting - Prevent brute force and scraping\n",
    "  rule {\n",
    "    name     = \"RateLimitRule\"\n",
    "    priority = 2\n",
    "\n",
    "    action {\n",
    "      block {}\n",
    "    }\n",
    "\n",
    "    statement {\n",
    "      rate_based_statement {\n",
    "        limit              = 2000  # Requests per 5 minutes per IP\n",
    "        aggregate_key_type = \"IP\"\n",
    "        \n",
    "        scope_down_statement {\n",
    "          not_statement {\n",
    "            statement {\n",
    "              ip_set_reference_statement {\n",
    "                arn = aws_wafv2_ip_set.whitelist.arn\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    visibility_config {\n",
    "      cloudwatch_metrics_enabled = true\n",
    "      metric_name                = \"RateLimitRuleMetric\"\n",
    "      sampled_requests_enabled   = true\n",
    "    }\n",
    "  }\n",
    "\n",
    "  # Custom Rule - Block specific attack patterns\n",
    "  rule {\n",
    "    name     = \"BlockBadBots\"\n",
    "    priority = 3\n",
    "\n",
    "    action {\n",
    "      block {}\n",
    "    }\n",
    "\n",
    "    statement {\n",
    "      regex_pattern_set_reference_statement {\n",
    "        arn = aws_wafv2_regex_pattern_set.bad_bots.arn\n",
    "        field_to_match {\n",
    "          single_header {\n",
    "            name = \"user-agent\"\n",
    "          }\n",
    "        }\n",
    "        text_transformation {\n",
    "          priority = 0\n",
    "          type     = \"LOWERCASE\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    visibility_config {\n",
    "      cloudwatch_metrics_enabled = true\n",
    "      metric_name                = \"BlockBadBotsMetric\"\n",
    "      sampled_requests_enabled   = true\n",
    "    }\n",
    "  }\n",
    "\n",
    "  # Geographic blocking\n",
    "  rule {\n",
    "    name     = \"GeoBlockRule\"\n",
    "    priority = 4\n",
    "\n",
    "    action {\n",
    "      block {}\n",
    "    }\n",
    "\n",
    "    statement {\n",
    "      geo_match_statement {\n",
    "        country_codes = [\"KP\", \"IR\", \"SY\", \"CU\"]  # Sanctioned countries\n",
    "      }\n",
    "    }\n",
    "\n",
    "    visibility_config {\n",
    "      cloudwatch_metrics_enabled = true\n",
    "      metric_name                = \"GeoBlockRuleMetric\"\n",
    "      sampled_requests_enabled   = true\n",
    "    }\n",
    "  }\n",
    "\n",
    "  visibility_config {\n",
    "    cloudwatch_metrics_enabled = true\n",
    "    metric_name                = \"production-waf-metric\"\n",
    "    sampled_requests_enabled   = true\n",
    "  }\n",
    "\n",
    "  tags = {\n",
    "    Environment = \"production\"\n",
    "    Compliance  = \"pci-dss\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# Associate WAF with ALB\n",
    "resource \"aws_wafv2_web_acl_association\" \"main\" {\n",
    "  resource_arn = aws_lb.application.arn\n",
    "  web_acl_arn  = aws_wafv2_web_acl.main.arn\n",
    "}\n",
    "\n",
    "# AWS Shield Advanced for DDoS protection\n",
    "resource \"aws_shield_protection\" \"alb\" {\n",
    "  name         = \"alb-shield-protection\"\n",
    "  resource_arn = aws_lb.application.arn\n",
    "  \n",
    "  tags = {\n",
    "    Purpose = \"DDoS-Protection\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Security Capabilities:**\n",
    "- **Virtual Patching:** Block SQL injection and XSS attacks at the edge before they reach application code\n",
    "- **Rate Limiting:** Prevent credential stuffing attacks by limiting requests per IP\n",
    "- **Bot Control:** Distinguish between legitimate crawlers and malicious scanners\n",
    "- **Geofencing:** Block traffic from high-risk geographic regions\n",
    "\n",
    "---\n",
    "\n",
    "## 14.2 Compute Hardening and Vulnerability Management\n",
    "\n",
    "Compute instances\u2014whether EC2, Azure VMs, or GCE instances\u2014require continuous hardening to mitigate vulnerabilities in operating systems, middleware, and application runtimes.\n",
    "\n",
    "### 14.2.1 CIS Benchmark Compliance\n",
    "\n",
    "The Center for Internet Security (CIS) provides prescriptive configuration guidelines (benchmarks) for secure operating system and container configurations.\n",
    "\n",
    "**AWS Systems Manager (SSM) for Automated Hardening:**\n",
    "\n",
    "```yaml\n",
    "# SSM Association to apply CIS Level 1 benchmarks\n",
    "Resources:\n",
    "  CISComplianceAssociation:\n",
    "    Type: AWS::SSM::Association\n",
    "    Properties:\n",
    "      Name: AWS-RunCISBenchmark\n",
    "      Parameters:\n",
    "        benchmark:\n",
    "          - cis\n",
    "        level:\n",
    "          - level-1\n",
    "      Targets:\n",
    "        - Key: tag:ComplianceLevel\n",
    "          Values:\n",
    "            - required\n",
    "      ScheduleExpression: rate(7 days)  # Weekly compliance checks\n",
    "      ComplianceSeverity: HIGH\n",
    "\n",
    "  # Remediation automation for non-compliant instances\n",
    "  RemediationRole:\n",
    "    Type: AWS::IAM::Role\n",
    "    Properties:\n",
    "      AssumeRolePolicyDocument:\n",
    "        Version: '2012-10-17'\n",
    "        Statement:\n",
    "          - Effect: Allow\n",
    "            Principal:\n",
    "              Service: ssm.amazonaws.com\n",
    "            Action: sts:AssumeRole\n",
    "      ManagedPolicyArns:\n",
    "        - arn:aws:iam::aws:policy/service-role/AmazonSSMAutomationRole\n",
    "\n",
    "  # Automation document to remediate common findings\n",
    "  HardeningAutomation:\n",
    "    Type: AWS::SSM::Document\n",
    "    Properties:\n",
    "      DocumentType: Automation\n",
    "      Content:\n",
    "        schemaVersion: '0.3'\n",
    "        description: Remediate CIS violations\n",
    "        parameters:\n",
    "          InstanceId:\n",
    "            type: String\n",
    "        mainSteps:\n",
    "          - name: DisablePasswordAuthentication\n",
    "            action: 'aws:runCommand'\n",
    "            inputs:\n",
    "              DocumentName: AWS-RunShellScript\n",
    "              InstanceIds:\n",
    "                - '{{ InstanceId }}'\n",
    "              Parameters:\n",
    "                commands:\n",
    "                  - sudo sed -i 's/#PasswordAuthentication yes/PasswordAuthentication no/g' /etc/ssh/sshd_config\n",
    "                  - sudo systemctl restart sshd\n",
    "          \n",
    "          - name: EnableAutomaticUpdates\n",
    "            action: 'aws:runCommand'\n",
    "            inputs:\n",
    "              DocumentName: AWS-RunShellScript\n",
    "              InstanceIds:\n",
    "                - '{{ InstanceId }}'\n",
    "              Parameters:\n",
    "                commands:\n",
    "                  - sudo yum install -y yum-cron\n",
    "                  - sudo systemctl enable yum-cron\n",
    "                  - sudo systemctl start yum-cron\n",
    "```\n",
    "\n",
    "**Terraform for AMI Hardening Pipeline:**\n",
    "\n",
    "```hcl\n",
    "# Packer configuration for golden AMI creation with CIS hardening\n",
    "resource \"aws_imagebuilder_component\" \"cis_hardening\" {\n",
    "  name        = \"cis-hardening-component\"\n",
    "  platform    = \"Linux\"\n",
    "  version     = \"1.0.0\"\n",
    "  description = \"Apply CIS Level 1 hardening\"\n",
    "\n",
    "  data = yamlencode({\n",
    "    schemaVersion = 1.0\n",
    "    phases = [{\n",
    "      name = \"build\"\n",
    "      steps = [\n",
    "        {\n",
    "          name = \"InstallCISBenchmark\"\n",
    "          action = \"ExecuteBash\"\n",
    "          inputs = {\n",
    "            commands = [\n",
    "              \"yum install -y scap-security-guide\",\n",
    "              \"oscap xccdf eval --profile xccdf_org.ssgproject.content_profile_cis_level1_server --remediate /usr/share/xml/scap/ssg/content/ssg-amazonlinux2-ds.xml\",\n",
    "              \"oscap xccdf eval --profile xccdf_org.ssgproject.content_profile_cis_level1_server --results /var/log/cis-scan.xml /usr/share/xml/scap/ssg/content/ssg-amazonlinux2-ds.xml\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          name = \"ConfigureCloudWatchAgent\"\n",
    "          action = \"ExecuteBash\"\n",
    "          inputs = {\n",
    "            commands = [\n",
    "              \"cat > /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json << 'EOF'\\n{\\n  \\\"metrics\\\": {\\n    \\\"namespace\\\": \\\"CISHardening\\\",\\n    \\\"metrics_collected\\\": {\\n      \\\"disk\\\": {\\n        \\\"measurement\\\": [\\\"used_percent\\\"],\\n        \\\"resources\\\": [\\\"*\\\"]\\n      }\\n    }\\n  }\\n}\\nEOF\",\n",
    "              \"/opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -s -c file:/opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json\"\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }]\n",
    "  })\n",
    "}\n",
    "\n",
    "# Image Recipe combining base AMI with hardening\n",
    "resource \"aws_imagebuilder_image_recipe\" \"hardened\" {\n",
    "  name         = \"cis-hardened-amazon-linux\"\n",
    "  parent_image = \"arn:aws:imagebuilder:us-east-1:aws:image/amazon-linux-2-x86/x.x.x\"\n",
    "  version      = \"1.0.0\"\n",
    "\n",
    "  component {\n",
    "    component_arn = aws_imagebuilder_component.cis_hardening.arn\n",
    "  }\n",
    "\n",
    "  block_device_mapping {\n",
    "    device_name = \"/dev/xvda\"\n",
    "\n",
    "    ebs {\n",
    "      delete_on_termination = true\n",
    "      volume_size           = 20\n",
    "      volume_type           = \"gp3\"\n",
    "      encrypted             = true\n",
    "      kms_key_id            = aws_kms_key.ebs_encryption.arn\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### 14.2.2 Vulnerability Scanning and Patch Management\n",
    "\n",
    "**Continuous Vulnerability Assessment:**\n",
    "\n",
    "```python\n",
    "# Lambda function triggered by Inspector findings\n",
    "import boto3\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def remediate_vulnerability(event, context):\n",
    "    \"\"\"\n",
    "    Auto-remediate critical vulnerabilities found by Amazon Inspector\n",
    "    \"\"\"\n",
    "    finding = json.loads(event['detail'])\n",
    "    \n",
    "    if finding['severity'] != 'CRITICAL':\n",
    "        return {\"status\": \"skipped\", \"reason\": \"Not critical severity\"}\n",
    "    \n",
    "    instance_id = finding['resources'][0]['id']\n",
    "    vulnerability = finding['title']\n",
    "    cve_id = finding['package_vulnerability_details']['vulnerability_id']\n",
    "    \n",
    "    ssm = boto3.client('ssm')\n",
    "    ec2 = boto3.client('ec2')\n",
    "    \n",
    "    try:\n",
    "        # Create snapshot before patching\n",
    "        volumes = ec2.describe_volumes(\n",
    "            Filters=[\n",
    "                {'Name': 'attachment.instance-id', 'Values': [instance_id]},\n",
    "                {'Name': 'attachment.device', 'Values': ['/dev/xvda']}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        if volumes['Volumes']:\n",
    "            snapshot = ec2.create_snapshot(\n",
    "                VolumeId=volumes['Volumes'][0]['VolumeId'],\n",
    "                Description=f\"Pre-patch snapshot for {cve_id} remediation\"\n",
    "            )\n",
    "            \n",
    "            # Wait for snapshot completion logic here...\n",
    "        \n",
    "        # Apply patch via SSM Run Command\n",
    "        response = ssm.send_command(\n",
    "            InstanceIds=[instance_id],\n",
    "            DocumentName=\"AWS-RunPatchBaseline\",\n",
    "            Parameters={\n",
    "                \"Operation\": [\"Install\"],\n",
    "                \"RebootOption\": [\"RebootIfNeeded\"]\n",
    "            },\n",
    "            Comment=f\"Auto-remediation for {cve_id}\"\n",
    "        )\n",
    "        \n",
    "        # Tag instance for tracking\n",
    "        ec2.create_tags(\n",
    "            Resources=[instance_id],\n",
    "            Tags=[\n",
    "                {'Key': 'LastPatched', 'Value': datetime.utcnow().isoformat()},\n",
    "                {'Key': 'VulnerabilityRemediated', 'Value': cve_id}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"remediated\",\n",
    "            \"instance\": instance_id,\n",
    "            \"command_id\": response['Command']['CommandId']\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Notify security team for manual remediation\n",
    "        sns = boto3.client('sns')\n",
    "        sns.publish(\n",
    "            TopicArn='arn:aws:sns:us-east-1:123456789012:vulnerability-alerts',\n",
    "            Subject=f\"Failed auto-remediation for {instance_id}\",\n",
    "            Message=json.dumps({\n",
    "                'instance': instance_id,\n",
    "                'vulnerability': cve_id,\n",
    "                'error': str(e)\n",
    "            })\n",
    "        )\n",
    "        raise\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 14.3 Container and Serverless Security\n",
    "\n",
    "Containerized workloads require specialized security controls addressing image vulnerabilities, runtime threats, and orchestration platform security.\n",
    "\n",
    "### 14.3.1 Container Image Security\n",
    "\n",
    "**Vulnerability Scanning with Amazon ECR:**\n",
    "\n",
    "```hcl\n",
    "resource \"aws_ecr_repository\" \"application\" {\n",
    "  name                 = \"production-application\"\n",
    "  image_tag_mutability = \"IMMUTABLE\"  # Prevent tag overwriting\n",
    "\n",
    "  image_scanning_configuration {\n",
    "    scan_on_push = true  # Automatic scanning on every push\n",
    "  }\n",
    "\n",
    "  encryption_configuration {\n",
    "    encryption_type = \"KMS\"\n",
    "    kms_key         = aws_kms_key.ecr_encryption.arn\n",
    "  }\n",
    "\n",
    "  force_delete = false\n",
    "}\n",
    "\n",
    "# Lifecycle policy to retain only secure images\n",
    "resource \"aws_ecr_lifecycle_policy\" \"application\" {\n",
    "  repository = aws_ecr_repository.application.name\n",
    "\n",
    "  policy = jsonencode({\n",
    "    rules = [\n",
    "      {\n",
    "        rulePriority = 1\n",
    "        description  = \"Expire images with critical vulnerabilities\"\n",
    "        selection = {\n",
    "          tagStatus   = \"any\"\n",
    "          countType   = \"imageCountMoreThan\"\n",
    "          countNumber = 1\n",
    "        }\n",
    "        action = {\n",
    "          type = \"expire\"\n",
    "        }\n",
    "        # In practice, use Lambda to check scan results before expiring\n",
    "      },\n",
    "      {\n",
    "        rulePriority = 2\n",
    "        description  = \"Keep last 30 production images\"\n",
    "        selection = {\n",
    "          tagStatus     = \"tagged\"\n",
    "          tagPrefixList = [\"prod\"]\n",
    "          countType     = \"imageCountMoreThan\"\n",
    "          countNumber   = 30\n",
    "        }\n",
    "        action = {\n",
    "          type = \"expire\"\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  })\n",
    "}\n",
    "\n",
    "# Lambda to block deployment of vulnerable images\n",
    "resource \"aws_lambda_function\" \"image_scan_remediation\" {\n",
    "  filename      = \"scan_remediation.zip\"\n",
    "  function_name = \"ecr-scan-enforcer\"\n",
    "  role          = aws_iam_role.lambda_role.arn\n",
    "  handler       = \"index.handler\"\n",
    "  runtime       = \"python3.11\"\n",
    "\n",
    "  environment {\n",
    "    variables = {\n",
    "      SEVERITY_THRESHOLD = \"HIGH\"\n",
    "      SLACK_WEBHOOK_URL  = \"https://hooks.slack.com/services/...\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# EventBridge rule to trigger on scan completion\n",
    "resource \"aws_cloudwatch_event_rule\" \"scan_completion\" {\n",
    "  name        = \"ecr-scan-completion\"\n",
    "  description = \"Trigger on ECR image scan completion\"\n",
    "\n",
    "  event_pattern = jsonencode({\n",
    "    source      = [\"aws.ecr\"]\n",
    "    detail-type = [\"ECR Image Scan\"]\n",
    "    detail = {\n",
    "      scan-status = [\"COMPLETE\"]\n",
    "    }\n",
    "  })\n",
    "}\n",
    "\n",
    "resource \"aws_cloudwatch_event_target\" \"lambda_target\" {\n",
    "  rule      = aws_cloudwatch_event_rule.scan_completion.name\n",
    "  target_id = \"ScanRemediation\"\n",
    "  arn       = aws_lambda_function.image_scan_remediation.arn\n",
    "}\n",
    "```\n",
    "\n",
    "**Falco for Runtime Threat Detection (EKS):**\n",
    "\n",
    "```yaml\n",
    "# Falco rules for EKS runtime security\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: falco-rules\n",
    "  namespace: falco\n",
    "data:\n",
    "  custom_rules.yaml: |\n",
    "    - rule: Unauthorized K8s API Access\n",
    "      desc: Detect attempts to access Kubernetes API from unauthorized pods\n",
    "      condition: >\n",
    "        spawned_process and\n",
    "        (proc.name in (kubectl, helm) or\n",
    "         proc.cmdline contains \"kubernetes.default\")\n",
    "      output: >\n",
    "        Unauthorized Kubernetes API access\n",
    "        (user=%user.name command=%proc.cmdline pod=%k8s.pod.name namespace=%k8s.ns.name)\n",
    "      priority: CRITICAL\n",
    "\n",
    "    - rule: Sensitive File Access\n",
    "      desc: Detect access to sensitive files (/etc/shadow, /etc/passwd)\n",
    "      condition: >\n",
    "        open_read and\n",
    "        (fd.name contains \"/etc/shadow\" or\n",
    "         fd.name contains \"/etc/passwd\" or\n",
    "         fd.name contains \"/etc/kubernetes/pki\")\n",
    "        and not proc.name in (passwd, shadow)\n",
    "      output: >\n",
    "        Sensitive file accessed\n",
    "        (user=%user.name file=%fd.name command=%proc.cmdline pod=%k8s.pod.name)\n",
    "      priority: HIGH\n",
    "\n",
    "    - rule: Outbound Connection from Database Pod\n",
    "      desc: Database pods should not make outbound connections (data exfiltration risk)\n",
    "      condition: >\n",
    "        outbound and\n",
    "        k8s.pod.label.app in (postgres, mysql, mongodb) and\n",
    "        not (fd.sip in (10.0.0.0/8, 172.16.0.0/12))\n",
    "      output: >\n",
    "        Database pod initiated external connection\n",
    "        (connection=%fd.name pod=%k8s.pod.name namespace=%k8s.ns.name)\n",
    "      priority: EMERGENCY\n",
    "\n",
    "    - macro: allowed_web_shell_commands\n",
    "      condition: (proc.name in (sh, bash) and proc.pname in (nginx, apache))\n",
    "\n",
    "    - rule: Web Shell Execution\n",
    "      desc: Detect reverse shells or web shells in application containers\n",
    "      condition: >\n",
    "        spawned_process and\n",
    "        shell_procs and\n",
    "        proc.pname in (nginx, apache, httpd) and\n",
    "        not allowed_web_shell_commands\n",
    "      output: >\n",
    "        Potential web shell execution\n",
    "        (parent=%proc.pname command=%proc.cmdline pod=%k8s.pod.name)\n",
    "      priority: CRITICAL\n",
    "```\n",
    "\n",
    "### 14.3.2 Pod Security Standards\n",
    "\n",
    "**Kubernetes Pod Security Admission (replacing Pod Security Policies):**\n",
    "\n",
    "```yaml\n",
    "# Pod Security Standard: Restricted\n",
    "apiVersion: v1\n",
    "kind: Namespace\n",
    "metadata:\n",
    "  name: production\n",
    "  labels:\n",
    "    pod-security.kubernetes.io/enforce: restricted\n",
    "    pod-security.kubernetes.io/enforce-version: latest\n",
    "    pod-security.kubernetes.io/audit: restricted\n",
    "    pod-security.kubernetes.io/warn: restricted\n",
    "\n",
    "---\n",
    "# Example compliant deployment\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: secure-application\n",
    "  namespace: production\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: secure-app\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: secure-app\n",
    "    spec:\n",
    "      securityContext:\n",
    "        runAsNonRoot: true\n",
    "        seccompProfile:\n",
    "          type: RuntimeDefault\n",
    "      \n",
    "      containers:\n",
    "        - name: application\n",
    "          image: myapp:v1.2.3\n",
    "          securityContext:\n",
    "            allowPrivilegeEscalation: false\n",
    "            readOnlyRootFilesystem: true\n",
    "            capabilities:\n",
    "              drop: [\"ALL\"]\n",
    "            runAsUser: 1000\n",
    "            runAsGroup: 1000\n",
    "          \n",
    "          resources:\n",
    "            limits:\n",
    "              memory: \"512Mi\"\n",
    "              cpu: \"500m\"\n",
    "            requests:\n",
    "              memory: \"256Mi\"\n",
    "              cpu: \"250m\"\n",
    "          \n",
    "          volumeMounts:\n",
    "            - name: tmp\n",
    "              mountPath: /tmp\n",
    "            - name: cache\n",
    "              mountPath: /var/cache\n",
    "      \n",
    "      volumes:\n",
    "        - name: tmp\n",
    "          emptyDir: {}\n",
    "        - name: cache\n",
    "          emptyDir: {}\n",
    "```\n",
    "\n",
    "**Security Controls:**\n",
    "- **Non-root execution:** Container runs as UID 1000, preventing privilege escalation to root\n",
    "- **Read-only root filesystem:** Prevents attackers from writing malware to container filesystem\n",
    "- **Capability dropping:** Removes all Linux capabilities (CAP_SYS_ADMIN, etc.) that could be exploited for container escape\n",
    "- **Resource limits:** Prevents DoS via resource exhaustion\n",
    "- **seccomp:** Restricts available syscalls to the runtime default profile\n",
    "\n",
    "---\n",
    "\n",
    "## 14.4 Secrets Management and Certificate Rotation\n",
    "\n",
    "Hardcoded credentials in source code or configuration files represent critical vulnerabilities. Cloud-native secrets management provides centralized, auditable, and automatically rotating credential storage.\n",
    "\n",
    "### 14.4.1 AWS Secrets Manager Implementation\n",
    "\n",
    "```hcl\n",
    "# Database credentials with automatic rotation\n",
    "resource \"aws_secretsmanager_secret\" \"db_credentials\" {\n",
    "  name                    = \"production/database/app-credentials\"\n",
    "  description             = \"RDS database credentials for application\"\n",
    "  kms_key_id              = aws_kms_key.secrets_encryption.arn\n",
    "  recovery_window_in_days = 30  # Prevent accidental deletion\n",
    "\n",
    "  tags = {\n",
    "    Environment = \"production\"\n",
    "    Rotation    = \"enabled\"\n",
    "  }\n",
    "}\n",
    "\n",
    "resource \"aws_secretsmanager_secret_version\" \"db_credentials\" {\n",
    "  secret_id     = aws_secretsmanager_secret.db_credentials.id\n",
    "  secret_string = jsonencode({\n",
    "    username = \"app_user\"\n",
    "    password = random_password.db_password.result\n",
    "    host     = aws_db_instance.main.address\n",
    "    port     = 5432\n",
    "    dbname   = \"production\"\n",
    "  })\n",
    "}\n",
    "\n",
    "# Automatic rotation every 30 days\n",
    "resource \"aws_secretsmanager_secret_rotation\" \"db_credentials\" {\n",
    "  secret_id           = aws_secretsmanager_secret.db_credentials.id\n",
    "  rotation_lambda_arn = aws_lambda_function.rotation_lambda.arn\n",
    "\n",
    "  rotation_rules {\n",
    "    automatically_after_days = 30\n",
    "  }\n",
    "}\n",
    "\n",
    "# Lambda function for rotation (managed by AWS, but can be customized)\n",
    "resource \"aws_lambda_function\" \"rotation_lambda\" {\n",
    "  filename      = \"rotation_lambda.zip\"\n",
    "  function_name = \"secrets-rotation-postgres\"\n",
    "  role          = aws_iam_role.rotation_role.arn\n",
    "  handler       = \"lambda_function.lambda_handler\"\n",
    "  runtime       = \"python3.11\"\n",
    "  timeout       = 30\n",
    "\n",
    "  vpc_config {\n",
    "    subnet_ids         = module.vpc.private_subnets\n",
    "    security_group_ids = [aws_security_group.lambda_rotation.id]\n",
    "  }\n",
    "}\n",
    "\n",
    "# Application retrieval with caching\n",
    "```\n",
    "\n",
    "**Application Code with Caching:**\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "from functools import lru_cache\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "secrets_client = boto3.client('secretsmanager')\n",
    "\n",
    "class SecretsManagerCache:\n",
    "    \"\"\"\n",
    "    Local cache for secrets to reduce API calls and latency\n",
    "    Implements best practices from AWS Secrets Manager documentation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._cache = {}\n",
    "        self._client = boto3.client('secretsmanager')\n",
    "    \n",
    "    def get_secret(self, secret_arn, version_stage='AWSCURRENT'):\n",
    "        \"\"\"\n",
    "        Retrieve secret with local caching\n",
    "        Falls back to API call if not cached or cache expired\n",
    "        \"\"\"\n",
    "        cache_key = f\"{secret_arn}:{version_stage}\"\n",
    "        \n",
    "        # Check local cache (in production, implement TTL)\n",
    "        if cache_key in self._cache:\n",
    "            return self._cache[cache_key]\n",
    "        \n",
    "        try:\n",
    "            response = self._client.get_secret_value(\n",
    "                SecretId=secret_arn,\n",
    "                VersionStage=version_stage\n",
    "            )\n",
    "            \n",
    "            if 'SecretString' in response:\n",
    "                secret = json.loads(response['SecretString'])\n",
    "            else:\n",
    "                # Binary secret (e.g., for certificates)\n",
    "                import base64\n",
    "                secret = base64.b64decode(response['SecretBinary'])\n",
    "            \n",
    "            # Cache locally (in Lambda, cache persists between invocations in the same execution environment)\n",
    "            self._cache[cache_key] = secret\n",
    "            return secret\n",
    "            \n",
    "        except ClientError as e:\n",
    "            error_code = e.response['Error']['Code']\n",
    "            if error_code == 'ResourceNotFoundException':\n",
    "                logger.error(f\"Secret {secret_arn} not found\")\n",
    "            elif error_code == 'InvalidRequestException':\n",
    "                logger.error(f\"Invalid request for secret {secret_arn}\")\n",
    "            raise\n",
    "\n",
    "# Usage in application\n",
    "cache = SecretsManagerCache()\n",
    "\n",
    "def get_database_connection():\n",
    "    creds = cache.get_secret(\"arn:aws:secretsmanager:us-east-1:123456789012:secret:production/database/app-credentials\")\n",
    "    \n",
    "    import psycopg2\n",
    "    conn = psycopg2.connect(\n",
    "        host=creds['host'],\n",
    "        database=creds['dbname'],\n",
    "        user=creds['username'],\n",
    "        password=creds['password'],\n",
    "        port=creds['port'],\n",
    "        sslmode='require'  # Enforce TLS\n",
    "    )\n",
    "    return conn\n",
    "```\n",
    "\n",
    "### 14.4.2 Certificate Management with ACM and Cert Manager\n",
    "\n",
    "**AWS Certificate Manager with DNS Validation:**\n",
    "\n",
    "```hcl\n",
    "resource \"aws_acm_certificate\" \"main\" {\n",
    "  domain_name               = \"app.company.com\"\n",
    "  subject_alternative_names = [\"api.company.com\", \"*.company.com\"]\n",
    "  validation_method         = \"DNS\"\n",
    "\n",
    "  lifecycle {\n",
    "    create_before_destroy = true  # Ensure new cert is ready before old one is destroyed\n",
    "  }\n",
    "\n",
    "  tags = {\n",
    "    Environment = \"production\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# DNS validation records\n",
    "resource \"aws_route53_record\" \"cert_validation\" {\n",
    "  for_each = {\n",
    "    for dvo in aws_acm_certificate.main.domain_validation_options : dvo.domain_name => {\n",
    "      name   = dvo.resource_record_name\n",
    "      record = dvo.resource_record_value\n",
    "      type   = dvo.resource_record_type\n",
    "    }\n",
    "  }\n",
    "\n",
    "  allow_overwrite = true\n",
    "  name            = each.value.name\n",
    "  records         = [each.value.record]\n",
    "  ttl             = 60\n",
    "  type            = each.value.type\n",
    "  zone_id         = aws_route53_zone.main.zone_id\n",
    "}\n",
    "\n",
    "# Certificate validation\n",
    "resource \"aws_acm_certificate_validation\" \"main\" {\n",
    "  certificate_arn         = aws_acm_certificate.main.arn\n",
    "  validation_record_fqdns = [for record in aws_route53_record.cert_validation : record.fqdn]\n",
    "}\n",
    "\n",
    "# TLS 1.3 Enforcement on ALB\n",
    "resource \"aws_lb_listener\" \"https\" {\n",
    "  load_balancer_arn = aws_lb.application.arn\n",
    "  port              = \"443\"\n",
    "  protocol          = \"HTTPS\"\n",
    "  ssl_policy        = \"ELBSecurityPolicy-TLS13-1-2-2021-06\"  # Forces TLS 1.2+\n",
    "  certificate_arn   = aws_acm_certificate_validation.main.certificate_arn\n",
    "\n",
    "  default_action {\n",
    "    type             = \"forward\"\n",
    "    target_group_arn = aws_lb_target_group.application.arn\n",
    "  }\n",
    "}\n",
    "\n",
    "# HTTP to HTTPS redirect\n",
    "resource \"aws_lb_listener\" \"http_redirect\" {\n",
    "  load_balancer_arn = aws_lb.application.arn\n",
    "  port              = \"80\"\n",
    "  protocol          = \"HTTP\"\n",
    "\n",
    "  default_action {\n",
    "    type = \"redirect\"\n",
    "\n",
    "    redirect {\n",
    "      port        = \"443\"\n",
    "      protocol    = \"HTTPS\"\n",
    "      status_code = \"HTTP_301\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 14.5 Security Monitoring and Logging Architecture\n",
    "\n",
    "Comprehensive observability is essential for detecting, investigating, and responding to security incidents. Cloud-native security monitoring aggregates logs, analyzes behavioral patterns, and correlates events across distributed systems.\n",
    "\n",
    "### 14.5.1 Centralized Logging with CloudTrail and Config\n",
    "\n",
    "**Organization-Wide CloudTrail:**\n",
    "\n",
    "```hcl\n",
    "resource \"aws_cloudtrail\" \"organization\" {\n",
    "  name           = \"organization-security-trail\"\n",
    "  s3_bucket_name = aws_s3_bucket.cloudtrail_logs.id\n",
    "  \n",
    "  is_organization_trail = true  # Apply to all accounts in AWS Org\n",
    "  is_multi_region_trail = true\n",
    "  \n",
    "  enable_logging = true\n",
    "  \n",
    "  event_selector {\n",
    "    read_write_type                 = \"All\"\n",
    "    include_management_events       = true\n",
    "    exclude_management_event_sources = []  # Log everything\n",
    "    \n",
    "    data_resource {\n",
    "      type   = \"AWS::S3::Object\"\n",
    "      values = [\"arn:aws:s3:::\"]  # Log all S3 object-level operations\n",
    "    }\n",
    "    \n",
    "    data_resource {\n",
    "      type   = \"AWS::Lambda::Function\"\n",
    "      values = [\"arn:aws:lambda\"]  # Log Lambda function invocations\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  insight_selector {\n",
    "    insight_type = \"ApiCallRateInsight\"  # Detect unusual API activity\n",
    "  }\n",
    "  \n",
    "  kms_key_id = aws_kms_key.cloudtrail_encryption.arn\n",
    "  \n",
    "  tags = {\n",
    "    Purpose     = \"SecurityAudit\"\n",
    "    Compliance  = \"SOC2\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# Log file validation (integrity checking)\n",
    "resource \"aws_cloudtrail\" \"validation\" {\n",
    "  enable_log_file_validation = true\n",
    "  \n",
    "  # ... other configuration\n",
    "}\n",
    "\n",
    "# S3 bucket for logs with strict security\n",
    "resource \"aws_s3_bucket\" \"cloudtrail_logs\" {\n",
    "  bucket        = \"org-cloudtrail-logs-${data.aws_caller_identity.current.account_id}\"\n",
    "  force_destroy = false\n",
    "  \n",
    "  tags = {\n",
    "    Security = \"critical\"\n",
    "  }\n",
    "}\n",
    "\n",
    "resource \"aws_s3_bucket_policy\" \"cloudtrail\" {\n",
    "  bucket = aws_s3_bucket.cloudtrail_logs.id\n",
    "  policy = jsonencode({\n",
    "    Version = \"2012-10-17\"\n",
    "    Statement = [\n",
    "      {\n",
    "        Sid    = \"AWSCloudTrailAclCheck\"\n",
    "        Effect = \"Allow\"\n",
    "        Principal = {\n",
    "          Service = \"cloudtrail.amazonaws.com\"\n",
    "        }\n",
    "        Action   = \"s3:GetBucketAcl\"\n",
    "        Resource = aws_s3_bucket.cloudtrail_logs.arn\n",
    "      },\n",
    "      {\n",
    "        Sid    = \"AWSCloudTrailWrite\"\n",
    "        Effect = \"Allow\"\n",
    "        Principal = {\n",
    "          Service = \"cloudtrail.amazonaws.com\"\n",
    "        }\n",
    "        Action   = \"s3:PutObject\"\n",
    "        Resource = \"${aws_s3_bucket.cloudtrail_logs.arn}/AWSLogs/${data.aws_caller_identity.current.account_id}/*\"\n",
    "        Condition = {\n",
    "          StringEquals = {\n",
    "            \"s3:x-amz-acl\" = \"bucket-owner-full-control\"\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        Sid    = \"DenyInsecureTransport\"\n",
    "        Effect = \"Deny\"\n",
    "        Principal = \"*\"\n",
    "        Action = \"s3:*\"\n",
    "        Resource = aws_s3_bucket.cloudtrail_logs.arn\n",
    "        Condition = {\n",
    "          Bool = {\n",
    "            \"aws:SecureTransport\" = \"false\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  })\n",
    "}\n",
    "```\n",
    "\n",
    "### 14.5.2 GuardDuty for Threat Detection\n",
    "\n",
    "**Intelligent Threat Detection:**\n",
    "\n",
    "```hcl\n",
    "resource \"aws_guardduty_detector\" \"main\" {\n",
    "  enable = true\n",
    "  \n",
    "  datasources {\n",
    "    s3_logs {\n",
    "      enable = true\n",
    "    }\n",
    "    kubernetes {\n",
    "      audit_logs {\n",
    "        enable = true\n",
    "      }\n",
    "    }\n",
    "    malware_protection {\n",
    "      scan_ec2_instance_with_findings {\n",
    "        enable = true\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  finding_publishing_frequency = \"FIFTEEN_MINUTES\"\n",
    "}\n",
    "\n",
    "# Auto-remediation for high-severity findings\n",
    "resource \"aws_cloudwatch_event_rule\" \"guardduty_high_severity\" {\n",
    "  name        = \"guardduty-high-severity\"\n",
    "  description = \"Capture high and critical GuardDuty findings\"\n",
    "\n",
    "  event_pattern = jsonencode({\n",
    "    source      = [\"aws.guardduty\"]\n",
    "    detail-type = [\"GuardDuty Finding\"]\n",
    "    detail = {\n",
    "      severity = [{ \"numeric\" = [\">=\", 7] }]  # High (7-8.9) and Critical (9+)\n",
    "    }\n",
    "  })\n",
    "}\n",
    "\n",
    "resource \"aws_cloudwatch_event_target\" \"remediation_lambda\" {\n",
    "  rule      = aws_cloudwatch_event_rule.guardduty_high_severity.name\n",
    "  target_id = \"GuardDutyRemediation\"\n",
    "  arn       = aws_lambda_function.guardduty_remediation.arn\n",
    "}\n",
    "```\n",
    "\n",
    "**Remediation Lambda for Compromised Instances:**\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "def isolate_compromised_instance(event, context):\n",
    "    \"\"\"\n",
    "    Automatically isolate EC2 instances flagged by GuardDuty\n",
    "    \"\"\"\n",
    "    detail = event['detail']\n",
    "    finding_type = detail['type']\n",
    "    severity = detail['severity']\n",
    "    \n",
    "    # Extract instance ID from finding\n",
    "    resource = detail['resource']\n",
    "    instance_id = None\n",
    "    \n",
    "    for res in resource['instanceDetails']['tags']:\n",
    "        if res['key'] == 'Name':\n",
    "            instance_name = res['value']\n",
    "    \n",
    "    instance_id = resource['instanceDetails']['instanceId']\n",
    "    \n",
    "    ec2 = boto3.client('ec2')\n",
    "    sns = boto3.client('sns')\n",
    "    \n",
    "    try:\n",
    "        # 1. Create isolation security group (no inbound/outbound)\n",
    "        isolation_sg = create_isolation_security_group(ec2, instance_id)\n",
    "        \n",
    "        # 2. Replace instance's security groups with isolation group\n",
    "        original_sgs = ec2.describe_instances(InstanceIds=[instance_id])['Reservations'][0]['Instances'][0]['SecurityGroups']\n",
    "        \n",
    "        ec2.modify_instance_attribute(\n",
    "            InstanceId=instance_id,\n",
    "            Groups=[isolation_sg['GroupId']]\n",
    "        )\n",
    "        \n",
    "        # 3. Create snapshot for forensics\n",
    "        volumes = ec2.describe_volumes(\n",
    "            Filters=[{'Name': 'attachment.instance-id', 'Values': [instance_id]}]\n",
    "        )\n",
    "        \n",
    "        for vol in volumes['Volumes']:\n",
    "            snapshot = ec2.create_snapshot(\n",
    "                VolumeId=vol['VolumeId'],\n",
    "                Description=f\"Forensic snapshot for compromised instance {instance_id}\",\n",
    "                TagSpecifications=[{\n",
    "                    'ResourceType': 'snapshot',\n",
    "                    'Tags': [\n",
    "                        {'Key': 'Incident', 'Value': finding_type},\n",
    "                        {'Key': 'Severity', 'Value': str(severity)},\n",
    "                        {'Key': 'InstanceId', 'Value': instance_id}\n",
    "                    ]\n",
    "                }]\n",
    "            )\n",
    "        \n",
    "        # 4. Tag instance\n",
    "        ec2.create_tags(\n",
    "            Resources=[instance_id],\n",
    "            Tags=[\n",
    "                {'Key': 'SecurityStatus', 'Value': 'ISOLATED'},\n",
    "                {'Key': 'IsolationTime', 'Value': event['time']},\n",
    "                {'Key': 'OriginalSGs', 'Value': json.dumps([sg['GroupId'] for sg in original_sgs])}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # 5. Notify security team\n",
    "        sns.publish(\n",
    "            TopicArn='arn:aws:sns:us-east-1:123456789012:security-incidents',\n",
    "            Subject=f'CRITICAL: Instance {instance_id} isolated due to {finding_type}',\n",
    "            Message=json.dumps({\n",
    "                'instance_id': instance_id,\n",
    "                'finding_type': finding_type,\n",
    "                'severity': severity,\n",
    "                'isolation_sg': isolation_sg['GroupId'],\n",
    "                'snapshots': [snapshot['SnapshotId']]\n",
    "            })\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        # If automation fails, page on-call immediately\n",
    "        sns.publish(\n",
    "            TopicArn='arn:aws:sns:us-east-1:123456789012:security-escalation',\n",
    "            Subject=f'URGENT: Failed to isolate compromised instance {instance_id}',\n",
    "            Message=str(e)\n",
    "        )\n",
    "        raise\n",
    "\n",
    "def create_isolation_security_group(ec2, instance_id):\n",
    "    \"\"\"Create quarantine security group with no ingress/egress\"\"\"\n",
    "    vpc_id = ec2.describe_instances(InstanceIds=[instance_id])['Reservations'][0]['Instances'][0]['VpcId']\n",
    "    \n",
    "    sg = ec2.create_security_group(\n",
    "        GroupName=f'isolation-{instance_id}',\n",
    "        Description=f'Isolation group for compromised instance {instance_id}',\n",
    "        VpcId=vpc_id,\n",
    "        TagSpecifications=[{\n",
    "            'ResourceType': 'security-group',\n",
    "            'Tags': [{'Key': 'Purpose', 'Value': 'IncidentResponse'}]\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    # Explicit deny all (no ingress/egress rules added)\n",
    "    return sg\n",
    "```\n",
    "\n",
    "### 14.5.3 SIEM Integration\n",
    "\n",
    "**Centralized Security Analytics:**\n",
    "\n",
    "```hcl\n",
    "# Kinesis Firehose to Splunk/ElasticSearch\n",
    "resource \"aws_kinesis_firehose_delivery_stream\" \"security_logs\" {\n",
    "  name        = \"security-log-stream\"\n",
    "  destination = \"http_endpoint\"\n",
    "\n",
    "  http_endpoint_configuration {\n",
    "    url                = \"https://http-inputs-splunk.company.com:443/services/collector/event\"\n",
    "    name               = \"Splunk\"\n",
    "    access_key         = var.splunk_hec_token\n",
    "    buffering_size     = 5\n",
    "    buffering_interval = 300\n",
    "    retry_duration     = 300\n",
    "    \n",
    "    request_configuration {\n",
    "      content_encoding = \"GZIP\"\n",
    "      \n",
    "      common_attributes {\n",
    "        name  = \"environment\"\n",
    "        value = \"production\"\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    s3_configuration {\n",
    "      role_arn           = aws_iam_role.firehose.arn\n",
    "      bucket_arn         = aws_s3_bucket.backup_logs.arn\n",
    "      buffering_size     = 10\n",
    "      buffering_interval = 400\n",
    "      compression_format = \"GZIP\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Subscribe CloudWatch Logs to Firehose\n",
    "resource \"aws_cloudwatch_log_subscription_filter\" \"vpc_flow_logs\" {\n",
    "  name            = \"vpc-flow-to-siem\"\n",
    "  log_group_name  = aws_cloudwatch_log_group.vpc_flow.name\n",
    "  filter_pattern  = \"[version, account_id, interface_id, srcaddr != 10.0.0.0/8, dstaddr, srcport, dstport, protocol, packets, bytes, start, end, action, log_status]\"  # Only external traffic\n",
    "  destination_arn = aws_kinesis_firehose_delivery_stream.security_logs.arn\n",
    "  role_arn        = aws_iam_role.cloudwatch_to_firehose.arn\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 14.6 Infrastructure as Code Security\n",
    "\n",
    "Security must shift left into the development pipeline. IaC scanning tools detect misconfigurations before they reach production.\n",
    "\n",
    "### 14.6.1 Policy as Code with Checkov\n",
    "\n",
    "```yaml\n",
    "# .github/workflows/iac-security.yml\n",
    "name: Infrastructure Security Scan\n",
    "on:\n",
    "  pull_request:\n",
    "    paths:\n",
    "      - 'terraform/**'\n",
    "      - 'cloudformation/**'\n",
    "\n",
    "jobs:\n",
    "  security-scan:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "      \n",
    "      - name: Run Checkov\n",
    "        id: checkov\n",
    "        uses: bridgecrewio/checkov-action@master\n",
    "        with:\n",
    "          directory: .\n",
    "          framework: terraform\n",
    "          output_format: sarif\n",
    "          output_file_path: reports/checkov.sarif\n",
    "          soft_fail: false  # Fail the build on violations\n",
    "          skip_check: CKV_AWS_18  # Skip specific checks if justified\n",
    "          \n",
    "      - name: Upload SARIF to GitHub Security\n",
    "        uses: github/codeql-action/upload-sarif@v2\n",
    "        with:\n",
    "          sarif_file: reports/checkov.sarif\n",
    "          \n",
    "      - name: Terraform Compliance\n",
    "        uses: terraform-compliance/github_action@main\n",
    "        with:\n",
    "          plan: terraform/tfplan.out\n",
    "        env:\n",
    "          TF_DIRS: terraform/\n",
    "```\n",
    "\n",
    "**Custom Checkov Policy:**\n",
    "\n",
    "```python\n",
    "# custom_policies/s3_encryption.py\n",
    "from checkov.common.models.enums import CheckResult, CheckCategories\n",
    "from checkov.terraform.checks.resource.base_resource_check import BaseResourceCheck\n",
    "\n",
    "class S3BucketEncryptionCheck(BaseResourceCheck):\n",
    "    def __init__(self):\n",
    "        name = \"Ensure S3 bucket has encryption enabled with customer managed key\"\n",
    "        id = \"CKV_CUSTOM_001\"\n",
    "        supported_resources = ['aws_s3_bucket']\n",
    "        categories = [CheckCategories.ENCRYPTION]\n",
    "        super().__init__(name=name, id=id, categories=categories, supported_resources=supported_resources)\n",
    "\n",
    "    def scan_resource_conf(self, conf):\n",
    "        \"\"\"\n",
    "        Looks for server_side_encryption_configuration with KMS\n",
    "        \"\"\"\n",
    "        if 'server_side_encryption_configuration' in conf.keys():\n",
    "            sse_config = conf['server_side_encryption_configuration'][0]\n",
    "            if 'rule' in sse_config:\n",
    "                rule = sse_config['rule'][0]\n",
    "                if 'apply_server_side_encryption_by_default' in rule:\n",
    "                    default = rule['apply_server_side_encryption_by_default'][0]\n",
    "                    if 'sse_algorithm' in default and default['sse_algorithm'][0] == 'aws:kms':\n",
    "                        if 'kms_master_key_id' in default:\n",
    "                            return CheckResult.PASSED\n",
    "        return CheckResult.FAILED\n",
    "\n",
    "scanner = S3BucketEncryptionCheck()\n",
    "```\n",
    "\n",
    "### 14.6.2 Terraform Sentinel (HashiCorp Enterprise)\n",
    "\n",
    "```hcl\n",
    "# enforce-mandatory-tags.sentinel\n",
    "import \"tfplan/v2\" as tfplan\n",
    "\n",
    "# Get all AWS instances\n",
    "aws_instances = filter tfplan.resource_changes as _, rc {\n",
    "    rc.type is \"aws_instance\" and\n",
    "    (rc.change.actions contains \"create\" or rc.change.actions contains \"update\")\n",
    "}\n",
    "\n",
    "# Mandatory tags\n",
    "mandatory_tags = [\n",
    "    \"Environment\",\n",
    "    \"Owner\",\n",
    "    \"DataClassification\",\n",
    "    \"CostCenter\"\n",
    "]\n",
    "\n",
    "# Rule to check for mandatory tags\n",
    "mandatory_tags_rule = rule {\n",
    "    all aws_instances as _, instance {\n",
    "        all mandatory_tags as tag {\n",
    "            keys(instance.change.after.tags) contains tag\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Main rule\n",
    "main = rule {\n",
    "    mandatory_tags_rule\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 14.7 Chapter Summary and Transition\n",
    "\n",
    "This chapter has implemented comprehensive infrastructure security controls that operationalize the architectural principles established in previous chapters. We architected defense-in-depth network security utilizing VPC segmentation, security groups, NACLs, and Web Application Firewalls to create multiple barriers against attack, moving beyond perimeter-based models to zero-trust micro-segmentation where every packet is inspected and every connection verified.\n",
    "\n",
    "Compute hardening strategies demonstrated automated compliance with CIS benchmarks through Systems Manager and golden AMI pipelines, coupled with vulnerability management workflows that automatically remediate critical findings or trigger incident response procedures. Container security addressed the unique challenges of ephemeral workloads through image scanning, runtime threat detection with Falco, and Pod Security Standards that enforce least privilege at the Kubernetes level.\n",
    "\n",
    "Data protection implementation covered centralized secrets management with automatic rotation, certificate lifecycle management with TLS 1.3 enforcement, and encryption key governance. Security monitoring architectures aggregated logs across distributed systems, implemented intelligent threat detection with GuardDuty, and established automated incident response workflows that isolate compromised resources within minutes of detection.\n",
    "\n",
    "Finally, we embedded security into the development lifecycle through Infrastructure as Code scanning, ensuring that misconfigurations are caught during pull request review rather than production deployment.\n",
    "\n",
    "However, even the most sophisticated preventive and detective controls cannot guarantee security in the face of determined adversaries or sophisticated supply chain attacks. When prevention fails\u2014and statistically, it eventually will\u2014organizations must be prepared to respond with speed and precision. Incident response in cloud environments presents unique challenges: ephemeral resources may disappear before forensic capture, cross-account compromises require rapid isolation of entire organizational units, and compliance obligations mandate specific breach notification timelines.\n",
    "\n",
    "In **Chapter 15: Cloud Security Operations and Incident Response**, we will shift from preventive architecture to reactive capability. You will learn to build Security Operations Centers (SOC) optimized for cloud telemetry, implement automated incident response playbooks that orchestrate across multiple accounts and regions, conduct forensic investigations in ephemeral serverless and container environments, and navigate the compliance and legal implications of cloud breaches. We will explore chaos engineering techniques for validating security controls under adversarial conditions and establish the metrics and KPIs that demonstrate security program maturity to stakeholders and regulators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='13. identity_and_access_management_deep_dive.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='15. cloud_security_operations.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}