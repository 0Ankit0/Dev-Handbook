{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8: Container Orchestration with Kubernetes\n",
    "\n",
    "The evolution of cloud computing has followed a clear trajectory: from physical servers to virtual machines, from VMs to containers, and now from individual containers to orchestrated fleets. While containers solved the \"it works on my machine\" problem by packaging applications with their dependencies, they introduced new challenges: How do we deploy hundreds of containers across thousands of machines? How do we ensure high availability when containers fail? How do we roll out updates without downtime?\n",
    "\n",
    "Kubernetes\u2014originally developed by Google and now maintained by the Cloud Native Computing Foundation (CNCF)\u2014has emerged as the de facto standard for container orchestration. It automates the deployment, scaling, and management of containerized applications. This chapter provides a comprehensive foundation in Kubernetes architecture, core concepts, and practical deployment patterns, preparing you to operate containerized workloads at scale in production environments.\n",
    "\n",
    "## 8.1 Containerization Deep Dive with Docker\n",
    "\n",
    "Before orchestrating containers, we must master their construction. Docker remains the standard tool for building container images, though Kubernetes uses the Open Container Initiative (OCI) standard, making it compatible with alternatives like containerd or CRI-O.\n",
    "\n",
    "### Docker Image Architecture\n",
    "Docker images are layered filesystems. Each instruction in a Dockerfile creates a new layer, and layers are cached and reused across builds.\n",
    "\n",
    "**Layer Optimization Principles:**\n",
    "1.  **Order by Change Frequency:** Put instructions that change rarely (base image, dependency installation) at the top; frequently changing instructions (application code) at the bottom.\n",
    "2.  **Minimize Layers:** Combine commands where logical (`&&` in RUN instructions).\n",
    "3.  **Multi-Stage Builds:** Separate build environment from runtime environment.\n",
    "\n",
    "**Code Snippet: Production-Optimized Dockerfile**\n",
    "```dockerfile\n",
    "# Stage 1: Build environment\n",
    "FROM node:18-alpine AS builder\n",
    "WORKDIR /build\n",
    "\n",
    "# Install dependencies first (cached layer)\n",
    "COPY package*.json ./\n",
    "RUN npm ci --only=production && npm cache clean --force\n",
    "\n",
    "# Copy source and build\n",
    "COPY . .\n",
    "RUN npm run build\n",
    "\n",
    "# Stage 2: Production runtime\n",
    "FROM node:18-alpine AS production\n",
    "\n",
    "# Security: Run as non-root user\n",
    "RUN addgroup -g 1001 -S nodejs && \\\n",
    "    adduser -S nodejs -u 1001\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy only necessary artifacts from builder\n",
    "COPY --from=builder --chown=nodejs:nodejs /build/dist ./dist\n",
    "COPY --from=builder --chown=nodejs:nodejs /build/node_modules ./node_modules\n",
    "COPY --from=builder --chown=nodejs:nodejs /build/package.json ./\n",
    "\n",
    "USER nodejs\n",
    "\n",
    "EXPOSE 3000\n",
    "\n",
    "# Health check for container orchestration\n",
    "HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n",
    "  CMD node -e \"require('http').get('http://localhost:3000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})\"\n",
    "\n",
    "CMD [\"node\", \"dist/server.js\"]\n",
    "```\n",
    "\n",
    "### Docker Security Best Practices\n",
    "1.  **Non-Root User:** Never run as root inside containers (`USER` instruction).\n",
    "2.  **Distroless Images:** Use Google's distroless or Alpine Linux for minimal attack surface.\n",
    "3.  **Scan Images:** Integrate Trivy, Clair, or Snyk into CI pipelines.\n",
    "4.  **Read-Only Filesystems:** Mount root filesystem as read-only where possible.\n",
    "5.  **Drop Capabilities:** Remove unnecessary Linux capabilities (e.g., `NET_ADMIN`, `SYS_ADMIN`).\n",
    "\n",
    "## 8.2 Kubernetes Architecture\n",
    "\n",
    "Understanding Kubernetes requires understanding its distributed systems architecture, which separates control plane responsibilities from workload execution.\n",
    "\n",
    "### 8.2.1 The Control Plane (Master Components)\n",
    "The control plane manages the cluster's global state and makes decisions about scheduling and responding to cluster events. In managed Kubernetes services (EKS, AKS, GKE), the cloud provider manages these components; in self-managed clusters, you operate them.\n",
    "\n",
    "**API Server (`kube-apiserver`):**\n",
    "The front end of the control plane. All communication (internal and external) goes through the API Server. It validates and configures data for API objects (pods, services, deployments).\n",
    "\n",
    "**etcd:**\n",
    "A consistent and highly-available key-value store used as Kubernetes' backing store for all cluster data. It is the single source of truth for the cluster state. Losing etcd means losing your cluster state (though workloads continue running).\n",
    "\n",
    "**Scheduler (`kube-scheduler`):**\n",
    "Watches for newly created Pods with no assigned node, and selects a node for them to run on based on resource requirements, hardware/software/policy constraints, affinity/anti-affinity specifications, and data locality.\n",
    "\n",
    "**Controller Manager (`kube-controller-manager`):**\n",
    "Runs controller processes that regulate the cluster state:\n",
    "*   **Node Controller:** Notices and responds when nodes go down.\n",
    "*   **Replication Controller:** Maintains the correct number of pods for every replication controller object.\n",
    "*   **Endpoints Controller:** Populates the Endpoints object (joins Services & Pods).\n",
    "*   **Service Account & Token Controllers:** Create default accounts and API access tokens.\n",
    "\n",
    "### 8.2.2 Worker Node Components\n",
    "Nodes are the machines (virtual or physical) that run your applications.\n",
    "\n",
    "**Kubelet:**\n",
    "An agent that runs on each node in the cluster. It ensures that containers are running in a Pod. The kubelet takes a set of PodSpecs provided through various mechanisms (primarily the API Server) and ensures the containers described in those PodSpecs are running and healthy.\n",
    "\n",
    "**Kube-Proxy:**\n",
    "A network proxy that maintains network rules on nodes, enabling the Kubernetes Service abstraction. It handles network communications inside or outside of your cluster, forwarding requests to appropriate pods.\n",
    "\n",
    "**Container Runtime:**\n",
    "The software responsible for running containers. Kubernetes supports any runtime implementing the Container Runtime Interface (CRI):\n",
    "*   **containerd:** Industry standard, lightweight (used by Docker internally).\n",
    "*   **CRI-O:** Lightweight alternative designed specifically for Kubernetes.\n",
    "*   **Docker Engine:** Still supported via dockershim (deprecated in 1.24, removed in 1.24+).\n",
    "\n",
    "## 8.3 Core Kubernetes Objects\n",
    "\n",
    "Kubernetes organizes resources through a declarative API. You describe desired state; Kubernetes controllers work to achieve and maintain that state.\n",
    "\n",
    "### 8.3.1 Pods: The Atomic Unit\n",
    "A Pod is the smallest deployable unit in Kubernetes, representing one or more containers that share storage and network resources.\n",
    "\n",
    "**Pod Characteristics:**\n",
    "*   **Ephemeral:** Pods are created and destroyed dynamically; they do not persist.\n",
    "*   **Shared Context:** Containers in a pod share the same IP address, port space, and storage volumes.\n",
    "*   **Single-Purpose:** Generally, one main container per pod (plus sidecars for logging, monitoring, or proxying).\n",
    "\n",
    "**Code Snippet: Pod Definition**\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: web-pod\n",
    "  labels:\n",
    "    app: web\n",
    "    tier: frontend\n",
    "spec:\n",
    "  containers:\n",
    "    - name: nginx\n",
    "      image: nginx:1.25-alpine\n",
    "      ports:\n",
    "        - containerPort: 80\n",
    "          protocol: TCP\n",
    "      resources:\n",
    "        requests:\n",
    "          memory: \"64Mi\"\n",
    "          cpu: \"100m\"\n",
    "        limits:\n",
    "          memory: \"128Mi\"\n",
    "          cpu: \"200m\"\n",
    "      livenessProbe:\n",
    "        httpGet:\n",
    "          path: /health\n",
    "          port: 80\n",
    "        initialDelaySeconds: 10\n",
    "        periodSeconds: 10\n",
    "      readinessProbe:\n",
    "        httpGet:\n",
    "          path: /ready\n",
    "          port: 80\n",
    "        initialDelaySeconds: 5\n",
    "        periodSeconds: 5\n",
    "      volumeMounts:\n",
    "        - name: cache-volume\n",
    "          mountPath: /var/cache/nginx\n",
    "  volumes:\n",
    "    - name: cache-volume\n",
    "      emptyDir: {}\n",
    "  restartPolicy: Always\n",
    "  securityContext:\n",
    "    runAsNonRoot: true\n",
    "    runAsUser: 1000\n",
    "    fsGroup: 1000\n",
    "```\n",
    "\n",
    "### 8.3.2 Deployments: Managing Replica Sets\n",
    "Deployments provide declarative updates for Pods and ReplicaSets. They enable rolling updates, rollbacks, and scaling.\n",
    "\n",
    "**Key Features:**\n",
    "*   **Rolling Updates:** Gradually replace old pods with new ones, ensuring zero downtime.\n",
    "*   **Rollback:** Revert to previous deployment revision if issues detected.\n",
    "*   **Self-Healing:** If a pod fails, the Deployment controller creates a replacement to maintain desired replica count.\n",
    "\n",
    "**Code Snippet: Production Deployment**\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: api-server\n",
    "  labels:\n",
    "    app: api\n",
    "    version: v1.2.3\n",
    "spec:\n",
    "  replicas: 3\n",
    "  strategy:\n",
    "    type: RollingUpdate\n",
    "    rollingUpdate:\n",
    "      maxSurge: 1          # Can exceed desired count by 1 during update\n",
    "      maxUnavailable: 0    # Never drop below desired count\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: api\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: api\n",
    "        version: v1.2.3\n",
    "      annotations:\n",
    "        prometheus.io/scrape: \"true\"\n",
    "        prometheus.io/port: \"8080\"\n",
    "    spec:\n",
    "      affinity:\n",
    "        podAntiAffinity:\n",
    "          preferredDuringSchedulingIgnoredDuringExecution:\n",
    "            - weight: 100\n",
    "              podAffinityTerm:\n",
    "                labelSelector:\n",
    "                  matchExpressions:\n",
    "                    - key: app\n",
    "                      operator: In\n",
    "                      values:\n",
    "                        - api\n",
    "                topologyKey: kubernetes.io/hostname\n",
    "      containers:\n",
    "        - name: api\n",
    "          image: myregistry/api:v1.2.3\n",
    "          imagePullPolicy: Always\n",
    "          ports:\n",
    "            - name: http\n",
    "              containerPort: 8080\n",
    "              protocol: TCP\n",
    "          env:\n",
    "            - name: DATABASE_URL\n",
    "              valueFrom:\n",
    "                secretKeyRef:\n",
    "                  name: api-secrets\n",
    "                  key: database-url\n",
    "            - name: REDIS_HOST\n",
    "              valueFrom:\n",
    "                configMapKeyRef:\n",
    "                  name: api-config\n",
    "                  key: redis-host\n",
    "          resources:\n",
    "            requests:\n",
    "              memory: \"256Mi\"\n",
    "              cpu: \"250m\"\n",
    "            limits:\n",
    "              memory: \"512Mi\"\n",
    "              cpu: \"500m\"\n",
    "          livenessProbe:\n",
    "            httpGet:\n",
    "              path: /health/live\n",
    "              port: 8080\n",
    "            initialDelaySeconds: 30\n",
    "            periodSeconds: 10\n",
    "            failureThreshold: 3\n",
    "          readinessProbe:\n",
    "            httpGet:\n",
    "              path: /health/ready\n",
    "              port: 8080\n",
    "            initialDelaySeconds: 5\n",
    "            periodSeconds: 5\n",
    "          startupProbe:\n",
    "            httpGet:\n",
    "              path: /health/startup\n",
    "              port: 8080\n",
    "            failureThreshold: 30\n",
    "            periodSeconds: 10\n",
    "      terminationGracePeriodSeconds: 60  # Time for graceful shutdown\n",
    "```\n",
    "\n",
    "### 8.3.3 Services: Networking and Discovery\n",
    "Services expose applications running on Pods as network services, providing stable endpoints despite Pod churn.\n",
    "\n",
    "**Service Types:**\n",
    "*   **ClusterIP:** Internal cluster access only (default).\n",
    "*   **NodePort:** Exposes service on each Node's IP at a static port.\n",
    "*   **LoadBalancer:** Creates external load balancer (cloud provider specific).\n",
    "*   **ExternalName:** Maps service to external DNS name (CNAME).\n",
    "\n",
    "**Code Snippet: Service Definitions**\n",
    "```yaml\n",
    "# Internal service (ClusterIP)\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: api-service\n",
    "  labels:\n",
    "    app: api\n",
    "spec:\n",
    "  type: ClusterIP\n",
    "  selector:\n",
    "    app: api\n",
    "  ports:\n",
    "    - name: http\n",
    "      port: 80\n",
    "      targetPort: 8080\n",
    "      protocol: TCP\n",
    "  sessionAffinity: None\n",
    "\n",
    "# External LoadBalancer with annotations for cloud-specific features\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: api-public\n",
    "  annotations:\n",
    "    # AWS-specific: Use NLB for TCP traffic\n",
    "    service.beta.kubernetes.io/aws-load-balancer-type: \"nlb\"\n",
    "    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: \"true\"\n",
    "    # Azure-specific: Internal load balancer\n",
    "    # service.beta.kubernetes.io/azure-load-balancer-internal: \"true\"\n",
    "spec:\n",
    "  type: LoadBalancer\n",
    "  selector:\n",
    "    app: api\n",
    "  ports:\n",
    "    - port: 443\n",
    "      targetPort: 8080\n",
    "  externalTrafficPolicy: Local  # Preserve client source IP\n",
    "\n",
    "# Headless service for StatefulSets (direct pod access)\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: db-headless\n",
    "spec:\n",
    "  clusterIP: None  # Headless\n",
    "  selector:\n",
    "    app: database\n",
    "  ports:\n",
    "    - port: 5432\n",
    "```\n",
    "\n",
    "### 8.3.4 ConfigMaps and Secrets: Configuration Management\n",
    "Externalize configuration from container images to enable environment-specific settings without rebuilding.\n",
    "\n",
    "**ConfigMaps:** For non-sensitive configuration (feature flags, URLs, logging levels).\n",
    "**Secrets:** For sensitive data (passwords, tokens, certificates)\u2014base64 encoded at rest, encrypted in etcd (when configured).\n",
    "\n",
    "**Code Snippet: ConfigMap and Secret Usage**\n",
    "```yaml\n",
    "# ConfigMap for application configuration\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: app-config\n",
    "  namespace: production\n",
    "data:\n",
    "  # Key-value pairs\n",
    "  LOG_LEVEL: \"info\"\n",
    "  CACHE_TTL: \"300\"\n",
    "  FEATURE_FLAGS: |\n",
    "    {\n",
    "      \"newCheckout\": true,\n",
    "      \"betaSearch\": false\n",
    "    }\n",
    "  \n",
    "  # File-like keys\n",
    "  nginx.conf: |\n",
    "    server {\n",
    "      listen 80;\n",
    "      location / {\n",
    "        proxy_pass http://localhost:8080;\n",
    "      }\n",
    "    }\n",
    "\n",
    "---\n",
    "# Secret for sensitive data (values must be base64 encoded)\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: app-secrets\n",
    "  namespace: production\n",
    "type: Opaque\n",
    "data:\n",
    "  # echo -n 'supersecretpassword' | base64\n",
    "  DB_PASSWORD: c3VwZXJzZWNyZXRwYXNzd29yZA==\n",
    "  API_KEY: bXlzZWNyZXRhcGlrZXk=\n",
    "  \n",
    "  # TLS certificates\n",
    "  tls.crt: LS0tLS1CRUdJTi...  # base64 encoded cert\n",
    "  tls.key: LS0tLS1CRUdJTi...  # base64 encoded key\n",
    "\n",
    "---\n",
    "# Using ConfigMaps and Secrets in Pods\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: api-deployment\n",
    "spec:\n",
    "  template:\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: api\n",
    "          image: myapp:latest\n",
    "          env:\n",
    "            # Direct value from ConfigMap\n",
    "            - name: LOG_LEVEL\n",
    "              valueFrom:\n",
    "                configMapKeyRef:\n",
    "                  name: app-config\n",
    "                  key: LOG_LEVEL\n",
    "            \n",
    "            # Secret as environment variable\n",
    "            - name: DB_PASSWORD\n",
    "              valueFrom:\n",
    "                secretKeyRef:\n",
    "                  name: app-secrets\n",
    "                  key: DB_PASSWORD\n",
    "                  optional: false  # Pod fails if secret doesn't exist\n",
    "            \n",
    "            # All keys from ConfigMap as env vars\n",
    "            - name: CACHE_TTL\n",
    "              valueFrom:\n",
    "                configMapKeyRef:\n",
    "                  name: app-config\n",
    "                  key: CACHE_TTL\n",
    "          \n",
    "          # Mount ConfigMap as files\n",
    "          volumeMounts:\n",
    "            - name: config-volume\n",
    "              mountPath: /etc/app/config\n",
    "              readOnly: true\n",
    "            - name: secret-volume\n",
    "              mountPath: /etc/app/secrets\n",
    "              readOnly: true\n",
    "      \n",
    "      volumes:\n",
    "        - name: config-volume\n",
    "          configMap:\n",
    "            name: app-config\n",
    "            items:\n",
    "              - key: nginx.conf\n",
    "                path: nginx.conf\n",
    "              - key: FEATURE_FLAGS\n",
    "                path: features.json\n",
    "        \n",
    "        - name: secret-volume\n",
    "          secret:\n",
    "            secretName: app-secrets\n",
    "            defaultMode: 0400  # Read-only permissions\n",
    "            items:\n",
    "              - key: tls.crt\n",
    "                path: cert.pem\n",
    "              - key: tls.key\n",
    "                path: key.pem\n",
    "```\n",
    "\n",
    "## 8.4 Managed Kubernetes Services\n",
    "\n",
    "Running self-managed Kubernetes (installing `kubeadm` on EC2 instances) requires deep operational expertise: managing etcd backups, upgrading control plane versions, and configuring CNI networking. Managed services abstract this complexity.\n",
    "\n",
    "### Amazon EKS (Elastic Kubernetes Service)\n",
    "*   **Control Plane:** AWS manages API server, etcd, and scheduler across three AZs.\n",
    "*   **Data Plane:** You manage worker nodes (EC2 or Fargate serverless).\n",
    "*   **Add-ons:** VPC CNI, CoreDNS, kube-proxy managed by AWS.\n",
    "*   **IAM Integration:** IAM Roles for Service Accounts (IRSA) allows fine-grained AWS API access from pods.\n",
    "\n",
    "**EKS Cluster Creation:**\n",
    "```bash\n",
    "# Using eksctl (official CLI)\n",
    "eksctl create cluster \\\n",
    "    --name production-cluster \\\n",
    "    --region us-east-1 \\\n",
    "    --node-type m6i.large \\\n",
    "    --nodes 3 \\\n",
    "    --nodes-min 2 \\\n",
    "    --nodes-max 10 \\\n",
    "    --managed \\\n",
    "    --asg-access \\\n",
    "    --external-dns-access \\\n",
    "    --full-ecr-access\n",
    "\n",
    "# Using Terraform\n",
    "module \"eks\" {\n",
    "  source  = \"terraform-aws-modules/eks/aws\"\n",
    "  version = \"~> 19.0\"\n",
    "\n",
    "  cluster_name    = \"production-cluster\"\n",
    "  cluster_version = \"1.28\"\n",
    "\n",
    "  cluster_endpoint_public_access  = true\n",
    "  cluster_endpoint_private_access = true\n",
    "\n",
    "  vpc_id     = module.vpc.vpc_id\n",
    "  subnet_ids = module.vpc.private_subnets\n",
    "\n",
    "  # EKS Managed Node Groups\n",
    "  eks_managed_node_groups = {\n",
    "    general = {\n",
    "      desired_size = 2\n",
    "      min_size     = 1\n",
    "      max_size     = 10\n",
    "\n",
    "      instance_types = [\"m6i.large\"]\n",
    "      capacity_type  = \"ON_DEMAND\"\n",
    "\n",
    "      labels = {\n",
    "        workload = \"general\"\n",
    "      }\n",
    "\n",
    "      taints = []  # Prevent pods from scheduling unless tolerated\n",
    "    }\n",
    "\n",
    "    spot = {\n",
    "      desired_size = 1\n",
    "      min_size     = 0\n",
    "      max_size     = 5\n",
    "\n",
    "      instance_types = [\"m6i.large\", \"m5.large\", \"m5a.large\"]\n",
    "      capacity_type  = \"SPOT\"  # 70% cost savings\n",
    "\n",
    "      labels = {\n",
    "        workload = \"batch\"\n",
    "      }\n",
    "\n",
    "      taints = [{\n",
    "        key    = \"spot\"\n",
    "        value  = \"true\"\n",
    "        effect = \"NoSchedule\"\n",
    "      }]\n",
    "    }\n",
    "  }\n",
    "\n",
    "  # AWS Auth ConfigMap for IAM integration\n",
    "  manage_aws_auth_configmap = true\n",
    "\n",
    "  aws_auth_roles = [\n",
    "    {\n",
    "      rolearn  = \"arn:aws:iam::123456789:role/AdminRole\"\n",
    "      username = \"admin\"\n",
    "      groups   = [\"system:masters\"]\n",
    "    }\n",
    "  ]\n",
    "\n",
    "  tags = {\n",
    "    Environment = \"production\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Azure AKS (Azure Kubernetes Service)\n",
    "*   **Control Plane:** Azure manages API server and etcd; free (you pay only for worker nodes).\n",
    "*   **Integration:** Native Azure AD authentication, Azure Monitor for containers, Azure Policy for governance.\n",
    "*   **Node Autoprovisioning:** Automatically selects VM sizes based on pod resource requirements.\n",
    "\n",
    "**AKS Creation:**\n",
    "```bash\n",
    "# Create resource group\n",
    "az group create --name myAKSResourceGroup --location eastus\n",
    "\n",
    "# Create cluster with monitoring\n",
    "az aks create \\\n",
    "    --resource-group myAKSResourceGroup \\\n",
    "    --name myAKSCluster \\\n",
    "    --node-count 3 \\\n",
    "    --enable-addons monitoring \\\n",
    "    --generate-ssh-keys \\\n",
    "    --node-vm-size Standard_DS2_v2 \\\n",
    "    --enable-cluster-autoscaler \\\n",
    "    --min-count 1 \\\n",
    "    --max-count 5\n",
    "\n",
    "# Get credentials\n",
    "az aks get-credentials --resource-group myAKSResourceGroup --name myAKSCluster\n",
    "```\n",
    "\n",
    "### Google GKE (Google Kubernetes Engine)\n",
    "*   **Autopilot Mode:** Google manages nodes entirely; you pay per pod, not per provisioned VM.\n",
    "*   **Standard Mode:** You manage node pools, but with advanced features like node auto-repair and auto-upgrade.\n",
    "*   **Anthos:** Hybrid/multi-cloud Kubernetes platform for consistent operations across on-premises and cloud.\n",
    "\n",
    "**GKE Creation:**\n",
    "```bash\n",
    "# Create cluster with autopilot\n",
    "gcloud container clusters create-auto production-cluster \\\n",
    "    --region us-central1 \\\n",
    "    --release-channel regular \\\n",
    "    --enable-vertical-pod-autoscaling\n",
    "\n",
    "# Or standard cluster with specific node configuration\n",
    "gcloud container clusters create standard-cluster \\\n",
    "    --zone us-central1-a \\\n",
    "    --num-nodes 3 \\\n",
    "    --machine-type e2-standard-4 \\\n",
    "    --disk-size 100GB \\\n",
    "    --enable-autoscaling \\\n",
    "    --min-nodes 1 \\\n",
    "    --max-nodes 10 \\\n",
    "    --enable-autorepair \\\n",
    "    --enable-autoupgrade \\\n",
    "    --cluster-version \"1.28\"\n",
    "```\n",
    "\n",
    "## 8.5 Kubernetes Workload Resources\n",
    "\n",
    "Beyond basic Pods, Kubernetes provides higher-level controllers for managing application lifecycles.\n",
    "\n",
    "### 8.5.1 Deployments (Stateless Applications)\n",
    "Deployments manage ReplicaSets, which ensure a specified number of pod replicas are running at all times.\n",
    "\n",
    "**Key Capabilities:**\n",
    "*   **Rolling Updates:** Gradual replacement of pods with new versions.\n",
    "*   **Rollback:** Revert to previous revision if issues detected.\n",
    "*   **Scaling:** Manual (`kubectl scale`) or automatic (Horizontal Pod Autoscaler).\n",
    "\n",
    "**Code Snippet: Production Deployment Manifest**\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: api-server\n",
    "  namespace: production\n",
    "  labels:\n",
    "    app: api\n",
    "    version: v1.2.3\n",
    "spec:\n",
    "  replicas: 3\n",
    "  strategy:\n",
    "    type: RollingUpdate\n",
    "    rollingUpdate:\n",
    "      maxSurge: 25%          # Can temporarily have 4 pods (3 + 25%)\n",
    "      maxUnavailable: 0      # Never have fewer than 3 available\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: api\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: api\n",
    "        version: v1.2.3\n",
    "      annotations:\n",
    "        prometheus.io/scrape: \"true\"\n",
    "        prometheus.io/port: \"8080\"\n",
    "        prometheus.io/path: \"/metrics\"\n",
    "    spec:\n",
    "      serviceAccountName: api-service-account  # Least privilege IAM\n",
    "      securityContext:\n",
    "        runAsNonRoot: true\n",
    "        runAsUser: 1000\n",
    "        fsGroup: 1000\n",
    "        seccompProfile:\n",
    "          type: RuntimeDefault\n",
    "      \n",
    "      topologySpreadConstraints:\n",
    "        - maxSkew: 1\n",
    "          topologyKey: topology.kubernetes.io/zone\n",
    "          whenUnsatisfiable: DoNotSchedule\n",
    "          labelSelector:\n",
    "            matchLabels:\n",
    "              app: api\n",
    "      \n",
    "      affinity:\n",
    "        podAntiAffinity:\n",
    "          preferredDuringSchedulingIgnoredDuringExecution:\n",
    "            - weight: 100\n",
    "              podAffinityTerm:\n",
    "                labelSelector:\n",
    "                  matchExpressions:\n",
    "                    - key: app\n",
    "                      operator: In\n",
    "                      values:\n",
    "                        - api\n",
    "                topologyKey: kubernetes.io/hostname\n",
    "      \n",
    "      containers:\n",
    "        - name: api\n",
    "          image: myregistry/api:v1.2.3\n",
    "          imagePullPolicy: Always\n",
    "          \n",
    "          ports:\n",
    "            - name: http\n",
    "              containerPort: 8080\n",
    "              protocol: TCP\n",
    "            - name: management\n",
    "              containerPort: 8081\n",
    "              protocol: TCP\n",
    "          \n",
    "          env:\n",
    "            - name: NODE_ENV\n",
    "              value: \"production\"\n",
    "            - name: DB_HOST\n",
    "              valueFrom:\n",
    "                configMapKeyRef:\n",
    "                  name: db-config\n",
    "                  key: host\n",
    "            - name: DB_PASSWORD\n",
    "              valueFrom:\n",
    "                secretKeyRef:\n",
    "                  name: db-credentials\n",
    "                  key: password\n",
    "                  optional: false\n",
    "          \n",
    "          resources:\n",
    "            requests:\n",
    "              memory: \"256Mi\"\n",
    "              cpu: \"250m\"\n",
    "              ephemeral-storage: \"1Gi\"\n",
    "            limits:\n",
    "              memory: \"512Mi\"\n",
    "              cpu: \"500m\"\n",
    "              ephemeral-storage: \"2Gi\"\n",
    "          \n",
    "          volumeMounts:\n",
    "            - name: tmp\n",
    "              mountPath: /tmp\n",
    "            - name: cache\n",
    "              mountPath: /var/cache\n",
    "          \n",
    "          livenessProbe:\n",
    "            httpGet:\n",
    "              path: /health/live\n",
    "              port: management\n",
    "            initialDelaySeconds: 60\n",
    "            periodSeconds: 10\n",
    "            timeoutSeconds: 5\n",
    "            failureThreshold: 3\n",
    "          \n",
    "          readinessProbe:\n",
    "            httpGet:\n",
    "              path: /health/ready\n",
    "              port: management\n",
    "            initialDelaySeconds: 5\n",
    "            periodSeconds: 5\n",
    "            timeoutSeconds: 3\n",
    "            failureThreshold: 3\n",
    "          \n",
    "          startupProbe:\n",
    "            httpGet:\n",
    "              path: /health/startup\n",
    "              port: management\n",
    "            initialDelaySeconds: 10\n",
    "            periodSeconds: 10\n",
    "            timeoutSeconds: 5\n",
    "            failureThreshold: 30  # 30 * 10 = 300s max startup time\n",
    "          \n",
    "          securityContext:\n",
    "            allowPrivilegeEscalation: false\n",
    "            readOnlyRootFilesystem: true\n",
    "            runAsNonRoot: true\n",
    "            runAsUser: 1000\n",
    "            capabilities:\n",
    "              drop:\n",
    "                - ALL\n",
    "      \n",
    "      volumes:\n",
    "        - name: tmp\n",
    "          emptyDir: {}\n",
    "        - name: cache\n",
    "          emptyDir:\n",
    "            sizeLimit: 500Mi\n",
    "      \n",
    "      terminationGracePeriodSeconds: 60\n",
    "```\n",
    "\n",
    "### 8.5.2 StatefulSets (Stateful Applications)\n",
    "For applications requiring stable network identity and persistent storage (databases, message queues).\n",
    "\n",
    "**Characteristics:**\n",
    "*   **Ordered Deployment:** Pods created sequentially (0, 1, 2...).\n",
    "*   **Stable Network ID:** Each pod gets a predictable name (`db-0`, `db-1`) and hostname.\n",
    "*   **Persistent Storage:** Each pod maintains its own PersistentVolume even after rescheduling.\n",
    "\n",
    "**Code Snippet: StatefulSet for PostgreSQL**\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: StatefulSet\n",
    "metadata:\n",
    "  name: postgres\n",
    "  namespace: database\n",
    "spec:\n",
    "  serviceName: postgres-headless\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: postgres\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: postgres\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: postgres\n",
    "          image: postgres:15-alpine\n",
    "          ports:\n",
    "            - containerPort: 5432\n",
    "              name: postgres\n",
    "          env:\n",
    "            - name: POSTGRES_USER\n",
    "              valueFrom:\n",
    "                secretKeyRef:\n",
    "                  name: postgres-credentials\n",
    "                  key: username\n",
    "            - name: POSTGRES_PASSWORD\n",
    "              valueFrom:\n",
    "                secretKeyRef:\n",
    "                  name: postgres-credentials\n",
    "                  key: password\n",
    "            - name: PGDATA\n",
    "              value: /var/lib/postgresql/data/pgdata\n",
    "          volumeMounts:\n",
    "            - name: postgres-storage\n",
    "              mountPath: /var/lib/postgresql/data\n",
    "          resources:\n",
    "            requests:\n",
    "              memory: \"512Mi\"\n",
    "              cpu: \"500m\"\n",
    "            limits:\n",
    "              memory: \"1Gi\"\n",
    "              cpu: \"1000m\"\n",
    "  volumeClaimTemplates:\n",
    "    - metadata:\n",
    "        name: postgres-storage\n",
    "      spec:\n",
    "        accessModes: [\"ReadWriteOnce\"]\n",
    "        storageClassName: \"fast-ssd\"  # SSD-backed storage class\n",
    "        resources:\n",
    "          requests:\n",
    "            storage: 10Gi\n",
    "\n",
    "---\n",
    "# Headless service for StatefulSet DNS\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: postgres-headless\n",
    "  namespace: database\n",
    "spec:\n",
    "  selector:\n",
    "    app: postgres\n",
    "  ports:\n",
    "    - port: 5432\n",
    "      name: postgres\n",
    "  clusterIP: None  # Headless\n",
    "  publishNotReadyAddresses: true  # Allow connection to initializing pods\n",
    "```\n",
    "\n",
    "### 8.5.3 DaemonSets and Jobs\n",
    "**DaemonSet:** Ensures a copy of a pod runs on every (or selected) node. Used for log collectors (Fluentd), monitoring agents (Prometheus Node Exporter), or network proxies.\n",
    "\n",
    "**Job:** Creates one or more pods that run to completion (batch processing). **CronJob:** Jobs scheduled on a cron schedule.\n",
    "\n",
    "## 8.6 Helm: The Kubernetes Package Manager\n",
    "\n",
    "Raw YAML manifests become unwieldy at scale. Helm packages Kubernetes resources into reusable, configurable units called **Charts**.\n",
    "\n",
    "### Chart Structure\n",
    "```\n",
    "mychart/\n",
    "\u251c\u2500\u2500 Chart.yaml          # Metadata (name, version, dependencies)\n",
    "\u251c\u2500\u2500 values.yaml         # Default configuration values\n",
    "\u251c\u2500\u2500 charts/             # Sub-charts (dependencies)\n",
    "\u251c\u2500\u2500 templates/          # Kubernetes manifests with templating\n",
    "\u2502   \u251c\u2500\u2500 _helpers.tpl   # Named templates\n",
    "\u2502   \u251c\u2500\u2500 deployment.yaml\n",
    "\u2502   \u251c\u2500\u2500 service.yaml\n",
    "\u2502   \u251c\u2500\u2500 ingress.yaml\n",
    "\u2502   \u2514\u2500\u2500 hpa.yaml       # Horizontal Pod Autoscaler\n",
    "\u2514\u2500\u2500 README.md\n",
    "```\n",
    "\n",
    "**Code Snippet: Helm Values and Templates**\n",
    "```yaml\n",
    "# values.yaml (Configuration)\n",
    "replicaCount: 3\n",
    "\n",
    "image:\n",
    "  repository: myregistry/myapp\n",
    "  tag: \"1.2.3\"\n",
    "  pullPolicy: IfNotPresent\n",
    "\n",
    "service:\n",
    "  type: ClusterIP\n",
    "  port: 80\n",
    "  targetPort: 8080\n",
    "\n",
    "ingress:\n",
    "  enabled: true\n",
    "  className: nginx\n",
    "  annotations:\n",
    "    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n",
    "    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n",
    "  hosts:\n",
    "    - host: api.example.com\n",
    "      paths:\n",
    "        - path: /\n",
    "          pathType: Prefix\n",
    "  tls:\n",
    "    - secretName: api-tls\n",
    "      hosts:\n",
    "        - api.example.com\n",
    "\n",
    "resources:\n",
    "  limits:\n",
    "    cpu: 1000m\n",
    "    memory: 1Gi\n",
    "  requests:\n",
    "    cpu: 500m\n",
    "    memory: 512Mi\n",
    "\n",
    "autoscaling:\n",
    "  enabled: true\n",
    "  minReplicas: 3\n",
    "  maxReplicas: 20\n",
    "  targetCPUUtilizationPercentage: 60\n",
    "  targetMemoryUtilizationPercentage: 70\n",
    "\n",
    "nodeSelector:\n",
    "  workload-type: general\n",
    "\n",
    "tolerations: []\n",
    "\n",
    "affinity:\n",
    "  podAntiAffinity:\n",
    "    preferredDuringSchedulingIgnoredDuringExecution:\n",
    "      - weight: 100\n",
    "        podAffinityTerm:\n",
    "          labelSelector:\n",
    "            matchExpressions:\n",
    "              - key: app.kubernetes.io/name\n",
    "                operator: In\n",
    "                values:\n",
    "                  - myapp\n",
    "          topologyKey: kubernetes.io/hostname\n",
    "```\n",
    "\n",
    "```yaml\n",
    "# templates/deployment.yaml (Templated manifest)\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: {{ include \"mychart.fullname\" . }}\n",
    "  labels:\n",
    "    {{- include \"mychart.labels\" . | nindent 4 }}\n",
    "spec:\n",
    "  {{- if not .Values.autoscaling.enabled }}\n",
    "  replicas: {{ .Values.replicaCount }}\n",
    "  {{- end }}\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      {{- include \"mychart.selectorLabels\" . | nindent 6 }}\n",
    "  template:\n",
    "    metadata:\n",
    "      annotations:\n",
    "        # Force redeployment when config changes\n",
    "        checksum/config: {{ include (print $.Template.BasePath \"/configmap.yaml\") . | sha256sum }}\n",
    "        prometheus.io/scrape: \"true\"\n",
    "        prometheus.io/port: \"{{ .Values.service.targetPort }}\"\n",
    "      labels:\n",
    "        {{- include \"mychart.selectorLabels\" . | nindent 8 }}\n",
    "    spec:\n",
    "      serviceAccountName: {{ include \"mychart.serviceAccountName\" . }}\n",
    "      securityContext:\n",
    "        runAsNonRoot: true\n",
    "        runAsUser: 1000\n",
    "        fsGroup: 1000\n",
    "      \n",
    "      {{- with .Values.nodeSelector }}\n",
    "      nodeSelector:\n",
    "        {{- toYaml . | nindent 8 }}\n",
    "      {{- end }}\n",
    "      \n",
    "      {{- with .Values.affinity }}\n",
    "      affinity:\n",
    "        {{- toYaml . | nindent 8 }}\n",
    "      {{- end }}\n",
    "      \n",
    "      {{- with .Values.tolerations }}\n",
    "      tolerations:\n",
    "        {{- toYaml . | nindent 8 }}\n",
    "      {{- end }}\n",
    "      \n",
    "      containers:\n",
    "        - name: {{ .Chart.Name }}\n",
    "          image: \"{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}\"\n",
    "          imagePullPolicy: {{ .Values.image.pullPolicy }}\n",
    "          \n",
    "          ports:\n",
    "            - name: http\n",
    "              containerPort: {{ .Values.service.targetPort }}\n",
    "              protocol: TCP\n",
    "          \n",
    "          env:\n",
    "            - name: ENVIRONMENT\n",
    "              value: {{ .Values.environment }}\n",
    "            {{- range .Values.env }}\n",
    "            - name: {{ .name }}\n",
    "              value: {{ .value }}\n",
    "            {{- end }}\n",
    "          \n",
    "          envFrom:\n",
    "            - configMapRef:\n",
    "                name: {{ include \"mychart.fullname\" . }}-config\n",
    "            - secretRef:\n",
    "                name: {{ include \"mychart.fullname\" . }}-secrets\n",
    "                optional: false\n",
    "          \n",
    "          resources:\n",
    "            {{- toYaml .Values.resources | nindent 12 }}\n",
    "          \n",
    "          livenessProbe:\n",
    "            httpGet:\n",
    "              path: /health/live\n",
    "              port: http\n",
    "            initialDelaySeconds: 30\n",
    "            periodSeconds: 10\n",
    "          \n",
    "          readinessProbe:\n",
    "            httpGet:\n",
    "              path: /health/ready\n",
    "              port: http\n",
    "            initialDelaySeconds: 5\n",
    "            periodSeconds: 5\n",
    "          \n",
    "          securityContext:\n",
    "            allowPrivilegeEscalation: false\n",
    "            readOnlyRootFilesystem: true\n",
    "            capabilities:\n",
    "              drop:\n",
    "                - ALL\n",
    "          \n",
    "          volumeMounts:\n",
    "            - name: tmp\n",
    "              mountPath: /tmp\n",
    "            - name: cache\n",
    "              mountPath: /var/cache\n",
    "      \n",
    "      volumes:\n",
    "        - name: tmp\n",
    "          emptyDir: {}\n",
    "        - name: cache\n",
    "          emptyDir:\n",
    "            sizeLimit: 500Mi\n",
    "```\n",
    "\n",
    "## 8.7 Advanced Kubernetes Patterns\n",
    "\n",
    "### Horizontal Pod Autoscaler (HPA)\n",
    "Automatically scales pod count based on CPU, memory, or custom metrics.\n",
    "\n",
    "```yaml\n",
    "apiVersion: autoscaling/v2\n",
    "kind: HorizontalPodAutoscaler\n",
    "metadata:\n",
    "  name: api-hpa\n",
    "spec:\n",
    "  scaleTargetRef:\n",
    "    apiVersion: apps/v1\n",
    "    kind: Deployment\n",
    "    name: api-server\n",
    "  minReplicas: 3\n",
    "  maxReplicas: 100\n",
    "  metrics:\n",
    "    - type: Resource\n",
    "      resource:\n",
    "        name: cpu\n",
    "        target:\n",
    "          type: Utilization\n",
    "          averageUtilization: 60\n",
    "    - type: Resource\n",
    "      resource:\n",
    "        name: memory\n",
    "        target:\n",
    "          type: Utilization\n",
    "          averageUtilization: 70\n",
    "    - type: Pods  # Custom metric\n",
    "      pods:\n",
    "        metric:\n",
    "          name: http_requests_per_second\n",
    "        target:\n",
    "          type: AverageValue\n",
    "          averageValue: \"1000\"\n",
    "  behavior:\n",
    "    scaleDown:\n",
    "      stabilizationWindowSeconds: 300  # Wait 5 min before scaling down\n",
    "      policies:\n",
    "        - type: Percent\n",
    "          value: 10\n",
    "          periodSeconds: 60\n",
    "    scaleUp:\n",
    "      stabilizationWindowSeconds: 0\n",
    "      policies:\n",
    "        - type: Percent\n",
    "          value: 100\n",
    "          periodSeconds: 15\n",
    "        - type: Pods\n",
    "          value: 4\n",
    "          periodSeconds: 15\n",
    "      selectPolicy: Max\n",
    "```\n",
    "\n",
    "### Pod Disruption Budgets (PDB)\n",
    "Ensure minimum availability during voluntary disruptions (node upgrades, cluster autoscaling).\n",
    "\n",
    "```yaml\n",
    "apiVersion: policy/v1\n",
    "kind: PodDisruptionBudget\n",
    "metadata:\n",
    "  name: api-pdb\n",
    "spec:\n",
    "  minAvailable: 2  # Or maxUnavailable: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: api\n",
    "```\n",
    "\n",
    "### Network Policies\n",
    "Firewall rules for pod-to-pod communication (zero-trust networking).\n",
    "\n",
    "```yaml\n",
    "apiVersion: networking.k8s.io/v1\n",
    "kind: NetworkPolicy\n",
    "metadata:\n",
    "  name: api-network-policy\n",
    "  namespace: production\n",
    "spec:\n",
    "  podSelector:\n",
    "    matchLabels:\n",
    "      app: api\n",
    "  policyTypes:\n",
    "    - Ingress\n",
    "    - Egress\n",
    "  ingress:\n",
    "    # Only accept traffic from ingress-nginx\n",
    "    - from:\n",
    "        - namespaceSelector:\n",
    "            matchLabels:\n",
    "              name: ingress-nginx\n",
    "        - podSelector:\n",
    "            matchLabels:\n",
    "              app.kubernetes.io/name: ingress-nginx\n",
    "      ports:\n",
    "        - protocol: TCP\n",
    "          port: 8080\n",
    "    # Allow prometheus scraping from monitoring namespace\n",
    "    - from:\n",
    "        - namespaceSelector:\n",
    "            matchLabels:\n",
    "              name: monitoring\n",
    "      ports:\n",
    "        - protocol: TCP\n",
    "          port: 8080\n",
    "  egress:\n",
    "    # Only allow egress to database on port 5432\n",
    "    - to:\n",
    "        - podSelector:\n",
    "            matchLabels:\n",
    "              app: postgres\n",
    "      ports:\n",
    "        - protocol: TCP\n",
    "          port: 5432\n",
    "    # Allow DNS resolution\n",
    "    - to:\n",
    "        - namespaceSelector: {}\n",
    "      ports:\n",
    "        - protocol: UDP\n",
    "          port: 53\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "In this chapter, we ascended from individual containers to orchestrated fleets. You mastered Docker image optimization through multi-stage builds and security hardening, understanding that containers are immutable artifacts requiring externalized configuration. We dissected Kubernetes architecture, distinguishing between the control plane's orchestration responsibilities and the data plane's execution duties. You learned to deploy production workloads using Deployments for stateless services and StatefulSets for persistent data stores, implementing health checks (liveness, readiness, startup) that enable self-healing systems. We explored the three major managed Kubernetes offerings\u2014EKS, AKS, and GKE\u2014understanding their unique features and IAM integration patterns. You practiced configuration management through ConfigMaps and Secrets, network isolation via Network Policies, and horizontal scaling through the Horizontal Pod Autoscaler. Finally, we introduced Helm as the package manager for Kubernetes, enabling templated, versioned deployments of complex applications.\n",
    "\n",
    "Kubernetes is the operating system of the cloud-native world. With these skills, you can deploy microservices that scale automatically, heal from failures without human intervention, and update seamlessly without downtime. Yet for many workloads, even container orchestration is too heavy. When you need to execute code in response to events without managing servers, clusters, or containers at all, you need serverless computing.\n",
    "\n",
    "**Next Up: Chapter 9 - Serverless Architectures**\n",
    "In the next chapter, we will explore Function as a Service (FaaS) and event-driven architectures that eliminate infrastructure management entirely. You will learn to build applications that scale from zero to thousands of executions instantly, paying only for the milliseconds your code is actually running. We will design event-driven pipelines using message queues, stream processors, and function compositions that react to cloud events in real-time, completing your journey from infrastructure management to pure application logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='7. cicd_pipelines_in_the_cloud.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='../4. advanced_cloud_architecture_and_patterns/9. serverless_architectures.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}