{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: CI/CD Pipelines in the Cloud\n",
    "\n",
    "Infrastructure as Code gives us repeatable, version-controlled environments. Now we must address how applications flow into those environments. Continuous Integration and Continuous Delivery (CI/CD) represent the automation of software delivery—from the moment a developer commits code to when that code serves production traffic.\n",
    "\n",
    "In modern cloud computing, CI/CD is not merely a convenience; it is a competitive necessity. Organizations deploying multiple times per day (the elite performers identified in the DORA State of DevOps reports) achieve significantly lower change failure rates and faster recovery times than those deploying monthly. This chapter teaches you to build the pipelines that enable this velocity without sacrificing stability.\n",
    "\n",
    "## 7.1 The CI/CD Philosophy: Automation of Trust\n",
    "\n",
    "### Continuous Integration (CI)\n",
    "CI is the practice of merging all developers' working copies to a shared mainline several times a day, validated by automated builds and tests.\n",
    "\n",
    "**Core Principles:**\n",
    "1.  **Trunk-Based Development:** Developers work in short-lived feature branches (hours, not days) merging frequently to `main`.\n",
    "2.  **Automated Testing:** Every merge triggers unit tests, integration tests, and code quality checks.\n",
    "3.  **Fast Feedback:** Failures notify developers within minutes, enabling immediate correction.\n",
    "\n",
    "### Continuous Delivery vs. Continuous Deployment\n",
    "**Continuous Delivery (CD):** Code is automatically built, tested, and *prepared* for release to production. The final deployment decision is manual (business approval, timing considerations).\n",
    "\n",
    "**Continuous Deployment (CD):** Every change that passes all quality gates is automatically deployed to production without human intervention. This requires comprehensive automated testing and feature flags to manage risk.\n",
    "\n",
    "**Formula for Deployment Frequency:**\n",
    "$$ \\text{Deployment Confidence} = \\frac{\\text{Automated Test Coverage} \\times \\text{Observability}}{\\text{Manual Steps}} $$\n",
    "\n",
    "As manual steps approach zero with high test coverage, deployment frequency increases exponentially.\n",
    "\n",
    "## 7.2 Building a Pipeline: The Stages of Software Delivery\n",
    "\n",
    "A production-grade pipeline consists of distinct stages, each a gate that must be passed before proceeding.\n",
    "\n",
    "### Stage 1: Source (Trigger)\n",
    "The pipeline initiates when code changes are detected:\n",
    "*   **Git Events:** Push to `main`, pull request opened/updated, tag created.\n",
    "*   **Webhook:** Git provider (GitHub, GitLab, Bitbucket) notifies CI service.\n",
    "*   **Polling:** CI service checks repository periodically (less common now).\n",
    "\n",
    "### Stage 2: Build (Compilation & Packaging)\n",
    "Transforming source code into deployable artifacts:\n",
    "*   **Compilation:** Java, C++, Go binaries.\n",
    "*   **Packaging:** Docker image builds, JAR/WAR files, npm packages.\n",
    "*   **Artifact Storage:** Immutable artifacts pushed to registries (ECR, ACR, GCR, Docker Hub, Nexus, Artifactory).\n",
    "\n",
    "**Code Snippet: Multi-Stage Docker Build Optimization**\n",
    "```dockerfile\n",
    "# Build stage - includes dev dependencies\n",
    "FROM node:18-alpine AS builder\n",
    "WORKDIR /app\n",
    "COPY package*.json ./\n",
    "RUN npm ci\n",
    "COPY . .\n",
    "RUN npm run build\n",
    "\n",
    "# Production stage - minimal attack surface\n",
    "FROM node:18-alpine AS production\n",
    "WORKDIR /app\n",
    "COPY package*.json ./\n",
    "RUN npm ci --only=production && \\\n",
    "    addgroup -g 1001 -S nodejs && \\\n",
    "    adduser -S nodejs -u 1001\n",
    "COPY --from=builder --chown=nodejs:nodejs /app/dist ./dist\n",
    "USER nodejs\n",
    "EXPOSE 3000\n",
    "HEALTHCHECK --interval=30s --timeout=3s \\\n",
    "  CMD curl -f http://localhost:3000/health || exit 1\n",
    "CMD [\"node\", \"dist/server.js\"]\n",
    "```\n",
    "\n",
    "### Stage 3: Testing (Quality Gates)\n",
    "Automated validation occurs in parallel or sequence:\n",
    "\n",
    "**Static Application Security Testing (SAST):**\n",
    "Analyze source code for vulnerabilities without execution.\n",
    "*   Tools: SonarQube, Checkmarx, Semgrep, Bandit (Python), ESLint Security.\n",
    "*   **Fail Threshold:** High/Critical vulnerabilities block deployment.\n",
    "\n",
    "**Unit Testing:**\n",
    "Fast, isolated tests (milliseconds) mocking dependencies.\n",
    "*   Target: >80% code coverage for critical paths.\n",
    "*   Tools: Jest (JavaScript), JUnit (Java), pytest (Python).\n",
    "\n",
    "**Integration Testing:**\n",
    "Validate component interactions (databases, APIs).\n",
    "*   Use test containers (ephemeral Docker databases) for isolation.\n",
    "*   Test database migrations (schema changes) in this stage.\n",
    "\n",
    "**Code Snippet: Integration Test with Testcontainers**\n",
    "```python\n",
    "# test_database.py\n",
    "import pytest\n",
    "from testcontainers.postgres import PostgresContainer\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def test_database_connection():\n",
    "    with PostgresContainer(\"postgres:15-alpine\") as postgres:\n",
    "        engine = create_engine(postgres.get_connection_url())\n",
    "        with engine.connect() as connection:\n",
    "            result = connection.execute(\"SELECT version()\")\n",
    "            assert result.fetchone() is not None\n",
    "```\n",
    "\n",
    "### Stage 4: Security Scanning (DevSecOps)\n",
    "Beyond SAST, comprehensive security validation:\n",
    "\n",
    "**Software Composition Analysis (SCA):**\n",
    "Scan dependencies for known vulnerabilities (CVEs).\n",
    "*   Tools: Snyk, OWASP Dependency-Check, GitHub Dependabot.\n",
    "*   Example: Detecting that `log4j-core-2.14.0.jar` contains Log4Shell (CVE-2021-44228).\n",
    "\n",
    "**Container Scanning:**\n",
    "Analyze Docker images for OS vulnerabilities and misconfigurations.\n",
    "```bash\n",
    "# Trivy container scan example\n",
    "trivy image --severity HIGH,CRITICAL --exit-code 1 myapp:latest\n",
    "\n",
    "# Check for secrets in code (prevent credential leakage)\n",
    "truffleHog --regex --entropy=False .\n",
    "```\n",
    "\n",
    "**Dynamic Application Security Testing (DAST):**\n",
    "Test running application for vulnerabilities (SQL injection, XSS).\n",
    "*   Executed in staging environment against deployed application.\n",
    "*   Tools: OWASP ZAP, Burp Suite.\n",
    "\n",
    "### Stage 5: Deployment (Release)\n",
    "Promoting artifacts through environments:\n",
    "\n",
    "**Environment Promotion Strategy:**\n",
    "Artifacts should be immutable—build once, deploy the same binary to dev, staging, and production. Configuration (environment variables) changes per environment, not the code.\n",
    "\n",
    "```\n",
    "Build → Artifact Registry → Dev Deploy → Staging Deploy → Prod Deploy\n",
    "                ↑                    ↑              ↑            ↑\n",
    "             Same Image           Same Image    Same Image   Same Image\n",
    "             Different Config     Different Config, etc.\n",
    "```\n",
    "\n",
    "## 7.3 Cloud-Native CI/CD Tools\n",
    "\n",
    "Each major cloud provider offers integrated CI/CD services that minimize setup and maximize integration with cloud resources.\n",
    "\n",
    "### AWS CodePipeline + CodeBuild\n",
    "Fully managed continuous delivery service that automates release pipelines.\n",
    "\n",
    "**Architecture:**\n",
    "*   **CodePipeline:** Orchestration engine defining workflow stages.\n",
    "*   **CodeBuild:** Serverless build environment (compiles, tests, packages).\n",
    "*   **CodeDeploy:** Automates deployment to EC2, Lambda, ECS, or on-premises.\n",
    "\n",
    "**Code Snippet: AWS CodeBuild Specification (`buildspec.yml`)**\n",
    "```yaml\n",
    "version: 0.2\n",
    "\n",
    "env:\n",
    "  variables:\n",
    "    AWS_DEFAULT_REGION: us-east-1\n",
    "    IMAGE_REPO_NAME: my-app\n",
    "    IMAGE_TAG: latest\n",
    "  secrets-manager:\n",
    "    DOCKER_HUB_TOKEN: prod/dockerhub:token  # Secure credential retrieval\n",
    "\n",
    "phases:\n",
    "  pre_build:\n",
    "    commands:\n",
    "      - echo Logging in to Amazon ECR...\n",
    "      - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
    "      - echo Running security scans...\n",
    "      - checkov --file infrastructure/\n",
    "  \n",
    "  build:\n",
    "    commands:\n",
    "      - echo Build started on `date`\n",
    "      - echo Building the Docker image...\n",
    "      - docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
    "      - docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$CODEBUILD_RESOLVED_SOURCE_VERSION\n",
    "      \n",
    "  post_build:\n",
    "    commands:\n",
    "      - echo Build completed on `date`\n",
    "      - echo Pushing the Docker image...\n",
    "      - docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$CODEBUILD_RESOLVED_SOURCE_VERSION\n",
    "      - printf '{\"ImageUri\":\"%s\"}' $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$CODEBUILD_RESOLVED_SOURCE_VERSION > imageDetail.json\n",
    "\n",
    "artifacts:\n",
    "  files:\n",
    "    - imageDetail.json\n",
    "    - infrastructure/**/*\n",
    "  name: build-$(date +%Y-%m-%d-%H-%M-%S)\n",
    "\n",
    "cache:\n",
    "  paths:\n",
    "    - '/root/.m2/**/*'\n",
    "    - '/root/.npm/**/*'\n",
    "```\n",
    "\n",
    "### Azure DevOps (Pipelines)\n",
    "Comprehensive DevOps platform with Azure Pipelines for CI/CD.\n",
    "\n",
    "**Key Features:**\n",
    "*   **YAML-Based:** Pipeline as code stored in repository (`azure-pipelines.yml`).\n",
    "*   **Multi-Cloud:** Can deploy to AWS and GCP, not just Azure.\n",
    "*   **Self-Hosted Agents:** Use your own build machines when cloud-hosted agents are insufficient.\n",
    "\n",
    "**Code Snippet: Azure Pipeline for Kubernetes Deployment**\n",
    "```yaml\n",
    "# azure-pipelines.yml\n",
    "trigger:\n",
    "  - main\n",
    "\n",
    "pool:\n",
    "  vmImage: 'ubuntu-latest'\n",
    "\n",
    "variables:\n",
    "  dockerRegistryServiceConnection: 'myACR'\n",
    "  imageRepository: 'myapp'\n",
    "  containerRegistry: 'myregistry.azurecr.io'\n",
    "  dockerfilePath: '$(Build.SourcesDirectory)/Dockerfile'\n",
    "  tag: '$(Build.BuildId)'\n",
    "  \n",
    "  # Agent VM image name\n",
    "  vmImageName: 'ubuntu-latest'\n",
    "\n",
    "stages:\n",
    "- stage: Build\n",
    "  displayName: Build and push stage\n",
    "  jobs:\n",
    "  - job: Build\n",
    "    displayName: Build\n",
    "    pool:\n",
    "      vmImage: $(vmImageName)\n",
    "    steps:\n",
    "    - task: Docker@2\n",
    "      displayName: Build and push image\n",
    "      inputs:\n",
    "        command: buildAndPush\n",
    "        repository: $(imageRepository)\n",
    "        dockerfile: $(dockerfilePath)\n",
    "        containerRegistry: $(dockerRegistryServiceConnection)\n",
    "        tags: |\n",
    "          $(tag)\n",
    "          latest\n",
    "\n",
    "- stage: Deploy\n",
    "  displayName: Deploy to AKS\n",
    "  dependsOn: Build\n",
    "  condition: succeeded()\n",
    "  jobs:\n",
    "  - deployment: Deploy\n",
    "    displayName: Deploy to Kubernetes\n",
    "    environment: 'production.production-namespace'\n",
    "    pool:\n",
    "      vmImage: $(vmImageName)\n",
    "    strategy:\n",
    "      runOnce:\n",
    "        deploy:\n",
    "          steps:\n",
    "          - task: KubernetesManifest@0\n",
    "            displayName: Deploy to Kubernetes cluster\n",
    "            inputs:\n",
    "              action: deploy\n",
    "              manifests: |\n",
    "                $(Pipeline.Workspace)/manifests/deployment.yml\n",
    "                $(Pipeline.Workspace)/manifests/service.yml\n",
    "              containers: |\n",
    "                $(containerRegistry)/$(imageRepository):$(tag)\n",
    "```\n",
    "\n",
    "### Google Cloud Build\n",
    "Serverless CI/CD platform deeply integrated with GCP services.\n",
    "\n",
    "**Distinctive Features:**\n",
    "*   **Build Config as Code:** `cloudbuild.yaml` defines steps using containerized commands.\n",
    "*   **Buildpacks:** Automatic containerization without Dockerfile (detects language and builds optimized image).\n",
    "*   **Integration with Binary Authorization:** Cryptographic signing of images before deployment to GKE.\n",
    "\n",
    "**Code Snippet: Cloud Build Configuration**\n",
    "```yaml\n",
    "# cloudbuild.yaml\n",
    "steps:\n",
    "  # Build container image\n",
    "  - name: 'gcr.io/cloud-builders/docker'\n",
    "    args: ['build', '-t', 'gcr.io/$PROJECT_ID/myapp:$COMMIT_SHA', '.']\n",
    "  \n",
    "  # Push to Container Registry\n",
    "  - name: 'gcr.io/cloud-builders/docker'\n",
    "    args: ['push', 'gcr.io/$PROJECT_ID/myapp:$COMMIT_SHA']\n",
    "  \n",
    "  # Run security scan using Container Analysis\n",
    "  - name: 'gcr.io/cloud-builders/gcloud'\n",
    "    entrypoint: 'bash'\n",
    "    args:\n",
    "      - '-c'\n",
    "      - |\n",
    "        echo \"Scanning for vulnerabilities...\"\n",
    "        gcloud artifacts docker images scan \\\n",
    "          gcr.io/$PROJECT_ID/myapp:$COMMIT_SHA \\\n",
    "          --format='value(response.scan)'\n",
    "  \n",
    "  # Deploy to Cloud Run\n",
    "  - name: 'gcr.io/cloud-builders/gcloud'\n",
    "    args:\n",
    "      - 'run'\n",
    "      - 'deploy'\n",
    "      - 'myapp-service'\n",
    "      - '--image'\n",
    "      - 'gcr.io/$PROJECT_ID/myapp:$COMMIT_SHA'\n",
    "      - '--region'\n",
    "      - 'us-central1'\n",
    "      - '--platform'\n",
    "      - 'managed'\n",
    "      - '--allow-unauthenticated'\n",
    "\n",
    "images:\n",
    "  - 'gcr.io/$PROJECT_ID/myapp:$COMMIT_SHA'\n",
    "\n",
    "options:\n",
    "  logging: CLOUD_LOGGING_ONLY\n",
    "```\n",
    "\n",
    "### Jenkins: The Open Source Standard\n",
    "While cloud-native tools offer convenience, Jenkins remains ubiquitous in enterprise environments due to its plugin ecosystem (1800+ plugins) and flexibility.\n",
    "\n",
    "**Modern Jenkins: Pipeline as Code (Jenkinsfile)**\n",
    "```groovy\n",
    "// Jenkinsfile (Declarative Pipeline)\n",
    "pipeline {\n",
    "    agent any\n",
    "    \n",
    "    environment {\n",
    "        DOCKER_REGISTRY = 'myregistry.azurecr.io'\n",
    "        IMAGE_NAME = 'myapp'\n",
    "        DOCKER_CREDENTIALS = credentials('docker-registry-credentials')\n",
    "    }\n",
    "    \n",
    "    stages {\n",
    "        stage('Checkout') {\n",
    "            steps {\n",
    "                checkout scm\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stage('Build') {\n",
    "            steps {\n",
    "                sh 'npm ci'\n",
    "                sh 'npm run build'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stage('Test') {\n",
    "            parallel {\n",
    "                stage('Unit Tests') {\n",
    "                    steps {\n",
    "                        sh 'npm test'\n",
    "                    }\n",
    "                    post {\n",
    "                        always {\n",
    "                            publishTestResults testResultsPattern: 'test-results.xml'\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                stage('Lint') {\n",
    "                    steps {\n",
    "                        sh 'npm run lint'\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stage('Security Scan') {\n",
    "            steps {\n",
    "                sh 'trivy filesystem --exit-code 1 --severity HIGH .'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stage('Build Docker Image') {\n",
    "            steps {\n",
    "                script {\n",
    "                    dockerImage = docker.build(\"${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER}\")\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stage('Push Image') {\n",
    "            steps {\n",
    "                script {\n",
    "                    docker.withRegistry(\"https://${DOCKER_REGISTRY}\", DOCKER_CREDENTIALS) {\n",
    "                        dockerImage.push()\n",
    "                        dockerImage.push('latest')\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stage('Deploy to Staging') {\n",
    "            when {\n",
    "                branch 'develop'\n",
    "            }\n",
    "            steps {\n",
    "                sh 'kubectl config use-context staging'\n",
    "                sh \"kubectl set image deployment/myapp myapp=${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER}\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    post {\n",
    "        failure {\n",
    "            emailext (\n",
    "                subject: \"FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'\",\n",
    "                body: \"Check console output at ${env.BUILD_URL}\",\n",
    "                to: \"${env.CHANGE_AUTHOR_EMAIL}\"\n",
    "            )\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "## 7.4 Container-Based Pipelines and GitOps\n",
    "\n",
    "### Kubernetes-Native CI/CD\n",
    "For organizations running Kubernetes, traditional push-based deployment (CI system executes `kubectl apply`) creates security and operational challenges. **GitOps** inverts this model.\n",
    "\n",
    "**GitOps Principles (as defined by Weaveworks):**\n",
    "1.  **Declarative:** System state defined in Git (YAML manifests, Helm charts, Kustomize).\n",
    "2.  **Versioned & Immutable:** Git is the single source of truth; rollback via `git revert`.\n",
    "3.  **Pulled Automatically:** Agents in the cluster (ArgoCD, Flux) pull desired state and apply it.\n",
    "4.  **Continuously Reconciled:** Agents detect drift (manual changes via `kubectl`) and self-heal to match Git.\n",
    "\n",
    "**ArgoCD Example:**\n",
    "```yaml\n",
    "# Application definition stored in Git\n",
    "apiVersion: argoproj.io/v1alpha1\n",
    "kind: Application\n",
    "metadata:\n",
    "  name: myapp-production\n",
    "  namespace: argocd\n",
    "spec:\n",
    "  project: default\n",
    "  source:\n",
    "    repoURL: https://github.com/org/gitops-repo.git\n",
    "    targetRevision: HEAD\n",
    "    path: overlays/production\n",
    "    helm:\n",
    "      valueFiles:\n",
    "        - values-production.yaml\n",
    "  destination:\n",
    "    server: https://kubernetes.default.svc\n",
    "    namespace: production\n",
    "  syncPolicy:\n",
    "    automated:\n",
    "      prune: true        # Remove resources not in Git\n",
    "      selfHeal: true     # Override manual changes\n",
    "    syncOptions:\n",
    "      - CreateNamespace=true\n",
    "```\n",
    "\n",
    "**CI vs. GitOps Separation:**\n",
    "*   **CI (Build):** Builds image, runs tests, pushes to registry, updates Git repo with new image tag.\n",
    "*   **GitOps (Deploy):** ArgoCD detects Git change, pulls and applies manifests to cluster.\n",
    "\n",
    "## 7.5 Deployment Strategies: Minimizing Risk\n",
    "\n",
    "Not all deployments are equal. Different strategies balance risk, resource cost, and complexity.\n",
    "\n",
    "### Rolling Deployment (Default)\n",
    "Gradually replaces old instances with new ones.\n",
    "*   **Process:** Take one instance offline, deploy new version, health check, proceed to next.\n",
    "*   **Pros:** No extra resources required.\n",
    "*   **Cons:** Rollback is slow; mixed versions run simultaneously (backward compatibility required).\n",
    "\n",
    "**Kubernetes Rolling Update:**\n",
    "```yaml\n",
    "spec:\n",
    "  strategy:\n",
    "    type: RollingUpdate\n",
    "    rollingUpdate:\n",
    "      maxSurge: 25%        # Max pods above desired count\n",
    "      maxUnavailable: 25%  # Max pods unavailable during update\n",
    "```\n",
    "\n",
    "### Blue/Green Deployment\n",
    "Two identical environments (\"Blue\" = current, \"Green\" = new). Traffic instantly switches from Blue to Green after testing.\n",
    "*   **Pros:** Instant rollback (switch back to Blue), zero downtime, complete environment validation before traffic hits it.\n",
    "*   **Cons:** Double resource requirements during deployment.\n",
    "\n",
    "**Implementation:**\n",
    "```bash\n",
    "# Route 53 or ALB weight-based routing\n",
    "# 1. Deploy Green environment\n",
    "kubectl apply -f deployment-green.yaml\n",
    "\n",
    "# 2. Verify Green health\n",
    "kubectl run -it --rm debug --image=curlimages/curl --restart=Never -- http://green-service/health\n",
    "\n",
    "# 3. Switch ALB target group from Blue to Green\n",
    "aws elbv2 modify-target-group --target-group-arn $GREEN_TG --health-check-path /health\n",
    "\n",
    "# 4. If issues detected, immediate rollback by switching back to Blue\n",
    "```\n",
    "\n",
    "### Canary Deployment\n",
    "Route small percentage of traffic (e.g., 5%) to new version, monitor metrics, gradually increase to 100%.\n",
    "*   **Pros:** Real-world testing with limited blast radius; automatic rollback if error rate increases.\n",
    "*   **Cons:** Complex to implement; requires sophisticated traffic splitting and monitoring.\n",
    "\n",
    "**Istio Service Mesh Example:**\n",
    "```yaml\n",
    "apiVersion: networking.istio.io/v1beta1\n",
    "kind: VirtualService\n",
    "metadata:\n",
    "  name: myapp\n",
    "spec:\n",
    "  hosts:\n",
    "    - myapp.example.com\n",
    "  http:\n",
    "    - route:\n",
    "        - destination:\n",
    "            host: myapp\n",
    "            subset: v1\n",
    "          weight: 95\n",
    "        - destination:\n",
    "            host: myapp\n",
    "            subset: v2\n",
    "          weight: 5\n",
    "      # Automatic rollback condition\n",
    "      retries:\n",
    "        attempts: 3\n",
    "        perTryTimeout: 2s\n",
    "```\n",
    "\n",
    "## 7.6 Secrets Management in Pipelines\n",
    "\n",
    "Hardcoding credentials in pipeline configurations is a critical security anti-pattern.\n",
    "\n",
    "**Best Practices:**\n",
    "1.  **Native Secret Stores:** Use AWS Secrets Manager, Azure Key Vault, or GCP Secret Manager.\n",
    "2.  **Pipeline Integration:** Inject secrets as environment variables at runtime, never log them.\n",
    "3.  **Dynamic Credentials:** Use temporary credentials (AWS STS, Azure Managed Identity) rather than long-lived keys.\n",
    "\n",
    "**Code Snippet: Secure Secret Handling**\n",
    "```yaml\n",
    "# GitHub Actions example\n",
    "name: Deploy\n",
    "on:\n",
    "  push:\n",
    "    branches: [main]\n",
    "\n",
    "jobs:\n",
    "  deploy:\n",
    "    runs-on: ubuntu-latest\n",
    "    permissions:\n",
    "      id-token: write  # Required for OIDC\n",
    "      contents: read\n",
    "    \n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "      \n",
    "      # AWS OIDC authentication (no long-lived keys stored)\n",
    "      - name: Configure AWS Credentials\n",
    "        uses: aws-actions/configure-aws-credentials@v4\n",
    "        with:\n",
    "          role-to-assume: arn:aws:iam::123456789:role/GitHubActionsRole\n",
    "          aws-region: us-east-1\n",
    "      \n",
    "      # Retrieve secrets from AWS Secrets Manager\n",
    "      - name: Get DB credentials\n",
    "        uses: aws-actions/aws-secretsmanager-get-secrets@v1\n",
    "        with:\n",
    "          secret-ids: |\n",
    "            prod/myapp/database\n",
    "          parse-json-secrets: true\n",
    "      \n",
    "      # Use secrets (masked in logs automatically)\n",
    "      - name: Deploy\n",
    "        run: |\n",
    "          helm upgrade --install myapp ./chart \\\n",
    "            --set database.password=\"${{ env.PROD_MYAPP_DATABASE_PASSWORD }}\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "In this chapter, we architected the automation backbone of cloud-native software delivery. You learned that CI/CD separates the mechanics of delivery from manual execution, enabling velocity through automation while maintaining quality through rigorous testing gates. We explored the complete pipeline lifecycle—from source control triggers through multi-stage builds, comprehensive security scanning (SAST, DAST, SCA), and artifact promotion. You mastered cloud-native tooling across AWS CodePipeline, Azure DevOps, and Google Cloud Build, while understanding Jenkins' continued relevance in enterprise environments. We examined deployment strategies that minimize risk: rolling updates for simplicity, Blue/Green for instant rollback capability, and Canary releases for real-world validation with limited exposure. Finally, we established security best practices including OIDC authentication, secrets management, and the principle of never persisting credentials in code or configuration.\n",
    "\n",
    "With CI/CD pipelines operational, your infrastructure provisions automatically and your applications deploy seamlessly. However, modern cloud-native applications rarely run directly on virtual machines—they run in containers orchestrated by Kubernetes. Understanding how to build, deploy, and manage containerized workloads at scale is essential for any cloud practitioner.\n",
    "\n",
    "**Next Up: Chapter 8 - Container Orchestration with Kubernetes**\n",
    "In the next chapter, we will dive deep into the de facto standard for container orchestration. You will learn Kubernetes architecture (control plane, nodes, pods, services), deployment patterns for stateless and stateful applications, scaling mechanisms, and service mesh integration. We will deploy a microservice application to a managed Kubernetes cluster (EKS, AKS, or GKE), implementing health checks, rolling updates, and autoscaling policies that bring together everything you have learned about infrastructure, application design, and automated deployment."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
