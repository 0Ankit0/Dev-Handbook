{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 31: Schema Migrations in Real Teams\n",
    "\n",
    "Database schema migrations are the most dangerous routine operation in application development. A failed migration can cause extended downtime, data corruption, or cascading failures across services. This chapter establishes industry-standard patterns for executing migrations safely in production environments, emphasizing zero-downtime techniques, backward compatibility, and team workflows that prevent the 3 AM \"migration stuck\" page.\n",
    "\n",
    "---\n",
    "\n",
    "## 31.1 Migration Philosophy and Constraints\n",
    "\n",
    "### 31.1.1 The Forward-Only Mandate\n",
    "\n",
    "**Industry Standard**: Production migrations must be **forward-only** and **idempotent**. \"Down\" or \"rollback\" migration scripts are prohibited in automated pipelines.\n",
    "\n",
    "**Rationale**:\n",
    "- Data loss is asymmetric: rolling back a column drop destroys data permanently\n",
    "- Application code may have already written new-format data that down migrations cannot interpret\n",
    "- Down migrations are rarely tested in production-like environments\n",
    "- Recovery should use database backups (PITR) or compensating transactions, not schema reversal\n",
    "\n",
    "```sql\n",
    "-- ANTI-PATTERN: Down migration (DO NOT USE)\n",
    "-- 0002_add_user_status.down.sql\n",
    "ALTER TABLE users DROP COLUMN status;\n",
    "\n",
    "-- PROBLEM: If any user was marked 'inactive' in production, \n",
    "-- that information is permanently lost when this runs\n",
    "\n",
    "-- INDUSTRY STANDARD: Forward-only with compensation\n",
    "-- 0003_remove_user_status.sql\n",
    "-- Step 1: Deprecate (keep column, stop using in app)\n",
    "-- Step 2: Later migration drops after 30-day grace period\n",
    "ALTER TABLE users ALTER COLUMN status DROP DEFAULT;\n",
    "-- Application ignores column, but data preserved if rollback needed\n",
    "```\n",
    "\n",
    "### 31.1.2 Idempotency and Safety Checks\n",
    "\n",
    "Every migration must be safe to run multiple times without error.\n",
    "\n",
    "```sql\n",
    "-- Safe pattern: Check before creating\n",
    "DO $$\n",
    "BEGIN\n",
    "    IF NOT EXISTS (\n",
    "        SELECT 1 FROM information_schema.columns \n",
    "        WHERE table_name = 'users' \n",
    "        AND column_name = 'status'\n",
    "    ) THEN\n",
    "        ALTER TABLE users ADD COLUMN status VARCHAR(20) DEFAULT 'active';\n",
    "    END IF;\n",
    "END $$;\n",
    "\n",
    "-- Alternative: PostgreSQL-native IF NOT EXISTS (PostgreSQL 9.6+)\n",
    "CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);\n",
    "CREATE TABLE IF NOT EXISTS audit_log (...);\n",
    "```\n",
    "\n",
    "**Migration Metadata Table** (Framework-agnostic):\n",
    "\n",
    "```sql\n",
    "-- Track applied migrations\n",
    "CREATE TABLE schema_migrations (\n",
    "    version VARCHAR(255) PRIMARY KEY,\n",
    "    applied_at TIMESTAMPTZ DEFAULT NOW(),\n",
    "    checksum VARCHAR(64),        -- SHA-256 of file contents\n",
    "    execution_time_ms INTEGER,\n",
    "    applied_by VARCHAR(100)      -- Who/what ran it\n",
    ");\n",
    "\n",
    "-- Check before execution\n",
    "SELECT 1 FROM schema_migrations WHERE version = '20241002143000_add_user_status';\n",
    "-- If row exists, skip (already applied)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 31.2 Migration Categories and Risk Profiles\n",
    "\n",
    "### 31.2.1 Metadata-Only Changes (Low Risk)\n",
    "\n",
    "Operations that rewrite only catalog tables, not heap data.\n",
    "\n",
    "```sql\n",
    "-- SAFE: No table rewrite, instantaneous\n",
    "ALTER TABLE users RENAME COLUMN email TO email_address;\n",
    "ALTER TABLE users ALTER COLUMN status SET DEFAULT 'pending';\n",
    "ALTER TYPE user_status ADD VALUE 'suspended';  -- Enum extension (end only)\n",
    "\n",
    "-- Creating indexes CONCURRENTLY (see below)\n",
    "CREATE INDEX CONCURRENTLY idx_orders_created_at ON orders(created_at);\n",
    "```\n",
    "\n",
    "### 31.2.2 Locking Changes (High Risk)\n",
    "\n",
    "Operations that acquire `ACCESS EXCLUSIVE` locks and rewrite tables.\n",
    "\n",
    "```sql\n",
    "-- DANGEROUS: Locks table for duration of rewrite\n",
    "ALTER TABLE users ADD COLUMN bio TEXT;                    -- Rewrites table (PG < 11)\n",
    "ALTER TABLE users ALTER COLUMN email TYPE VARCHAR(300);   -- Rewrites table\n",
    "ALTER TABLE users DROP COLUMN phone;                      -- Rewrites table (PG < 11)\n",
    "\n",
    "-- PostgreSQL 11+ optimizations:\n",
    "-- ADD COLUMN with default is metadata-only (fast)\n",
    "ALTER TABLE users ADD COLUMN created_at TIMESTAMPTZ NOT NULL DEFAULT NOW();\n",
    "\n",
    "-- But DROP COLUMN still rewrites (removes column physically)\n",
    "```\n",
    "\n",
    "**Mitigation Strategy**: Use `pg_repack` or `ALTER ... ADD COLUMN` followed by background population instead of blocking `ALTER`.\n",
    "\n",
    "### 31.2.3 Constraint Changes (Blocking Risk)\n",
    "\n",
    "```sql\n",
    "-- BLOCKING: Validates all rows immediately, holds lock\n",
    "ALTER TABLE orders ADD CONSTRAINT fk_orders_user \n",
    "    FOREIGN KEY (user_id) REFERENCES users(user_id);\n",
    "\n",
    "-- NON-BLOCKING: Add constraint as NOT VALID, then validate separately\n",
    "-- Step 1: Create constraint without validation (fast, minimal locking)\n",
    "ALTER TABLE orders ADD CONSTRAINT fk_orders_user \n",
    "    FOREIGN KEY (user_id) REFERENCES users(user_id) \n",
    "    NOT VALID;\n",
    "\n",
    "-- Step 2: Validate in background (acquires SHARE UPDATE EXCLUSIVE, not ACCESS EXCLUSIVE)\n",
    "ALTER TABLE orders VALIDATE CONSTRAINT fk_orders_user;\n",
    "-- This can take hours on large tables but doesn't block reads/writes\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 31.3 Zero-Downtime Migration Patterns\n",
    "\n",
    "### 31.3.1 The Expand-Contract Pattern\n",
    "\n",
    "The gold standard for structural changes without downtime or backward incompatibility.\n",
    "\n",
    "**Scenario**: Rename column `email` to `email_address`.\n",
    "\n",
    "```sql\n",
    "-- Phase 1: EXPAND (Deploy 1)\n",
    "-- Add new column, keep old column\n",
    "ALTER TABLE users ADD COLUMN email_address VARCHAR(255);\n",
    "\n",
    "-- Backfill in batches (see section 31.4)\n",
    "UPDATE users SET email_address = email WHERE email_address IS NULL;\n",
    "\n",
    "-- Application writes to BOTH columns (dual write)\n",
    "-- Application reads from OLD column (backward compatible)\n",
    "```\n",
    "\n",
    "```python\n",
    "# Application code (Deploy 1)\n",
    "class User:\n",
    "    def save(self):\n",
    "        # Dual write\n",
    "        db.execute(\"\"\"\n",
    "            UPDATE users \n",
    "            SET email = %s, email_address = %s \n",
    "            WHERE id = %s\n",
    "        \"\"\", (self.email, self.email, self.id))\n",
    "    \n",
    "    @property\n",
    "    def get_email(self):\n",
    "        return self.email  # Read from old column\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- Phase 2: MIGRATE (Deploy 2)\n",
    "-- Backfill complete, switch reads to new column\n",
    "-- Add trigger to keep old column synced (for rollback safety)\n",
    "CREATE OR REPLACE FUNCTION sync_email() RETURNS TRIGGER AS $$\n",
    "BEGIN\n",
    "    NEW.email = NEW.email_address;\n",
    "    RETURN NEW;\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "\n",
    "CREATE TRIGGER trg_sync_email \n",
    "    BEFORE UPDATE ON users \n",
    "    FOR EACH ROW \n",
    "    WHEN (NEW.email_address IS DISTINCT FROM OLD.email_address)\n",
    "    EXECUTE FUNCTION sync_email();\n",
    "```\n",
    "\n",
    "```python\n",
    "# Application code (Deploy 2)\n",
    "class User:\n",
    "    def save(self):\n",
    "        db.execute(\"\"\"\n",
    "            UPDATE users \n",
    "            SET email_address = %s \n",
    "            WHERE id = %s\n",
    "        \"\"\", (self.email, self.id))\n",
    "        # Trigger keeps old column updated\n",
    "    \n",
    "    @property\n",
    "    def get_email(self):\n",
    "        return self.email_address  # Read from new column\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- Phase 3: CONTRACT (Deploy 3, days later)\n",
    "-- Drop old column after grace period\n",
    "DROP TRIGGER trg_sync_email ON users;\n",
    "DROP FUNCTION sync_email();\n",
    "ALTER TABLE users DROP COLUMN email;\n",
    "```\n",
    "\n",
    "### 31.3.2 Adding Constraints Without Downtime\n",
    "\n",
    "**Adding a NOT NULL Constraint**:\n",
    "\n",
    "```sql\n",
    "-- ANTI-PATTERN: Blocks table while checking millions of rows\n",
    "ALTER TABLE users ALTER COLUMN email SET NOT NULL;\n",
    "\n",
    "-- SAFE PATTERN:\n",
    "-- Step 1: Add CHECK constraint as NOT VALID (no scan)\n",
    "ALTER TABLE users ADD CONSTRAINT chk_email_not_null \n",
    "    CHECK (email IS NOT NULL) NOT VALID;\n",
    "\n",
    "-- Step 2: Backfill any NULLs in batches (if migration missed any)\n",
    "UPDATE users SET email = 'legacy@example.com' WHERE email IS NULL;\n",
    "\n",
    "-- Step 3: Validate constraint (scan table, but doesn't block writes)\n",
    "ALTER TABLE users VALIDATE CONSTRAINT chk_email_not_null;\n",
    "\n",
    "-- Step 4: Make it a proper NOT NULL (metadata only, PostgreSQL 12+)\n",
    "-- Or keep as CHECK constraint (functionally equivalent)\n",
    "ALTER TABLE users ALTER COLUMN email SET NOT NULL;\n",
    "ALTER TABLE users DROP CONSTRAINT chk_email_not_null;  -- Optional cleanup\n",
    "```\n",
    "\n",
    "### 31.3.3 Index Creation Strategies\n",
    "\n",
    "**Concurrent Index Creation** (Essential for production):\n",
    "\n",
    "```sql\n",
    "-- BLOCKING: Locks table for entire index build\n",
    "CREATE INDEX idx_orders_total ON orders(total);\n",
    "\n",
    "-- NON-BLOCKING: Allows reads/writes during build\n",
    "CREATE INDEX CONCURRENTLY idx_orders_total ON orders(total);\n",
    "\n",
    "-- Caveats:\n",
    "-- 1. Takes longer (2-3x) due to multiple table scans\n",
    "-- 2. Cannot run inside transaction block\n",
    "-- 3. If build fails (e.g., unique constraint violation), leaves \"invalid\" index\n",
    "-- 4. Must be run outside standard transactional migration frameworks\n",
    "```\n",
    "\n",
    "**Handling Invalid Indexes**:\n",
    "\n",
    "```sql\n",
    "-- Check for invalid indexes (failed concurrent builds)\n",
    "SELECT indexname, indexdef \n",
    "FROM pg_indexes \n",
    "WHERE NOT indisvalid \n",
    "FROM pg_index JOIN pg_class ON pg_index.indexrelid = pg_class.oid\n",
    "WHERE NOT pg_index.indisvalid;\n",
    "\n",
    "-- Drop and retry\n",
    "DROP INDEX CONCURRENTLY idx_orders_total;\n",
    "CREATE INDEX CONCURRENTLY idx_orders_total ON orders(total);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 31.4 Long-Running Migrations (Batch Processing)\n",
    "\n",
    "### 31.4.1 The Problem with Single-Transaction Updates\n",
    "\n",
    "```sql\n",
    "-- ANTI-PATTERN: Locks rows for hours, fills WAL, blocks vacuum\n",
    "UPDATE users SET status = 'migrated' WHERE legacy_flag = true;\n",
    "-- Locks all matching rows until commit\n",
    "-- Generates massive WAL traffic (replication lag)\n",
    "-- Autovacuum can't clean dead tuples while transaction runs\n",
    "```\n",
    "\n",
    "### 31.4.2 Batch Update Pattern\n",
    "\n",
    "```python\n",
    "# Python implementation of batched migration\n",
    "import psycopg2\n",
    "import time\n",
    "\n",
    "def migrate_in_batches(batch_size=1000, sleep_interval=0.1):\n",
    "    conn = psycopg2.connect(DATABASE_URL)\n",
    "    conn.autocommit = False\n",
    "    \n",
    "    while True:\n",
    "        with conn.cursor() as cur:\n",
    "            # Update small batch\n",
    "            cur.execute(\"\"\"\n",
    "                UPDATE users \n",
    "                SET status = 'migrated'\n",
    "                WHERE user_id IN (\n",
    "                    SELECT user_id \n",
    "                    FROM users \n",
    "                    WHERE legacy_flag = true \n",
    "                    AND status != 'migrated'\n",
    "                    LIMIT %s\n",
    "                    FOR UPDATE SKIP LOCKED  -- Critical: skip locked rows\n",
    "                )\n",
    "                RETURNING user_id;\n",
    "            \"\"\", (batch_size,))\n",
    "            \n",
    "            updated = cur.rowcount\n",
    "            conn.commit()\n",
    "            \n",
    "            if updated == 0:\n",
    "                break\n",
    "                \n",
    "            print(f\"Migrated {updated} rows\")\n",
    "            time.sleep(sleep_interval)  -- Allow other queries between batches\n",
    "    \n",
    "    conn.close()\n",
    "```\n",
    "\n",
    "**Key Features**:\n",
    "- `LIMIT` controls batch size\n",
    "- `FOR UPDATE SKIP LOCKED` prevents blocking concurrent writes\n",
    "- Frequent `COMMIT` releases locks and allows vacuum to proceed\n",
    "- Sleep interval prevents CPU/IO saturation\n",
    "\n",
    "### 31.4.3 Background Migration Jobs\n",
    "\n",
    "For very large tables (billions of rows), use background job processors instead of DDL migrations.\n",
    "\n",
    "```sql\n",
    "-- Migration table tracks progress\n",
    "CREATE TABLE migration_jobs (\n",
    "    job_id SERIAL PRIMARY KEY,\n",
    "    table_name VARCHAR(100),\n",
    "    status VARCHAR(20),  -- pending, running, completed, failed\n",
    "    last_processed_id BIGINT DEFAULT 0,\n",
    "    batch_size INTEGER DEFAULT 1000,\n",
    "    started_at TIMESTAMPTZ,\n",
    "    completed_at TIMESTAMPTZ\n",
    ");\n",
    "\n",
    "-- Application worker processes chunks\n",
    "WITH batch AS (\n",
    "    SELECT user_id \n",
    "    FROM users \n",
    "    WHERE user_id > (SELECT last_processed_id FROM migration_jobs WHERE job_id = 1)\n",
    "    ORDER BY user_id\n",
    "    LIMIT 1000\n",
    "),\n",
    "updated AS (\n",
    "    UPDATE users \n",
    "    SET new_column = calculate_value(old_column)\n",
    "    WHERE user_id IN (SELECT user_id FROM batch)\n",
    "    RETURNING user_id\n",
    ")\n",
    "UPDATE migration_jobs \n",
    "SET last_processed_id = (SELECT MAX(user_id) FROM updated)\n",
    "WHERE job_id = 1;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 31.5 Version Compatibility and Deployment Coordination\n",
    "\n",
    "### 31.5.1 N-1 Compatibility Rule\n",
    "\n",
    "**Industry Standard**: Database schema must be compatible with both the current application version (N) and the previous version (N-1) during deployment.\n",
    "\n",
    "**Deployment Sequence**:\n",
    "1. Deploy migration (schema N+1 compatible with app N)\n",
    "2. Deploy application code (N+1)\n",
    "3. Verify health\n",
    "4. Deploy migration (schema N+2, cleanup of N compatibility)\n",
    "\n",
    "```sql\n",
    "-- Example: Removing a column safely\n",
    "-- App N uses column 'legacy_data'\n",
    "-- App N+1 ignores column 'legacy_data'\n",
    "\n",
    "-- Deploy 1: App N is running\n",
    "-- Schema must have legacy_data (App N needs it)\n",
    "\n",
    "-- Deploy 2: Migration (App N still running)\n",
    "-- Stop writing to legacy_data (App N+1 ready)\n",
    "-- But don't drop column yet (App N might read it)\n",
    "ALTER TABLE events ALTER COLUMN legacy_data DROP DEFAULT;\n",
    "\n",
    "-- Deploy 3: App N+1 deployed\n",
    "-- App no longer uses legacy_data\n",
    "\n",
    "-- Deploy 4: (One day later) Migration to drop column\n",
    "-- Now safe to drop because App N is gone\n",
    "ALTER TABLE events DROP COLUMN legacy_data;\n",
    "```\n",
    "\n",
    "### 31.5.2 Feature Flags for Schema Changes\n",
    "\n",
    "Coordinate schema changes with application behavior using feature flags.\n",
    "\n",
    "```sql\n",
    "-- Add column but don't enforce constraints yet\n",
    "ALTER TABLE orders ADD COLUMN priority_score INTEGER;\n",
    "\n",
    "-- Application checks feature flag before using new column\n",
    "if feature_flags.get('use_priority_scoring'):\n",
    "    query = \"SELECT * FROM orders ORDER BY priority_score DESC\"\n",
    "else:\n",
    "    query = \"SELECT * FROM ORDER BY created_at DESC\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 31.6 Migration Tooling Patterns\n",
    "\n",
    "### 31.6.1 Migration File Naming Conventions\n",
    "\n",
    "```text\n",
    "migrations/\n",
    "\u251c\u2500\u2500 20241002143000_create_users_table.sql\n",
    "\u251c\u2500\u2500 20241002144500_add_user_indexes.sql\n",
    "\u2514\u2500\u2500 20241002150000_populate_user_defaults.sql\n",
    "```\n",
    "\n",
    "**Naming**: `YYYYMMDDhhmmss_descriptive_name.sql`\n",
    "- Timestamp ensures ordering\n",
    "- Description aids debugging\n",
    "- No version numbers (conflict-prone in teams)\n",
    "\n",
    "### 31.6.2 Transaction Control\n",
    "\n",
    "```sql\n",
    "-- migrations/20241002143000_add_constraint.sql\n",
    "\n",
    "-- Wrap related changes in transaction\n",
    "BEGIN;\n",
    "\n",
    "-- Step 1: Add column\n",
    "ALTER TABLE users ADD COLUMN email_verified BOOLEAN DEFAULT false;\n",
    "\n",
    "-- Step 2: Create index concurrently (CANNOT be in transaction)\n",
    "-- This must be separate migration file run outside transaction\n",
    "\n",
    "COMMIT;\n",
    "\n",
    "-- migrations/20241002143500_add_index_concurrently.sql\n",
    "-- NO BEGIN/COMMIT - run as single statement\n",
    "CREATE INDEX CONCURRENTLY idx_users_email_verified ON users(email_verified);\n",
    "```\n",
    "\n",
    "### 31.6.3 Pre-Deployment Validation\n",
    "\n",
    "```sql\n",
    "-- Add to migration preamble\n",
    "DO $$\n",
    "DECLARE\n",
    "    row_count BIGINT;\n",
    "BEGIN\n",
    "    -- Safety check: Ensure table size is expected\n",
    "    SELECT COUNT(*) INTO row_count FROM users;\n",
    "    \n",
    "    IF row_count > 10000000 THEN\n",
    "        RAISE EXCEPTION 'Table too large for this migration. Use background job instead.';\n",
    "    END IF;\n",
    "    \n",
    "    -- Check for conflicting data before adding constraint\n",
    "    IF EXISTS (SELECT 1 FROM users WHERE email IS NULL) THEN\n",
    "        RAISE EXCEPTION 'NULL emails exist. Clean data before adding NOT NULL constraint.';\n",
    "    END IF;\n",
    "END $$;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 31.7 Safety Mechanisms and Checklists\n",
    "\n",
    "### 31.7.1 The Migration Safety Checklist\n",
    "\n",
    "Before running any migration in production:\n",
    "\n",
    "- [ ] **Tested** on production-sized dataset in staging\n",
    "- [ ] **Timing**: Run during lowest traffic window (monitor with `pg_stat_activity`)\n",
    "- [ ] **Locks**: Verify no long-running transactions (`SELECT * FROM pg_stat_activity WHERE state = 'active' AND xact_start < NOW() - INTERVAL '5 minutes'`)\n",
    "- [ ] **Disk Space**: Ensure 50% free space for rewrites (`SELECT pg_size_pretty(pg_database_size(current_database()))`)\n",
    "- [ ] **Replication**: Check replication lag (`SELECT * FROM pg_stat_replication`) < 5 minutes\n",
    "- [ ] **Backup**: Fresh base backup completed within last 24 hours\n",
    "- [ ] **Rollback Plan**: PITR target time documented, not \"down migration\"\n",
    "- [ ] **Monitoring**: Alerting configured for lock waits > 30 seconds\n",
    "\n",
    "### 31.7.2 Lock Timeout and Statement Timeout\n",
    "\n",
    "Prevent runaway migrations from hanging indefinitely:\n",
    "\n",
    "```sql\n",
    "-- At start of migration session\n",
    "SET lock_timeout = '5s';        -- Fail fast if can't acquire lock quickly\n",
    "SET statement_timeout = '1h';   -- Kill migration if it runs too long\n",
    "SET idle_in_transaction_session_timeout = '10min';\n",
    "```\n",
    "\n",
    "### 31.7.3 Emergency Cancellation\n",
    "\n",
    "If a migration is blocking production:\n",
    "\n",
    "```bash\n",
    "# Find the migration process\n",
    "psql -c \"SELECT pid, query, state, now() - query_start as duration \n",
    "         FROM pg_stat_activity \n",
    "         WHERE query LIKE '%ALTER TABLE%' \n",
    "         AND state = 'active';\"\n",
    "\n",
    "# Cancel gracefully (SIGINT)\n",
    "SELECT pg_cancel_backend(pid);\n",
    "\n",
    "# If unresponsive, terminate (SIGTERM)\n",
    "SELECT pg_terminate_backend(pid);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 31.8 Handling Migration Failures\n",
    "\n",
    "### 31.8.1 Failed Partial Migrations\n",
    "\n",
    "When a migration fails midway (network blip, constraint violation):\n",
    "\n",
    "```sql\n",
    "-- Check what actually got applied\n",
    "SELECT * FROM schema_migrations WHERE version = '20241002143000';\n",
    "SELECT column_name FROM information_schema.columns WHERE table_name = 'users';\n",
    "\n",
    "-- If partially applied, determine if safe to rerun (idempotent) or needs manual cleanup\n",
    "-- Option 1: Rerun (if idempotent)\n",
    "-- Option 2: Manual cleanup + mark as applied (if cleanup is safer than rerunning)\n",
    "INSERT INTO schema_migrations (version, applied_at) \n",
    "VALUES ('20241002143000', NOW());\n",
    "-- Then apply corrected migration as new version\n",
    "```\n",
    "\n",
    "### 31.8.2 Hotfix Migrations (Out-of-Band)\n",
    "\n",
    "Emergency fixes that skip the queue:\n",
    "\n",
    "```sql\n",
    "-- Naming: prefix with timestamp + 'hotfix'\n",
    "-- 20241002150000_hotfix_add_missing_index.sql\n",
    "\n",
    "-- Must be backward compatible with pending migrations\n",
    "-- If other migrations added columns this uses, ensure they run first or check existence\n",
    "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_emergency_lookup \n",
    "ON users(status, created_at) \n",
    "WHERE deleted_at IS NULL;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary\n",
    "\n",
    "In this chapter, you learned:\n",
    "\n",
    "1. **Forward-Only Philosophy**: Never use \"down\" migrations in production. Recover from bad migrations using PITR or compensating transactions. Schema changes must be additive and backward compatible during the transition window.\n",
    "\n",
    "2. **Risk Classification**: Distinguish between metadata-only changes (fast, safe), locking changes (require `CONCURRENTLY` or `NOT VALID` patterns), and table rewrites (require `pg_repack` or background jobs). Always prefer `VALIDATE CONSTRAINT` over direct constraint addition.\n",
    "\n",
    "3. **Expand-Contract Pattern**: For structural changes (column renames, type changes), use three-phase deployment: (1) Add new structure and dual-write, (2) Migrate reads to new structure, (3) Remove old structure after grace period. This maintains N-1 compatibility.\n",
    "\n",
    "4. **Batch Processing**: Never update millions of rows in a single transaction. Use batched updates with `LIMIT` and `FOR UPDATE SKIP LOCKED`, committing frequently to release locks and allow vacuum to proceed. For billion-row tables, use background job tables instead of DDL migrations.\n",
    "\n",
    "5. **Concurrent Indexing**: Always use `CREATE INDEX CONCURRENTLY` in production. Never run it inside a transaction block. Monitor for invalid indexes and rebuild them. Expect 2-3x longer build times in exchange for zero locking.\n",
    "\n",
    "6. **Safety Mechanisms**: Use `lock_timeout` to prevent indefinite waiting, validate preconditions in `DO $$` blocks, check table sizes before rewrites, and maintain N-1 version compatibility during deployment windows. Run migrations during low-traffic periods with replication lag monitoring.\n",
    "\n",
    "**Next**: In Chapter 32, we will explore Upgrades and Major Version Changes\u2014covering planning strategies for PostgreSQL major version upgrades, the `pg_upgrade` utility with its copy vs. link modes, logical replication migration strategies, and extension compatibility management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='30. point_in_time_recovery_pitr_and_wal.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='32. upgrades_and_major_version_changes.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}