{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 37: Configuration Basics (Practical, Not Mystical)\n",
    "\n",
    "PostgreSQL's out-of-the-box configuration is designed for compatibility across hardware profiles, not performance. A stock installation typically allocates only 128MB of memory and conservative I/O settings suitable for a Raspberry Pi, not production workloads. This chapter provides a practical, operations-focused approach to tuning PostgreSQL without resorting to cargo-cult configuration copy-pasted from internet forums.\n",
    "\n",
    "We focus on settings that yield measurable improvements while explaining the mechanics behind each parameter, enabling you to make informed decisions based on your specific hardware, workload, and consistency requirements.\n",
    "\n",
    "## 37.1 Configuration Architecture and File Hierarchy\n",
    "\n",
    "PostgreSQL reads configuration from several locations with specific precedence rules. Understanding this hierarchy is essential for maintaining configuration across environments and troubleshooting unexpected behavior.\n",
    "\n",
    "### 37.1.1 Configuration File Locations\n",
    "\n",
    "```sql\n",
    "-- Locate configuration files dynamically\n",
    "SELECT name, setting FROM pg_settings WHERE category = 'File Locations';\n",
    "-- Typical output:\n",
    "-- config_file          | /var/lib/postgresql/data/postgresql.conf\n",
    "-- data_directory       | /var/lib/postgresql/data\n",
    "-- external_pid_file    | \n",
    "-- hba_file             | /var/lib/postgresql/data/pg_hba.conf\n",
    "-- ident_file           | /var/lib/postgresql/data/pg_ident.conf\n",
    "\n",
    "-- Check if settings are from postgresql.conf or overridden elsewhere\n",
    "SELECT name, setting, source, sourcefile, sourceline \n",
    "FROM pg_settings \n",
    "WHERE name IN ('shared_buffers', 'max_connections');\n",
    "```\n",
    "\n",
    "**File Hierarchy:**\n",
    "\n",
    "1. **`postgresql.conf`**: Primary configuration file. Contains most server parameters.\n",
    "2. **`postgresql.auto.conf`**: Machine-generated file managed via `ALTER SYSTEM` commands. Takes precedence over `postgresql.conf`.\n",
    "3. **`pg_hba.conf`**: Host-Based Authentication configuration. Controls client authentication methods.\n",
    "4. **`pg_ident.conf`**: User name mapping for external authentication systems.\n",
    "\n",
    "**Configuration Precedence (highest to lowest):**\n",
    "1. Command-line parameters (`postgres -c parameter=value`)\n",
    "2. `postgresql.auto.conf` (ALTER SYSTEM)\n",
    "3. `postgresql.conf`\n",
    "4. Compiled-in defaults\n",
    "\n",
    "### 37.1.2 Configuration Inclusion and Organization\n",
    "\n",
    "Modern PostgreSQL deployments organize configuration using include directives rather than monolithic files.\n",
    "\n",
    "```conf\n",
    "-- postgresql.conf\n",
    "-- Base settings\n",
    "data_directory = '/var/lib/postgresql/16/main'\n",
    "hba_file = '/etc/postgresql/16/main/pg_hba.conf'\n",
    "\n",
    "-- Include directory for modular configuration\n",
    "include_dir = 'conf.d'  -- Includes all .conf files in this directory alphabetically\n",
    "\n",
    "-- Or include specific files\n",
    "include_if_exists = 'custom_tuning.conf'\n",
    "```\n",
    "\n",
    "**Industry Standard Directory Structure:**\n",
    "\n",
    "```bash\n",
    "/etc/postgresql/16/main/\n",
    "├── postgresql.conf          # Minimal base file with includes\n",
    "├── pg_hba.conf             # Authentication rules\n",
    "├── pg_ident.conf           # External user mapping\n",
    "├── conf.d/\n",
    "│   ├── 00-memory.conf      # Memory settings\n",
    "│   ├── 10-storage.conf     # WAL, checkpoints, vacuum\n",
    "│   ├── 20-replication.conf # Streaming replication settings\n",
    "│   ├── 30-logging.conf     # Log configuration\n",
    "│   └── 99-custom.conf      # Local overrides (gitignored)\n",
    "└── environment             # System environment variables\n",
    "```\n",
    "\n",
    "**Benefits of this approach:**\n",
    "- Version control friendly (separate files for different concerns)\n",
    "- Environment-specific overlays (different memory settings for dev/prod)\n",
    "- Ansible/Chef/Puppet can template individual files without parsing entire postgresql.conf\n",
    "- Safe rollback (remove specific include file vs editing large config)\n",
    "\n",
    "### 37.1.3 Applying Configuration Changes\n",
    "\n",
    "PostgreSQL recognizes three classes of parameter changes:\n",
    "\n",
    "```sql\n",
    "-- Check context for any parameter (determines change method)\n",
    "SELECT name, context, unit, short_desc \n",
    "FROM pg_settings \n",
    "WHERE name = 'shared_buffers';\n",
    "-- context = 'postmaster'  → Requires restart\n",
    "-- context = 'sighup'      → Reload configuration sufficient  \n",
    "-- context = 'user'        → Can be changed per session\n",
    "-- context = 'superuser'   → Can be changed by superuser for session/system\n",
    "```\n",
    "\n",
    "**Change Methods:**\n",
    "\n",
    "1. **Restart Required** (`context = 'postmaster'`):\n",
    "   ```bash\n",
    "   # Stop and start (not reload)\n",
    "   pg_ctl restart -D /var/lib/postgresql/data\n",
    "   \n",
    "   # Or systemd\n",
    "   systemctl restart postgresql@16-main\n",
    "   \n",
    "   # Settings affected:\n",
    "   # - shared_buffers, max_connections, listen_addresses\n",
    "   # - port, unix_socket_directories, max_prepared_transactions\n",
    "   ```\n",
    "\n",
    "2. **Configuration Reload** (`context = 'sighup'`):\n",
    "   ```bash   # Method 1: SQL command (superuser)\n",
    "   SELECT pg_reload_conf();\n",
    "   \n",
    "   # Method 2: Signal to postmaster\n",
    "   kill -HUP $(head -1 /var/lib/postgresql/data/postmaster.pid)\n",
    "   \n",
    "   # Method 3: pg_ctl\n",
    "   pg_ctl reload -D /var/lib/postgresql/data\n",
    "   \n",
    "   # Method 4: systemd\n",
    "   systemctl reload postgresql@16-main\n",
    "   \n",
    "   # Settings affected:\n",
    "   # - autovacuum settings, log settings, ssl settings\n",
    "   # - most connection/runtime tunables\n",
    "   ```\n",
    "\n",
    "3. **Per-Session Changes** (`context = 'user'` or `superuser'`):\n",
    "   ```sql\n",
    "   -- Current session only\n",
    "   SET work_mem = '256MB';\n",
    "   \n",
    "   -- Current transaction only\n",
    "   SET LOCAL work_mem = '1GB';\n",
    "   \n",
    "   -- For specific user (persistent)\n",
    "   ALTER USER reporting_user SET work_mem = '512MB';\n",
    "   \n",
    "   -- For specific database\n",
    "   ALTER DATABASE analytics SET work_mem = '1GB';\n",
    "   ```\n",
    "\n",
    "## 37.2 Memory Configuration\n",
    "\n",
    "PostgreSQL memory architecture separates shared memory (accessible by all backends) from per-connection private memory. Misconfiguration here causes either OOM kills (Linux out-of-memory killer) or suboptimal performance.\n",
    "\n",
    "### 37.2.1 Shared Buffers (The PostgreSQL Page Cache)\n",
    "\n",
    "`shared_buffers` determines how much memory PostgreSQL dedicates to caching disk blocks. Unlike filesystem cache, PostgreSQL manages this directly with its own clock sweep algorithm.\n",
    "\n",
    "```conf\n",
    "# postgresql.conf\n",
    "shared_buffers = 25GB  # Typically 25% of RAM on dedicated database servers\n",
    "```\n",
    "\n",
    "**Industry Guidelines:**\n",
    "\n",
    "- **Dedicated PostgreSQL Server**: 25% of total RAM (not 50% as commonly mythologized)\n",
    "  - Remaining memory available for:\n",
    "    - Operating system filesystem cache (crucial for sequential scans)\n",
    "    - Connection memory (work_mem × connections)\n",
    "    - Maintenance operations\n",
    "    - Application processes on same host (if any)\n",
    "\n",
    "- **Shared Server** (PostgreSQL + Application): 15-20% of RAM\n",
    "\n",
    "- **Containers/Cloud Instances**: Calculate based on cgroup limits, not host RAM:\n",
    "  ```sql\n",
    "  -- Check actual memory available to PostgreSQL process\n",
    "  -- (Linux-specific, requires pg_read_file access)\n",
    "  SELECT pg_read_file('/proc/meminfo');\n",
    "  ```\n",
    "\n",
    "**Why not 50% or more?**\n",
    "PostgreSQL relies heavily on the operating system's filesystem cache for:\n",
    "- Double buffering avoidance (kernel cache + shared_buffers)\n",
    "- Efficient sequential scan performance\n",
    "- WAL file caching\n",
    "- Temporary file handling\n",
    "\n",
    "```sql\n",
    "-- Verify shared_buffers effectiveness (cache hit ratio should be >99%)\n",
    "SELECT \n",
    "    sum(heap_blks_read) as heap_read,\n",
    "    sum(heap_blks_hit)  as heap_hit,\n",
    "    sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)) * 100 as ratio\n",
    "FROM pg_statio_user_tables;\n",
    "-- If ratio < 95%, increase shared_buffers (if memory available)\n",
    "-- If ratio > 99.5% and memory pressure exists, can reduce slightly\n",
    "```\n",
    "\n",
    "**Huge Pages (Linux Optimization):**\n",
    "\n",
    "For servers with >32GB RAM and large shared_buffers, enable Huge Pages to reduce TLB (Translation Lookaside Buffer) misses:\n",
    "\n",
    "```bash\n",
    "# /etc/sysctl.conf\n",
    "vm.nr_hugepages = 13312  # Calculation: shared_buffers / huge_page_size (usually 2MB)\n",
    "# 25GB / 2MB = ~12800, add 5% buffer = 13312\n",
    "\n",
    "# postgresql.conf\n",
    "huge_pages = try  # 'on' = fail if unavailable, 'try' = use if available, 'off' = never\n",
    "```\n",
    "\n",
    "### 37.2.2 Work Memory (Query Operations)\n",
    "\n",
    "`work_mem` specifies the amount of memory available for internal sort operations and hash tables before spilling to disk. Unlike shared_buffers, work_mem is allocated **per operation**, not per query or connection.\n",
    "\n",
    "```conf\n",
    "# Base setting (conservative for OLTP)\n",
    "work_mem = 4MB\n",
    "\n",
    "# Analytics/reporting database\n",
    "work_mem = 256MB\n",
    "```\n",
    "\n",
    "**Critical Understanding:**\n",
    "If a query performs:\n",
    "- 2 sorts (ORDER BY + merge join)\n",
    "- 1 hash join\n",
    "- 3 hash aggregations\n",
    "\n",
    "It can consume up to `6 × work_mem` per connection.\n",
    "\n",
    "**Calculation Formula:**\n",
    "\n",
    "```sql\n",
    "-- Safe work_mem calculation\n",
    "-- Available RAM = Total RAM - shared_buffers - (OS + other processes)\n",
    "-- Conservative: Available RAM / max_connections / 2 (average operations per query)\n",
    "-- Aggressive: Available RAM / max_connections / 4\n",
    "\n",
    "-- Example: 64GB RAM, shared_buffers=16GB, max_connections=200\n",
    "-- Available: 48GB\n",
    "-- Conservative: 48GB / 200 / 2 = 120MB\n",
    "-- Safe setting: work_mem = 64MB to 128MB depending on workload mix\n",
    "```\n",
    "\n",
    "**Monitoring Disk Spills:**\n",
    "\n",
    "```sql\n",
    "-- Identify queries spilling to disk (temp files)\n",
    "SELECT \n",
    "    pid,\n",
    "    usename,\n",
    "    query,\n",
    "    temp_blks_read + temp_blks_written as temp_blocks,\n",
    "    pg_size_pretty((temp_blks_read + temp_blks_written) * 8192) as temp_size\n",
    "FROM pg_stat_activity\n",
    "JOIN pg_stat_user_tables USING (relid)\n",
    "WHERE temp_blks_read + temp_blks_written > 0\n",
    "ORDER BY temp_blocks DESC;\n",
    "\n",
    "-- Historical analysis (requires pg_stat_statements)\n",
    "SELECT \n",
    "    query,\n",
    "    calls,\n",
    "    mean_exec_time,\n",
    "    temp_blks_written * 8 / 1024 as temp_mb_written\n",
    "FROM pg_stat_statements\n",
    "WHERE temp_blks_written > 0\n",
    "ORDER BY temp_blks_written DESC\n",
    "LIMIT 10;\n",
    "```\n",
    "\n",
    "**Per-Query Override Pattern:**\n",
    "\n",
    "```sql\n",
    "-- Increase work_mem for specific heavy reporting query\n",
    "BEGIN;\n",
    "SET LOCAL work_mem = '1GB';\n",
    "SELECT * FROM huge_table ORDER BY complex_expression;\n",
    "COMMIT;  -- work_mem reverts to default after commit\n",
    "\n",
    "-- Or set for specific user role\n",
    "ALTER ROLE analytics_app SET work_mem = '512MB';\n",
    "ALTER ROLE web_app SET work_mem = '8MB';\n",
    "```\n",
    "\n",
    "### 37.2.3 Maintenance Work Memory\n",
    "\n",
    "`maintenance_work_mem` controls memory for maintenance operations: VACUUM, CREATE INDEX, ALTER TABLE ADD FOREIGN KEY, and REINDEX.\n",
    "\n",
    "```conf\n",
    "maintenance_work_mem = 1GB  # Default 64MB is too low for production tables\n",
    "```\n",
    "\n",
    "**Guidelines:**\n",
    "- **VACUUM**: Can use up to 1GB effectively per worker (autovacuum_max_workers)\n",
    "- **CREATE INDEX**: More memory = faster sorts, especially for B-tree creation\n",
    "- **Adding FKs**: Requires table scan and validation; memory speeds this significantly\n",
    "\n",
    "```sql\n",
    "-- Temporarily increase for specific maintenance\n",
    "SET maintenance_work_mem = '8GB';\n",
    "CREATE INDEX CONCURRENTLY idx_large_table ON large_table (column1, column2);\n",
    "RESET maintenance_work_mem;\n",
    "```\n",
    "\n",
    "**Autovacuum-Specific Memory:**\n",
    "\n",
    "```conf\n",
    "autovacuum_work_mem = -1  # -1 means use maintenance_work_mem\n",
    "# Or set independently:\n",
    "autovacuum_work_mem = 512MB\n",
    "```\n",
    "\n",
    "### 37.2.4 Effective Cache Size (Planner Hint)\n",
    "\n",
    "`effective_cache_size` informs the query planner about the total available cache (shared_buffers + OS filesystem cache). It does **not** allocate memory; it only influences cost estimates.\n",
    "\n",
    "```conf\n",
    "effective_cache_size = 48GB  # Total RAM - shared_buffers - headroom\n",
    "```\n",
    "\n",
    "**Best Practice:**\n",
    "Set to approximately `(Total RAM - shared_buffers) × 0.9`. On a 64GB server with 16GB shared_buffers: `(48GB × 0.9) = ~43GB`.\n",
    "\n",
    "**Why it matters:**\n",
    "The planner chooses between index scans and sequential scans based on estimated cache hit probability. Underestimating causes unnecessary index usage; overestimating causes slow sequential scans.\n",
    "\n",
    "```sql\n",
    "-- Verify planner assumptions match reality\n",
    "EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM large_table WHERE id > 1000;\n",
    "-- Check if \"Shared Hit Blocks\" matches planner expectations\n",
    "```\n",
    "\n",
    "### 37.2.5 Connection Memory Overhead\n",
    "\n",
    "Each connection consumes memory regardless of activity:\n",
    "\n",
    "```conf\n",
    "# Memory per connection (approximate)\n",
    "# - Base overhead: ~1.5MB\n",
    "# - work_mem (worst case if multiple operations)\n",
    "# - temp_buffers: 8MB default (session-local temporary tables)\n",
    "# - max_prepared_transactions overhead if using prepared xacts\n",
    "\n",
    "# Calculate maximum theoretical memory usage:\n",
    "# shared_buffers + (max_connections × (work_mem × avg_ops_per_query + 1.5MB))\n",
    "```\n",
    "\n",
    "**Connection Pooling Strategy:**\n",
    "Since memory scales with connections, always use connection pooling (PgBouncer) in production:\n",
    "\n",
    "```conf\n",
    "# With PgBouncer transaction pooling:\n",
    "max_connections = 200          # Database level\n",
    "pgbouncer default_pool_size = 20  # Actual Postgres connections\n",
    "application connections = 1000    # Can be much higher\n",
    "```\n",
    "\n",
    "## 37.3 Write-Ahead Logging (WAL) Configuration\n",
    "\n",
    "The WAL is the center of PostgreSQL's durability and replication architecture. Proper configuration balances crash recovery time (RTO) against write performance.\n",
    "\n",
    "### 37.3.1 WAL Level and Archiving\n",
    "\n",
    "```conf\n",
    "# wal_level determines what information is written to WAL\n",
    "wal_level = replica  # Options: minimal, replica, logical\n",
    "\n",
    "# minimal: Only crash recovery (cannot replicate or use PITR)\n",
    "# replica: Supports streaming replication and PITR (most common)\n",
    "# logical: Supports logical replication and logical decoding\n",
    "```\n",
    "\n",
    "**Industry Standard:**\n",
    "- **Standalone/Development**: `minimal` (if you don't need replication)\n",
    "- **Production**: `replica` (minimum for backups and HA)\n",
    "- **Logical Replication**: `logical` (required for pglogical, pgoutput)\n",
    "\n",
    "### 37.3.2 Checkpoint Configuration\n",
    "\n",
    "Checkpoints ensure dirty buffers are written to disk and WAL can be recycled. Aggressive checkpointing improves crash recovery time but hurts performance; relaxed checkpointing improves performance but extends recovery time.\n",
    "\n",
    "```conf\n",
    "# Time-based checkpointing\n",
    "checkpoint_timeout = 15min        # Range: 30s to 1d, default 5min\n",
    "checkpoint_completion_target = 0.9 # Spread writes over 90% of checkpoint interval\n",
    "\n",
    "# Size-based checkpointing (Primary control in modern Postgres)\n",
    "max_wal_size = 4GB               # Default 1GB too small for busy systems\n",
    "min_wal_size = 1GB               # WAL recycling target\n",
    "```\n",
    "\n",
    "**Mechanism Explanation:**\n",
    "When WAL reaches `max_wal_size`, PostgreSQL initiates a checkpoint. With `checkpoint_completion_target = 0.9`, PostgreSQL spreads disk writes over `15min × 0.9 = 13.5 minutes` to avoid I/O spikes.\n",
    "\n",
    "**Tuning for SSD vs HDD:**\n",
    "\n",
    "```conf\n",
    "# SSD/NVMe (fast random I/O):\n",
    "checkpoint_timeout = 15min\n",
    "max_wal_size = 8GB to 32GB  # Larger = fewer checkpoints, but longer recovery\n",
    "checkpoint_completion_target = 0.9\n",
    "\n",
    "# Traditional HDD (slow seeks, benefit from fewer writes):\n",
    "checkpoint_timeout = 10min\n",
    "max_wal_size = 4GB\n",
    "checkpoint_completion_target = 0.5  # Complete faster to free buffers\n",
    "```\n",
    "\n",
    "**Monitoring Checkpoint Behavior:**\n",
    "\n",
    "```sql\n",
    "-- Check checkpoint frequency and timing\n",
    "SELECT \n",
    "    checkpoints_timed,      -- Scheduled by timeout\n",
    "    checkpoints_req,        -- Forced by WAL size (should be minority)\n",
    "    checkpoint_write_time,  -- Time writing buffers to disk (milliseconds)\n",
    "    checkpoint_sync_time    -- Time syncing to disk (fsync)\n",
    "FROM pg_stat_bgwriter;\n",
    "\n",
    "-- Ideal ratio: checkpoints_timed should be 80%+ of total checkpoints\n",
    "-- If checkpoints_req dominates, increase max_wal_size\n",
    "```\n",
    "\n",
    "### 37.3.3 WAL Buffers\n",
    "\n",
    "```conf\n",
    "wal_buffers = -1  # Auto-tuned: typically 1/32 of shared_buffers, capped at 16MB\n",
    "```\n",
    "\n",
    "**Manual Override:**\n",
    "Only change from `-1` if you observe WAL buffer waits:\n",
    "\n",
    "```sql\n",
    "-- Check for WAL write waits\n",
    "SELECT \n",
    "    wal_buffer_writes,  -- Times WAL data written to disk\n",
    "    wal_buffers_full    -- Times WAL buffers were full and waited\n",
    "FROM pg_stat_wal;  -- PostgreSQL 14+\n",
    "```\n",
    "\n",
    "**Guideline:**\n",
    "For high-write systems ( >1000 TPS), explicitly set:\n",
    "```conf\n",
    "wal_buffers = 16MB  # Maximum effective size\n",
    "```\n",
    "\n",
    "### 37.3.4 Synchronous Commit Modes\n",
    "\n",
    "`synchronous_commit` balances durability guarantees against commit latency.\n",
    "\n",
    "```conf\n",
    "synchronous_commit = on  # Default: wait for WAL flush to disk before acknowledging commit\n",
    "```\n",
    "\n",
    "**Options:**\n",
    "\n",
    "1. **`on`** (Production Default):\n",
    "   - Waits for WAL to reach disk before returning success to client\n",
    "   - Guarantees durability even if OS crashes\n",
    "   - Latency: Disk fsync time (0.5-5ms SSD, 5-20ms HDD)\n",
    "\n",
    "2. **`off`** (High-throughput, acceptable data loss window):\n",
    "   - Returns success immediately; WAL flushed by wal_writer process\n",
    "   - Risk: Last few seconds of transactions lost on crash\n",
    "   - Use case: Logging, analytics bulk loads, non-critical writes\n",
    "   \n",
    "   ```sql\n",
    "   -- Per-session for bulk load\n",
    "   BEGIN;\n",
    "   SET LOCAL synchronous_commit = off;\n",
    "   -- ... bulk insert ...\n",
    "   COMMIT;\n",
    "   ```\n",
    "\n",
    "3. **`local`**:\n",
    "   - Waits for local disk flush, not replica confirmation\n",
    "   - Used when streaming replication has `synchronous_standby_names` set but you don't want to wait for network round-trip\n",
    "\n",
    "4. **`remote_write`**, **`remote_apply`**, **`on`** (with sync replication):\n",
    "   - Wait for standby to receive/write/apply WAL\n",
    "   - See Chapter 33 for streaming replication details\n",
    "\n",
    "## 37.4 Autovacuum Tuning\n",
    "\n",
    "Autovacuum prevents transaction ID wraparound and maintains query performance by updating table statistics and reclaiming dead tuples. Default settings are too conservative for high-churn tables.\n",
    "\n",
    "### 37.4.1 Global Autovacuum Settings\n",
    "\n",
    "```conf\n",
    "autovacuum = on                    # Master switch\n",
    "autovacuum_max_workers = 3         # Parallel vacuum processes (default 3)\n",
    "autovacuum_naptime = 1min          # Check interval\n",
    "autovacuum_vacuum_threshold = 50   # Minimum dead tuples before vacuum\n",
    "autovacuum_vacuum_scale_factor = 0.2  # Fraction of table size to trigger vacuum\n",
    "autovacuum_analyze_threshold = 50\n",
    "autovacuum_analyze_scale_factor = 0.1\n",
    "```\n",
    "\n",
    "**Worker Memory and I/O:**\n",
    "\n",
    "```conf\n",
    "autovacuum_work_mem = -1           # Use maintenance_work_mem\n",
    "autovacuum_vacuum_cost_delay = 2ms  # Throttling (default 2ms)\n",
    "autovacuum_vacuum_cost_limit = -1   # -1 = use vacuum_cost_limit (default 10000)\n",
    "```\n",
    "\n",
    "**Cost-Based Throttling Explanation:**\n",
    "PostgreSQL assigns \"cost points\" to vacuum operations:\n",
    "- 1 for each page hit (buffer pool)\n",
    "- 10 for each page miss (disk read)\n",
    "- 20 for each dirty page written\n",
    "\n",
    "When accumulated cost reaches `autovacuum_vacuum_cost_limit`, vacuum sleeps for `autovacuum_vacuum_cost_delay`.\n",
    "\n",
    "**Modern SSD Tuning:**\n",
    "For SSD storage, increase the cost limit to allow faster vacuuming:\n",
    "\n",
    "```conf\n",
    "autovacuum_vacuum_cost_limit = 2000   # Double the default\n",
    "autovacuum_vacuum_cost_delay = 2ms    # Or even 0ms for very fast storage\n",
    "```\n",
    "\n",
    "### 37.4.2 Per-Table Autovacuum Configuration\n",
    "\n",
    "High-churn tables need aggressive vacuuming; large static tables need minimal attention.\n",
    "\n",
    "```sql\n",
    "-- Aggressive settings for high-update table (e.g., session store)\n",
    "ALTER TABLE user_sessions SET (\n",
    "    autovacuum_vacuum_scale_factor = 0.05,  -- Vacuum at 5% dead tuples (vs 20%)\n",
    "    autovacuum_analyze_scale_factor = 0.02, -- Analyze at 2% changes\n",
    "    autovacuum_vacuum_cost_limit = 1000,    -- Faster vacuum (less throttling)\n",
    "    fillfactor = 85                         -- Leave 15% free for HOT updates\n",
    ");\n",
    "\n",
    "-- Minimal vacuuming for append-only large table (e.g., audit log)\n",
    "ALTER TABLE audit_log SET (\n",
    "    autovacuum_vacuum_scale_factor = 0.4,   -- Only vacuum at 40% dead tuples\n",
    "    autovacuum_analyze_scale_factor = 0.0,  -- Disable auto-analyze\n",
    "    autovacuum_analyze_threshold = 0\n",
    ");\n",
    "-- Manually analyze during low-traffic windows instead\n",
    "```\n",
    "\n",
    "**Formula for Scale Factor:**\n",
    "Default `scale_factor = 0.2` on a 100GB table requires 20GB of dead tuples before vacuuming. Use `autovacuum_vacuum_insert_scale_factor` (PG13+) or absolute thresholds instead:\n",
    "\n",
    "```sql\n",
    "-- PostgreSQL 13+: Vacuum based on insert count (for anti-wraparound)\n",
    "ALTER TABLE high_insert_table SET (\n",
    "    autovacuum_vacuum_insert_threshold = 1000,\n",
    "    autovacuum_vacuum_insert_scale_factor = 0.05\n",
    ");\n",
    "\n",
    "-- Absolute threshold (better for large tables)\n",
    "ALTER TABLE large_table SET (\n",
    "    autovacuum_vacuum_threshold = 10000,\n",
    "    autovacuum_vacuum_scale_factor = 0.0  -- Ignore scale, use absolute threshold\n",
    ");\n",
    "-- Now vacuums when 10,000 dead tuples exist, regardless of table size\n",
    "```\n",
    "\n",
    "### 37.4.3 Freeze Thresholds and Anti-Wraparound\n",
    "\n",
    "Transaction ID wraparound is a critical failure mode. PostgreSQL forces vacuum when tables approach the 2 billion transaction limit.\n",
    "\n",
    "```conf\n",
    "vacuum_freeze_min_age = 50000000        # 50 million transactions\n",
    "vacuum_freeze_table_age = 150000000     # 150 million (forces aggressive vacuum)\n",
    "autovacuum_freeze_max_age = 200000000   # 200 million (forces autovacuum regardless of load)\n",
    "```\n",
    "\n",
    "**Monitoring Wraparound Risk:**\n",
    "\n",
    "```sql\n",
    "-- Critical: Check age of databases (must stay below 2 billion)\n",
    "SELECT \n",
    "    datname,\n",
    "    age(datfrozenxid) as xid_age,\n",
    "    2000000000 - age(datfrozenxid) as transactions_until_wraparound,\n",
    "    pg_size_pretty(pg_database_size(oid)) as db_size\n",
    "FROM pg_database\n",
    "ORDER BY age(datfrozenxid) DESC;\n",
    "\n",
    "-- Table-level detail\n",
    "SELECT \n",
    "    relname,\n",
    "    age(relfrozenxid) as xid_age,\n",
    "    n_dead_tup,\n",
    "    last_vacuum,\n",
    "    last_autovacuum\n",
    "FROM pg_stat_user_tables\n",
    "ORDER BY age(relfrozenxid) DESC\n",
    "LIMIT 20;\n",
    "```\n",
    "\n",
    "**Emergency Intervention:**\n",
    "If `age(relfrozenxid)` approaches 1.5 billion:\n",
    "```sql\n",
    "-- Vacuum with freeze (aggressive, blocks writes briefly)\n",
    "VACUUM (FREEZE, ANALYZE, VERBOSE) critical_table;\n",
    "```\n",
    "\n",
    "## 37.5 Environment-Specific Configuration Strategy\n",
    "\n",
    "Configuration must adapt to development, staging, and production constraints while maintaining consistency in logic (e.g., SQL behavior settings).\n",
    "\n",
    "### 37.5.1 Development Environment\n",
    "\n",
    "```conf\n",
    "# 00-memory-dev.conf\n",
    "shared_buffers = 256MB          # Small, laptop-friendly\n",
    "work_mem = 16MB                 # Allow complex queries during development\n",
    "maintenance_work_mem = 256MB    # Fast index creation on small datasets\n",
    "\n",
    "# Logging everything for debugging\n",
    "log_statement = 'all'           # Log every SQL statement\n",
    "log_duration = on\n",
    "log_min_duration_statement = 0  # Log all durations\n",
    "log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '\n",
    "log_checkpoints = on\n",
    "log_connections = on\n",
    "log_disconnections = on\n",
    "\n",
    "# Relaxed durability for speed\n",
    "synchronous_commit = off        # Faster, acceptable for dev data loss\n",
    "fsync = off                     # NEVER in production, acceptable for local dev\n",
    "full_page_writes = off          # NEVER in production\n",
    "```\n",
    "\n",
    "**Critical Safety:** Always use `ALTER SYSTEM` or distinct include files to prevent dev settings reaching production:\n",
    "\n",
    "```bash\n",
    "# Production deployment checklist\n",
    "grep -E \"^(fsync|synchronous_commit|full_page_writes)\" postgresql.conf\n",
    "# Should never see fsync = off in production\n",
    "```\n",
    "\n",
    "### 37.5.2 Staging/Testing Environment\n",
    "\n",
    "Mirror production hardware at smaller scale but maintain identical configuration logic:\n",
    "\n",
    "```conf\n",
    "# Staging should test production parameters\n",
    "shared_buffers = 2GB            # Scaled down from prod 32GB\n",
    "work_mem = 4MB                  # Same as production\n",
    "maintenance_work_mem = 512MB    # Same ratio as production\n",
    "\n",
    "# But enable heavy logging for performance testing\n",
    "log_min_duration_statement = 100  # Log slow queries for optimization\n",
    "auto_explain.log_min_duration = 100\n",
    "auto_explain.log_analyze = on     # See actual plans in logs\n",
    "```\n",
    "\n",
    "### 37.5.3 Production Environment\n",
    "\n",
    "```conf\n",
    "# 00-memory-prod.conf\n",
    "shared_buffers = 32GB           # 25% of 128GB RAM\n",
    "work_mem = 8MB                  # Conservative base, override per-role if needed\n",
    "maintenance_work_mem = 2GB\n",
    "effective_cache_size = 96GB     # (128GB - 32GB) * 0.9\n",
    "\n",
    "# 10-storage-prod.conf\n",
    "max_wal_size = 16GB\n",
    "checkpoint_timeout = 15min\n",
    "checkpoint_completion_target = 0.9\n",
    "wal_buffers = 16MB\n",
    "\n",
    "# 20-vacuum-prod.conf\n",
    "autovacuum_max_workers = 6      # More workers for high-churn OLTP\n",
    "autovacuum_vacuum_cost_limit = 2000  # Faster vacuum on SSD storage\n",
    "\n",
    "# 30-logging-prod.conf (minimal, for performance)\n",
    "log_min_duration_statement = 1000   # Only log queries > 1s\n",
    "log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '\n",
    "log_checkpoints = on                # Always monitor checkpoints\n",
    "log_lock_waits = on                 # Detect deadlock/lock timeout\n",
    "log_temp_files = 32MB               # Log disk sorts > 32MB\n",
    "```\n",
    "\n",
    "### 37.5.4 Configuration Validation Checklist\n",
    "\n",
    "Before applying configuration changes:\n",
    "\n",
    "```sql\n",
    "-- 1. Verify no typos (invalid parameter names)\n",
    "SELECT name FROM pg_settings WHERE source = 'configuration file';\n",
    "\n",
    "-- 2. Check for pending restarts (parameters changed but require restart)\n",
    "SELECT name, setting, pending_restart \n",
    "FROM pg_settings \n",
    "WHERE pending_restart = true;\n",
    "\n",
    "-- 3. Validate memory math won't cause OOM\n",
    "WITH mem_settings AS (\n",
    "    SELECT \n",
    "        (SELECT setting::int * 8192 FROM pg_settings WHERE name = 'shared_buffers') as shared_bytes,\n",
    "        (SELECT setting::int FROM pg_settings WHERE name = 'max_connections') as max_conn,\n",
    "        (SELECT setting::int * 1024 FROM pg_settings WHERE name = 'work_mem') as work_bytes,\n",
    "        (SELECT setting::int * 1024 FROM pg_settings WHERE name = 'maintenance_work_mem') as maint_bytes,\n",
    "        (SELECT setting::int FROM pg_settings WHERE name = 'autovacuum_max_workers') as vac_workers\n",
    ")\n",
    "SELECT \n",
    "    pg_size_pretty(shared_bytes) as shared_buffers,\n",
    "    max_conn,\n",
    "    pg_size_pretty(work_bytes) as work_mem,\n",
    "    -- Worst case memory (all connections doing 2 sorts + autovacuum maintenance)\n",
    "    pg_size_pretty(\n",
    "        shared_bytes + \n",
    "        (max_conn * work_bytes * 2) + \n",
    "        (vac_workers * maint_bytes)\n",
    "    ) as theoretical_max_memory\n",
    "FROM mem_settings;\n",
    "```\n",
    "\n",
    "## 37.6 Critical Parameters Reference\n",
    "\n",
    "### 37.6.1 Connection and Security\n",
    "\n",
    "```conf\n",
    "max_connections = 200           # Increase only if necessary; prefer pooling\n",
    "superuser_reserved_connections = 3  # Reserved for emergency access\n",
    "ssl = on\n",
    "ssl_cert_file = 'server.crt'\n",
    "ssl_key_file = 'server.key'\n",
    "password_encryption = scram-sha-256  # Modern standard, not md5\n",
    "```\n",
    "\n",
    "### 37.6.2 Query Planning\n",
    "\n",
    "```conf\n",
    "random_page_cost = 1.1          # For SSD storage (default 4.0 is for HDD)\n",
    "seq_page_cost = 1.0\n",
    "effective_io_concurrency = 200  # SSD random read capability\n",
    "```\n",
    "\n",
    "**Why `random_page_cost` matters:**\n",
    "Default `4.0` assumes random I/O is 4x slower than sequential. On SSDs, random and sequential performance are nearly equal (`1.1` or `1.0`). Setting this incorrectly causes the planner to avoid index scans in favor of sequential scans.\n",
    "\n",
    "### 37.6.3 Logging and Monitoring\n",
    "\n",
    "```conf\n",
    "logging_collector = on\n",
    "log_directory = 'log'\n",
    "log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'\n",
    "log_rotation_age = 1d\n",
    "log_rotation_size = 100MB\n",
    "\n",
    "# Performance insights\n",
    "track_io_timing = on            # Enable pg_stat_database blk_read_time\n",
    "track_functions = pl            # Track function execution times\n",
    "```\n",
    "\n",
    "## Chapter Summary\n",
    "\n",
    "In this chapter, you learned:\n",
    "\n",
    "1. **Configuration Architecture**: PostgreSQL uses `postgresql.conf` (base), `postgresql.auto.conf` (ALTER SYSTEM overrides), and include directories for modular management. Always organize production configs into logical include files (memory.conf, storage.conf, replication.conf).\n",
    "\n",
    "2. **Memory Management**: \n",
    "   - `shared_buffers`: 25% of RAM on dedicated servers, never exceed 40%\n",
    "   - `work_mem`: Conservative base (4-8MB), override per-session for analytics\n",
    "   - `maintenance_work_mem`: 1-2GB for fast index creation and vacuuming\n",
    "   - `effective_cache_size`: Planner hint set to ~70% of total RAM\n",
    "\n",
    "3. **WAL and Checkpoints**: \n",
    "   - `wal_level = replica` minimum for production (enables PITR and replication)\n",
    "   - `max_wal_size`: 4GB-32GB depending on write volume and recovery time objectives\n",
    "   - `checkpoint_completion_target = 0.9` to spread I/O evenly\n",
    "   - `synchronous_commit`: `on` for durability, `off` only for specific high-throughput batch loads\n",
    "\n",
    "4. **Autovacuum Tuning**: \n",
    "   - Increase `autovacuum_max_workers` to 4-6 for high-churn OLTP systems\n",
    "   - Reduce `autovacuum_vacuum_scale_factor` (to 0.05 or 0.1) for large tables using `ALTER TABLE`\n",
    "   - Monitor `pg_stat_user_tables` to ensure vacuum keeps up with dead tuple generation\n",
    "   - Watch transaction ID age (`age(relfrozenxid)`) to prevent wraparound emergencies\n",
    "\n",
    "5. **Environment Strategy**: \n",
    "   - Development: Relaxed durability (`fsync = off` acceptable only locally), verbose logging\n",
    "   - Production: Conservative memory settings, minimal logging (slow queries only), maximum durability\n",
    "   - Always validate configuration with `pg_settings` views before and after changes\n",
    "\n",
    "6. **Change Management**: Distinguish between reloadable parameters (SIGHUP) and restart-required parameters (postmaster). Use `SELECT pg_reload_conf()` for online tuning where possible.\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** In Chapter 38, we will examine Vacuum, Analyze, and Bloat management in detail—covering the mechanics of MVCC cleanup, table bloat detection and remediation, aggressive vacuuming strategies for high-churn tables, and the pg_dump/pg_repack tools for physical reorganization."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
