{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a032d981",
   "metadata": {},
   "source": [
    "# Chapter 18: Performance Tuning Playbook\n",
    "\n",
    "Performance optimization requires methodical diagnosis followed by targeted refactoring. This chapter provides actionable patterns for query restructuring, systematic index selection, batch operation optimization, and elimination of N+1 anti-patterns. These are the practical techniques used in production environments to achieve sub-100ms response times at scale.\n",
    "\n",
    "## 18.1 Query Refactoring Patterns\n",
    "\n",
    "Query structure fundamentally determines execution efficiency. These patterns transform computationally expensive operations into index-friendly, set-based operations.\n",
    "\n",
    "### 18.1.1 Eliminating SELECT * and Projection Pushdown\n",
    "\n",
    "```sql\n",
    "-- Anti-pattern: SELECT * with ORM defaults\n",
    "SELECT * FROM orders \n",
    "WHERE customer_id = 123 \n",
    "ORDER BY created_at DESC \n",
    "LIMIT 20;\n",
    "\n",
    "-- Problems:\n",
    "-- 1. Retrieves TOAST columns (large text/json) unnecessarily\n",
    "-- 2. Prevents index-only scans (must fetch heap for all columns)\n",
    "-- 3. Increases network bandwidth\n",
    "-- 4. Breaks covering index strategies\n",
    "\n",
    "-- Refactored: Explicit column selection\n",
    "SELECT order_id, total_amount, status, created_at \n",
    "FROM orders \n",
    "WHERE customer_id = 123 \n",
    "ORDER BY created_at DESC \n",
    "LIMIT 20;\n",
    "\n",
    "-- Benefits:\n",
    "-- 1. Enables index-only scan if covering index exists:\n",
    "--    CREATE INDEX idx_orders_cust_created_cover ON orders(customer_id, created_at) \n",
    "--    INCLUDE (order_id, total_amount, status);\n",
    "-- 2. Heap fetches reduced from 20 full rows to 0 (if covering) or minimal\n",
    "-- 3. TOAST data (large JSONB descriptions) not fetched\n",
    "\n",
    "-- Projection pushdown in CTEs (PostgreSQL 12+):\n",
    "WITH recent_orders AS MATERIALIZED (\n",
    "    SELECT order_id, customer_id, total FROM orders \n",
    "    WHERE created_at > NOW() - INTERVAL '7 days'\n",
    ")\n",
    "SELECT * FROM recent_orders ro\n",
    "JOIN customers c ON ro.customer_id = c.customer_id;\n",
    "\n",
    "-- Without MATERIALIZED, PostgreSQL inlines CTE and may push projections down\n",
    "-- With MATERIALIZED, CTE computes fully then projects\n",
    "-- Use MATERIALIZED when CTE acts as optimization fence (preventing bad plans)\n",
    "-- Avoid MATERIALIZED when CTE result large and further filtering possible\n",
    "```\n",
    "\n",
    "### 18.1.2 Subquery vs JOIN: Performance Characteristics\n",
    "\n",
    "```sql\n",
    "-- Scenario: Find customers with recent orders\n",
    "\n",
    "-- Approach 1: Correlated Subquery (row-by-row execution)\n",
    "SELECT customer_id, name \n",
    "FROM customers c\n",
    "WHERE EXISTS (\n",
    "    SELECT 1 FROM orders o \n",
    "    WHERE o.customer_id = c.customer_id \n",
    "      AND o.created_at > NOW() - INTERVAL '30 days'\n",
    ");\n",
    "\n",
    "-- Plan: Nested Loop Semi Join\n",
    "-- For each customer (outer), probe orders index (inner)\n",
    "-- Optimal when customers table small, orders index selective\n",
    "\n",
    "-- Approach 2: JOIN with DISTINCT (set-based)\n",
    "SELECT DISTINCT c.customer_id, c.name \n",
    "FROM customers c\n",
    "JOIN orders o ON c.customer_id = o.customer_id \n",
    "WHERE o.created_at > NOW() - INTERVAL '30 days';\n",
    "\n",
    "-- Plan: Hash Join or Merge Join\n",
    "-- Builds hash of orders first, then probes with customers\n",
    "-- Optimal when orders table moderate size, many customers have recent orders\n",
    "\n",
    "-- Approach 3: Semi-Join with IN (alternative syntax)\n",
    "SELECT customer_id, name \n",
    "FROM customers \n",
    "WHERE customer_id IN (\n",
    "    SELECT customer_id FROM orders \n",
    "    WHERE created_at > NOW() - INTERVAL '30 days'\n",
    ");\n",
    "\n",
    "-- Planner typically converts IN to JOIN or EXISTS automatically\n",
    "-- Use EXISTS when null handling matters (IN fails with NULLs in subquery)\n",
    "\n",
    "-- Decision matrix:\n",
    "-- Small outer, selective inner index: Correlated subquery (Nested Loop)\n",
    "-- Large outer, moderate inner: JOIN with DISTINCT (Hash/Merge)\n",
    "-- Need additional columns from inner: JOIN (not EXISTS)\n",
    "-- Anti-patterns (NOT IN): Use NOT EXISTS instead (handles NULLs correctly)\n",
    "```\n",
    "\n",
    "### 18.1.3 LATERAL Joins for Top-N per Group\n",
    "\n",
    "```sql\n",
    "-- Problem: Find the 3 most recent orders per customer\n",
    "-- Anti-pattern: Self-join with correlated subquery (O(n²))\n",
    "SELECT c.customer_id, o.order_id, o.total\n",
    "FROM customers c\n",
    "JOIN orders o ON o.customer_id = c.customer_id\n",
    "WHERE o.order_id IN (\n",
    "    SELECT order_id \n",
    "    FROM orders o2 \n",
    "    WHERE o2.customer_id = c.customer_id \n",
    "    ORDER BY created_at DESC \n",
    "    LIMIT 3\n",
    ");\n",
    "\n",
    "-- Inefficient: Correlated subquery runs per customer, no index optimization for LIMIT\n",
    "\n",
    "-- Solution: LATERAL join (row-by-row with optimizer support)\n",
    "SELECT c.customer_id, o.order_id, o.total, o.created_at\n",
    "FROM customers c\n",
    "LEFT JOIN LATERAL (\n",
    "    SELECT order_id, total, created_at\n",
    "    FROM orders o\n",
    "    WHERE o.customer_id = c.customer_id\n",
    "    ORDER BY created_at DESC\n",
    "    LIMIT 3\n",
    ") o ON true\n",
    "WHERE c.status = 'active';\n",
    "\n",
    "-- Plan structure:\n",
    "-- Nested Loop Left Join\n",
    "--   -> Index Scan on customers (filtered by status)\n",
    "--   -> Limit (child of Nested Loop)\n",
    "--         -> Index Scan on orders (using idx_orders_customer_created)\n",
    "--               Index Cond: (customer_id = c.customer_id)\n",
    "\n",
    "-- Key advantages:\n",
    "-- 1. Index on (customer_id, created_at DESC) used efficiently for each customer\n",
    "-- 2. Limit 3 applied per customer before join (minimal rows fetched)\n",
    "-- 3. No sorting of entire result set\n",
    "\n",
    "-- Alternative for small groups: Window functions\n",
    "SELECT customer_id, order_id, total, created_at\n",
    "FROM (\n",
    "    SELECT \n",
    "        c.customer_id, \n",
    "        o.order_id, \n",
    "        o.total, \n",
    "        o.created_at,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY c.customer_id \n",
    "            ORDER BY o.created_at DESC\n",
    "        ) as rn\n",
    "    FROM customers c\n",
    "    JOIN orders o ON c.customer_id = o.customer_id\n",
    "    WHERE c.status = 'active'\n",
    ") sub\n",
    "WHERE rn <= 3;\n",
    "\n",
    "-- Comparison:\n",
    "-- LATERAL: Best when few customers, many orders per customer\n",
    "-- Window functions: Best when many customers, scanning all orders acceptable\n",
    "-- LATERAL uses index efficiently for each probe; Window scans then filters\n",
    "```\n",
    "\n",
    "### 18.1.4 Window Functions vs Self-Joins\n",
    "\n",
    "```sql\n",
    "-- Problem: Calculate running total of orders per customer\n",
    "\n",
    "-- Anti-pattern: Self-join (quadratic growth)\n",
    "SELECT \n",
    "    a.customer_id,\n",
    "    a.order_id,\n",
    "    a.created_at,\n",
    "    SUM(b.total) as running_total\n",
    "FROM orders a\n",
    "JOIN orders b ON a.customer_id = b.customer_id \n",
    "    AND b.created_at <= a.created_at\n",
    "GROUP BY a.customer_id, a.order_id, a.created_at;\n",
    "\n",
    "-- Complexity: O(n²) - joins every row with all previous rows\n",
    "-- Fails beyond few thousand rows per customer\n",
    "\n",
    "-- Solution: Window functions (linear complexity)\n",
    "SELECT \n",
    "    customer_id,\n",
    "    order_id,\n",
    "    created_at,\n",
    "    SUM(total) OVER (\n",
    "        PARTITION BY customer_id \n",
    "        ORDER BY created_at\n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "    ) as running_total\n",
    "FROM orders;\n",
    "\n",
    "-- Plan: WindowAgg with Sort (or Index Scan if covering index exists)\n",
    "-- Complexity: O(n log n) due to sort, then O(n) for aggregation\n",
    "-- 1000x faster for large partitions\n",
    "\n",
    "-- Advanced window frame: Moving average\n",
    "SELECT \n",
    "    customer_id,\n",
    "    created_at,\n",
    "    total,\n",
    "    AVG(total) OVER (\n",
    "        PARTITION BY customer_id \n",
    "        ORDER BY created_at\n",
    "        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n",
    "    ) as seven_order_avg\n",
    "FROM orders;\n",
    "\n",
    "-- Frame exclusion (exclude current row from calculation):\n",
    "SUM(total) OVER (\n",
    "    PARTITION BY customer_id \n",
    "    ORDER BY created_at\n",
    "    ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    ") as total_before_this_order\n",
    "```\n",
    "\n",
    "### 18.1.5 CTE Optimization Strategies\n",
    "\n",
    "```sql\n",
    "-- PostgreSQL 12+ behavior: CTEs inlined by default (optimization fence removed)\n",
    "-- PostgreSQL 11 and earlier: CTEs always materialized (optimization fence)\n",
    "\n",
    "-- Anti-pattern: Unnecessary materialization (PostgreSQL 12+)\n",
    "WITH recent_orders AS (\n",
    "    SELECT * FROM orders WHERE created_at > NOW() - INTERVAL '1 day'\n",
    ")\n",
    "SELECT * FROM recent_orders \n",
    "WHERE customer_id = 123;\n",
    "\n",
    "-- In PostgreSQL 12+, this inlines to:\n",
    "-- SELECT * FROM orders WHERE created_at > NOW() - INTERVAL '1 day' AND customer_id = 123;\n",
    "-- Can use index on customer_id efficiently\n",
    "\n",
    "-- When to force materialization (optimization fence):\n",
    "WITH monthly_stats AS MATERIALIZED (\n",
    "    SELECT \n",
    "        customer_id, \n",
    "        COUNT(*) as order_count,\n",
    "        SUM(total) as revenue\n",
    "    FROM orders\n",
    "    WHERE created_at > NOW() - INTERVAL '30 days'\n",
    "    GROUP BY customer_id\n",
    ")\n",
    "SELECT * FROM monthly_stats \n",
    "WHERE order_count > 5;\n",
    "\n",
    "-- MATERIALIZED prevents planner from pushing filters into aggregation\n",
    "-- Good when: CTE result small, but source tables huge, and filter is selective\n",
    "-- Forces aggregation completion before filtering\n",
    "\n",
    "-- CTE for recursive queries (hierarchies):\n",
    "WITH RECURSIVE subordinates AS (\n",
    "    -- Anchor: Direct reports\n",
    "    SELECT employee_id, name, manager_id, 1 as level\n",
    "    FROM employees\n",
    "    WHERE manager_id = 123\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    -- Recursive: Next level down\n",
    "    SELECT e.employee_id, e.name, e.manager_id, s.level + 1\n",
    "    FROM employees e\n",
    "    JOIN subordinates s ON e.manager_id = s.employee_id\n",
    "    WHERE s.level < 5  -- Prevent infinite recursion\n",
    ")\n",
    "SELECT * FROM subordinates;\n",
    "\n",
    "-- Recursive CTEs always materialize per iteration\n",
    "-- Ensure recursion terminates (cycle detection or depth limit)\n",
    "-- Index on manager_id critical for performance\n",
    "```\n",
    "\n",
    "## 18.2 Index Selection Workflow\n",
    "\n",
    "Creating the right index requires analyzing query patterns, selectivity, and write overhead systematically.\n",
    "\n",
    "### 18.2.1 Decision Tree for Index Creation\n",
    "\n",
    "```sql\n",
    "-- Step 1: Identify candidate queries (slow query log, pg_stat_statements)\n",
    "SELECT \n",
    "    query,\n",
    "    calls,\n",
    "    mean_exec_time,\n",
    "    total_exec_time,\n",
    "    rows\n",
    "FROM pg_stat_statements\n",
    "WHERE query LIKE '%orders%'\n",
    "ORDER BY total_exec_time DESC\n",
    "LIMIT 10;\n",
    "\n",
    "-- Step 2: Analyze query patterns with EXPLAIN\n",
    "EXPLAIN (ANALYZE, BUFFERS)\n",
    "SELECT order_id, total, status \n",
    "FROM orders \n",
    "WHERE customer_id = 123 \n",
    "  AND created_at BETWEEN '2024-01-01' AND '2024-01-31';\n",
    "\n",
    "-- Current plan shows: Seq Scan, high buffers\n",
    "-- Decision: Needs index\n",
    "\n",
    "-- Step 3: Determine selectivity of each predicate\n",
    "SELECT \n",
    "    COUNT(DISTINCT customer_id) as unique_customers,\n",
    "    COUNT(*) as total_orders,\n",
    "    COUNT(DISTINCT customer_id)::float / COUNT(*) as customer_selectivity,\n",
    "    AVG(CASE WHEN created_at BETWEEN '2024-01-01' AND '2024-01-31' \n",
    "        THEN 1.0 ELSE 0.0 END) as date_selectivity\n",
    "FROM orders;\n",
    "\n",
    "-- Rule: Place most selective equality first in composite index\n",
    "-- If customer_id = 123 returns 0.1% of rows, and date range returns 10%,\n",
    "-- Index should be (customer_id, created_at) not (created_at, customer_id)\n",
    "\n",
    "-- Step 4: Check for covering index opportunity\n",
    "-- Query selects: order_id, total, status\n",
    "-- Index (customer_id, created_at) enables Index Scan\n",
    "-- Index (customer_id, created_at) INCLUDE (order_id, total, status) \n",
    "--   enables Index-Only Scan (no heap access)\n",
    "\n",
    "-- Step 5: Validate index effectiveness\n",
    "CREATE INDEX CONCURRENTLY idx_orders_customer_created_cover \n",
    "ON orders(customer_id, created_at) \n",
    "INCLUDE (order_id, total, status);\n",
    "\n",
    "-- Verify usage:\n",
    "EXPLAIN (ANALYZE, BUFFERS)\n",
    "SELECT order_id, total, status \n",
    "FROM orders \n",
    "WHERE customer_id = 123 \n",
    "  AND created_at BETWEEN '2024-01-01' AND '2024-01-31';\n",
    "\n",
    "-- Should show: Index Only Scan using idx_orders_customer_created_cover\n",
    "-- Heap Fetches: 0 (or very low if visibility map stale)\n",
    "\n",
    "-- Step 6: Monitor for 48 hours then decide\n",
    "SELECT \n",
    "    indexrelname,\n",
    "    idx_scan,  -- Should increase if query runs frequently\n",
    "    pg_size_pretty(pg_relation_size(indexrelid)) as size\n",
    "FROM pg_stat_user_indexes\n",
    "WHERE indexrelname = 'idx_orders_customer_created_cover';\n",
    "\n",
    "-- If idx_scan = 0 after 48 hours, index unused - drop it\n",
    "```\n",
    "\n",
    "### 18.2.2 Composite Index Strategy\n",
    "\n",
    "```sql\n",
    "-- Multi-column index ordering rules:\n",
    "-- 1. Equality columns (=) before range columns (<, >, BETWEEN)\n",
    "-- 2. High selectivity before low selectivity (for equality)\n",
    "-- 3. Columns used for ORDER BY after predicates\n",
    "-- 4. Include columns for covering after key columns\n",
    "\n",
    "-- Example: Query patterns on events table\n",
    "-- Pattern A: WHERE device_id = ? AND event_time BETWEEN ? AND ?\n",
    "-- Pattern B: WHERE device_id = ? AND event_type = ? AND event_time > ?\n",
    "-- Pattern C: WHERE event_type = ? ORDER BY event_time\n",
    "\n",
    "-- Analysis:\n",
    "-- Pattern A: (device_id, event_time) - device_id equality, event_time range\n",
    "-- Pattern B: (device_id, event_type, event_time) - two equalities, one range\n",
    "-- Pattern C: (event_type, event_time) - equality + order by\n",
    "\n",
    "-- Consolidation strategy:\n",
    "-- Option 1: Single index for A and B\n",
    "CREATE INDEX idx_events_device_type_time \n",
    "ON events(device_id, event_type, event_time);\n",
    "\n",
    "-- Pattern A uses first two columns (device_id equality, event_time range)\n",
    "--   But cannot skip event_type! Index usable if event_type is any value (IN clause)\n",
    "-- Pattern B uses all three perfectly\n",
    "\n",
    "-- Option 2: Separate indexes (higher write cost, better read performance)\n",
    "CREATE INDEX idx_events_device_time ON events(device_id, event_time);\n",
    "CREATE INDEX idx_events_device_type_time ON events(device_id, event_type, event_time);\n",
    "\n",
    "-- Option 3: Partial index for Pattern C (if event_type low cardinality)\n",
    "CREATE INDEX idx_events_type_time ON events(event_type, event_time) \n",
    "WHERE event_type IN ('error', 'critical');\n",
    "\n",
    "-- Decision criteria:\n",
    "-- If Pattern A frequent and event_type not selective: Option 1\n",
    "-- If Pattern B dominant: Option 1 (optimized for B)\n",
    "-- If write performance critical: Minimize indexes (Option 1 or 2, not both)\n",
    "```\n",
    "\n",
    "### 18.2.3 Partial Index Opportunities\n",
    "\n",
    "```sql\n",
    "-- High-write tables: Index only \"hot\" data (recent, active, pending)\n",
    "\n",
    "-- Example: Orders table with 90% completed, 10% pending/processing\n",
    "-- Query pattern: Check pending orders frequently\n",
    "-- Full index on status is wasteful (90% of index rarely used)\n",
    "\n",
    "-- Solution: Partial index on active statuses only\n",
    "CREATE INDEX idx_orders_pending ON orders(created_at, priority) \n",
    "WHERE status IN ('pending', 'processing', 'on_hold');\n",
    "\n",
    "-- Benefits:\n",
    "-- 1. Index size ~10% of full index\n",
    "-- 2. Faster inserts (completed orders don't touch this index)\n",
    "-- 3. Better cache locality (frequently accessed data in compact index)\n",
    "\n",
    "-- Query must match predicate exactly:\n",
    "SELECT * FROM orders \n",
    "WHERE status = 'pending' AND created_at < NOW() - INTERVAL '1 hour';\n",
    "-- Uses index (status IN pending matches predicate)\n",
    "\n",
    "SELECT * FROM orders \n",
    "WHERE status IN ('pending', 'processing') AND created_at < NOW() - INTERVAL '1 hour';\n",
    "-- Uses index (matches partial index condition)\n",
    "\n",
    "SELECT * FROM orders \n",
    "WHERE status = 'completed';\n",
    "-- Sequential scan (not in partial index, which is correct)\n",
    "\n",
    "-- Unique partial indexes for conditional uniqueness:\n",
    "CREATE UNIQUE INDEX idx_unique_email_active ON users(email) \n",
    "WHERE deleted_at IS NULL;\n",
    "-- Allows: alice@example.com (active), then soft delete, then new alice@example.com\n",
    "-- Prevents: Two active users with same email\n",
    "```\n",
    "\n",
    "## 18.3 Batch Operations and Round-Trip Minimization\n",
    "\n",
    "Database round-trips are often the bottleneck, not query complexity. Batch operations amortize network latency and transaction overhead.\n",
    "\n",
    "### 18.3.1 Bulk Insert Strategies\n",
    "\n",
    "```sql\n",
    "-- Anti-pattern: Individual inserts in loop (N round trips)\n",
    "-- Application code:\n",
    "-- for order in orders:\n",
    "--     db.execute(\"INSERT INTO orders (...) VALUES (...)\", order)  -- N trips\n",
    "\n",
    "-- Solution 1: Multi-row VALUES (up to 1000 rows per statement)\n",
    "INSERT INTO orders (customer_id, total, status) \n",
    "VALUES \n",
    "    (1, 100.00, 'pending'),\n",
    "    (2, 200.00, 'pending'),\n",
    "    (3, 150.00, 'completed'),\n",
    "    -- ... up to 1000 rows\n",
    "ON CONFLICT (order_id) DO UPDATE \n",
    "SET status = EXCLUDED.status, updated_at = NOW();\n",
    "\n",
    "-- Benefits:\n",
    "-- 1. Single parse/plan cycle\n",
    "-- 2. Single network round trip\n",
    "-- 3. Optimized WAL (single transaction)\n",
    "-- 4. Foreign key checks batched\n",
    "\n",
    "-- Solution 2: COPY protocol (fastest for large loads)\n",
    "-- Application uses COPY FROM STDIN or file\n",
    "COPY orders (customer_id, total, status) FROM STDIN WITH (FORMAT CSV);\n",
    "-- Or from file (superuser only usually):\n",
    "COPY orders FROM '/data/orders.csv' WITH (FORMAT CSV, HEADER);\n",
    "\n",
    "-- Performance: 10-50x faster than individual inserts\n",
    "-- Bypasses SQL layer, writes directly to heap\n",
    "-- Triggers fire per batch, not per row (check trigger logic)\n",
    "\n",
    "-- Solution 3: Unnest for dynamic batching (prepared statement friendly)\n",
    "INSERT INTO orders (customer_id, total, status)\n",
    "SELECT * FROM UNNEST(\n",
    "    $1::int[],      -- customer_ids\n",
    "    $2::numeric[],  -- totals  \n",
    "    $3::text[]      -- statuses\n",
    ") AS t(customer_id, total, status);\n",
    "\n",
    "-- Application passes arrays:\n",
    "-- execute(query, [array_of_ids], [array_of_totals], [array_of_statuses])\n",
    "-- Single round trip, dynamic batch size\n",
    "```\n",
    "\n",
    "### 18.3.2 Batch Updates with CTID\n",
    "\n",
    "```sql\n",
    "-- Problem: Update millions of rows without locking table for duration\n",
    "-- Anti-pattern:\n",
    "UPDATE large_table SET status = 'archived' WHERE created_at < '2023-01-01';\n",
    "-- Locks table for minutes/hours, generates massive WAL\n",
    "\n",
    "-- Solution: Batch updates by CTID (physical row ID)\n",
    "DO $$\n",
    "DECLARE\n",
    "    batch_size CONSTANT int := 1000;\n",
    "    rows_updated int;\n",
    "BEGIN\n",
    "    LOOP\n",
    "        UPDATE large_table \n",
    "        SET status = 'archived'\n",
    "        WHERE ctid IN (\n",
    "            SELECT ctid \n",
    "            FROM large_table \n",
    "            WHERE status != 'archived' \n",
    "              AND created_at < '2023-01-01'\n",
    "            LIMIT batch_size\n",
    "        );\n",
    "        \n",
    "        GET DIAGNOSTICS rows_updated = ROW_COUNT;\n",
    "        EXIT WHEN rows_updated = 0;\n",
    "        \n",
    "        COMMIT;  -- Release locks every batch\n",
    "        PERFORM pg_sleep(0.1);  -- Brief pause for concurrent queries\n",
    "        \n",
    "        -- Optional: Check replication lag and pause if needed\n",
    "    END LOOP;\n",
    "END $$;\n",
    "\n",
    "-- CTID advantages:\n",
    "-- 1. Fastest possible row identification (no index lookup)\n",
    "-- 2. No sorting overhead\n",
    "-- 3. Minimal locking per batch\n",
    "\n",
    "-- Alternative: Keyset pagination for batching\n",
    "UPDATE large_table \n",
    "SET status = 'archived'\n",
    "WHERE id IN (\n",
    "    SELECT id \n",
    "    FROM large_table \n",
    "    WHERE status != 'archived' \n",
    "      AND created_at < '2023-01-01'\n",
    "    ORDER BY id\n",
    "    LIMIT 1000\n",
    ");\n",
    "-- Slower than CTID (requires index scan) but works with primary keys\n",
    "-- Better for replication (CTID changes after VACUUM FULL)\n",
    "```\n",
    "\n",
    "### 18.3.3 Array Operations vs JOINs\n",
    "\n",
    "```sql\n",
    "-- Scenario: Check if any of user's tags match campaign tags\n",
    "\n",
    "-- Anti-pattern: JOIN with DISTINCT (expensive deduplication)\n",
    "SELECT DISTINCT u.user_id, u.email\n",
    "FROM users u\n",
    "JOIN user_tags ut ON u.user_id = ut.user_id\n",
    "JOIN campaign_tags ct ON ut.tag = ct.tag\n",
    "WHERE ct.campaign_id = 123;\n",
    "\n",
    "-- Solution 1: Array containment (if tags stored as arrays)\n",
    "SELECT user_id, email \n",
    "FROM users \n",
    "WHERE tags && ARRAY['postgres', 'database', 'performance'];\n",
    "-- && = overlap operator\n",
    "-- Uses GIN index on tags array: CREATE INDEX idx_user_tags ON users USING GIN(tags);\n",
    "\n",
    "-- Solution 2: EXISTS with LIMIT (stops at first match)\n",
    "SELECT u.user_id, u.email\n",
    "FROM users u\n",
    "WHERE EXISTS (\n",
    "    SELECT 1 FROM user_tags ut\n",
    "    JOIN campaign_tags ct ON ut.tag = ct.tag\n",
    "    WHERE ut.user_id = u.user_id \n",
    "      AND ct.campaign_id = 123\n",
    "    LIMIT 1\n",
    ");\n",
    "\n",
    "-- Solution 3: Integer arrays for many-to-many (space efficient)\n",
    "-- Store tags as int[] referencing tag_ids instead of text\n",
    "-- Smaller indexes, faster comparisons\n",
    "\n",
    "-- Solution 4: Bulk lookup with VALUES\n",
    "WITH target_tags(tag) AS (\n",
    "    VALUES ('postgres'), ('database'), ('performance')\n",
    ")\n",
    "SELECT DISTINCT u.user_id, u.email\n",
    "FROM users u\n",
    "JOIN user_tags ut ON u.user_id = ut.user_id\n",
    "JOIN target_tags tt ON ut.tag = tt.tag;\n",
    "-- Efficient for small tag lists (under 100)\n",
    "```\n",
    "\n",
    "## 18.4 Eliminating N+1 Queries\n",
    "\n",
    "The N+1 query pattern occurs when application queries parent rows, then iterates to query children for each parent, resulting in N+1 round trips.\n",
    "\n",
    "### 18.4.1 The N+1 Problem Defined\n",
    "\n",
    "```sql\n",
    "-- Application pattern causing N+1:\n",
    "-- customers = db.query(\"SELECT * FROM customers LIMIT 100\")\n",
    "-- for customer in customers:\n",
    "--     orders = db.query(\"SELECT * FROM orders WHERE customer_id = ?\", customer.id)\n",
    "-- Total queries: 1 + 100 = 101 queries\n",
    "\n",
    "-- PostgreSQL perspective: 100 separate queries with identical plan:\n",
    "-- Index Scan using idx_orders_customer on orders\n",
    "--   Index Cond: (customer_id = $1)\n",
    "--   Planning Time: 0.5ms * 100 = 50ms overhead\n",
    "--   Execution Time: 0.2ms * 100 = 20ms\n",
    "--   Network round trips: 100 * latency (2ms) = 200ms\n",
    "-- Total: 270ms for simple operation\n",
    "\n",
    "-- Solution 1: JOIN (single query)\n",
    "SELECT c.*, o.order_id, o.total, o.status\n",
    "FROM customers c\n",
    "LEFT JOIN orders o ON c.customer_id = o.customer_id\n",
    "WHERE c.customer_id IN (SELECT customer_id FROM customers LIMIT 100);\n",
    "\n",
    "-- Returns: 100 * avg_orders_per_customer rows (cartesian product)\n",
    "-- Application must group by customer_id to reconstruct objects\n",
    "-- Single round trip, but transfers redundant customer data\n",
    "\n",
    "-- Solution 2: Aggregation (optimal for limited children)\n",
    "SELECT \n",
    "    c.customer_id,\n",
    "    c.name,\n",
    "    c.email,\n",
    "    COALESCE(\n",
    "        jsonb_agg(\n",
    "            jsonb_build_object(\n",
    "                'order_id', o.order_id,\n",
    "                'total', o.total,\n",
    "                'status', o.status\n",
    "            ) ORDER BY o.created_at DESC\n",
    "        ) FILTER (WHERE o.order_id IS NOT NULL),\n",
    "        '[]'::jsonb\n",
    "    ) as orders\n",
    "FROM customers c\n",
    "LEFT JOIN orders o ON c.customer_id = o.customer_id\n",
    "WHERE c.customer_id IN (SELECT customer_id FROM customers LIMIT 100)\n",
    "GROUP BY c.customer_id, c.name, c.email;\n",
    "\n",
    "-- Returns: Exactly 100 rows\n",
    "-- Orders embedded as JSONB array\n",
    "-- Application parses single row into parent + children\n",
    "-- Network efficient, single query\n",
    "```\n",
    "\n",
    "### 18.4.2 LATERAL for Limited Children\n",
    "\n",
    "```sql\n",
    "-- Scenario: Get top 5 orders per customer (limit children per parent)\n",
    "\n",
    "-- Solution: LATERAL with LIMIT (as shown in 18.1.3, expanded here)\n",
    "SELECT \n",
    "    c.customer_id,\n",
    "    c.name,\n",
    "    o.order_id,\n",
    "    o.total,\n",
    "    o.created_at\n",
    "FROM customers c\n",
    "LEFT JOIN LATERAL (\n",
    "    SELECT order_id, total, created_at\n",
    "    FROM orders o\n",
    "    WHERE o.customer_id = c.customer_id\n",
    "    ORDER BY o.created_at DESC\n",
    "    LIMIT 5\n",
    ") o ON true\n",
    "WHERE c.segment = 'premium';\n",
    "\n",
    "-- Plan characteristics:\n",
    "-- Nested Loop Left Join\n",
    "--   -> Seq Scan on customers (filtered by segment)\n",
    "--   -> Limit\n",
    "--         -> Index Scan on orders \n",
    "--              Index Cond: (customer_id = c.customer_id)\n",
    "\n",
    "-- Scalability: O(customers * log(orders_per_customer))\n",
    "-- Efficient even with 10,000 customers (10k index lookups)\n",
    "-- vs JOIN which would sort/filter 50k rows (10k * 5)\n",
    "```\n",
    "\n",
    "### 18.4.3 Array Aggregation Pattern\n",
    "\n",
    "```sql\n",
    "-- Alternative to JSONB: Array aggregation for scalar children\n",
    "SELECT \n",
    "    c.customer_id,\n",
    "    c.name,\n",
    "    array_agg(o.order_id ORDER BY o.created_at) as order_ids,\n",
    "    array_agg(o.total ORDER BY o.created_at) as totals\n",
    "FROM customers c\n",
    "LEFT JOIN orders o ON c.customer_id = o.customer_id\n",
    "WHERE c.created_at > '2024-01-01'\n",
    "GROUP BY c.customer_id, c.name;\n",
    "\n",
    "-- Returns parallel arrays:\n",
    "-- customer_id | name | order_ids    | totals\n",
    "-- 1           | Alice| {101,102,103}| {100,200,150}\n",
    "\n",
    "-- Application reconstructs by array index\n",
    "-- More compact than JSONB for simple data\n",
    "-- Faster parsing in some languages\n",
    "\n",
    "-- For fixed number of children (pivot pattern):\n",
    "SELECT \n",
    "    customer_id,\n",
    "    max(case when rn = 1 then order_id end) as order_1_id,\n",
    "    max(case when rn = 1 then total end) as order_1_total,\n",
    "    max(case when rn = 2 then order_id end) as order_2_id,\n",
    "    max(case when rn = 2 then total end) as order_2_total\n",
    "FROM (\n",
    "    SELECT \n",
    "        c.customer_id,\n",
    "        o.order_id,\n",
    "        o.total,\n",
    "        row_number() OVER (PARTITION BY c.customer_id ORDER BY o.created_at DESC) as rn\n",
    "    FROM customers c\n",
    "    JOIN orders o ON c.customer_id = o.customer_id\n",
    ") sub\n",
    "WHERE rn <= 2\n",
    "GROUP BY customer_id;\n",
    "-- Returns flat structure (good for CSV export, simple APIs)\n",
    "```\n",
    "\n",
    "## 18.5 Slow Endpoint Diagnostics Checklist\n",
    "\n",
    "Systematic diagnosis prevents guesswork when production queries degrade.\n",
    "\n",
    "### 18.5.1 Immediate Checks (Under 2 Minutes)\n",
    "\n",
    "```sql\n",
    "-- 1. Check for locks blocking query\n",
    "SELECT \n",
    "    blocked_locks.pid AS blocked_pid,\n",
    "    blocked_activity.usename AS blocked_user,\n",
    "    blocking_locks.pid AS blocking_pid,\n",
    "    blocking_activity.usename AS blocking_user,\n",
    "    blocked_activity.query AS blocked_statement,\n",
    "    blocking_activity.query AS blocking_statement\n",
    "FROM pg_catalog.pg_locks blocked_locks\n",
    "JOIN pg_catalog.pg_stat_activity blocked_activity \n",
    "    ON blocked_activity.pid = blocked_locks.pid\n",
    "JOIN pg_catalog.pg_locks blocking_locks \n",
    "    ON blocking_locks.locktype = blocked_locks.locktype\n",
    "    AND blocking_locks.relation = blocked_locks.relation\n",
    "    AND blocking_locks.pid != blocked_locks.pid\n",
    "JOIN pg_catalog.pg_stat_activity blocking_activity \n",
    "    ON blocking_activity.pid = blocking_locks.pid\n",
    "WHERE NOT blocked_locks.granted;\n",
    "\n",
    "-- 2. Check query progress (PostgreSQL 13+)\n",
    "SELECT \n",
    "    pid,\n",
    "    query,\n",
    "    backend_type,\n",
    "    wait_event_type,\n",
    "    wait_event,\n",
    "    query_start,\n",
    "    now() - query_start as duration\n",
    "FROM pg_stat_activity \n",
    "WHERE state = 'active' \n",
    "  AND query ILIKE '%your_table%'\n",
    "  AND now() - query_start > interval '10 seconds';\n",
    "\n",
    "-- 3. Check for waiting on I/O (buffer cache miss)\n",
    "-- Run EXPLAIN (ANALYZE, BUFFERS) on slow query\n",
    "-- If shared read >> shared hit, cache cold or working set too large\n",
    "\n",
    "-- 4. Check table bloat (affects seq scan speed)\n",
    "SELECT \n",
    "    schemaname,\n",
    "    tablename,\n",
    "    n_dead_tup,\n",
    "    n_live_tup,\n",
    "    round(n_dead_tup::numeric / nullif(n_live_tup, 0) * 100, 2) as dead_pct\n",
    "FROM pg_stat_user_tables\n",
    "WHERE tablename = 'orders';\n",
    "-- If dead_pct > 20%, table bloated (needs vacuum or reindex)\n",
    "```\n",
    "\n",
    "### 18.5.2 Query Plan Analysis\n",
    "\n",
    "```sql\n",
    "-- Check for plan regression (different plan than yesterday):\n",
    "-- Compare current EXPLAIN output to historical plans (if logged)\n",
    "\n",
    "-- Key indicators of bad plan:\n",
    "-- 1. Seq Scan on large table with selective filter\n",
    "--    - Fix: Missing index or statistics stale (ANALYZE)\n",
    "-- 2. Nested Loop with high loops count (>1000)\n",
    "--    - Fix: Usually bad for large outer tables, force hash join with enable_nestloop=off\n",
    "-- 3. High \"Rows Removed by Filter\" relative to rows returned\n",
    "--    - Fix: Index not selective enough, consider partial index\n",
    "-- 4. Sort Method: external merge (disk sort)\n",
    "--    - Fix: Increase work_mem or add ORDER BY matching index\n",
    "-- 5. High Buffer reads with low row counts (inefficient index)\n",
    "--    - Fix: Check for implicit casts or function usage on indexed column\n",
    "\n",
    "-- Quick statistics refresh (if plan looks wrong):\n",
    "ANALYZE (VERBOSE) orders;  -- Update stats for suspected table\n",
    "```\n",
    "\n",
    "### 18.5.3 System-Level Checks\n",
    "\n",
    "```sql\n",
    "-- Check connection pool saturation:\n",
    "SELECT \n",
    "    state,\n",
    "    count(*)\n",
    "FROM pg_stat_activity\n",
    "GROUP BY state;\n",
    "-- If 'active' count approaches max_connections, pool exhaustion\n",
    "\n",
    "-- Check index usage (unused indexes waste write performance):\n",
    "SELECT \n",
    "    schemaname,\n",
    "    tablename,\n",
    "    indexrelname,\n",
    "    idx_scan,\n",
    "    pg_size_pretty(pg_relation_size(indexrelid)) as size\n",
    "FROM pg_stat_user_indexes\n",
    "WHERE schemaname = 'public'\n",
    "ORDER BY pg_relation_size(indexrelid) DESC;\n",
    "\n",
    "-- Check for missing foreign key indexes (cause table locks on parent delete):\n",
    "SELECT\n",
    "    tc.table_name, \n",
    "    kcu.column_name,\n",
    "    ccu.table_name AS foreign_table_name,\n",
    "    CASE \n",
    "        WHEN EXISTS (\n",
    "            SELECT 1 FROM pg_indexes \n",
    "            WHERE tablename = tc.table_name \n",
    "            AND indexdef LIKE '%(' || kcu.column_name || ')%'\n",
    "        ) THEN 'Indexed'\n",
    "        ELSE 'MISSING INDEX - Add immediately'\n",
    "    END as index_status\n",
    "FROM \n",
    "    information_schema.table_constraints AS tc \n",
    "    JOIN information_schema.key_column_usage AS kcu\n",
    "      ON tc.constraint_name = kcu.constraint_name\n",
    "    JOIN information_schema.constraint_column_usage AS ccu\n",
    "      ON ccu.constraint_name = tc.constraint_name\n",
    "WHERE tc.constraint_type = 'FOREIGN KEY';\n",
    "\n",
    "-- Check replication lag (if on replica):\n",
    "SELECT \n",
    "    extract(epoch from (now() - pg_last_xact_replay_timestamp())) as lag_seconds\n",
    "WHERE pg_is_in_recovery();\n",
    "-- If lag > 10 seconds on OLTP system, check WAL generation rate\n",
    "```\n",
    "\n",
    "### 18.5.4 Vacuum and Maintenance Status\n",
    "\n",
    "```sql\n",
    "-- Check auto-vacuum health:\n",
    "SELECT \n",
    "    relname,\n",
    "    n_tup_ins,\n",
    "    n_tup_upd,\n",
    "    n_tup_del,\n",
    "    n_live_tup,\n",
    "    n_dead_tup,\n",
    "    last_vacuum,\n",
    "    last_autovacuum,\n",
    "    last_analyze,\n",
    "    last_autoanalyze,\n",
    "    vacuum_count,\n",
    "    autovacuum_count\n",
    "FROM pg_stat_user_tables\n",
    "WHERE n_dead_tup > 10000\n",
    "ORDER BY n_dead_tup DESC\n",
    "LIMIT 10;\n",
    "\n",
    "-- If last_autovacuum is old and n_dead_tup high:\n",
    "-- 1. Check if autovacuum is running: SELECT * FROM pg_stat_activity WHERE query LIKE 'autovacuum:%';\n",
    "-- 2. May need aggressive settings: ALTER TABLE table_name SET (autovacuum_vacuum_scale_factor = 0.01);\n",
    "-- 3. Or manual: VACUUM ANALYZE table_name;\n",
    "\n",
    "-- Check for long-running transactions (prevent vacuum progress):\n",
    "SELECT \n",
    "    pid,\n",
    "    usename,\n",
    "    application_name,\n",
    "    state,\n",
    "    now() - xact_start as xact_duration,\n",
    "    now() - query_start as query_duration,\n",
    "    left(query, 100) as query_snippet\n",
    "FROM pg_stat_activity\n",
    "WHERE xact_start < now() - interval '5 minutes'\n",
    "  AND state != 'idle'\n",
    "ORDER BY xact_start;\n",
    "-- Long transactions hold back vacuum, causing bloat\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary\n",
    "\n",
    "In this chapter, you learned:\n",
    "\n",
    "1. **Query Refactoring**: Replace `SELECT *` with explicit columns to enable index-only scans. Use `EXISTS` instead of `IN` for semi-joins with potential NULLs. Prefer window functions over self-joins for running totals (O(n log n) vs O(n²)). Use `LATERAL` joins for top-N-per-group queries rather than correlated subqueries.\n",
    "\n",
    "2. **Index Selection Workflow**: Identify slow queries via `pg_stat_statements`. Place equality columns before range columns in composite indexes. Use partial indexes for selective filtering on high-churn tables (indexing only \"active\" rows). Verify effectiveness with `EXPLAIN (ANALYZE, BUFFERS)` and monitor `pg_stat_user_indexes` for usage.\n",
    "\n",
    "3. **Batch Operations**: Use multi-row `INSERT ... VALUES` (up to 1000 rows) or `COPY` for bulk loading. Implement CTID-based batching for large updates to prevent long transactions and table bloat. Replace iterative single-row updates with array `UNNEST` operations to minimize round trips.\n",
    "\n",
    "4. **N+1 Elimination**: Replace application-layer loops with single queries using `JOIN` + aggregation or `LATERAL` with `LIMIT`. Use `jsonb_agg()` or `array_agg()` to return hierarchical data in flat result sets. `LATERAL` joins provide optimal performance for fetching limited children per parent (top-N pattern).\n",
    "\n",
    "5. **Diagnostics Checklist**: Check for blocking locks (`pg_locks`), connection pool saturation (`pg_stat_activity` state counts), and plan regression (compare estimates vs actuals in `EXPLAIN`). Verify table bloat (`n_dead_tup` ratio) and missing foreign key indexes. Monitor replication lag and long-running transactions that prevent vacuum progress.\n",
    "\n",
    "**Next:** In Chapter 19, we will explore Transactions and MVCC—covering isolation levels, row versioning, visibility rules, and the practical implications of PostgreSQL's multi-version concurrency control for application correctness."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
