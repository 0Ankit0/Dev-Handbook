{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d5a991",
   "metadata": {},
   "source": [
    "# Chapter 14: How PostgreSQL Executes Queries\n",
    "\n",
    "Understanding PostgreSQL's query execution architecture is essential for performance tuning. This chapter demystifies the planner and executor, explains how PostgreSQL chooses between scan types and join strategies, and establishes the foundation for interpreting execution plans. Mastering these internals allows you to predict query behavior, diagnose performance issues, and write SQL that aligns with the optimizer's strengths.\n",
    "\n",
    "## 14.1 The Query Processing Pipeline\n",
    "\n",
    "Before PostgreSQL executes your SQL, it passes through several transformation stages. Understanding this pipeline helps you distinguish between syntax errors, planning failures, and execution bottlenecks.\n",
    "\n",
    "### 14.1.1 The Five Stages of Query Execution\n",
    "\n",
    "```sql\n",
    "-- Example query that will traverse all stages:\n",
    "SELECT u.user_id, u.email, COUNT(o.order_id) as order_count\n",
    "FROM users u\n",
    "LEFT JOIN orders o ON u.user_id = o.user_id\n",
    "WHERE u.created_at > '2024-01-01'\n",
    "  AND u.status = 'active'\n",
    "GROUP BY u.user_id, u.email\n",
    "HAVING COUNT(o.order_id) > 5\n",
    "ORDER BY order_count DESC\n",
    "LIMIT 10;\n",
    "```\n",
    "\n",
    "**Stage 1: Parser**\n",
    "- Checks SQL syntax against grammar rules\n",
    "- Validates table/column names exist in system catalogs\n",
    "- Produces a **query tree** (internal representation)\n",
    "- Errors here: `syntax error at or near \"FROM\"`, `column \"emial\" does not exist`\n",
    "\n",
    "**Stage 2: Rewriter**\n",
    "- Handles view expansion (replaces view names with underlying query)\n",
    "- Applies **rule system** (rarely used in modern apps)\n",
    "- Transforms `UPDATE`/`DELETE` with views into proper plans\n",
    "- Handles row-level security (RLS) predicate injection\n",
    "\n",
    "**Stage 3: Planner/Optimizer**\n",
    "- The most complex stage: generates execution plans and selects the cheapest\n",
    "- Considers scan methods, join orders, join algorithms\n",
    "- Estimates costs using statistics (covered in 14.3)\n",
    "- Output: **Plan Tree** (nodes like Seq Scan, Index Scan, Hash Join)\n",
    "\n",
    "**Stage 4: Executor**\n",
    "- Walks the plan tree and executes nodes\n",
    "- Calls storage manager to fetch pages from disk or buffer cache\n",
    "- Applies predicates, performs joins, sorts results\n",
    "- Returns rows to client\n",
    "\n",
    "### 14.1.2 Understanding Plan Nodes\n",
    "\n",
    "Every execution plan consists of **nodes** arranged in a tree. Data flows from leaf nodes (scans) up through intermediate nodes (joins, sorts) to the root.\n",
    "\n",
    "```sql\n",
    "-- Simple plan structure\n",
    "EXPLAIN (FORMAT TEXT, ANALYZE) \n",
    "SELECT * FROM users WHERE user_id = 123;\n",
    "\n",
    "-- Typical output:\n",
    "-- Index Scan using users_pkey on users  (cost=0.29..8.30 rows=1 width=72) (actual time=0.012..0.013 rows=1 loops=1)\n",
    "--   Index Cond: (user_id = 123)\n",
    "-- Planning Time: 0.123 ms\n",
    "-- Execution Time: 0.025 ms\n",
    "\n",
    "-- Node breakdown:\n",
    "-- \"Index Scan\" = Node type (operation)\n",
    "-- \"using users_pkey\" = Specific index used\n",
    "-- \"on users\" = Target table\n",
    "-- (cost=0.29..8.30...) = Planner's cost estimate (startup..total)\n",
    "-- (actual time=0.012..0.013...) = Actual execution time (first row..all rows)\n",
    "-- rows=1 = Estimated (planned) vs actual row count\n",
    "-- width=72 = Estimated bytes per row\n",
    "-- loops=1 = How many times this node executed (important for nested loops)\n",
    "```\n",
    "\n",
    "## 14.2 The Planner: How Decisions Are Made\n",
    "\n",
    "The planner's job is to find the fastest execution path. It uses a **cost-based optimizer** that assigns arbitrary cost units to operations and selects the plan with the lowest total cost.\n",
    "\n",
    "### 14.2.1 Cost Model Fundamentals\n",
    "\n",
    "PostgreSQL's cost model uses abstract units, not milliseconds. The planner estimates disk I/O and CPU operations.\n",
    "\n",
    "```sql\n",
    "-- View current cost settings (arbitrary units relative to seq_page_cost)\n",
    "SHOW seq_page_cost;        -- Default: 1.0 (cost of sequential page fetch)\n",
    "SHOW random_page_cost;     -- Default: 4.0 (cost of random page fetch, higher due to seek)\n",
    "SHOW cpu_tuple_cost;       -- Default: 0.01 (processing one row)\n",
    "SHOW cpu_index_tuple_cost; -- Default: 0.005 (processing index entry)\n",
    "SHOW cpu_operator_cost;    -- Default: 0.0025 (processing operator/function)\n",
    "\n",
    "-- Cost calculation example for sequential scan:\n",
    "-- Table: 10,000 rows, 100 pages (100 rows/page)\n",
    "-- Seq Scan cost = (pages * seq_page_cost) + (rows * cpu_tuple_cost)\n",
    "--               = (100 * 1.0) + (10000 * 0.01)\n",
    "--               = 100 + 100 = 200\n",
    "\n",
    "-- Index Scan cost calculation (simplified):\n",
    "-- Index pages to traverse + random page fetches + tuple processing\n",
    "-- Higher random_page_cost makes index scans more expensive unless very selective\n",
    "\n",
    "-- When to adjust random_page_cost:\n",
    "-- SSD storage: Lower to 1.1 or 1.2 (random reads almost as fast as sequential)\n",
    "-- RAID arrays with large cache: 2.0-2.5\n",
    "-- Spinning disks with heavy load: Keep at 4.0 or higher\n",
    "```\n",
    "\n",
    "### 14.2.2 Selectivity and Cardinality Estimation\n",
    "\n",
    "The planner estimates how many rows match a condition (**selectivity**) to choose between scan types.\n",
    "\n",
    "```sql\n",
    "-- Statistics overview\n",
    "SELECT \n",
    "    schemaname, tablename, attname as column,\n",
    "    n_distinct, \n",
    "    null_frac,\n",
    "    correlation,\n",
    "    most_common_vals::text::text[] as common_values,\n",
    "    most_common_freqs as frequencies\n",
    "FROM pg_stats \n",
    "WHERE tablename = 'users' \n",
    "  AND attname = 'status';\n",
    "\n",
    "-- n_distinct: \n",
    "--   > 0: Estimated number of distinct values\n",
    "--   < 0: Fraction of total rows (e.g., -0.5 means 50% of rows are distinct)\n",
    "-- null_frac: Fraction of rows that are NULL\n",
    "-- correlation: How well-ordered column is relative to physical storage (1.0 = perfectly sorted)\n",
    "-- most_common_vals: Array of most frequent values (histogram for others)\n",
    "\n",
    "-- Selectivity calculation example:\n",
    "-- Table has 1,000,000 rows\n",
    "-- status column: n_distinct = 5 (active, pending, deleted, suspended, archived)\n",
    "-- Query: WHERE status = 'active'\n",
    "-- If 'active' is 60% of rows (from most_common_freqs), selectivity = 0.6\n",
    "-- Estimated rows = 1,000,000 * 0.6 = 600,000 rows\n",
    "\n",
    "-- Planner decisions based on selectivity:\n",
    "-- Low selectivity (few rows match): Use Index Scan\n",
    "-- High selectivity (many rows match): Use Sequential Scan (faster than random I/O)\n",
    "\n",
    "-- When statistics are wrong:\n",
    "ANALYZE users;  -- Update statistics immediately\n",
    "-- Or for specific columns:\n",
    "ANALYZE users (status, created_at);\n",
    "\n",
    "-- Check actual vs estimated rows:\n",
    "EXPLAIN (ANALYZE, BUFFERS) \n",
    "SELECT * FROM users WHERE status = 'active';\n",
    "-- Look for \"rows=1000 (actual=50000)\" - big discrepancy means bad stats\n",
    "```\n",
    "\n",
    "## 14.3 Scan Types: How PostgreSQL Reads Data\n",
    "\n",
    "The **scan** is the leaf node of every execution plan. PostgreSQL chooses between sequential scans, index scans, and bitmap scans based on cost estimates.\n",
    "\n",
    "### 14.3.1 Sequential Scan (Seq Scan)\n",
    "\n",
    "Reads every row in the table sequentially. Often faster than index scans for large portions of the table due to sequential I/O efficiency.\n",
    "\n",
    "```sql\n",
    "-- Force a sequential scan (for testing)\n",
    "SET enable_indexscan = off;\n",
    "SET enable_bitmapscan = off;\n",
    "\n",
    "EXPLAIN (ANALYZE, BUFFERS, FORMAT TEXT)\n",
    "SELECT * FROM users WHERE status = 'active';\n",
    "\n",
    "-- Typical output:\n",
    "-- Seq Scan on users  (cost=0.00..15406.00 rows=50000 width=72) \n",
    "--                    (actual time=0.015..125.432 rows=50000 loops=1)\n",
    "--   Filter: (status = 'active')\n",
    "--   Rows Removed by Filter: 50000\n",
    "--   Buffers: shared read=10834\n",
    "\n",
    "-- Analysis:\n",
    "-- \"Seq Scan on users\": Reading table sequentially\n",
    "-- \"Filter\": Applied after reading row (not index lookup)\n",
    "-- \"Rows Removed by Filter\": 50k rows read, 50k discarded (50% selectivity)\n",
    "-- \"Buffers: shared read=10834\": Read 10834 pages from buffer cache/disk\n",
    "\n",
    "-- When Seq Scan is optimal:\n",
    "-- 1. Table is small (< few thousand rows)\n",
    "-- 2. Query matches large percentage of rows (>5-10%)\n",
    "-- 3. No suitable index exists\n",
    "-- 4. Index would require random I/O for many rows (slower than sequential read)\n",
    "\n",
    "-- Parallel sequential scans (PostgreSQL 9.6+)\n",
    "EXPLAIN (ANALYZE) SELECT * FROM large_table WHERE x > 100;\n",
    "-- Workers Planned: 2\n",
    "-- Workers Launched: 2\n",
    "-- Multiple processes scan different portions of the table simultaneously\n",
    "```\n",
    "\n",
    "### 14.3.2 Index Scan\n",
    "\n",
    "Uses an index to find rows, then fetches the actual table data (heap). Efficient for retrieving small numbers of rows.\n",
    "\n",
    "```sql\n",
    "-- Enable index scans\n",
    "SET enable_indexscan = on;\n",
    "\n",
    "EXPLAIN (ANALYZE, BUFFERS)\n",
    "SELECT * FROM users WHERE user_id = 123;\n",
    "\n",
    "-- Typical output:\n",
    "-- Index Scan using users_pkey on users  \n",
    "--   (cost=0.29..8.30 rows=1 width=72) \n",
    "--   (actual time=0.008..0.009 rows=1 loops=1)\n",
    "--   Index Cond: (user_id = 123)\n",
    "--   Buffers: shared hit=3\n",
    "\n",
    "-- Analysis:\n",
    "-- \"Index Scan\": Uses index to find row location, then fetches from heap\n",
    "-- \"using users_pkey\": B-tree index on user_id\n",
    "-- \"Index Cond\": Predicate applied to index (efficient)\n",
    "-- \"Buffers: shared hit=3\": 3 buffer cache hits (index root, leaf, heap page)\n",
    "\n",
    "-- Index Scan with multiple conditions\n",
    "EXPLAIN (ANALYZE)\n",
    "SELECT * FROM users \n",
    "WHERE status = 'active' \n",
    "  AND created_at > '2024-01-01';\n",
    "\n",
    "-- If index exists on (status) or (created_at), planner chooses based on selectivity\n",
    "-- May see: Index Scan using idx_status, then Filter: (created_at > '2024-01-01')\n",
    "-- Or: Bitmap Index Scan combining both indexes (see next section)\n",
    "\n",
    "-- Backward index scan (for DESC order)\n",
    "EXPLAIN (ANALYZE)\n",
    "SELECT * FROM users \n",
    "WHERE user_id < 1000 \n",
    "ORDER BY user_id DESC \n",
    "LIMIT 10;\n",
    "-- Index Scan Backward using users_pkey\n",
    "-- B-trees are bidirectional; no sort needed for ORDER BY matching index direction\n",
    "```\n",
    "\n",
    "### 14.3.3 Bitmap Index Scan\n",
    "\n",
    "Combines multiple indexes or handles moderate selectivity efficiently by avoiding random I/O for many rows.\n",
    "\n",
    "```sql\n",
    "-- Bitmap scan example (moderate selectivity, multiple conditions)\n",
    "EXPLAIN (ANALYZE, BUFFERS)\n",
    "SELECT * FROM users \n",
    "WHERE status = 'active' \n",
    "  AND email_verified = true\n",
    "  AND created_at > '2023-01-01';\n",
    "\n",
    "-- Typical output:\n",
    "-- Bitmap Heap Scan on users  \n",
    "--   (cost=24.50..1500.80 rows=500 width=72)\n",
    "--   (actual time=0.523..5.234 rows=450 loops=1)\n",
    "--   Recheck Cond: ((status = 'active') AND (email_verified = true))\n",
    "--   Filter: (created_at > '2023-01-01')\n",
    "--   Heap Blocks: exact=200\n",
    "--   ->  BitmapAnd  \n",
    "--       ->  Bitmap Index Scan on idx_status  \n",
    "--             Index Cond: (status = 'active')\n",
    "--       ->  Bitmap Index Scan on idx_email_verified  \n",
    "--             Index Cond: (email_verified = true)\n",
    "\n",
    "-- How Bitmap Scans work:\n",
    "-- 1. Scan each index to create a bitmap of matching row locations\n",
    "-- 2. Combine bitmaps (AND/OR) in memory\n",
    "-- 3. Scan heap sequentially, checking bitmap before fetching each page\n",
    "-- 4. \"Recheck Cond\": Verify row matches conditions (bitmap may have false positives)\n",
    "\n",
    "-- Advantages over Index Scan:\n",
    "-- 1. Avoids random I/O when fetching many rows (reads heap pages sequentially)\n",
    "-- 2. Can combine multiple indexes efficiently (BitmapAnd/BitmapOr)\n",
    "-- 3. Better cache utilization for moderate selectivity (5-20% of table)\n",
    "\n",
    "-- When Bitmap Scan is chosen:\n",
    "-- 1. Moderate selectivity (too many rows for Index Scan random I/O, too few for Seq Scan)\n",
    "-- 2. Multiple index conditions combined with AND\n",
    "-- 3. OR conditions across different indexes\n",
    "\n",
    "-- Bitmap Index Scan vs Bitmap Heap Scan:\n",
    "-- Bitmap Index Scan: Builds the bitmap from index pages\n",
    "-- Bitmap Heap Scan: Uses the bitmap to fetch table pages sequentially\n",
    "```\n",
    "\n",
    "### 14.3.4 Index-Only Scans (Covering Indexes)\n",
    "\n",
    "When all requested columns exist in the index, PostgreSQL can avoid accessing the heap entirely.\n",
    "\n",
    "```sql\n",
    "-- Index-only scan example\n",
    "-- Table: users(user_id PK, email, status)\n",
    "-- Index: CREATE INDEX idx_email_status ON users(email, status);\n",
    "\n",
    "EXPLAIN (ANALYZE, BUFFERS)\n",
    "SELECT email, status FROM users \n",
    "WHERE email = 'alice@example.com';\n",
    "\n",
    "-- Output:\n",
    "-- Index Only Scan using idx_email_status on users  \n",
    "--   (cost=0.29..4.30 rows=1 width=36)\n",
    "--   (actual time=0.008..0.009 rows=1 loops=1)\n",
    "--   Index Cond: (email = 'alice@example.com')\n",
    "--   Heap Fetches: 0  <-- Key indicator: no heap access needed\n",
    "--   Buffers: shared hit=2\n",
    "\n",
    "-- Visibility Map Check:\n",
    "-- PostgreSQL must verify row visibility without accessing heap\n",
    "-- Uses Visibility Map (VM) to check if page is all-visible (no dead tuples)\n",
    "-- If VM says \"all visible\", heap fetch avoided\n",
    "-- If VM is stale (recent updates), may need heap fetches\n",
    "\n",
    "-- Check visibility map status:\n",
    "SELECT \n",
    "    relname,\n",
    "    n_live_tup,\n",
    "    n_dead_tup,\n",
    "    last_vacuum,\n",
    "    last_autovacuum\n",
    "FROM pg_stat_user_tables \n",
    "WHERE relname = 'users';\n",
    "-- High n_dead_tup means visibility map is dirty, index-only scans degrade\n",
    "\n",
    "-- Covering index with INCLUDE (PostgreSQL 11+)\n",
    "-- Include non-key columns to enable index-only scans for more queries\n",
    "CREATE INDEX idx_users_email_covering ON users(email) \n",
    "INCLUDE (full_name, created_at, status);\n",
    "-- email is index key (tree structure)\n",
    "-- full_name, created_at, status are payload (stored in leaf pages only)\n",
    "-- Query can be index-only: SELECT full_name, created_at FROM users WHERE email = 'x'\n",
    "\n",
    "-- Index-only scan limitations:\n",
    "-- 1. Requires all columns in index or INCLUDE\n",
    "-- 2. Visibility map must be reasonably current (recent VACUUM)\n",
    "-- 3. Cannot work if query references system columns (ctid, xmin, etc.)\n",
    "-- 4. Expressions in SELECT must match index expressions exactly\n",
    "```\n",
    "\n",
    "## 14.4 Join Strategies and Algorithms\n",
    "\n",
    "PostgreSQL implements three join algorithms: Nested Loop, Hash Join, and Merge Join. The planner chooses based on table sizes, indexes, and selectivity.\n",
    "\n",
    "### 14.4.1 Nested Loop Join\n",
    "\n",
    "Best for small outer tables with indexed inner tables. Conceptually: for each outer row, scan inner table.\n",
    "\n",
    "```sql\n",
    "-- Nested Loop example: Small table driving large indexed table\n",
    "EXPLAIN (ANALYZE, BUFFERS)\n",
    "SELECT u.email, o.order_id, o.total\n",
    "FROM users u\n",
    "JOIN orders o ON u.user_id = o.user_id\n",
    "WHERE u.status = 'active'\n",
    "  AND u.created_at > NOW() - INTERVAL '7 days';\n",
    "-- Assumption: users table has 100 recent active users\n",
    "-- orders table has 1,000,000 rows with index on user_id\n",
    "\n",
    "-- Typical plan:\n",
    "-- Nested Loop  (cost=0.29..1234.56 rows=500 width=50)\n",
    "--   ->  Index Scan using idx_users_created_at on users\n",
    "--         Index Cond: ((status = 'active') AND (created_at > ...))\n",
    "--         Rows: 100\n",
    "--   ->  Index Scan using idx_orders_user_id on orders\n",
    "--         Index Cond: (user_id = users.user_id)\n",
    "--         Rows: 5 per loop\n",
    "\n",
    "-- How Nested Loop works:\n",
    "-- 1. Scan outer table (users) to get 100 rows\n",
    "-- 2. For each of the 100 rows:\n",
    "--    a. Take the user_id\n",
    "--    b. Probe inner table (orders) using index on user_id\n",
    "--    c. Return matching rows\n",
    "-- 3. Total inner probes: 100 index scans\n",
    "\n",
    "-- Cost calculation:\n",
    "-- Outer scan cost: ~10 (index scan on users)\n",
    "-- Inner probe cost: ~4 per iteration (index probe on orders)\n",
    "-- Total: 10 + (100 * 4) = 410 (plus tuple processing)\n",
    "\n",
    "-- When Nested Loop is chosen:\n",
    "-- 1. Outer table is small (low number of rows)\n",
    "-- 2. Inner table has index on join column\n",
    "-- 3. Join condition is selective (few matches per outer row)\n",
    "-- 4. No better alternative (hash/merge not viable)\n",
    "\n",
    "-- Nested Loop with Materialize (caching inner results)\n",
    "-- If inner side is expensive and outer is small, PostgreSQL may materialize (cache) inner results\n",
    "-- ->  Materialize  (cost=0.00..234.00 rows=1000 width=20)\n",
    "--       ->  Seq Scan on small_lookup_table\n",
    "-- Then nested loop probes the materialized result instead of rescanning\n",
    "```\n",
    "\n",
    "### 14.4.2 Hash Join\n",
    "\n",
    "Best when joining large tables without suitable indexes. Builds a hash table from the smaller relation, then probes with the larger.\n",
    "\n",
    "```sql\n",
    "-- Hash Join example: Two large tables, no suitable index\n",
    "EXPLAIN (ANALYZE, BUFFERS)\n",
    "SELECT u.user_id, u.email, o.order_id\n",
    "FROM users u\n",
    "JOIN orders o ON u.user_id = o.user_id\n",
    "WHERE u.created_at BETWEEN '2023-01-01' AND '2023-12-31'\n",
    "  AND o.total > 1000;\n",
    "-- Assumption: 500,000 users in date range, 200,000 large orders\n",
    "-- No index on o.total (or planner decides it's not selective enough)\n",
    "\n",
    "-- Typical plan:\n",
    "-- Hash Join  (cost=12345.67..67890.12 rows=50000 width=40)\n",
    "--   Hash Cond: (o.user_id = u.user_id)\n",
    "--   ->  Seq Scan on orders o\n",
    "--         Filter: (total > 1000)\n",
    "--         Rows Removed by Filter: 800000\n",
    "--   ->  Hash\n",
    "--         ->  Index Scan using idx_users_created_at on users u\n",
    "--               Index Cond: ((created_at >= '2023-01-01') AND (created_at <= '2023-12-31'))\n",
    "\n",
    "-- How Hash Join works:\n",
    "-- 1. Build Phase: Scan smaller relation (users) and build hash table in memory\n",
    "--    - Hash key: user_id\n",
    "--    - Value: entire row (or needed columns)\n",
    "-- 2. Probe Phase: Scan larger relation (orders)\n",
    "--    - For each order row, hash the user_id\n",
    "--    - Look up in hash table\n",
    "--    - If match found, emit joined row\n",
    "\n",
    "-- Memory considerations:\n",
    "-- work_mem (default 4MB) limits hash table size\n",
    "-- If hash table exceeds work_mem, it spills to disk (slower)\n",
    "-- EXPLAIN will show: \"Buckets: 131072 Batches: 2 Memory Usage: 3072kB\"\n",
    "-- If Batches > 1, disk I/O occurred (performance concern)\n",
    "\n",
    "-- When Hash Join is chosen:\n",
    "-- 1. Joining large tables (no small outer table for nested loop)\n",
    "-- 2. No suitable index on inner table (or index not selective enough)\n",
    "-- 3. Equality join condition (hash requires exact match)\n",
    "-- 4. Can fit in work_mem (or acceptable spill to disk)\n",
    "\n",
    "-- Hash Join vs Merge Join:\n",
    "-- Hash Join: Good when one table is much smaller, no index requirement\n",
    "-- Merge Join: Good when both tables are sorted or sortable efficiently\n",
    "```\n",
    "\n",
    "### 14.4.3 Merge Join (Sort-Merge Join)\n",
    "\n",
    "Best when joining large, sorted datasets or when input is already ordered. Requires sortable data types and equality conditions.\n",
    "\n",
    "```sql\n",
    "-- Merge Join example: Pre-sorted data or efficient sorting\n",
    "EXPLAIN (ANALYZE, BUFFERS)\n",
    "SELECT u.user_id, u.email, o.order_id, o.total\n",
    "FROM users u\n",
    "JOIN orders o ON u.user_id = o.user_id\n",
    "ORDER BY u.user_id;\n",
    "-- Assumption: Both tables large, joining on sorted key (user_id)\n",
    "-- Query asks for output ordered by user_id (same as join key)\n",
    "\n",
    "-- Typical plan:\n",
    "-- Merge Join  (cost=0.57..34567.89 rows=1000000 width=60)\n",
    "--   Merge Cond: (u.user_id = o.user_id)\n",
    "--   ->  Index Scan using users_pkey on users u\n",
    "--   ->  Index Scan using idx_orders_user_id on orders o\n",
    "\n",
    "-- How Merge Join works:\n",
    "-- 1. Sort Phase: Get both inputs sorted on join key (user_id)\n",
    "--    - If inputs come from index scans, already sorted (cheapest)\n",
    "--    - Otherwise, sort nodes added (expensive for large data)\n",
    "-- 2. Merge Phase: \n",
    "--    - Start with first row from both inputs\n",
    "--    - If match, emit joined row, advance inner pointer\n",
    "--    - If outer < inner, advance outer\n",
    "--    - If inner < outer, advance inner\n",
    "--    - Continue until one input exhausted\n",
    "\n",
    "-- Visual:\n",
    "-- Users (sorted): [1, 2, 3, 5, 7, 9]\n",
    "-- Orders (sorted): [1, 1, 2, 4, 5, 5, 5, 8]\n",
    "-- Matches: (1,1), (1,1), (2,2), (5,5), (5,5), (5,5)\n",
    "\n",
    "-- When Merge Join is chosen:\n",
    "-- 1. Joining large tables on sorted columns\n",
    "-- 2. Inputs naturally ordered (index scans) or sortable within work_mem\n",
    "-- 3. Equality join conditions\n",
    "-- 4. Query requires output sorted by join key (merge preserves order, avoids final sort)\n",
    "\n",
    "-- Sort node costs:\n",
    "-- If inputs not pre-sorted:\n",
    "-- Sort  (cost=10000.00..10500.00 rows=200000 width=40)\n",
    "--   Sort Key: u.user_id\n",
    "--   Sort Method: quicksort  Memory: 25000kB\n",
    "--   ->  Seq Scan on users u\n",
    "-- \"Memory\" indicates in-memory sort (fast)\n",
    "-- If \"External Merge\" shown, spilled to disk (slow, needs work_mem increase)\n",
    "```\n",
    "\n",
    "### 14.4.4 Join Order and Join Tree Shapes\n",
    "\n",
    "For multi-table joins, the planner chooses the order of joining and the shape of the join tree (left-deep, bushy, right-deep).\n",
    "\n",
    "```sql\n",
    "-- Three-way join example\n",
    "EXPLAIN (ANALYZE)\n",
    "SELECT u.email, o.order_id, p.amount\n",
    "FROM users u\n",
    "JOIN orders o ON u.user_id = o.user_id\n",
    "JOIN payments p ON o.order_id = p.order_id\n",
    "WHERE u.status = 'active';\n",
    "\n",
    "-- Possible plans:\n",
    "-- 1. ((users JOIN orders) JOIN payments) - Left-deep tree\n",
    "--    - Join users->orders (small filter on users first)\n",
    "--    - Join result->payments\n",
    "--    - Usually preferred (intermediate results materialized efficiently)\n",
    "\n",
    "-- 2. (users JOIN (orders JOIN payments)) - Bushy tree\n",
    "--    - Join orders->payments first (might be large)\n",
    "--    - Then join with users\n",
    "--    - Rarely optimal unless orders->payments is highly selective\n",
    "\n",
    "-- Planner uses dynamic programming (DP) for join ordering:\n",
    "-- - For < 12 tables: Exhaustive search (all possible orders)\n",
    "-- - For >= 12 tables: Genetic algorithm (GEQO) to avoid combinatorial explosion\n",
    "-- Controlled by: geqo_threshold (default 12), geqo_effort\n",
    "\n",
    "-- Forcing join order (rarely needed, for testing):\n",
    "SET join_collapse_limit = 1;  -- Prevents reordering of explicit JOINs\n",
    "-- Or use CTEs (materialize intermediate results)\n",
    "WITH active_users AS MATERIALIZED (\n",
    "    SELECT * FROM users WHERE status = 'active'\n",
    ")\n",
    "SELECT * FROM active_users u\n",
    "JOIN orders o ON u.user_id = o.user_id;\n",
    "-- MATERIALIZED forces CTE to be computed first (like a temp table)\n",
    "-- Without MATERIALIZED, CTEs are inlined and optimized with main query (PostgreSQL 12+)\n",
    "```\n",
    "\n",
    "## 14.5 Statistics: The Foundation of Good Plans\n",
    "\n",
    "The planner is only as good as its statistics. Understanding how PostgreSQL collects and uses statistics is crucial for diagnosing plan quality.\n",
    "\n",
    "### 14.5.1 How Statistics Are Collected\n",
    "\n",
    "```sql\n",
    "-- Manual statistics collection\n",
    "ANALYZE users;  -- Update stats for table\n",
    "ANALYZE users (status, created_at);  -- Specific columns only\n",
    "\n",
    "-- Automatic statistics collection\n",
    "-- Autovacuum daemon runs ANALYZE automatically:\n",
    "-- - When 10% of table changes (default: autovacuum_analyze_threshold = 50, \n",
    "--   autovacuum_analyze_scale_factor = 0.1)\n",
    "-- - For large tables: 10% of 100M rows = 10M changes before analyze!\n",
    "--   Consider lowering scale_factor for large tables:\n",
    "ALTER TABLE big_table SET (autovacuum_analyze_scale_factor = 0.01);  -- 1% for big tables\n",
    "\n",
    "-- Viewing statistics\n",
    "SELECT * FROM pg_stats WHERE tablename = 'users';\n",
    "SELECT * FROM pg_statistic WHERE starelid = 'users'::regclass;  -- Raw binary stats\n",
    "\n",
    "-- Extended statistics (PostgreSQL 10+)\n",
    "-- For correlations between columns\n",
    "CREATE STATISTICS stats_users_status_date ON status, created_at FROM users;\n",
    "ANALYZE users;\n",
    "-- Helps planner estimate combined selectivity of status='active' AND created_at > X\n",
    "-- Without this, planner assumes independence (multiplies selectivities)\n",
    "```\n",
    "\n",
    "### 14.5.2 Histograms and Selectivity\n",
    "\n",
    "```sql\n",
    "-- Most Common Values (MCV) list\n",
    "-- For columns with few distinct values (e.g., status, boolean flags)\n",
    "-- Stores top N values and their frequencies (default N=100)\n",
    "\n",
    "-- Histogram bounds\n",
    "-- For high-cardinality columns (timestamps, IDs, text)\n",
    "-- Divides range into buckets (default 100 buckets)\n",
    "SELECT histogram_bounds::text::text[] \n",
    "FROM pg_stats \n",
    "WHERE tablename = 'users' AND attname = 'created_at';\n",
    "-- Returns array of timestamp boundaries\n",
    "\n",
    "-- Selectivity estimation example:\n",
    "-- Query: WHERE created_at > '2024-06-01'\n",
    "-- Histogram shows bucket boundaries: ['2024-01-01', '2024-02-01', ..., '2024-12-01']\n",
    "-- '2024-06-01' falls in bucket 6 of 100\n",
    "-- Selectivity = (100 - 6) / 100 = 0.94 (94% of rows)\n",
    "-- Planner will likely choose Seq Scan (high selectivity)\n",
    "\n",
    "-- Query: WHERE created_at > '2024-11-01'\n",
    "-- Falls in bucket 11\n",
    "-- Selectivity = (100 - 11) / 100 = 0.09 (9% of rows)\n",
    "-- Planner may choose Index Scan (moderate selectivity)\n",
    "```\n",
    "\n",
    "## 14.6 Specialized Scan Types\n",
    "\n",
    "### 14.6.1 Tid Scan (Tuple ID Scan)\n",
    "\n",
    "Directly accesses rows by their physical location (ctid). Used when PostgreSQL knows exactly which rows to fetch.\n",
    "\n",
    "```sql\n",
    "-- Tid Scan occurs with:\n",
    "-- 1. ctid = constant (rare in apps)\n",
    "-- 2. Current-of cursor operations\n",
    "-- 3. Some subquery optimizations\n",
    "\n",
    "EXPLAIN SELECT * FROM users WHERE ctid = '(0,1)';\n",
    "-- Tid Scan on users\n",
    "--   Tid Cond: (ctid = '(0,1)')\n",
    "\n",
    "-- Practical use: Efficient updates of specific rows found via subquery\n",
    "UPDATE users SET status = 'archived'\n",
    "WHERE ctid IN (\n",
    "    SELECT ctid FROM users \n",
    "    WHERE last_login < '2023-01-01' \n",
    "    LIMIT 1000\n",
    ");\n",
    "-- Avoids repeated index scans during update\n",
    "```\n",
    "\n",
    "### 14.6.2 Subquery Scans and Materialization\n",
    "\n",
    "```sql\n",
    "-- Subquery scan (uncorrelated subquery)\n",
    "EXPLAIN SELECT * FROM users \n",
    "WHERE user_id IN (SELECT user_id FROM premium_users);\n",
    "\n",
    "-- Plan:\n",
    "-- Seq Scan on users\n",
    "--   Filter: (SubPlan 1)\n",
    "--   SubPlan 1\n",
    "--     ->  Materialize  <-- Caches subquery result\n",
    "--           ->  Seq Scan on premium_users\n",
    "\n",
    "-- Materialize node:\n",
    "-- - Executes subquery once, stores in memory\n",
    "-- - Subsequent scans read from memory (fast)\n",
    "-- - If result too large, spills to disk (slow)\n",
    "\n",
    "-- InitPlan (scalar subquery, executes once)\n",
    "EXPLAIN SELECT * FROM users \n",
    "WHERE created_at > (SELECT MAX(created_at) FROM deleted_users);\n",
    "-- InitPlan 1 (returns 1 row)\n",
    "--   ->  Aggregate\n",
    "--         ->  Seq Scan on deleted_users\n",
    "-- Seq Scan on users\n",
    "--   Filter: (created_at > $1)  -- $1 is result of InitPlan\n",
    "\n",
    "-- Correlated subquery (executes once per outer row - expensive)\n",
    "EXPLAIN SELECT * FROM users u\n",
    "WHERE EXISTS (\n",
    "    SELECT 1 FROM orders o \n",
    "    WHERE o.user_id = u.user_id  -- Correlated: references outer query\n",
    "      AND o.total > 1000\n",
    ");\n",
    "-- Nested Loop Semi Join  <-- Semi Join = EXISTS optimization\n",
    "--   ->  Seq Scan on users u\n",
    "--   ->  Index Scan using idx_orders_user_id on orders o\n",
    "--         Index Cond: (user_id = u.user_id)\n",
    "--         Filter: (total > 1000)\n",
    "```\n",
    "\n",
    "## 14.7 Understanding Cost Estimates\n",
    "\n",
    "Cost units are arbitrary but based on sequential page reads. Understanding cost components helps you identify why the planner made specific choices.\n",
    "\n",
    "### 14.7.1 Cost Components Explained\n",
    "\n",
    "```sql\n",
    "-- Cost format: startup_cost..total_cost\n",
    "-- startup_cost: Cost to produce first row (e.g., sorting must complete first)\n",
    "-- total_cost: Cost to produce all rows\n",
    "\n",
    "EXPLAIN (FORMAT JSON)\n",
    "SELECT * FROM users ORDER BY email;\n",
    "\n",
    "-- Sort node:\n",
    "-- \"Startup Cost\": 15406.00 (must sort all rows before returning first)\n",
    "-- \"Total Cost\": 17906.00 (sorting cost + sequential scan cost)\n",
    "-- Sort Cost formula: (N * log2(N)) * cpu_operator_cost + comparison costs\n",
    "\n",
    "-- Join cost estimation:\n",
    "-- Nested Loop: outer_startup + (outer_cardinality * inner_cost_per_row)\n",
    "-- Hash Join: inner_hash_build_cost + (outer_cardinality * probe_cost)\n",
    "-- Merge Join: sort_outer_cost + sort_inner_cost + merge_cost\n",
    "\n",
    "-- Real example with calculations:\n",
    "EXPLAIN SELECT * FROM users u JOIN orders o ON u.user_id = o.user_id;\n",
    "\n",
    "-- If users has 10,000 rows, orders has 1,000,000 rows:\n",
    "-- Nested Loop cost: \n",
    "--   Scan users: 100 (seq scan)\n",
    "--   Index probe orders: 4 per row * 10,000 = 40,000\n",
    "--   Total: ~40,100\n",
    "\n",
    "-- Hash Join cost:\n",
    "--   Build hash on users (smaller): 100 + (10000 * 0.1) = 1,100\n",
    "--   Scan orders (probe): 10,000 (seq scan) + (1000000 * 0.01) = 20,000\n",
    "--   Total: ~21,100 (wins over nested loop)\n",
    "\n",
    "-- Merge Join cost:\n",
    "--   Sort users: 100 + (10000 * log2(10000) * 0.0025) ≈ 400\n",
    "--   Sort orders: 10000 + (1000000 * log2(1000000) * 0.0025) ≈ 60,000\n",
    "--   Merge: 1000000 * 0.01 = 10,000\n",
    "--   Total: ~70,500 (loses due to sort cost on large table)\n",
    "```\n",
    "\n",
    "### 14.7.2 When Plans Go Wrong\n",
    "\n",
    "```sql\n",
    "-- Statistics mismatch example\n",
    "-- Table has 1M rows, but stats are stale (table grew to 10M)\n",
    "EXPLAIN SELECT * FROM users WHERE user_id = 9999999;\n",
    "-- Index Scan (cost=0.29..8.30 rows=1 width=72)\n",
    "-- Actual: Seq Scan, because user_id doesn't exist (planner thought it might)\n",
    "\n",
    "-- Fix:\n",
    "ANALYZE users;\n",
    "\n",
    "-- Correlation and clustering\n",
    "-- If table is physically ordered by user_id (high correlation), \n",
    "-- index scans are faster (sequential prefetch)\n",
    "-- If table is random (low correlation), index scans cause random I/O\n",
    "\n",
    "SELECT attname, correlation \n",
    "FROM pg_stats \n",
    "WHERE tablename = 'users' AND attname = 'user_id';\n",
    "-- correlation=1.0: Perfectly sorted (index scan very fast)\n",
    "-- correlation=0.0: Random order (index scan slower, random I/O)\n",
    "\n",
    "-- Constraint exclusion (partitioning)\n",
    "-- If table is partitioned by date, planner excludes irrelevant partitions\n",
    "EXPLAIN SELECT * FROM events WHERE event_date = '2024-01-01';\n",
    "-- Partition pruning: Only scans events_2024_01 partition\n",
    "-- Shows: \"Append\" node with only relevant child scans\n",
    "```\n",
    "\n",
    "## 14.8 Practical Plan Reading\n",
    "\n",
    "### 14.8.1 Identifying Bottlenecks\n",
    "\n",
    "```sql\n",
    "-- High buffer reads (disk I/O)\n",
    "EXPLAIN (ANALYZE, BUFFERS)\n",
    "SELECT * FROM large_table WHERE unindexed_column = 'value';\n",
    "-- Buffers: shared read=100000  <-- High physical reads\n",
    "-- Solution: Add index or improve query\n",
    "\n",
    "-- High rows removed by filter (bad index selectivity)\n",
    "EXPLAIN (ANALYZE)\n",
    "SELECT * FROM users WHERE status = 'active' AND age > 25;\n",
    "-- Index Scan using idx_status\n",
    "--   Index Cond: (status = 'active')\n",
    "--   Filter: (age > 25)\n",
    "--   Rows Removed by Filter: 95000  <-- Index returned 100k rows, filter kept 5k\n",
    "-- Solution: Composite index on (status, age) or (age, status) depending on selectivity\n",
    "\n",
    "-- High execution time vs planning time\n",
    "EXPLAIN (ANALYZE)\n",
    "SELECT * FROM complex_view WHERE id = 1;\n",
    "-- Planning Time: 45.000 ms  <-- Too long (complex view, many tables)\n",
    "-- Execution Time: 0.500 ms\n",
    "-- Solution: Materialized view, or simplify view, or use plan caching (prepared statements)\n",
    "\n",
    "-- Memory usage (hash operations)\n",
    "EXPLAIN (ANALYZE)\n",
    "SELECT * FROM large_table GROUP BY many_columns;\n",
    "-- HashAggregate\n",
    "--   Peak Memory Usage: 1048576kB  <-- Hit work_mem limit\n",
    "--   Disk Usage: 500000kB  <-- Spilled to disk (slow)\n",
    "-- Solution: Increase work_mem, or better indexing, or reduce GROUP BY complexity\n",
    "```\n",
    "\n",
    "### 14.8.2 Plan Node Reference\n",
    "\n",
    "```sql\n",
    "-- Common node types you'll see:\n",
    "\n",
    "-- 1. Scan Nodes (leaf nodes)\n",
    "-- Seq Scan: Sequential table read\n",
    "-- Index Scan: Index lookup + heap fetch\n",
    "-- Index Only Scan: Index lookup only (no heap)\n",
    "-- Bitmap Index Scan + Bitmap Heap Scan: Bitmap combination\n",
    "-- Tid Scan: Direct ctid access\n",
    "-- Subquery Scan: Wrapper for subquery results\n",
    "\n",
    "-- 2. Join Nodes\n",
    "-- Nested Loop: Iterate outer, probe inner\n",
    "-- Hash Join: Build hash on inner, probe with outer\n",
    "-- Merge Join: Sort both, merge\n",
    "-- Nested Loop Semi Join: EXISTS optimization\n",
    "-- Nested Loop Anti Join: NOT EXISTS optimization\n",
    "\n",
    "-- 3. Aggregation Nodes\n",
    "-- Aggregate: General grouping (sort or hash based)\n",
    "-- GroupAggregate: Sorted input grouping\n",
    "-- HashAggregate: Hash table grouping (usually faster)\n",
    "-- MixedAggregate: For GROUPING SETS\n",
    "\n",
    "-- 4. Sorting and Limiting\n",
    "-- Sort: QuickSort or external merge sort\n",
    "-- Limit: Stop after N rows\n",
    "-- Limit with Ties: Include ties when using WITH TIES\n",
    "-- Unique: DISTINCT operation (often via HashAggregate or Unique node)\n",
    "\n",
    "-- 5. Set Operations\n",
    "-- Append: UNION ALL, partitioned table scans\n",
    "-- Merge Append: UNION (sorted), partitioned ordered scans\n",
    "-- SetOp: INTERSECT/EXCEPT (via hashing or sorting)\n",
    "-- HashSetOp: Hash-based INTERSECT/EXCEPT\n",
    "\n",
    "-- 6. Modification Nodes\n",
    "-- Insert, Update, Delete: Top-level DML nodes\n",
    "-- ModifyTable: Wrapper for INSERT/UPDATE/DELETE\n",
    "-- LockRows: FOR UPDATE/SHARE locking\n",
    "-- Result: Constant projection or one-time evaluation\n",
    "```\n",
    "\n",
    "## 14.9 Configuration Parameters Affecting Planning\n",
    "\n",
    "```sql\n",
    "-- Enable/disable specific plan types (for testing or hints)\n",
    "SET enable_seqscan = off;        -- Force index usage (testing only)\n",
    "SET enable_indexscan = on;       -- Allow index scans\n",
    "SET enable_bitmapscan = on;      -- Allow bitmap scans\n",
    "SET enable_tidscan = on;         -- Allow tid scans\n",
    "\n",
    "SET enable_nestloop = off;       -- Avoid nested loops (often for star schemas)\n",
    "SET enable_hashjoin = on;        -- Allow hash joins\n",
    "SET enable_mergejoin = on;       -- Allow merge joins\n",
    "\n",
    "-- Cost constants (calibration)\n",
    "SET seq_page_cost = 1.0;         -- Cost of sequential page read\n",
    "SET random_page_cost = 4.0;      -- Cost of random page read (lower for SSDs: 1.1)\n",
    "SET cpu_tuple_cost = 0.01;       -- Processing cost per row\n",
    "SET cpu_index_tuple_cost = 0.005; -- Index entry processing cost\n",
    "SET cpu_operator_cost = 0.0025;  -- Operator evaluation cost\n",
    "\n",
    "-- Memory constraints\n",
    "SET work_mem = '4MB';            -- Per-operation memory (sorts, hashes, bitmaps)\n",
    "-- Hash joins: Build table must fit in work_mem or spill to disk\n",
    "-- Sorts: External merge sort uses work_mem per sort operation\n",
    "-- Bitmap scans: Bitmap size limited by work_mem (or uses \"lossy\" bitmaps)\n",
    "\n",
    "-- Parallelism (PostgreSQL 9.6+)\n",
    "SET max_parallel_workers_per_gather = 2;  -- Parallel workers for scans/joins\n",
    "SET parallel_tuple_cost = 0.1;              -- Cost of passing tuples between processes\n",
    "SET parallel_setup_cost = 1000;             -- Cost of starting worker processes\n",
    "\n",
    "-- Genetic Query Optimizer (GEQO)\n",
    "SET geqo = on;                    -- Enable for complex joins (>12 tables default)\n",
    "SET geqo_threshold = 12;          -- Switch to genetic algorithm above this\n",
    "SET geqo_effort = 5;              -- Search effort (1-10, higher = better plans, slower planning)\n",
    "```\n",
    "\n",
    "## 14.10 Industry Best Practices and Anti-Patterns\n",
    "\n",
    "### 14.10.1 When to Trust the Planner\n",
    "\n",
    "```sql\n",
    "-- Good: Sequential scan on small table\n",
    "EXPLAIN SELECT * FROM countries WHERE continent = 'Europe';\n",
    "-- Seq Scan is correct for 200 rows, even with index available\n",
    "-- Random I/O of index scan would be slower than reading 2 pages sequentially\n",
    "\n",
    "-- Good: Sequential scan on large unselective query\n",
    "EXPLAIN SELECT * FROM logs WHERE level IN ('INFO', 'DEBUG');\n",
    "-- If 90% of logs are INFO/DEBUG, reading 90% of table via index is wasteful\n",
    "-- Seq Scan reads sequentially, better cache utilization\n",
    "\n",
    "-- Bad: Sequential scan due to stale statistics\n",
    "EXPLAIN SELECT * FROM users WHERE status = 'admin';\n",
    "-- Seq Scan on 1M rows, but only 10 admins exist!\n",
    "-- Fix: ANALYZE users;\n",
    "-- Then: Index Scan using idx_status\n",
    "\n",
    "-- Bad: Sequential scan due to function on column\n",
    "EXPLAIN SELECT * FROM users WHERE EXTRACT(YEAR FROM created_at) = 2024;\n",
    "-- Seq Scan with Filter: (EXTRACT(year FROM created_at) = 2024)\n",
    "-- Cannot use index on created_at\n",
    "-- Fix: Use range query (SARGable)\n",
    "EXPLAIN SELECT * FROM users \n",
    "WHERE created_at >= '2024-01-01' \n",
    "  AND created_at < '2025-01-01';\n",
    "-- Index Scan using idx_created_at\n",
    "```\n",
    "\n",
    "### 14.10.2 Join Strategy Selection Guidelines\n",
    "\n",
    "```sql\n",
    "-- Nested Loop: Small outer, indexed inner\n",
    "-- Best for: OLTP lookups, recent data filters\n",
    "SELECT * FROM users u\n",
    "JOIN orders o ON u.user_id = o.user_id\n",
    "WHERE u.user_id = 123;  -- Single user (1 row outer)\n",
    "-- Plan: Nested Loop with Index Scan on orders\n",
    "\n",
    "-- Hash Join: Large tables, no suitable index, equality join\n",
    "-- Best for: Analytics, reporting, star schema joins\n",
    "SELECT * FROM fact_sales f\n",
    "JOIN dim_product p ON f.product_id = p.product_id\n",
    "WHERE f.sale_date BETWEEN '2024-01-01' AND '2024-12-31';\n",
    "-- Plan: Seq Scan on fact_sales (large), Hash on dim_product (small), Hash Join\n",
    "\n",
    "-- Merge Join: Large tables, sorted inputs, range queries\n",
    "-- Best for: Range joins, inequality conditions, pre-sorted data\n",
    "SELECT * FROM events e1\n",
    "JOIN events e2 ON e1.start_time <= e2.end_time \n",
    "               AND e1.end_time >= e2.start_time;\n",
    "-- Temporal overlap join (inequality)\n",
    "-- Plan: Sort both inputs, Merge Join\n",
    "\n",
    "-- Anti-Join patterns (NOT EXISTS)\n",
    "SELECT * FROM users u\n",
    "WHERE NOT EXISTS (\n",
    "    SELECT 1 FROM orders o WHERE o.user_id = u.user_id\n",
    ");\n",
    "-- Plan: Nested Loop Anti Join\n",
    "-- Stops at first match (efficient for \"not exists\")\n",
    "-- Never returns rows from right side (anti-join semantics)\n",
    "```\n",
    "\n",
    "### 14.10.3 Plan Instability and Management\n",
    "\n",
    "```sql\n",
    "-- Plan caching and parameter sniffing (PostgreSQL uses generic plans after 5 executions)\n",
    "PREPARE get_user_orders(BIGINT) AS\n",
    "SELECT * FROM orders WHERE user_id = $1;\n",
    "\n",
    "-- First 5 executions: Custom plan generated for specific parameter values\n",
    "-- 6th+ execution: Generic plan (unless custom plan is much cheaper)\n",
    "-- Check with:\n",
    "EXPLAIN EXECUTE get_user_orders(123);\n",
    "\n",
    "-- Forcing custom plans (if generic plan is bad for specific values):\n",
    "SET plan_cache_mode = 'force_custom_plan';\n",
    "\n",
    "-- Plan hints (extension required: pg_hint_plan)\n",
    "-- PostgreSQL doesn't support hints natively (by design), but extension available:\n",
    "-- /*+ SeqScan(users) IndexScan(orders idx_orders_user_id) NestLoop(users orders) */\n",
    "\n",
    "-- Better approach: Use query structure to guide planner\n",
    "-- Force index usage by making condition index-friendly\n",
    "-- Force hash join by ensuring large inputs\n",
    "-- Force nested loop by limiting outer query with LIMIT\n",
    "\n",
    "-- Join order hints via CTEs (PostgreSQL 12+):\n",
    "WITH active_users AS MATERIALIZED (\n",
    "    SELECT * FROM users WHERE status = 'active' LIMIT 100\n",
    ")\n",
    "SELECT * FROM active_users u\n",
    "JOIN orders o ON u.user_id = o.user_id;\n",
    "-- MATERIALIZED forces evaluation of CTE first (limits join order flexibility)\n",
    "-- Use sparingly; prevents optimizer from pushing predicates into CTE\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary\n",
    "\n",
    "In this chapter, you learned:\n",
    "\n",
    "1. **Query Processing Pipeline**: SQL passes through Parser (syntax), Rewriter (views/rules), Planner (optimization), and Executor (runtime). The Planner generates the critical execution plan using cost estimates.\n",
    "\n",
    "2. **Cost Model**: PostgreSQL uses abstract cost units based on `seq_page_cost` (1.0) and `random_page_cost` (4.0). Costs include I/O (pages) and CPU (tuples, operators). Costs are relative, not milliseconds.\n",
    "\n",
    "3. **Statistics**: The planner relies on `pg_stats` (populated by `ANALYZE`) containing most common values, histograms, and correlation. Stale statistics cause bad plans (Seq Scans on selective queries). High-churn tables need adjusted `autovacuum_analyze_scale_factor`.\n",
    "\n",
    "4. **Scan Types**:\n",
    "   - **Seq Scan**: Sequential read of all pages. Best for small tables or high selectivity (>10% of rows).\n",
    "   - **Index Scan**: Index lookup followed by heap fetch. Best for low selectivity (<5% of rows) or when order matches index.\n",
    "   - **Bitmap Index Scan + Bitmap Heap Scan**: Builds bitmap of matching rows from index, then fetches heap pages in order. Best for moderate selectivity (5-20%) or combining multiple indexes.\n",
    "   - **Index-Only Scan**: Reads only index, no heap access. Requires covering index and clean visibility map.\n",
    "\n",
    "5. **Join Algorithms**:\n",
    "   - **Nested Loop**: Iterate outer, probe inner. Best for small outer with indexed inner (OLTP).\n",
    "   - **Hash Join**: Build hash table on smaller input, probe with larger. Best for large tables without indexes (Analytics).\n",
    "   - **Merge Join**: Sort both inputs, merge. Best for pre-sorted data or range joins (inequalities).\n",
    "\n",
    "6. **Plan Reading**: Look for actual vs estimated row discrepancies (indicates bad statistics), buffer counts (I/O intensity), and node timing (where time is spent). High \"Rows Removed by Filter\" suggests index selectivity issues.\n",
    "\n",
    "7. **Configuration**: `work_mem` affects hash and sort operations (spill to disk if exceeded). `random_page_cost` should be lowered for SSDs (1.1 vs default 4.0). `geqo_threshold` switches to genetic optimizer for many-table joins.\n",
    "\n",
    "**Next:** In Chapter 15, we will explore Index Fundamentals—covering B-tree structure, index selection criteria, covering indexes, and the critical distinction between index scans and index-only scans in production environments."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
