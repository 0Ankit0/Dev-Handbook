{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 46: Database Testing Strategies\n",
    "\n",
    "Testing database logic requires specialized approaches that balance isolation, performance, and realism. Unlike application code, database tests must validate not only logical correctness but also constraint enforcement, transaction behavior, and query performance under realistic data distributions. This chapter establishes industry-standard patterns for testing PostgreSQL logic across unit, integration, and property-based paradigms.\n",
    "\n",
    "## 46.1 Unit Testing Database Objects\n",
    "\n",
    "### 46.1.1 Testing Philosophy: The Database Test Pyramid\n",
    "\n",
    "Database testing follows a hierarchy where the majority of tests should be fast and isolated, while fewer tests validate full integration paths.\n",
    "\n",
    "```\n",
    "    /\\\n",
    "   /  \\     E2E Tests (Full application + DB)\n",
    "  /____\\      [Few tests - slow, expensive]\n",
    " /      \\\n",
    "/________\\  Integration Tests (Repository/DAO layer)\n",
    " \\      /     [Medium count - realistic data]\n",
    "  \\    /\n",
    "   \\  /    Unit Tests (Functions, Constraints, Triggers)\n",
    "    \\/        [Many tests - fast, isolated]\n",
    "```\n",
    "\n",
    "**Testing Boundaries:**\n",
    "- **Unit Tests**: Pure SQL functions, constraint logic, trigger behavior (in-memory or transaction-rolled-back)\n",
    "- **Integration Tests**: Repository patterns, connection pooling, transaction management across application layers\n",
    "- **E2E Tests**: Full request/response cycles with committed data (minimal set, typically <50 tests)\n",
    "\n",
    "### 46.1.2 pgTAP: The Industry Standard for PostgreSQL Testing\n",
    "\n",
    "pgTAP is a unit testing framework for PostgreSQL that provides xUnit-style assertions accessible via SQL.\n",
    "\n",
    "```sql\n",
    "-- Install pgTAP extension (one-time per database)\n",
    "CREATE EXTENSION IF NOT EXISTS pgtap;\n",
    "\n",
    "-- Test function: Calculate order total with tax\n",
    "CREATE OR REPLACE FUNCTION calculate_order_total(\n",
    "    subtotal NUMERIC,\n",
    "    tax_rate NUMERIC DEFAULT 0.08\n",
    ") RETURNS NUMERIC AS $$\n",
    "BEGIN\n",
    "    IF subtotal IS NULL OR subtotal < 0 THEN\n",
    "        RAISE EXCEPTION 'Invalid subtotal: %', subtotal;\n",
    "    END IF;\n",
    "    RETURN ROUND(subtotal * (1 + tax_rate), 2);\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "\n",
    "-- Unit test file: tests/test_calculate_order_total.sql\n",
    "BEGIN;\n",
    "SELECT plan(6);  -- Declare number of tests\n",
    "\n",
    "-- Test 1: Basic calculation\n",
    "SELECT is(\n",
    "    calculate_order_total(100, 0.08),\n",
    "    108.00,\n",
    "    'Should calculate 8% tax on $100'\n",
    ");\n",
    "\n",
    "-- Test 2: Default tax rate\n",
    "SELECT is(\n",
    "    calculate_order_total(100),\n",
    "    108.00,\n",
    "    'Should use default 8% tax rate'\n",
    ");\n",
    "\n",
    "-- Test 3: Zero subtotal edge case\n",
    "SELECT is(\n",
    "    calculate_order_total(0, 0.08),\n",
    "    0,\n",
    "    'Should handle zero subtotal'\n",
    ");\n",
    "\n",
    "-- Test 4: Rounding behavior\n",
    "SELECT is(\n",
    "    calculate_order_total(99.999, 0.08),\n",
    "    108.00,\n",
    "    'Should round to 2 decimal places'\n",
    ");\n",
    "\n",
    "-- Test 5: Exception on negative input\n",
    "SELECT throws_ok(\n",
    "    'SELECT calculate_order_total(-10, 0.08)',\n",
    "    'P0001',\n",
    "    'Invalid subtotal: -10',\n",
    "    'Should raise exception for negative subtotal'\n",
    ");\n",
    "\n",
    "-- Test 6: Exception on NULL\n",
    "SELECT throws_ok(\n",
    "    'SELECT calculate_order_total(NULL, 0.08)',\n",
    "    'P0001',\n",
    "    'Invalid subtotal: %',  -- % matches any message content\n",
    "    'Should raise exception for NULL subtotal'\n",
    ");\n",
    "\n",
    "-- Verify test count\n",
    "SELECT * FROM finish();\n",
    "ROLLBACK;  -- Always rollback to keep database clean\n",
    "```\n",
    "\n",
    "**pgTAP Assertion Categories:**\n",
    "\n",
    "| Category | Functions | Use Case |\n",
    "|----------|-----------|----------|\n",
    "| Equality | `is()`, `isnt()` | Result matching |\n",
    "| Boolean | `ok()`, `cmp_ok()` | Truthy checks, comparisons |\n",
    "| Matching | `matches()`, `imatches()` | Regex pattern matching |\n",
    "| Set Ops | `bag_eq()`, `set_eq()` | Rowset comparisons |\n",
    "| Exceptions | `throws_ok()`, `lives_ok()` | Error handling validation |\n",
    "| Schema | `has_table()`, `has_column()`, `has_index()` | Schema verification |\n",
    "| Performance | `perform_ok()` | Execution time limits |\n",
    "\n",
    "### 46.1.3 Testing Constraints and Triggers\n",
    "\n",
    "Complex business logic often resides in constraints and triggers; these require specific testing patterns.\n",
    "\n",
    "```sql\n",
    "-- Test complex check constraint: Email domain validation\n",
    "ALTER TABLE users ADD CONSTRAINT chk_email_domain \n",
    "CHECK (email ~* '^[A-Za-z0-9._%+-]+@(example\\.com|example\\.org)$');\n",
    "\n",
    "-- Test file: tests/test_email_constraints.sql\n",
    "BEGIN;\n",
    "SELECT plan(4);\n",
    "\n",
    "-- Prepare test data (in transaction, will rollback)\n",
    "INSERT INTO users (user_id, email, full_name) \n",
    "VALUES (gen_random_uuid(), 'test@example.com', 'Test User');\n",
    "\n",
    "-- Test valid domain\n",
    "SELECT lives_ok(\n",
    "    'INSERT INTO users (user_id, email, full_name) \n",
    "     VALUES (gen_random_uuid(), ''valid@example.com'', ''Valid'')',\n",
    "    'Should accept example.com emails'\n",
    ");\n",
    "\n",
    "-- Test invalid domain\n",
    "SELECT throws_ok(\n",
    "    'INSERT INTO users (user_id, email, full_name) \n",
    "     VALUES (gen_random_uuid(), ''invalid@gmail.com'', ''Invalid'')',\n",
    "    '23514',  -- check_violation\n",
    "    NULL,\n",
    "    'Should reject non-example domains'\n",
    ");\n",
    "\n",
    "-- Test trigger: Audit log creation\n",
    "CREATE OR REPLACE FUNCTION audit_user_changes()\n",
    "RETURNS TRIGGER AS $$\n",
    "BEGIN\n",
    "    INSERT INTO audit_log (table_name, record_id, action, changed_at, old_data, new_data)\n",
    "    VALUES (\n",
    "        TG_TABLE_NAME,\n",
    "        NEW.user_id,\n",
    "        TG_OP,\n",
    "        NOW(),\n",
    "        to_jsonb(OLD),\n",
    "        to_jsonb(NEW)\n",
    "    );\n",
    "    RETURN NEW;\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "\n",
    "CREATE TRIGGER trg_users_audit\n",
    "AFTER UPDATE ON users\n",
    "FOR EACH ROW\n",
    "EXECUTE FUNCTION audit_user_changes();\n",
    "\n",
    "-- Test audit trigger\n",
    "UPDATE users SET full_name = 'Updated Name' WHERE email = 'test@example.com';\n",
    "\n",
    "SELECT results_eq(\n",
    "    'SELECT action, old_data->>''full_name'', new_data->>''full_name'' \n",
    "     FROM audit_log \n",
    "     WHERE table_name = ''users'' \n",
    "     ORDER BY changed_at DESC \n",
    "     LIMIT 1',\n",
    "    $$ VALUES ('UPDATE'::text, 'Test User'::text, 'Updated Name'::text) $$,\n",
    "    'Audit log should capture old and new values'\n",
    ");\n",
    "\n",
    "SELECT * FROM finish();\n",
    "ROLLBACK;\n",
    "```\n",
    "\n",
    "### 46.1.4 Testing Transaction Behavior and Isolation\n",
    "\n",
    "Database unit tests must verify transaction boundaries and concurrency behavior.\n",
    "\n",
    "```sql\n",
    "-- Test idempotency key handling (exactly-once processing)\n",
    "CREATE TABLE payment_processing (\n",
    "    idempotency_key TEXT PRIMARY KEY,\n",
    "    payment_id UUID,\n",
    "    status TEXT,\n",
    "    processed_at TIMESTAMPTZ DEFAULT NOW()\n",
    ");\n",
    "\n",
    "-- Function with atomic upsert\n",
    "CREATE OR REPLACE FUNCTION process_payment(\n",
    "    p_idempotency_key TEXT,\n",
    "    p_amount NUMERIC\n",
    ") RETURNS UUID AS $$\n",
    "DECLARE\n",
    "    v_payment_id UUID;\n",
    "BEGIN\n",
    "    INSERT INTO payments (amount, status) \n",
    "    VALUES (p_amount, 'pending')\n",
    "    RETURNING payment_id INTO v_payment_id;\n",
    "    \n",
    "    INSERT INTO payment_processing (idempotency_key, payment_id, status)\n",
    "    VALUES (p_idempotency_key, v_payment_id, 'completed')\n",
    "    ON CONFLICT (idempotency_key) DO UPDATE\n",
    "    SET status = EXCLUDED.status\n",
    "    WHERE payment_processing.status != 'completed'\n",
    "    RETURNING payment_id INTO v_payment_id;\n",
    "    \n",
    "    RETURN v_payment_id;\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "\n",
    "-- Test: Concurrent calls should return same ID\n",
    "BEGIN;\n",
    "SELECT plan(2);\n",
    "\n",
    "-- First call creates payment\n",
    "SELECT isnt(\n",
    "    process_payment('key-123', 100.00),\n",
    "    NULL,\n",
    "    'First call should create payment'\n",
    ") AS first_call_id \\gset\n",
    "\n",
    "-- Second call with same key should return same ID (idempotent)\n",
    "SELECT is(\n",
    "    process_payment('key-123', 100.00),\n",
    "    :first_call_id,\n",
    "    'Second call should return same payment_id (idempotent)'\n",
    ");\n",
    "\n",
    "-- Verify only one payment exists\n",
    "SELECT is(\n",
    "    (SELECT COUNT(*) FROM payments),\n",
    "    1::BIGINT,\n",
    "    'Should create exactly one payment despite two calls'\n",
    ");\n",
    "\n",
    "SELECT * FROM finish();\n",
    "ROLLBACK;\n",
    "```\n",
    "\n",
    "## 46.2 Integration Testing with Ephemeral Databases\n",
    "\n",
    "### 46.2.1 Testcontainers Pattern (Docker-based Isolation)\n",
    "\n",
    "Testcontainers provide lightweight, throwaway PostgreSQL instances for integration tests, ensuring test isolation without mocking.\n",
    "\n",
    "```python\n",
    "# Python example using testcontainers-postgres\n",
    "import pytest\n",
    "from testcontainers.postgres import PostgresContainer\n",
    "from sqlalchemy import create_engine, text\n",
    "import psycopg2\n",
    "\n",
    "@pytest.fixture(scope=\"function\")\n",
    "def postgres_container():\n",
    "    \"\"\"Provides fresh PostgreSQL container for each test function\"\"\"\n",
    "    with PostgresContainer(\"postgres:16-alpine\") as postgres:\n",
    "        # Container starts automatically\n",
    "        yield postgres\n",
    "        # Container stops and is removed automatically after test\n",
    "\n",
    "@pytest.fixture\n",
    "def db_engine(postgres_container):\n",
    "    \"\"\"SQLAlchemy engine connected to ephemeral database\"\"\"\n",
    "    connection_url = postgres.get_connection_url()\n",
    "    engine = create_engine(connection_url)\n",
    "    \n",
    "    # Run migrations (using your migration tool)\n",
    "    run_migrations(engine)\n",
    "    \n",
    "    yield engine\n",
    "    \n",
    "    # Cleanup: dispose connections\n",
    "    engine.dispose()\n",
    "\n",
    "def test_user_repository_create(db_engine):\n",
    "    \"\"\"Integration test with real PostgreSQL\"\"\"\n",
    "    from myapp.repositories import UserRepository\n",
    "    \n",
    "    repo = UserRepository(db_engine)\n",
    "    \n",
    "    # Test\n",
    "    user = repo.create(email=\"test@example.com\", full_name=\"Test User\")\n",
    "    \n",
    "    # Verify\n",
    "    assert user.id is not None\n",
    "    assert user.created_at is not None\n",
    "    \n",
    "    # Verify in database (not just mock return)\n",
    "    with db_engine.connect() as conn:\n",
    "        result = conn.execute(\n",
    "            text(\"SELECT email FROM users WHERE user_id = :id\"),\n",
    "            {\"id\": user.id}\n",
    "        ).scalar()\n",
    "        assert result == \"test@example.com\"\n",
    "```\n",
    "\n",
    "**Node.js/JavaScript Implementation:**\n",
    "\n",
    "```javascript\n",
    "// test/setup.js - Jest configuration with testcontainers\n",
    "const { PostgreSqlContainer } = require(\"testcontainers\");\n",
    "const { Client } = require(\"pg\");\n",
    "const { migrate } = require(\"postgres-migrations\");\n",
    "\n",
    "let container;\n",
    "\n",
    "beforeAll(async () => {\n",
    "  // Start container once for all tests in file\n",
    "  container = await new PostgreSqlContainer(\"postgres:16-alpine\")\n",
    "    .withDatabase(\"test_db\")\n",
    "    .withUsername(\"test_user\")\n",
    "    .withPassword(\"test_pass\")\n",
    "    .start();\n",
    "    \n",
    "  process.env.DATABASE_URL = container.getConnectionUri();\n",
    "});\n",
    "\n",
    "afterAll(async () => {\n",
    "  await container.stop();\n",
    "});\n",
    "\n",
    "beforeEach(async () => {\n",
    "  // Clean state between tests: truncate all tables\n",
    "  const client = new Client({ connectionString: container.getConnectionUri() });\n",
    "  await client.connect();\n",
    "  \n",
    "  // Get all tables and truncate (faster than recreating container)\n",
    "  const tables = await client.query(`\n",
    "    SELECT tablename FROM pg_tables \n",
    "    WHERE schemaname = 'public'\n",
    "  `);\n",
    "  \n",
    "  for (const row of tables.rows) {\n",
    "    await client.query(`TRUNCATE TABLE ${row.tablename} CASCADE`);\n",
    "  }\n",
    "  \n",
    "  await client.end();\n",
    "});\n",
    "\n",
    "// Example test\n",
    "describe(\"Order Repository\", () => {\n",
    "  test(\"should create order with line items\", async () => {\n",
    "    const repo = new OrderRepository();\n",
    "    \n",
    "    const order = await repo.create({\n",
    "      userId: \"user-123\",\n",
    "      items: [\n",
    "        { productId: \"prod-1\", quantity: 2, price: 1000 }\n",
    "      ]\n",
    "    });\n",
    "    \n",
    "    // Verify with raw SQL to ensure constraints fired\n",
    "    const client = new Client({ connectionString: process.env.DATABASE_URL });\n",
    "    await client.connect();\n",
    "    \n",
    "    const result = await client.query(\n",
    "      \"SELECT total_cents FROM orders WHERE order_id = $1\",\n",
    "      [order.id]\n",
    "    );\n",
    "    \n",
    "    expect(result.rows[0].total_cents).toBe(2000); // 2 * 1000\n",
    "    await client.end();\n",
    "  });\n",
    "});\n",
    "```\n",
    "\n",
    "### 46.2.2 Transaction Rollback Strategy (Fastest Integration Tests)\n",
    "\n",
    "For sub-millisecond test execution, run tests within transactions that always rollback, avoiding database cleanup overhead.\n",
    "\n",
    "```python\n",
    "# pytest fixture with transaction rollback\n",
    "import pytest\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker, Session\n",
    "\n",
    "@pytest.fixture(scope=\"session\")\n",
    "def engine():\n",
    "    \"\"\"Create engine connected to test database (persistent for session)\"\"\"\n",
    "    return create_engine(\"postgresql://test:test@localhost/test_db\")\n",
    "\n",
    "@pytest.fixture(scope=\"function\")\n",
    "def db_session(engine):\n",
    "    \"\"\"\n",
    "    Creates transactional scope around test.\n",
    "    Rolls back all changes after test completion.\n",
    "    \"\"\"\n",
    "    connection = engine.connect()\n",
    "    transaction = connection.begin()\n",
    "    session = Session(bind=connection)\n",
    "    \n",
    "    # Begin nested transaction (savepoint)\n",
    "    session.begin_nested()\n",
    "    \n",
    "    # Listen for rollback events to re-establish savepoint\n",
    "    @event.listens_for(session, \"after_transaction_end\")\n",
    "    def restart_savepoint(session, transaction):\n",
    "        if transaction.nested and not transaction._parent.nested:\n",
    "            session.begin_nested()\n",
    "    \n",
    "    yield session\n",
    "    \n",
    "    # Cleanup: rollback everything\n",
    "    session.close()\n",
    "    transaction.rollback()\n",
    "    connection.close()\n",
    "\n",
    "def test_user_creation(db_session):\n",
    "    \"\"\"Test runs in transaction, changes never committed\"\"\"\n",
    "    user = User(email=\"test@example.com\")\n",
    "    db_session.add(user)\n",
    "    db_session.flush()  # Send to DB but don't commit\n",
    "    \n",
    "    # Verify in database\n",
    "    result = db_session.query(User).filter_by(email=\"test@example.com\").first()\n",
    "    assert result is not None\n",
    "    \n",
    "    # After test function exits, transaction rolls back\n",
    "    # Database remains clean for next test\n",
    "```\n",
    "\n",
    "**Critical Considerations for Transaction Rollback:**\n",
    "\n",
    "1. **Connection Pool Conflicts**: Application code must use the same connection as the test transaction; disable connection pooling in tests or use `Session(bind=connection)` explicitly\n",
    "2. **DDL Limitations**: `CREATE TABLE`, `ALTER TABLE` commit implicit transactions in PostgreSQL; use separate schema setup or `TRUNCATE` strategy for migration tests\n",
    "3. **Concurrency Testing**: Transaction rollback prevents testing true concurrent behavior (use separate containers for concurrency tests)\n",
    "\n",
    "### 46.2.3 Database Cleaning Strategies\n",
    "\n",
    "When transaction rollback isn't feasible (DDL changes, multiple connections), explicit cleanup is required.\n",
    "\n",
    "```sql\n",
    "-- Truncate strategy (fast, preserves table structure, resets sequences)\n",
    "CREATE OR REPLACE FUNCTION truncate_all_tables()\n",
    "RETURNS void AS $$\n",
    "DECLARE\n",
    "    rec RECORD;\n",
    "BEGIN\n",
    "    -- Disable triggers to avoid foreign key constraint errors\n",
    "    FOR rec IN \n",
    "        SELECT tablename \n",
    "        FROM pg_tables \n",
    "        WHERE schemaname = 'public'\n",
    "    LOOP\n",
    "        EXECUTE 'ALTER TABLE ' || rec.tablename || ' DISABLE TRIGGER ALL';\n",
    "    END LOOP;\n",
    "    \n",
    "    -- Truncate all tables\n",
    "    FOR rec IN \n",
    "        SELECT tablename \n",
    "        FROM pg_tables \n",
    "        WHERE schemaname = 'public'\n",
    "    LOOP\n",
    "        EXECUTE 'TRUNCATE TABLE ' || rec.tablename || ' CASCADE';\n",
    "    END LOOP;\n",
    "    \n",
    "    -- Re-enable triggers\n",
    "    FOR rec IN \n",
    "        SELECT tablename \n",
    "        FROM pg_tables \n",
    "        WHERE schemaname = 'public'\n",
    "    LOOP\n",
    "        EXECUTE 'ALTER TABLE ' || rec.tablename || ' ENABLE TRIGGER ALL';\n",
    "    END LOOP;\n",
    "    \n",
    "    -- Reset sequences\n",
    "    FOR rec IN \n",
    "        SELECT sequencename \n",
    "        FROM pg_sequences \n",
    "        WHERE schemaname = 'public'\n",
    "    LOOP\n",
    "        EXECUTE 'ALTER SEQUENCE ' || rec.sequencename || ' RESTART WITH 1';\n",
    "    END LOOP;\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "```\n",
    "\n",
    "**Strategy Comparison:**\n",
    "\n",
    "| Strategy | Speed | Isolation | Use Case |\n",
    "|----------|-------|-----------|----------|\n",
    "| Transaction Rollback | <1ms | Perfect | Unit/integration tests without DDL |\n",
    "| Truncate | 10-100ms | Good | Tests with DDL, large datasets |\n",
    "| Recreate Schema | 1-5s | Perfect | Migration tests, schema validation |\n",
    "| New Container | 5-30s | Perfect | Parallel test suites, CI/CD |\n",
    "\n",
    "## 46.3 Property-Based Testing for SQL Correctness\n",
    "\n",
    "### 46.3.1 Generating Test Cases with Hypothesis (Python)\n",
    "\n",
    "Property-based testing generates thousands of random inputs to find edge cases missed by manual test writing.\n",
    "\n",
    "```python\n",
    "# test_property_based.py\n",
    "from hypothesis import given, strategies as st, settings\n",
    "import pytest\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Strategy: Generate valid email strings\n",
    "email_strategy = st.emails()\n",
    "\n",
    "# Strategy: Generate monetary amounts (cents to avoid float errors)\n",
    "money_strategy = st.integers(min_value=0, max_value=1000000)\n",
    "\n",
    "@given(email=email_strategy, amount=money_strategy)\n",
    "@settings(max_examples=1000)  # Run 1000 random combinations\n",
    "def test_payment_processing_idempotent(db_session, email, amount):\n",
    "    \"\"\"\n",
    "    Property: Processing the same payment twice should always \n",
    "    return the same payment_id (idempotency invariant)\n",
    "    \"\"\"\n",
    "    idempotency_key = f\"{email}-{amount}-{datetime.now().isoformat()}\"\n",
    "    \n",
    "    # First call\n",
    "    result1 = db_session.execute(\n",
    "        text(\"SELECT process_payment(:key, :amount)\"),\n",
    "        {\"key\": idempotency_key, \"amount\": amount / 100}  # Convert cents to dollars\n",
    "    ).scalar()\n",
    "    \n",
    "    # Second call with same key\n",
    "    result2 = db_session.execute(\n",
    "        text(\"SELECT process_payment(:key, :amount)\"),\n",
    "        {\"key\": idempotency_key, \"amount\": amount / 100}\n",
    "    ).scalar()\n",
    "    \n",
    "    # Property: Results must be identical\n",
    "    assert result1 == result2, f\"Idempotency failed for {email}, {amount}\"\n",
    "    \n",
    "    # Property: Exactly one payment record exists\n",
    "    count = db_session.execute(\n",
    "        text(\"SELECT COUNT(*) FROM payments WHERE payment_id = :id\"),\n",
    "        {\"id\": result1}\n",
    "    ).scalar()\n",
    "    assert count == 1\n",
    "\n",
    "@given(\n",
    "    st.lists(st.tuples(st.integers(min_value=1), st.integers(min_value=1)), \n",
    "             min_size=1, max_size=100)\n",
    ")\n",
    "def test_order_total_calculation(db_session, line_items):\n",
    "    \"\"\"\n",
    "    Property: Order total should equal sum of (price * quantity) for all items\n",
    "    \"\"\"\n",
    "    # Generate random line items\n",
    "    items = [{\"product_id\": i, \"qty\": qty, \"price_cents\": price} \n",
    "             for i, (qty, price) in enumerate(line_items)]\n",
    "    \n",
    "    expected_total = sum(item[\"qty\"] * item[\"price_cents\"] for item in items)\n",
    "    \n",
    "    # Insert order via repository\n",
    "    order_repo = OrderRepository(db_session)\n",
    "    order = order_repo.create(items=items)\n",
    "    \n",
    "    # Property: Total must match calculated sum\n",
    "    assert order.total_cents == expected_total, \\\n",
    "        f\"Expected {expected_total}, got {order.total_cents} for items {items}\"\n",
    "```\n",
    "\n",
    "### 46.3.2 Testing SQL Invariants\n",
    "\n",
    "Database invariants (constraints that must always hold) can be verified against random data states.\n",
    "\n",
    "```python\n",
    "# Test database invariants\n",
    "@given(st.data())\n",
    "def test_account_balance_invariant(db_session, data):\n",
    "    \"\"\"\n",
    "    Property: Account balance should always equal \n",
    "    sum of credits minus sum of debits\n",
    "    \"\"\"\n",
    "    # Generate random transaction history\n",
    "    num_transactions = data.draw(st.integers(min_value=0, max_value=50))\n",
    "    \n",
    "    account_id = create_test_account(db_session)\n",
    "    \n",
    "    transactions = []\n",
    "    for _ in range(num_transactions):\n",
    "        amount = data.draw(st.integers(min_value=1, max_value=10000))\n",
    "        is_credit = data.draw(st.booleans())\n",
    "        transactions.append((amount, is_credit))\n",
    "        \n",
    "        if is_credit:\n",
    "            db_session.execute(\n",
    "                text(\"INSERT INTO transactions (account_id, amount, type) VALUES (:id, :amt, 'credit')\"),\n",
    "                {\"id\": account_id, \"amt\": amount}\n",
    "            )\n",
    "        else:\n",
    "            db_session.execute(\n",
    "                text(\"INSERT INTO transactions (account_id, amount, type) VALUES (:id, :amt, 'debit')\"),\n",
    "                {\"id\": account_id, \"amt\": amount}\n",
    "            )\n",
    "    \n",
    "    # Calculate expected balance\n",
    "    credits = sum(amt for amt, is_cred in transactions if is_cred)\n",
    "    debits = sum(amt for amt, is_cred in transactions if not is_cred)\n",
    "    expected_balance = credits - debits\n",
    "    \n",
    "    # Query database view or function\n",
    "    actual_balance = db_session.execute(\n",
    "        text(\"SELECT get_account_balance(:id)\"),\n",
    "        {\"id\": account_id}\n",
    "    ).scalar()\n",
    "    \n",
    "    # Invariant must hold\n",
    "    assert actual_balance == expected_balance, \\\n",
    "        f\"Balance mismatch: expected {expected_balance}, got {actual_balance}\"\n",
    "```\n",
    "\n",
    "### 46.3.3 Edge Case Discovery\n",
    "\n",
    "Property-based testing excels at finding boundary conditions.\n",
    "\n",
    "```python\n",
    "# Discovering SQL injection vulnerabilities or parsing edge cases\n",
    "@given(st.text(alphabet=st.characters(whitelist_categories=('L', 'N')), min_size=0, max_size=100))\n",
    "def test_safe_string_handling(db_session, input_string):\n",
    "    \"\"\"\n",
    "    Property: String inputs should never cause SQL errors or \n",
    "    unexpected behavior (fuzzing test)\n",
    "    \"\"\"\n",
    "    # Test that function handles any string safely\n",
    "    try:\n",
    "        result = db_session.execute(\n",
    "            text(\"SELECT safe_slugify(:input)\"),\n",
    "            {\"input\": input_string}\n",
    "        ).scalar()\n",
    "        \n",
    "        # Property: Result should be lowercase and contain only safe chars\n",
    "        assert result.islower() or result == \"\"\n",
    "        assert all(c.isalnum() or c == '-' for c in result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Only acceptable exception is our custom validation error\n",
    "        assert \"Invalid input\" in str(e), f\"Unexpected error for input '{input_string}': {e}\"\n",
    "\n",
    "@given(st.lists(st.integers(), min_size=0, max_size=1000))\n",
    "def test_median_calculation(db_session, numbers):\n",
    "    \"\"\"\n",
    "    Property: Median of sorted list should equal median of unsorted list\n",
    "    \"\"\"\n",
    "    if not numbers:\n",
    "        return  # Skip empty list edge case\n",
    "        \n",
    "    # Insert into temp table\n",
    "    for num in numbers:\n",
    "        db_session.execute(text(\"INSERT INTO temp_numbers (val) VALUES (:v)\"), {\"v\": num})\n",
    "    \n",
    "    # Calculate via SQL\n",
    "    sql_median = db_session.execute(\n",
    "        text(\"SELECT percentile_cont(0.5) WITHIN GROUP (ORDER BY val) FROM temp_numbers\")\n",
    "    ).scalar()\n",
    "    \n",
    "    # Calculate via Python (reference implementation)\n",
    "    sorted_nums = sorted(numbers)\n",
    "    n = len(sorted_nums)\n",
    "    if n % 2 == 1:\n",
    "        expected_median = sorted_nums[n // 2]\n",
    "    else:\n",
    "        expected_median = (sorted_nums[n // 2 - 1] + sorted_nums[n // 2]) / 2\n",
    "    \n",
    "    assert sql_median == expected_median\n",
    "    \n",
    "    # Cleanup\n",
    "    db_session.execute(text(\"TRUNCATE temp_numbers\"))\n",
    "```\n",
    "\n",
    "## 46.4 Test Data Management and Determinism\n",
    "\n",
    "### 46.4.1 Factory Pattern for Test Data\n",
    "\n",
    "Factories create valid entities with sensible defaults while allowing test-specific overrides.\n",
    "\n",
    "```python\n",
    "# Python implementation with factory_boy\n",
    "import factory\n",
    "from factory import Faker\n",
    "from datetime import datetime\n",
    "\n",
    "class UserFactory(factory.Factory):\n",
    "    class Meta:\n",
    "        model = User  # SQLAlchemy model or dataclass\n",
    "    \n",
    "    user_id = factory.LazyFunction(uuid.uuid4)\n",
    "    email = factory.Sequence(lambda n: f\"user{n}@example.com\")  # Unique per instance\n",
    "    full_name = Faker(\"name\")\n",
    "    created_at = factory.LazyFunction(datetime.utcnow)\n",
    "    status = \"active\"\n",
    "    \n",
    "    # Trait: Specific states\n",
    "    class Params:\n",
    "        admin = factory.Trait(\n",
    "            email=\"admin@example.com\",  # Override sequence\n",
    "            role=\"admin\"\n",
    "        )\n",
    "        deleted = factory.Trait(\n",
    "            deleted_at=datetime.utcnow(),\n",
    "            status=\"deleted\"\n",
    "        )\n",
    "\n",
    "class OrderFactory(factory.Factory):\n",
    "    class Meta:\n",
    "        model = Order\n",
    "    \n",
    "    order_id = factory.LazyFunction(uuid.uuid4)\n",
    "    user = factory.SubFactory(UserFactory)  # Creates user automatically\n",
    "    total_cents = 0  # Will be calculated from items\n",
    "    \n",
    "    @factory.post_generation\n",
    "    def items(self, create, extracted, **kwargs):\n",
    "        \"\"\"Add line items after order creation\"\"\"\n",
    "        if not create:\n",
    "            return\n",
    "        \n",
    "        if extracted:\n",
    "            # Use provided items\n",
    "            for item in extracted:\n",
    "                OrderItemFactory(order=self, **item)\n",
    "        else:\n",
    "            # Create default items\n",
    "            OrderItemFactory(order=self, product_id=\"prod-1\", quantity=1, price_cents=1000)\n",
    "        \n",
    "        # Recalculate total\n",
    "        self.total_cents = sum(\n",
    "            item.quantity * item.price_cents \n",
    "            for item in self.items\n",
    "        )\n",
    "\n",
    "# Usage in tests\n",
    "def test_order_discount(db_session):\n",
    "    # Arrange: Create order with specific items\n",
    "    order = OrderFactory(\n",
    "        items=[\n",
    "            {\"product_id\": \"p1\", \"quantity\": 2, \"price_cents\": 5000},\n",
    "            {\"product_id\": \"p2\", \"quantity\": 1, \"price_cents\": 10000}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Act: Apply 10% discount\n",
    "    apply_discount(order.id, percentage=0.10)\n",
    "    \n",
    "    # Assert: Total should be (20000 - 2000) = 18000 cents\n",
    "    assert order.total_cents == 18000\n",
    "```\n",
    "\n",
    "**SQL-Based Factories (for pure SQL testing):**\n",
    "\n",
    "```sql\n",
    "-- test/factories.sql\n",
    "CREATE OR REPLACE FUNCTION create_test_user(\n",
    "    p_email TEXT DEFAULT NULL,\n",
    "    p_status TEXT DEFAULT 'active',\n",
    "    p_created_at TIMESTAMPTZ DEFAULT NOW()\n",
    ") RETURNS UUID AS $$\n",
    "DECLARE\n",
    "    v_user_id UUID;\n",
    "    v_email TEXT;\n",
    "BEGIN\n",
    "    v_email := COALESCE(p_email, 'test_' || extract(epoch from clock_timestamp()) || '@example.com');\n",
    "    \n",
    "    INSERT INTO users (user_id, email, status, created_at, full_name)\n",
    "    VALUES (\n",
    "        gen_random_uuid(),\n",
    "        v_email,\n",
    "        p_status,\n",
    "        p_created_at,\n",
    "        'Test User ' || extract(epoch from clock_timestamp())\n",
    "    )\n",
    "    RETURNING user_id INTO v_user_id;\n",
    "    \n",
    "    RETURN v_user_id;\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "\n",
    "-- Factory with relationships\n",
    "CREATE OR REPLACE FUNCTION create_test_order(\n",
    "    p_user_id UUID DEFAULT NULL,\n",
    "    p_item_count INT DEFAULT 1,\n",
    "    p_status TEXT DEFAULT 'pending'\n",
    ") RETURNS UUID AS $$\n",
    "DECLARE\n",
    "    v_order_id UUID;\n",
    "    v_user_id UUID;\n",
    "    v_total INT := 0;\n",
    "    i INT;\n",
    "BEGIN\n",
    "    -- Create user if not provided\n",
    "    v_user_id := COALESCE(p_user_id, create_test_user());\n",
    "    \n",
    "    -- Create order\n",
    "    INSERT INTO orders (order_id, user_id, status, total_cents)\n",
    "    VALUES (gen_random_uuid(), v_user_id, p_status, 0)\n",
    "    RETURNING order_id INTO v_order_id;\n",
    "    \n",
    "    -- Create line items\n",
    "    FOR i IN 1..p_item_count LOOP\n",
    "        INSERT INTO order_items (order_id, product_id, quantity, price_cents)\n",
    "        VALUES (v_order_id, 'prod-' || i, 1, 1000 * i);\n",
    "        \n",
    "        v_total := v_total + (1000 * i);\n",
    "    END LOOP;\n",
    "    \n",
    "    -- Update order total\n",
    "    UPDATE orders SET total_cents = v_total WHERE order_id = v_order_id;\n",
    "    \n",
    "    RETURN v_order_id;\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "```\n",
    "\n",
    "### 46.4.2 Deterministic Data for Reproducible Tests\n",
    "\n",
    "Non-deterministic tests (flaky tests) often result from random data generation without fixed seeds or time mocking.\n",
    "\n",
    "```python\n",
    "# Ensure determinism with frozen time and fixed seeds\n",
    "import pytest\n",
    "from freezegun import freeze_time\n",
    "import faker\n",
    "\n",
    "@pytest.fixture\n",
    "def deterministic_factory():\n",
    "    \"\"\"Factory with fixed seed for reproducible tests\"\"\"\n",
    "    fake = faker.Faker()\n",
    "    fake.seed_instance(12345)  # Fixed seed\n",
    "    \n",
    "    # Reset sequences\n",
    "    UserFactory.reset_sequence(1000)\n",
    "    \n",
    "    return fake\n",
    "\n",
    "@freeze_time(\"2024-01-15 12:00:00\")  # Freeze time for all tests in module\n",
    "def test_order_timestamp(deterministic_factory):\n",
    "    # Time is frozen at 2024-01-15 12:00:00\n",
    "    order = OrderFactory()\n",
    "    \n",
    "    assert order.created_at.isoformat() == \"2024-01-15T12:00:00\"\n",
    "    \n",
    "    # Faker produces same \"random\" data every run\n",
    "    user = UserFactory()\n",
    "    assert user.full_name == \"John Smith\"  # Always same with seed 12345\n",
    "```\n",
    "\n",
    "**Database Sequences in Tests:**\n",
    "\n",
    "```sql\n",
    "-- Ensure predictable IDs for assertions\n",
    "ALTER SEQUENCE users_user_id_seq RESTART WITH 100000;\n",
    "ALTER SEQUENCE orders_order_id_seq RESTART WITH 100000;\n",
    "\n",
    "-- In test setup, always reset sequences\n",
    "CREATE OR REPLACE FUNCTION reset_test_sequences()\n",
    "RETURNS void AS $$\n",
    "BEGIN\n",
    "    PERFORM setval('users_user_id_seq', 100000, false);\n",
    "    PERFORM setval('orders_order_id_seq', 100000, false);\n",
    "    PERFORM setval('products_product_id_seq', 100000, false);\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "```\n",
    "\n",
    "### 46.4.3 Reference Data and Lookup Tables\n",
    "\n",
    "Static reference data (enums, country codes, tax rates) should be loaded once per test suite, not per test.\n",
    "\n",
    "```yaml\n",
    "# test/fixtures/reference-data.yml\n",
    "user_roles:\n",
    "  - role_name: admin\n",
    "    permissions: [\"read\", \"write\", \"delete\"]\n",
    "  - role_name: user  \n",
    "    permissions: [\"read\", \"write\"]\n",
    "  - role_name: guest\n",
    "    permissions: [\"read\"]\n",
    "\n",
    "tax_rates:\n",
    "  - region: US-CA\n",
    "    rate: 0.0825\n",
    "  - region: US-NY\n",
    "    rate: 0.08875\n",
    "  - region: US-TX\n",
    "    rate: 0.0625\n",
    "```\n",
    "\n",
    "```python\n",
    "# conftest.py - Load once per session\n",
    "@pytest.fixture(scope=\"session\", autouse=True)\n",
    "def load_reference_data(postgres_container):\n",
    "    \"\"\"Load reference data once for all tests\"\"\"\n",
    "    engine = create_engine(postgres_container.get_connection_url())\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        # Load roles\n",
    "        for role in REFERENCE_DATA[\"user_roles\"]:\n",
    "            conn.execute(\n",
    "                text(\"INSERT INTO user_roles (role_name, permissions) VALUES (:name, :perms)\"),\n",
    "                {\"name\": role[\"role_name\"], \"perms\": json.dumps(role[\"permissions\"])}\n",
    "            )\n",
    "        conn.commit()\n",
    "    \n",
    "    yield\n",
    "    \n",
    "    # Cleanup after session (optional)\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"TRUNCATE user_roles CASCADE\"))\n",
    "        conn.commit()\n",
    "```\n",
    "\n",
    "## 46.5 CI/CD Integration and Automation\n",
    "\n",
    "### 46.5.1 Parallel Test Execution\n",
    "\n",
    "Modern CI/CD requires parallel test execution while maintaining database isolation.\n",
    "\n",
    "```yaml\n",
    "# .github/workflows/test.yml (GitHub Actions)\n",
    "name: Database Tests\n",
    "\n",
    "on: [push, pull_request]\n",
    "\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "    strategy:\n",
    "      matrix:\n",
    "        # Parallelize by test category\n",
    "        test-group: [unit, integration, property]\n",
    "        postgres-version: [14, 15, 16]\n",
    "    \n",
    "    services:\n",
    "      postgres:\n",
    "        image: postgres:${{ matrix.postgres-version }}-alpine\n",
    "        env:\n",
    "          POSTGRES_PASSWORD: postgres\n",
    "          POSTGRES_DB: test_db\n",
    "        options: >-\n",
    "          --health-cmd pg_isready\n",
    "          --health-interval 10s\n",
    "          --health-timeout 5s\n",
    "          --health-retries 5\n",
    "        ports:\n",
    "          - 5432:5432\n",
    "\n",
    "    steps:\n",
    "      - uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Setup Python\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: '3.11'\n",
    "          \n",
    "      - name: Install dependencies\n",
    "        run: pip install -r requirements.txt\n",
    "        \n",
    "      - name: Run migrations\n",
    "        env:\n",
    "          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db\n",
    "        run: alembic upgrade head\n",
    "        \n",
    "      - name: Run tests (${{ matrix.test-group }})\n",
    "        env:\n",
    "          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db\n",
    "          TEST_GROUP: ${{ matrix.test-group }}\n",
    "        run: pytest -m ${{ matrix.test-group }} --parallel-threads=4\n",
    "        \n",
    "      - name: Upload coverage\n",
    "        uses: codecov/codecov-action@v3\n",
    "```\n",
    "\n",
    "**Test Tagging for Parallelization:**\n",
    "\n",
    "```python\n",
    "# Mark tests by type and speed\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.unit\n",
    "@pytest.mark.fast  # < 100ms\n",
    "def test_calculate_tax():\n",
    "    pass\n",
    "\n",
    "@pytest.mark.integration\n",
    "@pytest.mark.slow  # > 1s\n",
    "def test_payment_gateway_integration():\n",
    "    pass\n",
    "\n",
    "@pytest.mark.property\n",
    "def test_idempotency_invariant():\n",
    "    pass\n",
    "\n",
    "# Run commands:\n",
    "# pytest -m \"unit and fast\"        # Pre-commit hooks\n",
    "# pytest -m \"integration\"          # PR validation\n",
    "# pytest -m \"not slow\"             # Developer feedback loop\n",
    "# pytest -m \"property\"             # Nightly builds\n",
    "```\n",
    "\n",
    "### 46.5.2 Database Migration Testing\n",
    "\n",
    "Test migrations forward and backward to ensure deploy safety.\n",
    "\n",
    "```python\n",
    "# test_migrations.py\n",
    "import pytest\n",
    "from alembic.config import Config\n",
    "from alembic import command\n",
    "from sqlalchemy import create_engine, inspect\n",
    "\n",
    "def test_migrations_up_down():\n",
    "    \"\"\"Verify all migrations can upgrade and downgrade\"\"\"\n",
    "    alembic_cfg = Config(\"alembic.ini\")\n",
    "    \n",
    "    # Upgrade to head\n",
    "    command.upgrade(alembic_cfg, \"head\")\n",
    "    \n",
    "    # Verify schema objects exist\n",
    "    engine = create_engine(TEST_DATABASE_URL)\n",
    "    inspector = inspect(engine)\n",
    "    assert \"users\" in inspector.get_table_names()\n",
    "    \n",
    "    # Downgrade to base\n",
    "    command.downgrade(alembic_cfg, \"base\")\n",
    "    \n",
    "    # Verify clean state\n",
    "    assert len(inspector.get_table_names()) == 0\n",
    "\n",
    "def test_migration_idempotency():\n",
    "    \"\"\"Running migration twice should not fail\"\"\"\n",
    "    alembic_cfg = Config(\"alembic.ini\")\n",
    "    \n",
    "    command.upgrade(alembic_cfg, \"head\")\n",
    "    command.downgrade(alembic_cfg, \"-1\")  # Down one\n",
    "    command.upgrade(alembic_cfg, \"+1\")   # Up one (same migration)\n",
    "    # Should not raise error\n",
    "```\n",
    "\n",
    "### 46.5.3 Performance Regression Testing\n",
    "\n",
    "Prevent performance degradation via automated query timing assertions.\n",
    "\n",
    "```python\n",
    "# test_performance.py\n",
    "import pytest\n",
    "import time\n",
    "from sqlalchemy import text\n",
    "\n",
    "@pytest.mark.performance\n",
    "def test_critical_query_performance(db_session):\n",
    "    \"\"\"Ensure critical queries meet SLA\"\"\"\n",
    "    \n",
    "    # Warmup (caching)\n",
    "    db_session.execute(text(\"SELECT * FROM large_table WHERE status = 'active'\")).fetchall()\n",
    "    \n",
    "    # Time the query\n",
    "    start = time.perf_counter()\n",
    "    result = db_session.execute(\n",
    "        text(\"\"\"\n",
    "            SELECT u.email, COUNT(o.order_id) as order_count\n",
    "            FROM users u\n",
    "            LEFT JOIN orders o ON u.user_id = o.user_id\n",
    "            WHERE u.status = 'active'\n",
    "            GROUP BY u.user_id, u.email\n",
    "            HAVING COUNT(o.order_id) > 10\n",
    "        \"\"\")\n",
    "    ).fetchall()\n",
    "    duration = time.perf_counter() - start\n",
    "    \n",
    "    # Assert performance SLA (100ms for this query)\n",
    "    assert duration < 0.1, f\"Query took {duration}s, expected < 0.1s\"\n",
    "    \n",
    "    # Assert explain plan uses index\n",
    "    explain = db_session.execute(\n",
    "        text(\"EXPLAIN (FORMAT JSON) SELECT ...\")  # Same query\n",
    "    ).scalar()\n",
    "    \n",
    "    plan = json.loads(explain)[0][\"Plan\"]\n",
    "    assert plan[\"Node Type\"] != \"Seq Scan\", \"Query should not use sequential scan\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary\n",
    "\n",
    "In this chapter, you learned:\n",
    "\n",
    "1. **Unit Testing with pgTAP**: Install the pgTAP extension to write xUnit-style tests directly in SQL; test functions with `is()` and `throws_ok()`; validate schema objects with `has_table()` and `has_index()`; always wrap tests in transactions that roll back to maintain isolation.\n",
    "\n",
    "2. **Integration Testing Patterns**: Use Testcontainers to spin up ephemeral PostgreSQL instances for true integration tests without mocks; implement transaction rollback strategies for sub-millisecond test execution; choose cleaning strategies (truncate vs recreate) based on test type and DDL requirements.\n",
    "\n",
    "3. **Property-Based Testing**: Generate thousands of random inputs using Hypothesis or similar frameworks to discover edge cases; test invariants (e.g., \"balance equals credits minus debits\") rather than specific examples; fuzz test string inputs to prevent SQL injection vulnerabilities.\n",
    "\n",
    "4. **Test Data Management**: Implement Factory patterns with sensible defaults and trait overrides (e.g., `admin=True`, `deleted=True`); ensure determinism via fixed random seeds, frozen timestamps, and reset database sequences; load reference data once per test session rather than per test.\n",
    "\n",
    "5. **CI/CD Integration**: Run tests in parallel using matrix strategies with isolated database services per job; tag tests by speed (`fast` vs `slow`) and type (`unit`, `integration`, `property`) to optimize feedback loops; test migrations both up and down to ensure deploy safety; implement performance regression tests with execution time SLAs and execution plan validation.\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** In Chapter 47, we will explore CI/CD for Databasesâ€”covering migration checks in CI pipelines, SQL linting and formatting, drift detection strategies, and release playbooks that ensure zero-downtime deployments with safe rollback procedures."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
