{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 33: Streaming Replication (Physical)\n",
    "\n",
    "Streaming replication provides high availability and read scaling by maintaining one or more standby servers that continuously apply changes from the primary. This chapter covers the architecture, configuration, and operational procedures for robust physical replication, emphasizing the critical tradeoffs between consistency, availability, and performance that define production replication topologies.\n",
    "\n",
    "---\n",
    "\n",
    "## 33.1 Replication Architecture Fundamentals\n",
    "\n",
    "### 33.1.1 Primary-Standby Concepts\n",
    "\n",
    "PostgreSQL physical replication operates on a single-primary, multi-standby model where the primary server streams Write-Ahead Log (WAL) records to standby servers.\n",
    "\n",
    "**Core Components**:\n",
    "- **Primary**: The read-write source of truth; generates WAL\n",
    "- **Standby**: Read-only replica; applies WAL via startup process\n",
    "- **WAL Sender**: Primary process that transmits WAL to standbys\n",
    "- **WAL Receiver**: Standby process that receives and writes WAL to disk\n",
    "- **Startup Process**: Standby process that replays WAL into the database\n",
    "\n",
    "**Replication Flow**:\n",
    "```\n",
    "Primary: INSERT → WAL Record → WAL Sender → Network → WAL Receiver → pg_wal/ → Startup Process → Data Files\n",
    "```\n",
    "\n",
    "### 33.1.2 Hot Standby vs Warm Standby\n",
    "\n",
    "**Hot Standby** (Production Standard):\n",
    "```ini\n",
    "# postgresql.conf on standby\n",
    "hot_standby = on\n",
    "```\n",
    "- Accepts read-only queries while applying replication\n",
    "- Requires `wal_level = replica` or higher on primary\n",
    "- May see replication lag (slight delay between primary commit and standby visibility)\n",
    "\n",
    "**Warm Standby**:\n",
    "```ini\n",
    "hot_standby = off  # Default before recovery completes\n",
    "```\n",
    "- Does not accept connections during recovery\n",
    "- Used for disaster recovery only, not read scaling\n",
    "- Slightly faster WAL application (no query conflict resolution)\n",
    "\n",
    "### 33.1.3 WAL Shipping vs Streaming\n",
    "\n",
    "**WAL Shipping** (Archive-based):\n",
    "- Standby restores from `restore_command` (files copied from archive)\n",
    "- Delayed by archive interval (typically minutes)\n",
    "- Used as fallback when streaming disconnects\n",
    "\n",
    "**Streaming Replication** (Real-time):\n",
    "- Direct TCP connection between primary and standby\n",
    "- Synchronous or asynchronous\n",
    "- Near-real-time lag (milliseconds to seconds)\n",
    "\n",
    "**Hybrid Mode** (Industry Standard):\n",
    "```ini\n",
    "# Standby configuration\n",
    "restore_command = 'cp /archive/%f %p'  # Fallback\n",
    "primary_conninfo = 'host=primary.internal port=5432 user=repl_user ...'  # Streaming\n",
    "```\n",
    "- Uses streaming when connected\n",
    "- Falls back to WAL shipping if network interrupted\n",
    "- Ensures zero data loss during temporary network partitions (if archiving configured)\n",
    "\n",
    "---\n",
    "\n",
    "## 33.2 Primary Server Configuration\n",
    "\n",
    "### 33.2.1 WAL Level and Replication Parameters\n",
    "\n",
    "```ini\n",
    "# postgresql.conf on PRIMARY\n",
    "\n",
    "# 1. WAL Generation (requires restart)\n",
    "wal_level = replica          # Minimum for physical replication\n",
    "                             # 'replica' = supports archiving and hot standby\n",
    "                             # 'logical' = adds logical decoding (more WAL volume)\n",
    "\n",
    "# 2. Connection Slots\n",
    "max_wal_senders = 10         # Maximum concurrent replication connections\n",
    "                             # Count: 1 per standby + 1 per pg_basebackup + headroom\n",
    "\n",
    "max_replication_slots = 10   # Maximum replication slots (must be >= max_wal_senders)\n",
    "\n",
    "# 3. WAL Retention\n",
    "wal_keep_size = 1GB          # Minimum WAL to retain for streaming connections (PG13+)\n",
    "                             # Prevents deletion of WAL still needed by lagging standby\n",
    "                             # Previously wal_keep_segments in PG12 and earlier\n",
    "\n",
    "# 4. Archive Mode (optional but recommended for PITR and as safety net)\n",
    "archive_mode = on\n",
    "archive_command = 'test ! -f /archive/%f && cp %p /archive/%f'\n",
    "                             # Or use wal-g, pgbackrest, etc.\n",
    "\n",
    "# 5. Checkpointing (balance between recovery time and I/O)\n",
    "checkpoint_timeout = 10min\n",
    "max_wal_size = 4GB\n",
    "checkpoint_completion_target = 0.9\n",
    "```\n",
    "\n",
    "### 33.2.2 Replication User Creation\n",
    "\n",
    "**Security Principle**: Dedicated replication user with minimal privileges.\n",
    "\n",
    "```sql\n",
    "-- On PRIMARY\n",
    "CREATE USER replicator WITH REPLICATION ENCRYPTED PASSWORD 'cryptographically_random_string';\n",
    "\n",
    "-- Do NOT grant superuser or createdb\n",
    "-- REPLICATION privilege allows:\n",
    "-- - Streaming replication connections\n",
    "-- - pg_basebackup\n",
    "-- - pg_dump with --snapshot\n",
    "-- - pg_start_backup/pg_stop_backup\n",
    "\n",
    "-- Optional: Connection limit to prevent resource exhaustion\n",
    "ALTER USER replicator WITH CONNECTION LIMIT 5;\n",
    "```\n",
    "\n",
    "**pg_hba.conf Entries**:\n",
    "```conf\n",
    "# Replication connections (hostssl mandatory for production)\n",
    "hostssl replication replicator 10.0.2.0/24 scram-sha-256\n",
    "\n",
    "# Specific standby IPs (more secure)\n",
    "hostssl replication replicator 10.0.2.10/32 scram-sha-256  # standby-1\n",
    "hostssl replication replicator 10.0.2.11/32 scram-sha-256  # standby-2\n",
    "\n",
    "# Never allow replication from 0.0.0.0/0 (wildcards)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 33.3 Standby Server Setup\n",
    "\n",
    "### 33.3.1 Initial Base Backup\n",
    "\n",
    "The standby begins as a byte-for-byte copy of the primary.\n",
    "\n",
    "```bash\n",
    "# On STANDBY server as postgres user\n",
    "\n",
    "# 1. Create data directory\n",
    "mkdir -p /var/lib/postgresql/16/main\n",
    "chown postgres:postgres /var/lib/postgresql/16/main\n",
    "chmod 700 /var/lib/postgresql/16/main\n",
    "\n",
    "# 2. Execute pg_basebackup from standby machine\n",
    "pg_basebackup \\\n",
    "    -h primary.internal \\\n",
    "    -p 5432 \\\n",
    "    -U replicator \\\n",
    "    -D /var/lib/postgresql/16/main \\\n",
    "    -Fp \\                      # Plain format (files as-is)\n",
    "    -Xs \\                      # Stream WAL during backup (essential)\n",
    "    -P \\                       # Progress bar\n",
    "    -v \\                       # Verbose\n",
    "    -W \\                       # Force password prompt (or use .pgpass)\n",
    "    --checkpoint=fast \\        # Immediate checkpoint (don't wait)\n",
    "    --wal-method=stream        # Stream WAL (fetch if PG < 10)\n",
    "\n",
    "# 3. Verify backup_label exists (proves base backup taken)\n",
    "cat /var/lib/postgresql/16/main/backup_label\n",
    "# OUTPUT: START WAL LOCATION: 0/2000028 (file 000000010000000000000002)\n",
    "#         CHECKPOINT LOCATION: 0/2000060\n",
    "#         BACKUP METHOD: streamed\n",
    "#         BACKUP FROM: primary\n",
    "#         START TIME: 2024-10-02 14:30:00 GMT\n",
    "```\n",
    "\n",
    "### 33.3.2 Standby Configuration\n",
    "\n",
    "```ini\n",
    "# postgresql.conf on STANDBY\n",
    "\n",
    "# Connection to primary\n",
    "primary_conninfo = 'host=primary.internal port=5432 user=replicator password=secret sslmode=require application_name=standby_1'\n",
    "\n",
    "# Hot standby for read queries\n",
    "hot_standby = on\n",
    "\n",
    "# Recovery settings\n",
    "restore_command = 'cp /archive/%f %p'  # Fallback if streaming lags\n",
    "\n",
    "# Optional: Delayed replication (disaster recovery protection against operator error)\n",
    "recovery_min_apply_delay = 5min        # Apply WAL 5 minutes after primary\n",
    "                                       # Prevents cascading deletes/corruption to standby immediately\n",
    "```\n",
    "\n",
    "**Standby Signal File** (PostgreSQL 12+):\n",
    "```bash\n",
    "# Create file to indicate this is a standby (not a crashed primary)\n",
    "touch /var/lib/postgresql/16/main/standby.signal\n",
    "\n",
    "# For PostgreSQL 11 and earlier, used recovery.conf (deprecated)\n",
    "```\n",
    "\n",
    "### 33.3.3 Read-Only Workload Tuning\n",
    "\n",
    "Standby servers benefit from different tuning than primaries.\n",
    "\n",
    "```ini\n",
    "# postgresql.conf on STANDBY (read replica)\n",
    "\n",
    "# More aggressive query planning for reporting workloads\n",
    "random_page_cost = 1.1         # Assume SSD/NVMe, encourage index usage\n",
    "effective_cache_size = 24GB    # Adjust to available RAM\n",
    "\n",
    "# Hot standby feedback (prevent query cancellation from cleanup records)\n",
    "hot_standby_feedback = on      # Send feedback to primary about queries in progress\n",
    "                               # Prevents primary from removing dead tuples still needed by standby\n",
    "                               # Tradeoff: May cause bloat on primary if standby has long queries\n",
    "\n",
    "# Max conflict resolution delay\n",
    "max_standby_streaming_delay = 30s    # Cancel queries blocking WAL application after 30s\n",
    "max_standby_archive_delay = 60s      # Same for archive recovery\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 33.4 Synchronous vs Asynchronous Replication\n",
    "\n",
    "### 33.4.1 Asynchronous Replication (Default)\n",
    "\n",
    "**Characteristics**:\n",
    "- Primary commits immediately; WAL streamed asynchronously\n",
    "- Near-zero latency impact on primary\n",
    "- Risk: Recent commits may be lost if primary fails (RPO > 0)\n",
    "- Use case: Read scaling, disaster recovery with acceptable data loss (seconds)\n",
    "\n",
    "```ini\n",
    "# Primary configuration (default)\n",
    "synchronous_commit = on        # Local durability only\n",
    "synchronous_standby_names = '' # Empty = asynchronous\n",
    "```\n",
    "\n",
    "**Monitoring Lag**:\n",
    "```sql\n",
    "-- On PRIMARY: Check replication lag\n",
    "SELECT \n",
    "    client_addr,\n",
    "    state,\n",
    "    sent_lsn,\n",
    "    write_lsn,\n",
    "    flush_lsn,\n",
    "    replay_lsn,\n",
    "    pg_size_pretty(pg_wal_lsn_diff(sent_lsn, replay_lsn)) as replication_lag\n",
    "FROM pg_stat_replication;\n",
    "\n",
    "-- On STANDBY: Check received vs applied\n",
    "SELECT \n",
    "    pg_last_wal_receive_lsn() as received,\n",
    "    pg_last_wal_replay_lsn() as replayed,\n",
    "    pg_wal_lsn_diff(pg_last_wal_receive_lsn(), pg_last_wal_replay_lsn()) as apply_lag_bytes,\n",
    "    pg_last_xact_replay_timestamp() as last_replay_time,\n",
    "    NOW() - pg_last_xact_replay_timestamp() as lag_interval;\n",
    "```\n",
    "\n",
    "### 33.4.2 Synchronous Replication\n",
    "\n",
    "**Characteristics**:\n",
    "- Primary waits for standby confirmation before committing\n",
    "- Zero data loss (RPO = 0) if standby up-to-date at failure\n",
    "- Latency impact: Round-trip time to standby\n",
    "- Risk: If standby fails, primary may halt writes (unless configured with priority)\n",
    "\n",
    "**Configuration Levels**:\n",
    "```ini\n",
    "# postgresql.conf on PRIMARY\n",
    "\n",
    "# Option 1: ANY (quorum commit, PG10+)\n",
    "# Wait for ANY 1 of 2 standbys (majority of 2 is 2, but ANY allows 1)\n",
    "synchronous_standby_names = 'ANY 1 (standby_1, standby_2)'\n",
    "\n",
    "# Option 2: FIRST (priority order)\n",
    "# Wait for first 2 in list (standby_1 preferred, then standby_2)\n",
    "synchronous_standby_names = 'FIRST 2 (standby_1, standby_2)'\n",
    "\n",
    "# Option 3: Single standby (older style)\n",
    "synchronous_standby_names = 'standby_1'\n",
    "\n",
    "# Application choice per transaction (flexible)\n",
    "synchronous_commit = remote_apply  # Strictest: visible on standby\n",
    "# Other options:\n",
    "# - remote_write: Written to standby OS (not fsynced)\n",
    "# - remote_flush: Fsynced on standby (durable but not visible)\n",
    "# - local: Primary only (async for this transaction)\n",
    "```\n",
    "\n",
    "**Application-Level Control**:\n",
    "```sql\n",
    "-- Critical transaction (wait for sync replica)\n",
    "BEGIN;\n",
    "SET LOCAL synchronous_commit = remote_apply;\n",
    "INSERT INTO payments (...) VALUES (...);\n",
    "COMMIT;\n",
    "\n",
    "-- Non-critical transaction (async for speed)\n",
    "BEGIN;\n",
    "SET LOCAL synchronous_commit = local;\n",
    "INSERT INTO logs (...) VALUES (...);\n",
    "COMMIT;\n",
    "```\n",
    "\n",
    "### 33.4.3 Tradeoff Matrix\n",
    "\n",
    "| Mode | Durability | Latency | Availability Risk | Use Case |\n",
    "|------|------------|---------|-------------------|----------|\n",
    "| **async** | Local only | ~1ms | Low | Read replicas, analytics |\n",
    "| **remote_write** | OS cache | ~5-20ms | Medium | Near-sync, minor risk |\n",
    "| **remote_flush** | Disk | ~10-50ms | High | Financial transactions |\n",
    "| **remote_apply** | Visible | ~20-100ms | High | Strict consistency |\n",
    "\n",
    "---\n",
    "\n",
    "## 33.5 Replication Slots and Retention Management\n",
    "\n",
    "### 33.5.1 The Purpose of Replication Slots\n",
    "\n",
    "Replication slots prevent the primary from removing WAL that standby still needs, even during network interruptions.\n",
    "\n",
    "```sql\n",
    "-- On PRIMARY: Create slot for specific standby\n",
    "SELECT pg_create_physical_replication_slot('standby_1_slot', true);\n",
    "-- Second parameter 'true' = immediately_reserve (reserve WAL)\n",
    "\n",
    "-- View slots\n",
    "SELECT \n",
    "    slot_name,\n",
    "    plugin,\n",
    "    slot_type,\n",
    "    database,\n",
    "    active,\n",
    "    restart_lsn,\n",
    "    confirmed_flush_lsn,\n",
    "    pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn)) as retained_wal\n",
    "FROM pg_replication_slots;\n",
    "```\n",
    "\n",
    "### 33.5.2 The Retention Risk (Critical)\n",
    "\n",
    "**Danger**: If a standby with a slot goes offline permanently, the primary retains WAL indefinitely, causing disk space exhaustion.\n",
    "\n",
    "**Monitoring**:\n",
    "```sql\n",
    "-- Alert if retained WAL > 50GB\n",
    "SELECT \n",
    "    slot_name,\n",
    "    active,\n",
    "    pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn) as lag_bytes\n",
    "FROM pg_replication_slots\n",
    "WHERE pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn) > 53687091200;  -- 50GB\n",
    "```\n",
    "\n",
    "**Mitigation Strategies**:\n",
    "```sql\n",
    "-- 1. Set max_slot_wal_keep_size (PG13+) to limit retention\n",
    "-- Primary will remove WAL even if slot needs it (breaks replication, prevents disk full)\n",
    "max_slot_wal_keep_size = '100GB'  -- Drop replication rather than fill disk\n",
    "\n",
    "-- 2. Monitor and drop dead slots\n",
    "SELECT pg_drop_replication_slot('standby_1_slot');\n",
    "-- Only drop if standby permanently decommissioned\n",
    "\n",
    "-- 3. Use temporary slots (auto-drop on disconnect)\n",
    "-- In pg_basebackup or connection string: -S slotname --create-slot --slot-name=temporary\n",
    "```\n",
    "\n",
    "### 33.5.3 Slot Synchronization\n",
    "\n",
    "When promoting a standby, it inherits slots from primary (if using `pg_basebackup` with `--slot`).\n",
    "\n",
    "```sql\n",
    "-- After failover, old primary may have slots that should be recreated on new primary\n",
    "-- Check for inactive slots consuming space\n",
    "SELECT * FROM pg_replication_slots WHERE NOT active;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 33.6 Failover Basics and Caveats\n",
    "\n",
    "### 33.6.1 Manual Failover Procedure\n",
    "\n",
    "**Scenario**: Primary is down; promote standby.\n",
    "\n",
    "```bash\n",
    "# On STANDBY (to be promoted)\n",
    "# Step 1: Verify replication lag is acceptable (near 0)\n",
    "psql -c \"SELECT pg_wal_lsn_diff(pg_last_wal_receive_lsn(), pg_last_wal_replay_lsn());\"\n",
    "# Should return 0 or small number\n",
    "\n",
    "# Step 2: Prevent further connections (graceful)\n",
    "pg_ctl stop -m fast -D /var/lib/postgresql/16/main\n",
    "# Or if primary is truly dead, skip\n",
    "\n",
    "# Step 3: Promote standby to primary\n",
    "pg_ctl promote -D /var/lib/postgresql/16/main\n",
    "# Or: SELECT pg_promote();\n",
    "\n",
    "# Step 4: Verify promotion\n",
    "psql -c \"SELECT pg_is_in_recovery();\"  # Should return 'f' (false)\n",
    "```\n",
    "\n",
    "### 33.6.2 The Split-Brain Risk\n",
    "\n",
    "**Critical Danger**: If the old primary comes back online after failover, you have two primaries (split-brain), causing data divergence.\n",
    "\n",
    "**Prevention**:\n",
    "```bash\n",
    "# On old primary (before bringing back), ensure it cannot accept writes:\n",
    "# Option 1: Start in recovery mode (as new standby)\n",
    "touch /var/lib/postgresql/16/main/standby.signal\n",
    "# Configure primary_conninfo to point to new primary\n",
    "\n",
    "# Option 2: Use fencing (STONITH - Shoot The Other Node In The Head)\n",
    "# AWS: Detach EBS volumes, terminate instance\n",
    "# VMware: Power off VM\n",
    "# Physical: IPMI power off\n",
    "```\n",
    "\n",
    "### 33.6.3 Timeline Divergence\n",
    "\n",
    "Each promotion creates a new timeline to prevent old primaries from confusing the cluster.\n",
    "\n",
    "```bash\n",
    "# Check current timeline\n",
    "psql -c \"SELECT timeline_id FROM pg_control_checkpoint();\"\n",
    "\n",
    "# WAL file naming includes timeline: TTTTTTTTXXXXXXXXYYYYYYYY\n",
    "# 00000002.history contains fork point from timeline 1\n",
    "```\n",
    "\n",
    "**Recovery**: If old primary is started accidentally and diverges, you must:\n",
    "1. Resync from new primary using `pg_basebackup`, OR\n",
    "2. Use `pg_rewind` if divergence is small (rewinds data files to match new primary)\n",
    "\n",
    "```bash\n",
    "# pg_rewind (requires wal_log_hints = on in primary config)\n",
    "pg_rewind \\\n",
    "    --target-pgdata=/var/lib/postgresql/16/main \\\n",
    "    --source-server='host=new_primary.internal port=5432 user=postgres' \\\n",
    "    --write-recovery-conf\n",
    "# Rewinds old primary to match new primary, allowing it to become standby\n",
    "```\n",
    "\n",
    "### 33.6.4 Automated Failover Tools\n",
    "\n",
    "Manual failover takes minutes. For RTO < 60 seconds, use:\n",
    "\n",
    "- **Patroni**: Python-based HA template with etcd/ZooKeeper/Consul\n",
    "- **repmgr**: Replication manager with automatic failover\n",
    "- **pg_auto_failover**: Official Microsoft/PostgreSQL extension\n",
    "- **Stolon**: Cloud-native PostgreSQL HA (Kubernetes)\n",
    "\n",
    "**Caution**: Automated failover without proper fencing and health checks causes more outages than it prevents. Implement only after thorough testing.\n",
    "\n",
    "---\n",
    "\n",
    "## 33.7 Monitoring and Maintenance\n",
    "\n",
    "### 33.7.1 Critical Replication Metrics\n",
    "\n",
    "```sql\n",
    "-- Replication lag in human-readable format\n",
    "SELECT \n",
    "    client_addr,\n",
    "    application_name,\n",
    "    state,\n",
    "    pg_size_pretty(pg_wal_lsn_diff(sent_lsn, replay_lsn)) as lag_size,\n",
    "    EXTRACT(EPOCH FROM (now() - backend_start)) as connected_seconds\n",
    "FROM pg_stat_replication;\n",
    "\n",
    "-- Check for replication conflicts (queries blocking WAL replay)\n",
    "SELECT \n",
    "    datname,\n",
    "    usename,\n",
    "    application_name,\n",
    "    client_addr,\n",
    "    state,\n",
    "    sync_state\n",
    "FROM pg_stat_replication\n",
    "WHERE sync_state = 'async'  -- Monitor async standbys for lag spikes\n",
    "ORDER BY sent_lsn - replay_lsn DESC;\n",
    "```\n",
    "\n",
    "### 33.7.2 Handling Replication Conflicts\n",
    "\n",
    "Hot standby may cancel queries if they conflict with WAL replay (e.g., accessing rows being modified by replay).\n",
    "\n",
    "```sql\n",
    "-- Check for conflicts\n",
    "SELECT \n",
    "    datname,\n",
    "    conflicts,\n",
    "    pg_stat_database.conflicts_snapshot,\n",
    "    pg_stat_database.conflicts_bufferpin,\n",
    "    pg_stat_database.conflicts_deadlock\n",
    "FROM pg_stat_database\n",
    "WHERE datname = 'production';\n",
    "\n",
    "-- Reduce conflicts:\n",
    "-- 1. hot_standby_feedback = on (in standby postgresql.conf)\n",
    "-- 2. Increase max_standby_streaming_delay (allow longer locks)\n",
    "-- 3. Avoid long-running queries on standbys during heavy write periods\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary\n",
    "\n",
    "In this chapter, you learned:\n",
    "\n",
    "1. **Physical Replication Architecture**: Primary generates WAL; standbys apply via startup process. Streaming provides near-real-time replication, while WAL shipping provides resilience against network partitions. Configure `wal_level = replica` and dedicated `replicator` users restricted by `pg_hba.conf` to specific standby IPs.\n",
    "\n",
    "2. **Standby Setup**: Use `pg_basebackup` with `-Xs` (stream WAL) to initialize standbys. Create `standby.signal` file to indicate recovery mode. Configure `primary_conninfo` with SSL requirements and `hot_standby = on` for read replicas.\n",
    "\n",
    "3. **Synchronous vs Asynchronous**: Asynchronous replication (default) offers minimal latency but risks data loss (RPO > 0). Synchronous replication with `synchronous_commit = remote_flush` or `remote_apply` guarantees zero data loss but adds latency (network round-trip) and availability risk (primary stalls if standby fails). Use `ANY 1 (standby_1, standby_2)` quorum commit for balance.\n",
    "\n",
    "4. **Replication Slots**: Slots (`pg_create_physical_replication_slot`) prevent WAL removal needed by standbys, but create disk space risk if standby disconnects permanently. Set `max_slot_wal_keep_size` to prevent disk exhaustion, monitor `pg_replication_slots` for inactive slots, and drop slots only when standbys are permanently decommissioned.\n",
    "\n",
    "5. **Failover Procedures**: Promote standby with `pg_ctl promote` or `SELECT pg_promote()`. Always fence the old primary (power off or reconfigure as standby) to prevent split-brain. Use `pg_rewind` to resync diverged old primaries if `wal_log_hints` was enabled, otherwise require full `pg_basebackup` resync.\n",
    "\n",
    "6. **Operational Safety**: Monitor replication lag via `pg_stat_replication` and `pg_stat_wal_receiver`. Use `hot_standby_feedback` to reduce query conflicts but watch for primary bloat. Never let replication lag exceed `wal_keep_size` or slot retention limits, or standby will require reinitialization.\n",
    "\n",
    "**Next**: In Chapter 34, we will cover Logical Replication—exploring publication/subscription mechanics, selective data replication, conflict handling for multi-master scenarios, and use cases for zero-downtime migrations and data warehousing."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
