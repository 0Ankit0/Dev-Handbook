{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 67: Infrastructure as Code\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Understand the concept of Infrastructure as Code (IaC) and its benefits for managing ML systems\n",
    "- Distinguish between declarative and imperative infrastructure management\n",
    "- Use Terraform to define and provision cloud resources for the NEPSE prediction system\n",
    "- Write CloudFormation templates for AWS resources\n",
    "- Automate server configuration with Ansible\n",
    "- Define Kubernetes resources using YAML manifests and manage them with Helm charts\n",
    "- Store IaC definitions in Git and integrate with CI/CD pipelines\n",
    "- Manage secrets securely using tools like HashiCorp Vault or cloud secrets managers\n",
    "- Apply best practices for IaC: modularity, versioning, state management, and testing\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In earlier chapters, we deployed the NEPSE prediction system on various cloud platforms, manually clicking through web consoles or running one‑off scripts. As the system grows—adding more services, environments (dev, staging, prod), and team members—manual management becomes error‑prone, inconsistent, and hard to reproduce. **Infrastructure as Code (IaC)** solves these problems by treating infrastructure the same way we treat application code: defined in files, versioned in Git, tested, and automatically deployed.\n",
    "\n",
    "IaC is the practice of managing and provisioning infrastructure through machine‑readable definition files, rather than physical hardware configuration or interactive configuration tools. It brings several benefits:\n",
    "\n",
    "- **Consistency**: The same configuration can be applied repeatedly, eliminating drift.\n",
    "- **Reproducibility**: Entire environments can be recreated from scratch.\n",
    "- **Versioning**: Infrastructure changes are tracked in Git, enabling rollbacks and audits.\n",
    "- **Automation**: Infrastructure can be provisioned as part of CI/CD pipelines.\n",
    "- **Documentation**: The code itself documents the infrastructure.\n",
    "\n",
    "For the NEPSE system, IaC allows us to define our cloud resources (S3 buckets, databases, Kubernetes clusters) in code, and spin up identical environments for development, testing, and production with a single command.\n",
    "\n",
    "In this chapter, we will explore the main IaC tools and apply them to the NEPSE project. We'll use **Terraform** for cloud resource provisioning, **Kubernetes manifests** for container orchestration, and **Helm** for packaging. We'll also discuss secrets management and best practices.\n",
    "\n",
    "---\n",
    "\n",
    "## 67.1 Infrastructure as Code Fundamentals\n",
    "\n",
    "### 67.1.1 Declarative vs. Imperative\n",
    "\n",
    "- **Declarative** approach: You specify the desired end state, and the tool figures out how to achieve it. Examples: Terraform, CloudFormation, Kubernetes YAML.\n",
    "- **Imperative** approach: You specify step‑by‑step commands to reach the desired state. Examples: shell scripts, Ansible playbooks (though Ansible is declarative in its playbook language, it executes imperatively).\n",
    "\n",
    "Declarative IaC is generally preferred because it is idempotent and easier to reason about.\n",
    "\n",
    "### 67.1.2 Core Concepts\n",
    "\n",
    "- **Resource**: A discrete piece of infrastructure (e.g., an EC2 instance, an S3 bucket).\n",
    "- **Provider**: A plugin that interacts with a cloud API (e.g., AWS, Azure, GCP).\n",
    "- **State**: The current state of your infrastructure as recorded by the tool. Used to plan changes.\n",
    "- **Module**: A reusable group of resources (like a Terraform module or a CloudFormation nested stack).\n",
    "\n",
    "### 67.1.3 IaC in the ML Lifecycle\n",
    "\n",
    "For the NEPSE system, IaC can manage:\n",
    "\n",
    "- **Data storage**: S3 buckets for raw data, processed features, and model artifacts.\n",
    "- **Compute**: SageMaker instances for training, EC2 for batch jobs, EKS for serving.\n",
    "- **Networking**: VPCs, subnets, security groups.\n",
    "- **Databases**: RDS for metadata, Redis for online feature store.\n",
    "- **Serverless functions**: Lambda for lightweight inference.\n",
    "- **CI/CD infrastructure**: Build servers, artifact repositories.\n",
    "\n",
    "All of these can be defined in code and versioned alongside the application code.\n",
    "\n",
    "---\n",
    "\n",
    "## 67.2 Terraform\n",
    "\n",
    "Terraform by HashiCorp is the most popular IaC tool. It uses a declarative language (HCL) and supports many cloud providers.\n",
    "\n",
    "### 67.2.1 Installing Terraform\n",
    "\n",
    "```bash\n",
    "# On macOS\n",
    "brew install terraform\n",
    "\n",
    "# On Linux\n",
    "wget -O- https://apt.releases.hashicorp.com/gpg | gpg --dearmor | sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg\n",
    "echo \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/hashicorp.list\n",
    "sudo apt update && sudo apt install terraform\n",
    "```\n",
    "\n",
    "### 67.2.2 Basic Terraform Configuration for NEPSE\n",
    "\n",
    "Let's create a simple Terraform configuration that sets up an S3 bucket for storing NEPSE data and model artifacts.\n",
    "\n",
    "**File: `main.tf`**\n",
    "\n",
    "```hcl\n",
    "# Configure the AWS provider\n",
    "provider \"aws\" {\n",
    "  region = \"us-east-1\"\n",
    "}\n",
    "\n",
    "# Create an S3 bucket for raw data\n",
    "resource \"aws_s3_bucket\" \"nepse_raw_data\" {\n",
    "  bucket = \"nepse-raw-data-${random_string.suffix.result}\"\n",
    "  acl    = \"private\"\n",
    "\n",
    "  versioning {\n",
    "    enabled = true\n",
    "  }\n",
    "\n",
    "  tags = {\n",
    "    Name        = \"NEPSE Raw Data\"\n",
    "    Environment = \"Production\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# Create an S3 bucket for model artifacts\n",
    "resource \"aws_s3_bucket\" \"nepse_models\" {\n",
    "  bucket = \"nepse-models-${random_string.suffix.result}\"\n",
    "  acl    = \"private\"\n",
    "\n",
    "  versioning {\n",
    "    enabled = true\n",
    "  }\n",
    "\n",
    "  tags = {\n",
    "    Name        = \"NEPSE Models\"\n",
    "    Environment = \"Production\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# Generate a random suffix to ensure globally unique bucket names\n",
    "resource \"random_string\" \"suffix\" {\n",
    "  length  = 8\n",
    "  special = false\n",
    "  upper   = false\n",
    "}\n",
    "\n",
    "# Output the bucket names\n",
    "output \"raw_data_bucket\" {\n",
    "  value = aws_s3_bucket.nepse_raw_data.bucket\n",
    "}\n",
    "\n",
    "output \"models_bucket\" {\n",
    "  value = aws_s3_bucket.nepse_models.bucket\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "- We specify the AWS provider and region.\n",
    "- We define two S3 buckets, each with versioning enabled (important for data and model lineage).\n",
    "- Because S3 bucket names must be globally unique, we use a random suffix generated by the `random_string` resource.\n",
    "- Finally, we output the bucket names so they can be used elsewhere (e.g., in training scripts).\n",
    "\n",
    "### 67.2.3 Initialising and Applying\n",
    "\n",
    "```bash\n",
    "terraform init      # Downloads provider plugins and sets up backend\n",
    "terraform plan      # Shows what changes will be made\n",
    "terraform apply     # Creates the resources (prompts for confirmation)\n",
    "```\n",
    "\n",
    "After applying, Terraform creates a `terraform.tfstate` file that tracks the current state. This file is critical and should be stored remotely for team use (e.g., in an S3 bucket with locking via DynamoDB).\n",
    "\n",
    "### 67.2.4 Remote State Management\n",
    "\n",
    "For teams, store the state file remotely:\n",
    "\n",
    "**File: `backend.tf`**\n",
    "\n",
    "```hcl\n",
    "terraform {\n",
    "  backend \"s3\" {\n",
    "    bucket         = \"my-terraform-state-bucket\"\n",
    "    key            = \"nepse/terraform.tfstate\"\n",
    "    region         = \"us-east-1\"\n",
    "    dynamodb_table = \"terraform-locks\"\n",
    "    encrypt        = true\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "This configures Terraform to store the state in an S3 bucket and use DynamoDB for state locking to prevent concurrent modifications. You must create the S3 bucket and DynamoDB table separately (or bootstrap them with a separate Terraform configuration).\n",
    "\n",
    "### 67.2.5 Modules\n",
    "\n",
    "Terraform modules allow you to package and reuse infrastructure components. For example, we could create a module for a standard NEPSE environment (VPC, subnets, S3 buckets, EKS cluster) and reuse it for dev, staging, and prod.\n",
    "\n",
    "**Example module usage:**\n",
    "\n",
    "```hcl\n",
    "module \"nepse_dev_env\" {\n",
    "  source = \"./modules/nepse_environment\"\n",
    "  environment = \"dev\"\n",
    "  vpc_cidr = \"10.0.0.0/16\"\n",
    "  # ... other variables\n",
    "}\n",
    "```\n",
    "\n",
    "### 67.2.6 Managing Kubernetes with Terraform\n",
    "\n",
    "Terraform can also provision Kubernetes resources via the Kubernetes provider. For example, after creating an EKS cluster, we can deploy our prediction service:\n",
    "\n",
    "```hcl\n",
    "resource \"kubernetes_deployment\" \"nepse_predictor\" {\n",
    "  metadata {\n",
    "    name      = \"nepse-predictor\"\n",
    "    namespace = \"default\"\n",
    "  }\n",
    "\n",
    "  spec {\n",
    "    replicas = 3\n",
    "\n",
    "    selector {\n",
    "      match_labels = {\n",
    "        app = \"nepse-predictor\"\n",
    "      }\n",
    "    }\n",
    "\n",
    "    template {\n",
    "      metadata {\n",
    "        labels = {\n",
    "          app = \"nepse-predictor\"\n",
    "        }\n",
    "      }\n",
    "\n",
    "      spec {\n",
    "        container {\n",
    "          image = \"myregistry/nepse-predictor:v1\"\n",
    "          name  = \"predictor\"\n",
    "          port {\n",
    "            container_port = 8000\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "This Kubernetes deployment manifest is embedded in Terraform HCL. It defines a deployment with three replicas, using the Docker image `myregistry/nepse-predictor:v1`. Terraform will apply this to the cluster if the Kubernetes provider is configured with the correct kubeconfig.\n",
    "\n",
    "---\n",
    "\n",
    "## 67.3 AWS CloudFormation\n",
    "\n",
    "CloudFormation is AWS's native IaC service. Templates are written in JSON or YAML. It is deeply integrated with AWS and supports almost all AWS resources.\n",
    "\n",
    "### 67.3.1 Basic CloudFormation Template\n",
    "\n",
    "**File: `nepse-bucket.yaml`**\n",
    "\n",
    "```yaml\n",
    "AWSTemplateFormatVersion: '2010-09-09'\n",
    "Description: 'NEPSE S3 buckets'\n",
    "\n",
    "Parameters:\n",
    "  Environment:\n",
    "    Type: String\n",
    "    Default: prod\n",
    "    AllowedValues: [dev, staging, prod]\n",
    "\n",
    "Resources:\n",
    "  RawDataBucket:\n",
    "    Type: AWS::S3::Bucket\n",
    "    Properties:\n",
    "      BucketName: !Sub 'nepse-raw-${Environment}-${AWS::AccountId}'\n",
    "      VersioningConfiguration:\n",
    "        Status: Enabled\n",
    "      Tags:\n",
    "        - Key: Name\n",
    "          Value: !Sub 'NEPSE Raw Data ${Environment}'\n",
    "\n",
    "  ModelsBucket:\n",
    "    Type: AWS::S3::Bucket\n",
    "    Properties:\n",
    "      BucketName: !Sub 'nepse-models-${Environment}-${AWS::AccountId}'\n",
    "      VersioningConfiguration:\n",
    "        Status: Enabled\n",
    "      Tags:\n",
    "        - Key: Name\n",
    "          Value: !Sub 'NEPSE Models ${Environment}'\n",
    "\n",
    "Outputs:\n",
    "  RawDataBucketName:\n",
    "    Value: !Ref RawDataBucket\n",
    "  ModelsBucketName:\n",
    "    Value: !Ref ModelsBucket\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "- `Parameters` allow us to pass in the environment name.\n",
    "- `Resources` define the two S3 buckets. The bucket names include the environment and account ID to ensure uniqueness.\n",
    "- `!Sub` is a YAML function that substitutes variables.\n",
    "- `Outputs` export the bucket names for use in other stacks or scripts.\n",
    "\n",
    "### 67.3.2 Deploying with CloudFormation\n",
    "\n",
    "You can deploy via AWS CLI:\n",
    "\n",
    "```bash\n",
    "aws cloudformation deploy \\\n",
    "  --template-file nepse-bucket.yaml \\\n",
    "  --stack-name nepse-storage \\\n",
    "  --parameter-overrides Environment=dev \\\n",
    "  --capabilities CAPABILITY_IAM\n",
    "```\n",
    "\n",
    "CloudFormation manages the state for you, and you can update or delete the stack later.\n",
    "\n",
    "---\n",
    "\n",
    "## 67.4 Ansible\n",
    "\n",
    "Ansible is an automation tool that can configure servers, install software, and deploy applications. It is agentless (uses SSH) and uses YAML playbooks.\n",
    "\n",
    "### 67.4.1 Ansible Playbook for Setting Up a Prediction Server\n",
    "\n",
    "Suppose we have an EC2 instance that will serve our NEPSE model. Ansible can install dependencies, copy the model, and start the service.\n",
    "\n",
    "**File: `nepse-server.yml`**\n",
    "\n",
    "```yaml\n",
    "---\n",
    "- name: Configure NEPSE prediction server\n",
    "  hosts: prediction_servers\n",
    "  become: yes\n",
    "  vars:\n",
    "    model_version: v1.2\n",
    "    repo_url: https://github.com/org/nepse-predictor.git\n",
    "\n",
    "  tasks:\n",
    "    - name: Update apt cache\n",
    "      apt:\n",
    "        update_cache: yes\n",
    "\n",
    "    - name: Install Python and pip\n",
    "      apt:\n",
    "        name:\n",
    "          - python3\n",
    "          - python3-pip\n",
    "          - python3-venv\n",
    "        state: present\n",
    "\n",
    "    - name: Create app directory\n",
    "      file:\n",
    "        path: /opt/nepse\n",
    "        state: directory\n",
    "        owner: ubuntu\n",
    "        group: ubuntu\n",
    "\n",
    "    - name: Clone repository\n",
    "      git:\n",
    "        repo: \"{{ repo_url }}\"\n",
    "        dest: /opt/nepse/app\n",
    "        version: \"{{ model_version }}\"\n",
    "\n",
    "    - name: Create virtual environment\n",
    "      pip:\n",
    "        requirements: /opt/nepse/app/requirements.txt\n",
    "        virtualenv: /opt/nepse/venv\n",
    "        virtualenv_command: python3 -m venv\n",
    "\n",
    "    - name: Copy model file (from S3)\n",
    "      aws_s3:\n",
    "        bucket: nepse-models-prod\n",
    "        object: \"/models/{{ model_version }}/model.pkl\"\n",
    "        dest: /opt/nepse/app/model.pkl\n",
    "        mode: get\n",
    "\n",
    "    - name: Create systemd service\n",
    "      template:\n",
    "        src: nepse-predictor.service.j2\n",
    "        dest: /etc/systemd/system/nepse-predictor.service\n",
    "      notify: restart nepse\n",
    "\n",
    "    - name: Start and enable service\n",
    "      systemd:\n",
    "        name: nepse-predictor\n",
    "        state: started\n",
    "        enabled: yes\n",
    "\n",
    "  handlers:\n",
    "    - name: restart nepse\n",
    "      systemd:\n",
    "        name: nepse-predictor\n",
    "        state: restarted\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "- The playbook runs on hosts in the `prediction_servers` group.\n",
    "- It installs dependencies, clones the code from Git, sets up a virtual environment, downloads the model from S3, and installs a systemd service.\n",
    "- The `template` module uses a Jinja2 template (`nepse-predictor.service.j2`) to generate the service file.\n",
    "- Handlers restart the service if the template changes.\n",
    "\n",
    "Ansible is great for configuration management, but for provisioning cloud resources, Terraform or CloudFormation are more suitable. They are often used together: Terraform provisions the servers, and Ansible configures them.\n",
    "\n",
    "---\n",
    "\n",
    "## 67.5 Kubernetes Manifests\n",
    "\n",
    "For containerised applications (like our NEPSE prediction API), Kubernetes is the de facto orchestration platform. Kubernetes resources are defined in YAML manifests.\n",
    "\n",
    "### 67.5.1 Basic Deployment and Service\n",
    "\n",
    "**File: `nepse-deployment.yaml`**\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: nepse-predictor\n",
    "  labels:\n",
    "    app: nepse-predictor\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: nepse-predictor\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: nepse-predictor\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: predictor\n",
    "        image: myregistry/nepse-predictor:v1.2\n",
    "        ports:\n",
    "        - containerPort: 8000\n",
    "        env:\n",
    "        - name: MODEL_PATH\n",
    "          value: /app/model.pkl\n",
    "        - name: REDIS_HOST\n",
    "          value: redis-service\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"512Mi\"\n",
    "            cpu: \"500m\"\n",
    "          limits:\n",
    "            memory: \"1Gi\"\n",
    "            cpu: \"1000m\"\n",
    "        livenessProbe:\n",
    "          httpGet:\n",
    "            path: /health\n",
    "            port: 8000\n",
    "          initialDelaySeconds: 30\n",
    "          periodSeconds: 10\n",
    "        readinessProbe:\n",
    "          httpGet:\n",
    "            path: /ready\n",
    "            port: 8000\n",
    "          initialDelaySeconds: 5\n",
    "          periodSeconds: 5\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: nepse-predictor\n",
    "spec:\n",
    "  selector:\n",
    "    app: nepse-predictor\n",
    "  ports:\n",
    "    - protocol: TCP\n",
    "      port: 80\n",
    "      targetPort: 8000\n",
    "  type: LoadBalancer\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "- The Deployment defines the desired state: 3 replicas of the container, with resource requests/limits, environment variables, and health probes.\n",
    "- The Service exposes the deployment internally (ClusterIP) or externally (LoadBalancer). Here, we use a LoadBalancer to get a public IP.\n",
    "\n",
    "### 67.5.2 Managing with `kubectl`\n",
    "\n",
    "```bash\n",
    "kubectl apply -f nepse-deployment.yaml\n",
    "```\n",
    "\n",
    "To update the image (e.g., to version v1.3), you can either edit the file and reapply, or use:\n",
    "\n",
    "```bash\n",
    "kubectl set image deployment/nepse-predictor predictor=myregistry/nepse-predictor:v1.3\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 67.6 Helm Charts\n",
    "\n",
    "Helm is a package manager for Kubernetes. It allows you to define, install, and upgrade even the most complex Kubernetes applications as a single unit, called a chart. Charts are reusable and can be versioned.\n",
    "\n",
    "### 67.6.1 Chart Structure\n",
    "\n",
    "A Helm chart has a standard directory layout:\n",
    "\n",
    "```\n",
    "nepse-chart/\n",
    "  Chart.yaml          # Metadata\n",
    "  values.yaml         # Default configuration values\n",
    "  templates/          # Kubernetes manifest templates\n",
    "  templates/deployment.yaml\n",
    "  templates/service.yaml\n",
    "  templates/_helpers.tpl\n",
    "  ...\n",
    "```\n",
    "\n",
    "### 67.6.2 Example `values.yaml`\n",
    "\n",
    "```yaml\n",
    "# Default values for nepse-chart.\n",
    "replicaCount: 3\n",
    "image:\n",
    "  repository: myregistry/nepse-predictor\n",
    "  tag: v1.2\n",
    "  pullPolicy: IfNotPresent\n",
    "\n",
    "service:\n",
    "  type: LoadBalancer\n",
    "  port: 80\n",
    "\n",
    "resources:\n",
    "  requests:\n",
    "    memory: 512Mi\n",
    "    cpu: 500m\n",
    "  limits:\n",
    "    memory: 1Gi\n",
    "    cpu: 1000m\n",
    "\n",
    "env:\n",
    "  MODEL_PATH: /app/model.pkl\n",
    "  REDIS_HOST: redis-service\n",
    "```\n",
    "\n",
    "### 67.6.3 Templated Deployment\n",
    "\n",
    "**File: `templates/deployment.yaml`**\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: {{ include \"nepse-chart.fullname\" . }}\n",
    "  labels:\n",
    "    app.kubernetes.io/name: {{ include \"nepse-chart.name\" . }}\n",
    "    helm.sh/chart: {{ include \"nepse-chart.chart\" . }}\n",
    "spec:\n",
    "  replicas: {{ .Values.replicaCount }}\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app.kubernetes.io/name: {{ include \"nepse-chart.name\" . }}\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app.kubernetes.io/name: {{ include \"nepse-chart.name\" . }}\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: predictor\n",
    "          image: \"{{ .Values.image.repository }}:{{ .Values.image.tag }}\"\n",
    "          imagePullPolicy: {{ .Values.image.pullPolicy }}\n",
    "          ports:\n",
    "            - containerPort: 8000\n",
    "          env:\n",
    "            {{- range $key, $value := .Values.env }}\n",
    "            - name: {{ $key }}\n",
    "              value: {{ $value | quote }}\n",
    "            {{- end }}\n",
    "          resources:\n",
    "            {{- toYaml .Values.resources | nindent 10 }}\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "Helm templates use Go templating. Values from `values.yaml` are injected. This allows the same chart to be used for different environments by overriding values.\n",
    "\n",
    "### 67.6.4 Installing with Helm\n",
    "\n",
    "```bash\n",
    "helm install nepse-prod ./nepse-chart --values prod-values.yaml\n",
    "```\n",
    "\n",
    "To upgrade:\n",
    "\n",
    "```bash\n",
    "helm upgrade nepse-prod ./nepse-chart --values prod-values.yaml\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 67.7 Secrets Management\n",
    "\n",
    "Never store secrets (passwords, API keys) in plain text in your IaC files. Use a secrets management tool.\n",
    "\n",
    "### 67.7.1 HashiCorp Vault\n",
    "\n",
    "Vault can store and control access to secrets. Applications can retrieve secrets at runtime.\n",
    "\n",
    "### 67.7.2 Cloud Secrets Managers\n",
    "\n",
    "- **AWS Secrets Manager**\n",
    "- **AWS Systems Manager Parameter Store** (for less sensitive data)\n",
    "- **Google Cloud Secret Manager**\n",
    "- **Azure Key Vault**\n",
    "\n",
    "### 67.7.3 Using Secrets in Terraform\n",
    "\n",
    "Terraform can retrieve secrets from AWS Secrets Manager and use them in resource definitions.\n",
    "\n",
    "```hcl\n",
    "data \"aws_secretsmanager_secret_version\" \"db_password\" {\n",
    "  secret_id = \"nepse-db-password\"\n",
    "}\n",
    "\n",
    "resource \"aws_db_instance\" \"nepse_db\" {\n",
    "  # ...\n",
    "  password = data.aws_secretsmanager_secret_version.db_password.secret_string\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "The `data` source fetches the secret value. Terraform does not store it in state in plain text if you configure the backend to encrypt.\n",
    "\n",
    "### 67.7.4 Using Secrets in Kubernetes\n",
    "\n",
    "For Kubernetes, you can use:\n",
    "\n",
    "- **Secrets** objects (base64 encoded, but not encrypted by default). For production, enable encryption at rest.\n",
    "- **External Secrets Operator** to sync secrets from Vault/AWS Secrets Manager into Kubernetes Secrets.\n",
    "- **Sealed Secrets** for GitOps: encrypt secrets into a SealedSecret resource that can be stored in Git.\n",
    "\n",
    "---\n",
    "\n",
    "## 67.8 CI/CD Integration\n",
    "\n",
    "IaC should be integrated into your CI/CD pipelines. For example, on every push to the main branch, you can run `terraform plan` and after approval, `terraform apply`.\n",
    "\n",
    "### 67.8.1 GitHub Actions for Terraform\n",
    "\n",
    "```yaml\n",
    "name: Terraform CI/CD\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [ main ]\n",
    "  pull_request:\n",
    "    branches: [ main ]\n",
    "\n",
    "jobs:\n",
    "  terraform:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "    - uses: actions/checkout@v2\n",
    "\n",
    "    - name: Setup Terraform\n",
    "      uses: hashicorp/setup-terraform@v1\n",
    "      with:\n",
    "        terraform_version: 1.3.0\n",
    "\n",
    "    - name: Terraform Init\n",
    "      run: terraform init\n",
    "      env:\n",
    "        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}\n",
    "        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n",
    "\n",
    "    - name: Terraform Plan\n",
    "      run: terraform plan -no-color\n",
    "      continue-on-error: true\n",
    "      id: plan\n",
    "\n",
    "    - name: Terraform Apply (on main)\n",
    "      if: github.ref == 'refs/heads/main' && github.event_name == 'push'\n",
    "      run: terraform apply -auto-approve\n",
    "      env:\n",
    "        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}\n",
    "        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "- The workflow runs on every push and pull request.\n",
    "- It initialises Terraform and runs a plan. On the main branch after a merge, it automatically applies the changes (with `-auto-approve`). In a production setup, you might want a manual approval step.\n",
    "\n",
    "---\n",
    "\n",
    "## 67.9 Best Practices for IaC\n",
    "\n",
    "1. **Use version control**: All IaC files should be in Git.\n",
    "2. **Modularise**: Break large configurations into reusable modules.\n",
    "3. **Use remote state**: Store state remotely with locking.\n",
    "4. **Tag resources**: Apply consistent tags for cost tracking and management.\n",
    "5. **Validate changes**: Run `plan` in CI to catch errors.\n",
    "6. **Manage secrets securely**: Never hard‑code secrets.\n",
    "7. **Pin provider versions**: Specify provider versions to avoid unexpected changes.\n",
    "8. **Test infrastructure**: Use tools like Terratest to write automated tests for your infrastructure.\n",
    "9. **Document**: Explain why certain resources are created, not just how.\n",
    "10. **Destroy unused resources**: Regularly review and remove unused infrastructure to save costs.\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary\n",
    "\n",
    "In this chapter, we explored Infrastructure as Code and its application to the NEPSE prediction system. We covered:\n",
    "\n",
    "- The principles of IaC and its benefits: consistency, reproducibility, versioning, automation.\n",
    "- Terraform for provisioning cloud resources (S3 buckets, databases, etc.) with examples.\n",
    "- AWS CloudFormation as an alternative.\n",
    "- Ansible for configuring servers.\n",
    "- Kubernetes manifests and Helm charts for deploying containerised applications.\n",
    "- Secrets management using cloud services and tools.\n",
    "- Integrating IaC into CI/CD pipelines.\n",
    "- Best practices for maintaining IaC at scale.\n",
    "\n",
    "By adopting IaC, the NEPSE system becomes fully reproducible and manageable. The same code can spin up development, staging, and production environments, reducing errors and increasing confidence. Infrastructure is no longer a black box but a versioned, auditable part of the project.\n",
    "\n",
    "In the next chapter, we will discuss **Monitoring and Alerting**, ensuring that once our infrastructure is in place, we can keep track of its health and performance.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 67**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
