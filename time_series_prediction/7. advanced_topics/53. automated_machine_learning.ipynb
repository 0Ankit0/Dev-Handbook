{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 53: Automated Machine Learning\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Understand what Automated Machine Learning (AutoML) is and how it can accelerate model development\n",
    "- Identify the components of an AutoML system: feature engineering, model selection, hyperparameter tuning, and architecture search\n",
    "- Apply automated feature engineering techniques using libraries like `tsfresh` and `Featuretools` on the NEPSE dataset\n",
    "- Use AutoML frameworks such as AutoGluon, H2O AutoML, and TPOT to build high\u2011performance models with minimal manual intervention\n",
    "- Understand the principles behind hyperparameter optimization methods (grid search, random search, Bayesian optimization)\n",
    "- Explore Neural Architecture Search (NAS) for finding optimal neural network architectures\n",
    "- Recognize the limitations and potential pitfalls of AutoML, especially in time\u2011series forecasting\n",
    "- Decide when to use AutoML versus manual modeling based on project constraints\n",
    "- Customize AutoML frameworks to incorporate domain knowledge and business constraints\n",
    "- Adopt best practices for integrating AutoML into a production MLOps pipeline\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Building a high\u2011quality machine learning model for a task like NEPSE stock prediction involves many decisions: which features to create, which algorithm to use, how to set its hyperparameters, and sometimes even how to design a neural network architecture. Each of these decisions can significantly impact performance, and exploring all possibilities manually is time\u2011consuming and requires deep expertise.\n",
    "\n",
    "**Automated Machine Learning (AutoML)** aims to automate the end\u2011to\u2011end process of applying machine learning to real\u2011world problems. An AutoML system takes a dataset and a task (e.g., classification or regression) and automatically produces a well\u2011performing model, often with little or no human intervention. AutoML has democratized machine learning, enabling non\u2011experts to build models and allowing experts to focus on higher\u2011level problems.\n",
    "\n",
    "In this chapter, we will explore the components of AutoML and apply several popular frameworks to the NEPSE stock prediction problem. We will also discuss when AutoML is appropriate and how to customize it for specific needs.\n",
    "\n",
    "---\n",
    "\n",
    "## 53.1 AutoML Overview\n",
    "\n",
    "AutoML is not a single algorithm but a combination of techniques that automate the machine learning pipeline. A typical AutoML system performs the following steps:\n",
    "\n",
    "1. **Data preprocessing**: Handling missing values, scaling, encoding categorical variables.\n",
    "2. **Feature engineering**: Creating new features from raw data, selecting the most relevant ones.\n",
    "3. **Model selection**: Choosing among a set of candidate algorithms (e.g., linear models, tree\u2011based models, neural networks).\n",
    "4. **Hyperparameter optimization**: Tuning the hyperparameters of the chosen algorithm.\n",
    "5. **Ensemble construction**: Often combining multiple models to improve performance.\n",
    "\n",
    "The goal is to find the best possible model within given constraints (time, computational resources). AutoML systems are evaluated on the quality of the final model and the efficiency of the search.\n",
    "\n",
    "For the NEPSE system, AutoML could automatically try different lag combinations, technical indicators, and model types to find the best predictor of next\u2011day price direction, saving us weeks of manual experimentation.\n",
    "\n",
    "---\n",
    "\n",
    "## 53.2 Automated Feature Engineering\n",
    "\n",
    "Feature engineering is often the most time\u2011consuming part of a machine learning project. AutoML frameworks can automate this by generating a large set of candidate features from the raw data and then selecting the most useful ones.\n",
    "\n",
    "### 53.2.1 tsfresh for Time\u2011Series\n",
    "\n",
    "`tsfresh` (Time Series Feature extraction based on scalable hypothesis tests) is a Python library that automatically extracts hundreds of features from time\u2011series data. It is particularly well\u2011suited for our NEPSE dataset, which consists of multiple time series (one per stock symbol).\n",
    "\n",
    "**Example: Using tsfresh on NEPSE data**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "\n",
    "# Load NEPSE data (assume we have columns: Date, Symbol, Close, Volume, ...)\n",
    "df = pd.read_csv('nepse_daily.csv', parse_dates=['Date'])\n",
    "df = df.sort_values(['Symbol', 'Date'])\n",
    "\n",
    "# tsfresh requires a DataFrame with columns: id (symbol), time (date), and the value columns\n",
    "df_tsfresh = df.melt(id_vars=['Symbol', 'Date'], value_vars=['Close', 'Volume'], \n",
    "                     var_name='kind', value_name='value')\n",
    "df_tsfresh = df_tsfresh.rename(columns={'Symbol': 'id', 'Date': 'time'})\n",
    "\n",
    "# Extract all possible features (this may take a while)\n",
    "extraction_settings = ComprehensiveFCParameters()\n",
    "X = extract_features(df_tsfresh, column_id='id', column_sort='time', \n",
    "                     column_kind='kind', column_value='value',\n",
    "                     default_fc_parameters=extraction_settings,\n",
    "                     impute_function=impute)\n",
    "\n",
    "print(f\"Extracted {X.shape[1]} features\")\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "`extract_features` generates features such as mean, variance, trend coefficients, Fourier transform coefficients, etc., for each combination of `id` (symbol) and `kind` (Close, Volume). The result is a DataFrame with one row per symbol and columns for each extracted feature. This can then be merged with target labels for model training.\n",
    "\n",
    "After extraction, we can use `select_features` to filter out features that are not statistically relevant to the target.\n",
    "\n",
    "```python\n",
    "# Assuming y contains the target (e.g., next\u2011day direction) for each symbol\u2011day\n",
    "# Note: tsfresh expects y to be aligned with the extracted features\n",
    "# This may require careful merging; often you extract features per symbol over rolling windows.\n",
    "\n",
    "# For demonstration, we use a simple approach: align features with target\n",
    "# Here we assume X has a MultiIndex (id, time) and y has the same index.\n",
    "X_selected = select_features(X, y, fdr_level=0.05)\n",
    "print(f\"Selected {X_selected.shape[1]} features\")\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "`select_features` performs hypothesis tests to keep only features that are significantly related to the target. This reduces dimensionality and prevents overfitting.\n",
    "\n",
    "### 53.2.2 Featuretools for Relational Feature Engineering\n",
    "\n",
    "Featuretools performs **Deep Feature Synthesis (DFS)**, which can generate features from relational data by applying primitives (like mean, max, trend) across relationships. For NEPSE, we might have multiple tables: stock prices, sector information, macroeconomic indicators. Featuretools can automatically combine them.\n",
    "\n",
    "**Example: Generating features with Featuretools**\n",
    "\n",
    "```python\n",
    "import featuretools as ft\n",
    "\n",
    "# Create an entityset\n",
    "es = ft.EntitySet(id=\"nepse\")\n",
    "\n",
    "# Add the main dataframe as an entity\n",
    "es = es.add_dataframe(\n",
    "    dataframe_name=\"prices\",\n",
    "    dataframe=df,\n",
    "    index=\"index\",  # create a temporary index\n",
    "    time_index=\"Date\"\n",
    ")\n",
    "\n",
    "# Add a second entity, e.g., sector information\n",
    "sector_df = pd.DataFrame({'Symbol': ['NABIL', 'NTC'], 'Sector': ['Bank', 'Telecom']})\n",
    "es = es.add_dataframe(\n",
    "    dataframe_name=\"sectors\",\n",
    "    dataframe=sector_df,\n",
    "    index=\"Symbol\"\n",
    ")\n",
    "\n",
    "# Define relationship\n",
    "es = es.add_relationship(\"sectors\", \"Symbol\", \"prices\", \"Symbol\")\n",
    "\n",
    "# Run deep feature synthesis\n",
    "feature_matrix, feature_defs = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_dataframe=\"prices\",\n",
    "    agg_primitives=[\"mean\", \"max\", \"min\", \"std\", \"trend\"],\n",
    "    trans_primitives=[\"diff\", \"percent_change\"],\n",
    "    max_depth=2\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(feature_defs)} features\")\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "DFS creates features like `MEAN(prices.Close over sectors)` or `TREND(prices.Close over time)`. This can capture interactions between different stocks in the same sector, for example.\n",
    "\n",
    "---\n",
    "\n",
    "## 53.3 Automated Model Selection\n",
    "\n",
    "AutoML frameworks typically evaluate multiple algorithms on the given dataset and select the best one. They often include:\n",
    "\n",
    "- Linear models (Ridge, Lasso, ElasticNet)\n",
    "- Tree\u2011based models (Random Forest, Gradient Boosting)\n",
    "- Support Vector Machines\n",
    "- Neural networks\n",
    "- k\u2011Nearest Neighbors\n",
    "\n",
    "The selection is based on cross\u2011validation performance, often using a holdout validation set or time\u2011series cross\u2011validation.\n",
    "\n",
    "**Example: Using TPOT for automated model selection**\n",
    "\n",
    "TPOT (Tree\u2011based Pipeline Optimization Tool) uses genetic programming to search over feature preprocessors, models, and hyperparameters.\n",
    "\n",
    "```python\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Prepare data (assuming X already contains engineered features)\n",
    "# Note: For time series, we must use time\u2011aware cross\u2011validation\n",
    "tpot = TPOTClassifier(\n",
    "    generations=5,\n",
    "    population_size=20,\n",
    "    cv=TimeSeriesSplit(n_splits=3),\n",
    "    verbosity=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "print(f\"Test accuracy: {tpot.score(X_test, y_test):.4f}\")\n",
    "\n",
    "# Export the best pipeline\n",
    "tpot.export('tpot_nepse_pipeline.py')\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "TPOT evolves pipelines over generations, selecting operators like `StandardScaler`, `RandomForestClassifier`, `XGBClassifier`, etc. It outputs a Python file with the best pipeline found. For time\u2011series, we pass a `TimeSeriesSplit` cross\u2011validator to avoid leakage.\n",
    "\n",
    "---\n",
    "\n",
    "## 53.4 Hyperparameter Optimization\n",
    "\n",
    "Hyperparameter optimization (HPO) is a core component of AutoML. Methods range from simple grid search to sophisticated Bayesian optimization.\n",
    "\n",
    "### 53.4.1 Grid Search and Random Search\n",
    "\n",
    "Grid search exhaustively tries all combinations of specified hyperparameter values. Random search samples combinations randomly and often finds good configurations faster.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 500),\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 5)\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_dist, n_iter=50,\n",
    "    cv=TimeSeriesSplit(n_splits=3),\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Best CV accuracy: {random_search.best_score_:.4f}\")\n",
    "```\n",
    "\n",
    "### 53.4.2 Bayesian Optimization\n",
    "\n",
    "Bayesian optimization builds a probabilistic model (e.g., Gaussian Process) of the objective function and uses it to select the most promising hyperparameters to evaluate next. It is more efficient than random search.\n",
    "\n",
    "**Example with scikit\u2011optimize**\n",
    "\n",
    "```python\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real\n",
    "\n",
    "search_spaces = {\n",
    "    'n_estimators': Integer(50, 500),\n",
    "    'max_depth': Integer(5, 50),\n",
    "    'min_samples_split': Integer(2, 10),\n",
    "    'min_samples_leaf': Integer(1, 4),\n",
    "    'max_features': Real(0.1, 1.0)\n",
    "}\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    search_spaces,\n",
    "    n_iter=30,\n",
    "    cv=TimeSeriesSplit(n_splits=3),\n",
    "    scoring='accuracy',\n",
    "    random_state=42\n",
    ")\n",
    "bayes_search.fit(X_train, y_train)\n",
    "print(f\"Best parameters: {bayes_search.best_params_}\")\n",
    "```\n",
    "\n",
    "### 53.4.3 Hyperparameter Optimization for Gradient Boosting\n",
    "\n",
    "Libraries like XGBoost, LightGBM, and CatBoost have many hyperparameters. Tools like `hyperopt` or `optuna` can optimize them.\n",
    "\n",
    "**Example with Optuna**\n",
    "\n",
    "```python\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True)\n",
    "    }\n",
    "    # Use early stopping with a validation set\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_val, label=y_val)\n",
    "    model = xgb.train(params, dtrain, num_boost_round=1000,\n",
    "                      evals=[(dvalid, 'valid')], early_stopping_rounds=50,\n",
    "                      verbose_eval=False)\n",
    "    preds = (model.predict(dvalid) > 0.5).astype(int)\n",
    "    acc = accuracy_score(y_val, preds)\n",
    "    return acc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "print(study.best_params)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 53.5 Neural Architecture Search (NAS)\n",
    "\n",
    "For deep learning models, AutoML can also search over network architectures. This is called Neural Architecture Search. NAS methods are computationally expensive but can find architectures that outperform manually designed ones.\n",
    "\n",
    "**Example: Using AutoKeras for NAS**\n",
    "\n",
    "AutoKeras is an AutoML library for deep learning that performs architecture search.\n",
    "\n",
    "```python\n",
    "import autokeras as ak\n",
    "\n",
    "# Initialize the time series regressor/classifier\n",
    "clf = ak.StructuredDataClassifier(\n",
    "    max_trials=10,  # number of different architectures to try\n",
    "    overwrite=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Fit with time\u2011series split (AutoKeras uses its own validation split)\n",
    "# For time series, we should ensure the split does not shuffle randomly.\n",
    "# AutoKeras may not handle time series natively; we can pass a validation set manually.\n",
    "val_split_idx = int(0.8 * len(X_train))\n",
    "clf.fit(\n",
    "    X_train[:val_split_idx], y_train[:val_split_idx],\n",
    "    validation_data=(X_train[val_split_idx:], y_train[val_split_idx:]),\n",
    "    epochs=50,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "accuracy = clf.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy}\")\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "AutoKeras searches over different neural network architectures (e.g., number of layers, units, activation functions) using Bayesian optimization. It also tunes preprocessing and training hyperparameters. For time\u2011series, we must be careful to maintain temporal order; AutoKeras's built\u2011in validation split might shuffle, so we provide a fixed validation set.\n",
    "\n",
    "**Limitations:** NAS is resource\u2011intensive. For a small dataset like NEPSE, simpler models may suffice.\n",
    "\n",
    "---\n",
    "\n",
    "## 53.6 AutoML Frameworks\n",
    "\n",
    "Several mature AutoML frameworks are available. We will highlight a few and show how to apply them to NEPSE.\n",
    "\n",
    "### 53.6.1 AutoGluon (from Amazon)\n",
    "\n",
    "AutoGluon focuses on tabular data (including time\u2011series) and automatically trains multiple models and stacks them.\n",
    "\n",
    "```python\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "# Prepare data\n",
    "train_data = TabularDataset(pd.concat([X_train, y_train], axis=1))\n",
    "test_data = TabularDataset(pd.concat([X_test, y_test], axis=1))\n",
    "\n",
    "# Train predictor\n",
    "predictor = TabularPredictor(label='Target', eval_metric='accuracy')\n",
    "predictor.fit(\n",
    "    train_data,\n",
    "    time_limit=3600,  # seconds\n",
    "    presets='medium_quality'  # can be 'best_quality' for better but slower\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "performance = predictor.evaluate(test_data)\n",
    "print(performance)\n",
    "\n",
    "# Get leaderboard of models\n",
    "leaderboard = predictor.leaderboard(test_data)\n",
    "print(leaderboard)\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "AutoGluon automatically preprocesses data, trains multiple models (Random Forest, XGBoost, LightGBM, CatBoost, neural networks), and creates an ensemble. It handles time\u2011series if we provide the data in the correct format (with time column, but it does not automatically enforce temporal cross\u2011validation; we should ensure our train/test split respects time order).\n",
    "\n",
    "### 53.6.2 H2O AutoML\n",
    "\n",
    "H2O's AutoML is a popular platform that trains and tunes many algorithms, including stacked ensembles.\n",
    "\n",
    "```python\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "h2o.init()\n",
    "\n",
    "# Convert pandas to H2O frames\n",
    "train_h2o = h2o.H2OFrame(pd.concat([X_train, y_train], axis=1))\n",
    "test_h2o = h2o.H2OFrame(pd.concat([X_test, y_test], axis=1))\n",
    "\n",
    "# Specify target and features\n",
    "x = train_h2o.columns[:-1]\n",
    "y = train_h2o.columns[-1]\n",
    "train_h2o[y] = train_h2o[y].asfactor()  # for classification\n",
    "\n",
    "# Run AutoML\n",
    "aml = H2OAutoML(max_models=20, seed=42, max_runtime_secs=300)\n",
    "aml.train(x=x, y=y, training_frame=train_h2o)\n",
    "\n",
    "# View leaderboard\n",
    "lb = aml.leaderboard\n",
    "print(lb.head())\n",
    "\n",
    "# Predict on test\n",
    "preds = aml.leader.predict(test_h2o)\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "H2O AutoML runs a fixed set of algorithms (GLM, Random Forest, GBM, XGBoost, deep learning) and builds two stacked ensembles. It reports performance via cross\u2011validation. Note that H2O's cross\u2011validation is random; for time\u2011series, we should instead provide a validation frame that is later in time, or use time\u2011based folds manually.\n",
    "\n",
    "### 53.6.3 TPOT\n",
    "\n",
    "We already introduced TPOT for model selection. It can also handle feature preprocessing.\n",
    "\n",
    "```python\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, cv=3, random_state=42, n_jobs=-1)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_pipeline.py')\n",
    "```\n",
    "\n",
    "### 53.6.4 Custom Solutions\n",
    "\n",
    "Sometimes you need to build your own AutoML pipeline to incorporate domain constraints. For example, you might fix the set of features (e.g., only use lags and technical indicators) and only search over models and hyperparameters. You can use `GridSearchCV`, `RandomizedSearchCV`, or `Optuna` to automate the search.\n",
    "\n",
    "**Example: Custom pipeline with scikit\u2011learn and Optuna**\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Choose classifier\n",
    "    classifier_name = trial.suggest_categorical('classifier', ['rf', 'svm', 'lr'])\n",
    "    if classifier_name == 'rf':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('rf_n_estimators', 50, 500),\n",
    "            'max_depth': trial.suggest_int('rf_max_depth', 3, 20),\n",
    "            'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 10)\n",
    "        }\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "    elif classifier_name == 'svm':\n",
    "        params = {\n",
    "            'C': trial.suggest_float('svm_C', 1e-2, 10, log=True),\n",
    "            'gamma': trial.suggest_float('svm_gamma', 1e-3, 1, log=True)\n",
    "        }\n",
    "        model = SVC(**params, probability=True, random_state=42)\n",
    "    else:\n",
    "        params = {\n",
    "            'C': trial.suggest_float('lr_C', 1e-2, 10, log=True)\n",
    "        }\n",
    "        model = LogisticRegression(**params, random_state=42)\n",
    "\n",
    "    # Pipeline with scaling\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('clf', model)])\n",
    "\n",
    "    # Cross\u2011validation (time\u2011series)\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in tscv.split(X_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        pipeline.fit(X_tr, y_tr)\n",
    "        scores.append(accuracy_score(y_val, pipeline.predict(X_val)))\n",
    "    return np.mean(scores)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "print(study.best_params)\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "This custom search selects both a model type and its hyperparameters, using time\u2011series cross\u2011validation. It demonstrates how to build a flexible AutoML pipeline tailored to your problem.\n",
    "\n",
    "---\n",
    "\n",
    "## 53.7 Limitations of AutoML\n",
    "\n",
    "While AutoML is powerful, it is not a silver bullet. Some limitations include:\n",
    "\n",
    "- **Computational cost**: AutoML can be expensive, especially with large datasets and complex search spaces.\n",
    "- **Overfitting risk**: Without careful validation, AutoML can overfit to the validation set, especially if the search is too extensive.\n",
    "- **Lack of domain knowledge**: AutoML may generate features that are nonsensical or miss important domain\u2011specific ones (e.g., circuit breaker flags in NEPSE).\n",
    "- **Time\u2011series challenges**: Most AutoML frameworks assume i.i.d. data. Applying them to time\u2011series requires manual intervention to ensure temporal ordering and avoid leakage.\n",
    "- **Interpretability**: The final model may be a complex ensemble that is hard to explain.\n",
    "- **Reproducibility**: AutoML results can be sensitive to random seeds and search parameters.\n",
    "\n",
    "---\n",
    "\n",
    "## 53.8 When to Use AutoML\n",
    "\n",
    "AutoML is beneficial when:\n",
    "\n",
    "- You need a baseline model quickly.\n",
    "- You lack deep expertise in the domain or in machine learning.\n",
    "- You have a large search space and want to explore it efficiently.\n",
    "- You are building many models and want to automate routine work.\n",
    "\n",
    "For the NEPSE system, AutoML could be used to:\n",
    "\n",
    "- Quickly benchmark different modeling approaches.\n",
    "- Automate model retraining as new data arrives.\n",
    "- Explore feature engineering combinations automatically (with caution).\n",
    "\n",
    "However, you should still incorporate domain knowledge (e.g., by restricting the search space or by manually engineering certain features) and always validate results with time\u2011series\u2011appropriate methods.\n",
    "\n",
    "---\n",
    "\n",
    "## 53.9 Customizing AutoML\n",
    "\n",
    "AutoML frameworks often allow customization. For example:\n",
    "\n",
    "- In AutoGluon, you can specify `hyperparameters` to tune and `excluded_model_types`.\n",
    "- In H2O, you can set `include_algos` to restrict the algorithm set.\n",
    "- In TPOT, you can customize the operators in the genetic programming search.\n",
    "- You can also provide a fixed preprocessing pipeline and let AutoML tune only certain parts.\n",
    "\n",
    "**Example: Restricting AutoGluon to tree\u2011based models**\n",
    "\n",
    "```python\n",
    "predictor = TabularPredictor(label='Target').fit(\n",
    "    train_data,\n",
    "    hyperparameters={\n",
    "        'GBM': {},\n",
    "        'RF': {},\n",
    "        'XGB': {}\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "**Example: Adding a custom feature to the AutoML loop**\n",
    "\n",
    "If using a custom pipeline with Optuna, you can add a step that tries different feature sets (e.g., with or without technical indicators).\n",
    "\n",
    "---\n",
    "\n",
    "## 53.10 Best Practices\n",
    "\n",
    "1. **Start with a simple baseline** \u2013 Before running AutoML, have a simple model (e.g., logistic regression) to compare against.\n",
    "2. **Use proper validation** \u2013 For time\u2011series, always use time\u2011based splits or walk\u2011forward validation.\n",
    "3. **Limit search space** \u2013 Restrict the search to reasonable values and models to avoid wasting resources.\n",
    "4. **Incorporate domain knowledge** \u2013 Manually create important features and let AutoML handle the rest.\n",
    "5. **Monitor for overfitting** \u2013 Use a final holdout test set that was never used in the AutoML process.\n",
    "6. **Reproducibility** \u2013 Set random seeds and log all experiments.\n",
    "7. **Interpretability** \u2013 If explainability is required, consider using simpler models or post\u2011hoc explanation methods.\n",
    "8. **Resource management** \u2013 Set time limits and use early stopping to control costs.\n",
    "\n",
    "---\n",
    "\n",
    "## Chapter Summary\n",
    "\n",
    "In this chapter, we explored Automated Machine Learning and its application to the NEPSE stock prediction system. We covered:\n",
    "\n",
    "- The components of AutoML: automated feature engineering, model selection, hyperparameter optimization, and neural architecture search.\n",
    "- How to use `tsfresh` and `Featuretools` to automatically generate features from time\u2011series data.\n",
    "- AutoML frameworks like TPOT, AutoGluon, and H2O AutoML, with code examples showing how to apply them to NEPSE.\n",
    "- Hyperparameter optimization techniques, including grid search, random search, Bayesian optimization, and tools like Optuna.\n",
    "- Neural Architecture Search and its limitations.\n",
    "- The limitations of AutoML and when it is appropriate to use.\n",
    "- Customizing AutoML to incorporate domain knowledge and best practices for successful application.\n",
    "\n",
    "AutoML is a powerful ally in the machine learning practitioner's toolkit, especially for quickly establishing baselines and automating routine tasks. For the NEPSE system, AutoML can help explore a wide range of models and features, but must be used with care to respect the temporal nature of financial data. In the next chapter, we will discuss **Reinforcement Learning for Time\u2011Series**, exploring how agents can learn trading strategies directly.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 53**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='52. transfer_learning_and_pre_training.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='54. reinforcement_learning_for_time_series.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}