{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 83: Multi-Model Systems\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Understand why a single model may not be sufficient for complex time\u2011series prediction tasks.\n",
    "- Distinguish between different multi\u2011model patterns: ensemble, routing, cascade, and expert systems.\n",
    "- Implement ensemble methods (bagging, boosting, stacking) in the context of time\u2011series, using the NEPSE stock prediction system as an example.\n",
    "- Design a model router that dynamically selects the best model based on market conditions or input features.\n",
    "- Build a cascade system where a simple model handles easy cases and a complex model is invoked only when needed.\n",
    "- Evaluate the performance of multi\u2011model systems, including per\u2011model accuracy and overall system latency.\n",
    "- Monitor for model drift and automatically adjust routing or retrain individual models.\n",
    "- Understand the trade\u2011offs between accuracy, complexity, and computational cost.\n",
    "\n",
    "---\n",
    "\n",
    "## **83.1 Introduction to Multi\u2011Model Systems**\n",
    "\n",
    "In previous chapters, we focused on building and deploying a single model for a given prediction task. However, real\u2011world time\u2011series prediction often benefits from using **multiple models** in concert. Reasons include:\n",
    "\n",
    "- **Diverse market regimes**: A single model may perform well during stable periods but fail during high volatility. A regime\u2011switching approach can use different models for different conditions.\n",
    "- **Complementary strengths**: Some models capture linear trends well, while others excel at non\u2011linear patterns. Combining them can yield better overall performance.\n",
    "- **Robustness**: Ensembles reduce the risk of choosing a single \u201cwrong\u201d model.\n",
    "- **Computational efficiency**: A lightweight model can handle most requests, reserving a heavy model for complex cases.\n",
    "- **Interpretability**: A simple model may be used for explanations, while a complex one provides accuracy.\n",
    "\n",
    "In the NEPSE system, we might have:\n",
    "\n",
    "- A **linear model** (e.g., ARIMA) for calm periods.\n",
    "- A **tree\u2011based model** (e.g., XGBoost) for normal conditions.\n",
    "- A **deep learning model** (e.g., LSTM) for volatile periods with complex patterns.\n",
    "- An **ensemble** that averages predictions from all three.\n",
    "\n",
    "Multi\u2011model systems introduce additional complexity: we must decide which model to use when, how to combine outputs, and how to maintain multiple models. This chapter explores the patterns and practical implementation.\n",
    "\n",
    "---\n",
    "\n",
    "## **83.2 Patterns for Multi\u2011Model Systems**\n",
    "\n",
    "We can classify multi\u2011model systems into several patterns:\n",
    "\n",
    "### **83.2.1 Ensemble**\n",
    "Multiple models are trained on the same data (or different views of it) and their predictions are combined, typically by averaging (regression) or voting (classification). Ensembles are often more accurate and robust than any single model. Common ensemble methods include bagging, boosting, and stacking.\n",
    "\n",
    "### **83.2.2 Model Routing**\n",
    "A **router** or **selector** decides which model to use for each prediction based on input features or context. For example, a classifier might predict the current market regime (calm, volatile, trending) and then invoke the model specialised for that regime.\n",
    "\n",
    "### **83.2.3 Cascade**\n",
    "Models are arranged in a sequence. A simple, fast model is applied first; if its confidence is high enough, its prediction is used. If not, a more complex model is invoked. This is common in computer vision but can apply to time\u2011series (e.g., if a linear model\u2019s residual is large, trigger an LSTM).\n",
    "\n",
    "### **83.2.4 Expert Systems**\n",
    "Different models are trained on different subsets of data (e.g., by sector, by time of day) and a rule\u2011based system selects the appropriate expert. In NEPSE, we might have separate models for banking stocks, hydropower stocks, etc., because they behave differently.\n",
    "\n",
    "### **83.2.5 Hybrid**\n",
    "Combinations of the above, e.g., an ensemble of routed models.\n",
    "\n",
    "In this chapter, we will implement examples of ensemble, routing, and cascade using the NEPSE dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## **83.3 Ensemble Methods**\n",
    "\n",
    "Ensemble methods combine multiple models to produce a single prediction. They are well\u2011studied and often yield state\u2011of\u2011the\u2011art results.\n",
    "\n",
    "### **83.3.1 Bagging (Bootstrap Aggregating)**\n",
    "Train multiple instances of the same model on different bootstrap samples of the training data. For regression, predictions are averaged; for classification, majority vote. Random forests are a classic example.\n",
    "\n",
    "In time\u2011series, we must be careful with bootstrapping because temporal order matters. Instead of random sampling with replacement, we can use **block bootstrapping** (sampling blocks of consecutive days) to preserve autocorrelation. However, a simpler approach is to train on different time periods (e.g., different years) \u2013 this is more like a time\u2011series ensemble.\n",
    "\n",
    "### **83.3.2 Boosting**\n",
    "Sequentially train models, each focusing on the errors of the previous one. Gradient boosting machines (XGBoost, LightGBM) are themselves ensembles of weak learners. In a multi\u2011model system, we might treat different boosting models as separate members.\n",
    "\n",
    "### **83.3.3 Stacking (Stacked Generalization)**\n",
    "Train several base models (level\u20110) and then train a meta\u2011model (level\u20111) that learns to combine their predictions optimally. The meta\u2011model is trained on the predictions of the base models on a hold\u2011out validation set.\n",
    "\n",
    "### **83.3.4 Implementing an Ensemble for NEPSE**\n",
    "\n",
    "We'll build a stacking ensemble with three base models:\n",
    "\n",
    "- **ARIMA** (statistical)\n",
    "- **XGBoost** (tree\u2011based)\n",
    "- **LSTM** (deep learning)\n",
    "\n",
    "We'll use historical NEPSE data (synthetic) and train on a time\u2011based split.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Generate synthetic NEPSE data (as in Chapter 74)\n",
    "def generate_nepse_data(days=1000):\n",
    "    dates = pd.date_range(start='2020-01-01', periods=days, freq='B')\n",
    "    prices = 1000 + np.cumsum(np.random.randn(days) * 5)\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'close': prices,\n",
    "        'volume': np.random.lognormal(12, 1, days)\n",
    "    })\n",
    "    # Add some features (simplified)\n",
    "    df['lag_1'] = df['close'].shift(1)\n",
    "    df['lag_5'] = df['close'].shift(5)\n",
    "    df['sma_10'] = df['close'].rolling(10).mean()\n",
    "    df['volatility'] = df['close'].rolling(20).std()\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df = generate_nepse_data(days=1500)\n",
    "print(df.head())\n",
    "\n",
    "# Prepare features and target (predict next day close)\n",
    "feature_cols = ['lag_1', 'lag_5', 'sma_10', 'volatility', 'volume']\n",
    "X = df[feature_cols]\n",
    "y = df['close'].shift(-1).dropna()\n",
    "X = X.iloc[:-1]  # align\n",
    "\n",
    "# Time-based split\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "# --- Base Model 1: ARIMA (univariate, using only close) ---\n",
    "# For simplicity, we'll use a fixed order; in practice, tune with AIC.\n",
    "arima_model = ARIMA(y_train, order=(5,1,0))\n",
    "arima_fit = arima_model.fit()\n",
    "# ARIMA predicts next step; we'll need to align predictions with test set\n",
    "# For stacking, we need predictions on validation set to train meta-model.\n",
    "# We'll do a time-series split to generate out-of-sample predictions for stacking.\n",
    "\n",
    "# We'll implement a proper stacking with time-series cross-validation later.\n",
    "# For now, let's demonstrate a simple average ensemble.\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- We generate synthetic NEPSE data and create simple features.\n",
    "- We prepare three base models: ARIMA, XGBoost, and LSTM.\n",
    "- For a stacking ensemble, we need to generate predictions from base models on a validation set that was not used to train them. This requires careful time\u2011based splitting to avoid look\u2011ahead.\n",
    "\n",
    "### **83.3.5 Time\u2011Series Cross\u2011Validation for Stacking**\n",
    "\n",
    "We'll use a walk\u2011forward approach to generate out\u2011of\u2011sample predictions for the base models, then train a meta\u2011model.\n",
    "\n",
    "```python\n",
    "def walk_forward_predictions(model_fn, X, y, initial_train_size, step=1):\n",
    "    \"\"\"\n",
    "    Generate out-of-sample predictions using walk-forward validation.\n",
    "    model_fn: function that takes (X_train, y_train) and returns a predict function.\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    predictions = np.full(n, np.nan)\n",
    "    for i in range(initial_train_size, n, step):\n",
    "        train_idx = slice(0, i)\n",
    "        test_idx = i\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_test = X.iloc[[test_idx]]\n",
    "        model = model_fn(X_train, y_train)\n",
    "        pred = model(X_test)\n",
    "        predictions[test_idx] = pred\n",
    "    return predictions\n",
    "\n",
    "# Example for XGBoost\n",
    "def train_xgb(X_train, y_train):\n",
    "    model = xgb.XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1)\n",
    "    model.fit(X_train, y_train)\n",
    "    return lambda X: model.predict(X)[0]\n",
    "\n",
    "xgb_preds = walk_forward_predictions(train_xgb, X, y, initial_train_size=500, step=1)\n",
    "\n",
    "# For ARIMA (univariate, using y only)\n",
    "def train_arima(y_train):\n",
    "    model = ARIMA(y_train, order=(5,1,0))\n",
    "    fit = model.fit()\n",
    "    return lambda X: fit.forecast(steps=1)[0]  # X ignored\n",
    "\n",
    "arima_preds = walk_forward_predictions(train_arima, pd.DataFrame(index=y.index), y, initial_train_size=500, step=1)\n",
    "\n",
    "# For LSTM (requires reshaping)\n",
    "def train_lstm(X_train, y_train):\n",
    "    # Reshape to [samples, timesteps, features] \u2013 we'll use 10 timesteps\n",
    "    # This is simplified; in practice you'd create sequences\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation='relu', input_shape=(10, X_train.shape[1])),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # Create sequences\n",
    "    def create_sequences(X, y, seq_len=10):\n",
    "        X_seq, y_seq = [], []\n",
    "        for i in range(seq_len, len(X)):\n",
    "            X_seq.append(X.iloc[i-seq_len:i].values)\n",
    "            y_seq.append(y.iloc[i])\n",
    "        return np.array(X_seq), np.array(y_seq)\n",
    "    X_seq, y_seq = create_sequences(X_train, y_train)\n",
    "    model.fit(X_seq, y_seq, epochs=10, verbose=0)\n",
    "    def predict(X_new):\n",
    "        # X_new is a single row; need last 10 rows from training to form sequence\n",
    "        # This is tricky in walk-forward; for simplicity, we'll skip LSTM in this example.\n",
    "        return np.nan\n",
    "    return predict\n",
    "\n",
    "# For simplicity, we'll proceed with xgb_preds and arima_preds only.\n",
    "\n",
    "# Remove NaNs from beginning\n",
    "valid_idx = ~np.isnan(xgb_preds) & ~np.isnan(arima_preds)\n",
    "X_meta = pd.DataFrame({\n",
    "    'xgb': xgb_preds[valid_idx],\n",
    "    'arima': arima_preds[valid_idx]\n",
    "})\n",
    "y_meta = y[valid_idx]\n",
    "\n",
    "# Train meta-model (simple linear regression)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(X_meta, y_meta)\n",
    "\n",
    "# Evaluate on test set (last 20%)\n",
    "test_start = int(len(y) * 0.8)\n",
    "X_test_meta = X_meta.iloc[test_start:]\n",
    "y_test_meta = y_meta.iloc[test_start:]\n",
    "y_pred_meta = meta_model.predict(X_test_meta)\n",
    "mae = mean_absolute_error(y_test_meta, y_pred_meta)\n",
    "print(f\"Stacking ensemble MAE: {mae:.2f}\")\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- `walk_forward_predictions` simulates a rolling forecast: for each day from `initial_train_size` onward, train the model on all previous data and predict the next day. This yields out\u2011of\u2011sample predictions that can be used to train the meta\u2011model without look\u2011ahead bias.\n",
    "- We implement this for XGBoost and ARIMA (LSTM would require careful sequence handling).\n",
    "- The meta\u2011model (linear regression) learns the optimal combination of the base models.\n",
    "- This stacking approach often outperforms simple averaging because it weights models based on their recent performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **83.4 Model Routing**\n",
    "\n",
    "In model routing, we dynamically select which model to use for each prediction based on the input features or the current market state. This is particularly useful when different models excel under different conditions.\n",
    "\n",
    "### **83.4.1 Regime Detection as a Router**\n",
    "\n",
    "We can build a regime classifier that predicts the market state (e.g., using features like volatility, volume, trend strength). Then, for each regime, we have a specialised prediction model.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. **Label historical data** with regimes (e.g., using volatility thresholds, trend following indicators, or clustering).\n",
    "2. **Train a classifier** (e.g., random forest) to predict the regime from features.\n",
    "3. **Train a separate prediction model** for each regime.\n",
    "4. At inference, first predict the regime, then use the corresponding model.\n",
    "\n",
    "### **83.4.2 Implementing a Router for NEPSE**\n",
    "\n",
    "We'll define three regimes based on 20\u2011day volatility:\n",
    "\n",
    "- **Low volatility**: rolling std < 20\n",
    "- **Medium volatility**: 20 \u2264 rolling std < 40\n",
    "- **High volatility**: rolling std \u2265 40\n",
    "\n",
    "```python\n",
    "# Add volatility to dataframe\n",
    "df['volatility_20'] = df['close'].rolling(20).std()\n",
    "\n",
    "# Define regimes\n",
    "def label_regime(row):\n",
    "    if row['volatility_20'] < 20:\n",
    "        return 'low'\n",
    "    elif row['volatility_20'] < 40:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "df['regime'] = df.apply(label_regime, axis=1)\n",
    "\n",
    "# Shift target (next day close)\n",
    "df['target'] = df['close'].shift(-1)\n",
    "df = df.dropna()\n",
    "\n",
    "# Train a regime classifier (use features from current day to predict regime for next day?)\n",
    "# We want to predict the regime for which we will apply the model. Usually, we use features known at prediction time.\n",
    "feature_cols = ['lag_1', 'lag_5', 'sma_10', 'volume']\n",
    "X_class = df[feature_cols]\n",
    "y_class = df['regime']\n",
    "\n",
    "# Time-based split\n",
    "split = int(0.8 * len(df))\n",
    "X_train_class, X_test_class = X_class.iloc[:split], X_class.iloc[split:]\n",
    "y_train_class, y_test_class = y_class.iloc[:split], y_class.iloc[split:]\n",
    "\n",
    "# Train classifier (simple random forest)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Evaluate classifier accuracy\n",
    "print(\"Classifier accuracy:\", clf.score(X_test_class, y_test_class))\n",
    "\n",
    "# Now train separate regression models for each regime\n",
    "models = {}\n",
    "for regime in ['low', 'medium', 'high']:\n",
    "    mask = (df['regime'] == regime) & (df.index < split)  # train on training period only\n",
    "    X_reg = df.loc[mask, feature_cols]\n",
    "    y_reg = df.loc[mask, 'target']\n",
    "    if len(X_reg) > 0:\n",
    "        model = xgb.XGBRegressor(n_estimators=100, max_depth=5)\n",
    "        model.fit(X_reg, y_reg)\n",
    "        models[regime] = model\n",
    "    else:\n",
    "        models[regime] = None\n",
    "\n",
    "# Predict on test set using router\n",
    "y_pred = []\n",
    "for i in range(split, len(df)):\n",
    "    row = df.iloc[i]\n",
    "    X_row = row[feature_cols].values.reshape(1, -1)\n",
    "    # Predict regime\n",
    "    regime = clf.predict(X_row)[0]\n",
    "    model = models.get(regime)\n",
    "    if model is not None:\n",
    "        pred = model.predict(X_row)[0]\n",
    "    else:\n",
    "        # fallback to a global model (e.g., trained on all data)\n",
    "        pred = global_model.predict(X_row)[0]  # assume we have a global model\n",
    "    y_pred.append(pred)\n",
    "\n",
    "y_true = df['target'].iloc[split:].values\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(f\"Routing model MAE: {mae:.2f}\")\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- We label each day with a volatility regime based on the current day's volatility.\n",
    "- A classifier is trained to predict the regime from features (note: this uses current day's features to predict the regime for the same day \u2013 but the regime is based on current volatility, which is known at prediction time, so it's valid).\n",
    "- Separate XGBoost models are trained for each regime using only data from that regime.\n",
    "- At inference, we first classify the regime, then use the corresponding model.\n",
    "- If a regime model doesn't exist (e.g., not enough training data), we fall back to a global model.\n",
    "\n",
    "---\n",
    "\n",
    "## **83.5 Cascade Systems**\n",
    "\n",
    "A cascade system processes predictions through a sequence of models, typically starting with a cheap, simple model and only invoking a more expensive model if the simple model's confidence is low.\n",
    "\n",
    "### **83.5.1 Designing a Cascade for NEPSE**\n",
    "\n",
    "We can use a linear model (e.g., ARIMA) as the first stage. If its prediction error on recent known data is high, or if the predicted value has high uncertainty (e.g., wide confidence interval), we invoke a complex model (e.g., XGBoost or LSTM).\n",
    "\n",
    "To measure confidence, we can use:\n",
    "\n",
    "- The standard error of the ARIMA forecast.\n",
    "- The residual from a recent validation period.\n",
    "- A separate uncertainty model.\n",
    "\n",
    "### **83.5.2 Implementing a Simple Cascade**\n",
    "\n",
    "```python\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import numpy as np\n",
    "\n",
    "class CascadePredictor:\n",
    "    def __init__(self, simple_model_fn, complex_model, threshold=5.0):\n",
    "        self.simple_model_fn = simple_model_fn  # function to train simple model on expanding data\n",
    "        self.complex_model = complex_model      # pre-trained complex model\n",
    "        self.threshold = threshold              # if simple model's recent MAE > threshold, use complex\n",
    "    \n",
    "    def predict(self, X, y_history, date_idx):\n",
    "        \"\"\"\n",
    "        X: features for current prediction (for complex model)\n",
    "        y_history: array of recent actuals (for evaluating simple model)\n",
    "        date_idx: index to know where to split\n",
    "        \"\"\"\n",
    "        # Train simple model on data up to date_idx-1\n",
    "        simple = self.simple_model_fn(y_history[:date_idx])\n",
    "        # Make simple prediction\n",
    "        simple_pred = simple.forecast(steps=1)[0]\n",
    "        \n",
    "        # Evaluate simple model on recent validation period (e.g., last 5 days)\n",
    "        if date_idx > 5:\n",
    "            recent_actuals = y_history[date_idx-5:date_idx]\n",
    "            recent_preds = []\n",
    "            for i in range(5):\n",
    "                # Re-train simple model up to date_idx-5+i? This is expensive.\n",
    "                # Instead, we can use residuals from the fitted model on the validation period.\n",
    "                # Simpler: use a fixed threshold based on recent volatility.\n",
    "                pass\n",
    "        \n",
    "        # For simplicity, we'll just use the threshold on the absolute predicted return\n",
    "        # If simple_pred indicates a large move, we might want complex model.\n",
    "        # But that's not a good confidence measure.\n",
    "        \n",
    "        # Here we'll just use a heuristic: if the simple model's prediction deviates too much from recent average, use complex.\n",
    "        recent_avg = np.mean(y_history[date_idx-5:date_idx]) if date_idx >=5 else simple_pred\n",
    "        if abs(simple_pred - recent_avg) > self.threshold:\n",
    "            # Use complex model\n",
    "            X_input = X.values.reshape(1, -1)\n",
    "            complex_pred = self.complex_model.predict(X_input)[0]\n",
    "            return complex_pred\n",
    "        else:\n",
    "            return simple_pred\n",
    "\n",
    "# Example usage\n",
    "# We need to pre-train a complex model on the entire training set\n",
    "complex_model = xgb.XGBRegressor(n_estimators=100)\n",
    "complex_model.fit(X_train, y_train)\n",
    "\n",
    "# Simple model function (ARIMA with fixed order)\n",
    "def train_arima(y):\n",
    "    model = ARIMA(y, order=(5,1,0))\n",
    "    return model.fit()\n",
    "\n",
    "cascade = CascadePredictor(train_arima, complex_model, threshold=10.0)\n",
    "\n",
    "# Simulate walk-forward\n",
    "y_history = y_train.tolist()  # start with training data\n",
    "predictions = []\n",
    "for i in range(len(X_test)):\n",
    "    X_row = X_test.iloc[i]\n",
    "    pred = cascade.predict(X_row, y_history, len(y_history))\n",
    "    predictions.append(pred)\n",
    "    # Append actual test value to history (simulating we observe it next day)\n",
    "    y_history.append(y_test.iloc[i])\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f\"Cascade MAE: {mae:.2f}\")\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- The cascade predictor uses a simple ARIMA model that is retrained on all available history for each step (computationally heavy; in practice you might use a rolling ARIMA or a pre\u2011fitted model with updates).\n",
    "- The decision to invoke the complex model is based on a simple heuristic: if the simple model's prediction deviates from the recent average by more than a threshold, we assume the situation is unusual and use the complex model.\n",
    "- This reduces the number of complex model invocations, saving computation while maintaining accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## **83.6 Multi\u2011Model System Architecture**\n",
    "\n",
    "In a production system, multi\u2011model logic needs to be integrated into the prediction service. We can extend the microservices architecture from Chapter 81:\n",
    "\n",
    "- **Model Registry** now stores multiple models, each with metadata about its type, regime, or ensemble weight.\n",
    "- **Prediction Service** contains a **router** component that, based on input features, decides which model(s) to invoke.\n",
    "- For ensembles, the prediction service may call multiple models in parallel and combine results.\n",
    "- For cascades, it may call models sequentially.\n",
    "\n",
    "We can also have a dedicated **Ensemble Service** that handles the combination logic, but keeping it within the prediction service is simpler.\n",
    "\n",
    "---\n",
    "\n",
    "## **83.7 Monitoring and Maintenance**\n",
    "\n",
    "With multiple models, monitoring becomes more complex. We need to track:\n",
    "\n",
    "- **Per\u2011model performance** (MAE, bias) over time, to detect when a model degrades.\n",
    "- **Router accuracy** (if using a classifier), to ensure it's selecting the right model.\n",
    "- **Ensemble weights** (if using stacking) \u2013 they may drift and need recalibration.\n",
    "- **Latency** \u2013 cascades may have variable latency depending on how often the complex model is invoked.\n",
    "\n",
    "We can extend the monitoring service from Chapter 73 to log which model was used for each prediction and compute per\u2011model metrics. Alerts can be set up if a particular model's performance drops below a threshold.\n",
    "\n",
    "### **83.7.1 Automated Retraining and Recalibration**\n",
    "\n",
    "- For routing models, if the classifier's accuracy drops, we may need to retrain it with new regime labels.\n",
    "- For stacking, the meta\u2011model weights can be recalibrated periodically using recent out\u2011of\u2011sample predictions.\n",
    "- For individual models, retraining schedules may differ (e.g., complex models retrained less often).\n",
    "\n",
    "---\n",
    "\n",
    "## **83.8 Trade\u2011offs and Best Practices**\n",
    "\n",
    "### **83.8.1 Accuracy vs. Complexity**\n",
    "Adding more models generally improves accuracy up to a point, but the gain diminishes. Consider the computational cost and maintenance overhead.\n",
    "\n",
    "### **83.8.2 Latency**\n",
    "Ensembles that run models in parallel can be acceptable if each model is fast. Cascades can reduce average latency but may have high latency for the worst\u2011case path.\n",
    "\n",
    "### **83.8.3 Interpretability**\n",
    "Simple models are more interpretable. In a multi\u2011model system, you can still provide explanations from the simple model when it is used, or use SHAP on the ensemble (though it becomes complex).\n",
    "\n",
    "### **83.8.4 Testing**\n",
    "Test each model individually and the combined system. Ensure that the routing logic itself doesn't introduce bias.\n",
    "\n",
    "### **83.8.5 Start Simple**\n",
    "Begin with a single strong model. Add multi\u2011model complexity only when you have evidence that it improves performance on a hold\u2011out set.\n",
    "\n",
    "---\n",
    "\n",
    "## **83.9 Case Study: Multi\u2011Model NEPSE System in Production**\n",
    "\n",
    "Imagine a production NEPSE system that uses:\n",
    "\n",
    "- A **LightGBM model** as the primary workhorse.\n",
    "- An **LSTM model** for high\u2011volatility regimes, triggered by a router.\n",
    "- A **simple ARIMA** as a fallback if the primary model is unavailable.\n",
    "- An **ensemble** of the LightGBM and LSTM for the final prediction during volatile periods.\n",
    "\n",
    "The system logs predictions and model usage. Once a week, a batch job recomputes the router's classifier and retrains the LightGBM model on new data. The LSTM is retrained monthly due to higher computational cost.\n",
    "\n",
    "If the ensemble's performance degrades, an alert is sent to the data science team.\n",
    "\n",
    "---\n",
    "\n",
    "## **83.10 Future Directions**\n",
    "\n",
    "- **Automated model selection**: Use meta\u2011learning to choose the best model architecture based on time\u2011series characteristics.\n",
    "- **Neural architecture search** for time\u2011series: automatically discover the best model combination.\n",
    "- **Online learning** for routers: adapt the routing policy in real time based on recent performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "In this chapter, we explored multi\u2011model systems for time\u2011series prediction. We discussed ensemble methods (bagging, boosting, stacking), model routing based on regime detection, and cascade systems that trade off accuracy for computational efficiency. We implemented a stacking ensemble for NEPSE using walk\u2011forward validation, a router using volatility regimes, and a simple cascade. We also covered monitoring, maintenance, and best practices. Multi\u2011model systems can significantly improve robustness and accuracy, but they require careful design and monitoring. In the next chapter, we will delve into **Real\u2011Time Learning Systems**, where models update continuously as new data arrives.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 83**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='82. event_driven_architecture.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='84. real_time_learning_systems.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}