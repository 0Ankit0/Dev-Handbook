{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 19: Defining Prediction Targets**\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Understand how to translate business goals into precise prediction targets\n",
    "- Design target variables appropriate for different forecasting horizons\n",
    "- Create binary, multi‑class, and regression targets from raw NEPSE data\n",
    "- Distinguish between price prediction, return prediction, and directional prediction\n",
    "- Implement probability targets and confidence intervals\n",
    "- Prevent target leakage when constructing labels\n",
    "- Validate targets for consistency and practical utility\n",
    "- Choose the right target for your specific trading or investment strategy\n",
    "\n",
    "---\n",
    "\n",
    "## **19.1 Understanding Your Prediction Goal**\n",
    "\n",
    "Before writing any code or training any model, you must be crystal clear about what you are trying to predict. The prediction target is the variable your model will learn to forecast. In the context of the NEPSE stock prediction system, the goal might be:\n",
    "\n",
    "- **Predict the exact closing price** for tomorrow – useful for limit orders or valuation.\n",
    "- **Predict the direction of price movement** (up/down) – sufficient for many trading strategies.\n",
    "- **Predict the magnitude of return** – for position sizing.\n",
    "- **Predict volatility** – for risk management.\n",
    "- **Predict whether a stock will hit its circuit breaker** – a binary event.\n",
    "\n",
    "Each goal leads to a different target variable and often a different modeling approach. Defining the target correctly is the most important step in the entire pipeline; a poorly chosen target will yield useless models no matter how sophisticated the features.\n",
    "\n",
    "### **19.1.1 Connecting Business Goals to Targets**\n",
    "\n",
    "Let’s consider a few realistic scenarios for a trader using the NEPSE system:\n",
    "\n",
    "| Business Goal | Desired Prediction | Target Type | Example Target |\n",
    "|---------------|--------------------|-------------|----------------|\n",
    "| Buy at a specific price tomorrow | Exact closing price | Regression | `Close` at t+1 |\n",
    "| Decide whether to buy or sell | Direction (up/down) | Binary classification | 1 if `Close` at t+1 > `Close` at t, else 0 |\n",
    "| Scale position size | Magnitude of return | Regression | `(Close_{t+1} - Close_t) / Close_t` |\n",
    "| Avoid circuit breaker hits | Probability of hitting upper circuit | Probability / Binary | 1 if `Daily_Return` ≥ 4% |\n",
    "| Hedge volatility | Future volatility | Regression | 20-day rolling standard deviation of returns |\n",
    "\n",
    "In this chapter, we will focus on the most common targets: next-day close price, next-day return, and direction. However, the principles apply to any target you might define.\n",
    "\n",
    "---\n",
    "\n",
    "## **19.2 Target Variable Design**\n",
    "\n",
    "Designing a target variable involves deciding what exactly the model should predict and over what horizon. The raw NEPSE CSV contains many columns, but the most common source for targets is the `Close` price. However, we must be careful: using raw prices can lead to non‑stationarity issues (see Chapter 2). Often it is better to predict returns or transformations that are more stationary.\n",
    "\n",
    "### **19.2.1 Predicting Raw Prices**\n",
    "\n",
    "Predicting the exact future closing price is the most direct regression task. It is straightforward to implement:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load NEPSE data\n",
    "df = pd.read_csv('nepse_data.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values(['Symbol', 'Date']).reset_index(drop=True)\n",
    "\n",
    "# Create target: next day's closing price\n",
    "df['Target_Close_t+1'] = df.groupby('Symbol')['Close'].shift(-1)\n",
    "\n",
    "# Check the result\n",
    "print(df[['Date', 'Symbol', 'Close', 'Target_Close_t+1']].head(10))\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- We use `groupby('Symbol')` because each symbol has its own time series. Without grouping, the shift would incorrectly use the next row even if it belongs to a different stock.\n",
    "- `shift(-1)` moves the next day's close value up by one row. For the last row of each symbol, the target will be `NaN` (since there is no next day). We will drop those rows later.\n",
    "- This target is intuitive: the model learns to output a number that should be as close as possible to the actual next closing price.\n",
    "\n",
    "**Drawbacks of raw price targets:**\n",
    "- Prices are non‑stationary; they trend over time. A model trained on old prices may not generalize to new price levels.\n",
    "- Performance metrics like RMSE are scale‑dependent; a stock trading at 1000 NPR will have larger errors than one at 100 NPR, even if the relative error is the same.\n",
    "\n",
    "### **19.2.2 Predicting Returns**\n",
    "\n",
    "Returns (percentage changes) are much more stationary than raw prices. Most financial forecasting models use returns as the target. The daily return can be computed as:\n",
    "\n",
    "```\n",
    "Return_t+1 = (Close_t+1 - Close_t) / Close_t\n",
    "```\n",
    "\n",
    "or in log form: `log(Close_t+1) - log(Close_t)`.\n",
    "\n",
    "```python\n",
    "# Compute daily return\n",
    "df['Return'] = df.groupby('Symbol')['Close'].pct_change()\n",
    "\n",
    "# Target: next day's return\n",
    "df['Target_Return_t+1'] = df.groupby('Symbol')['Return'].shift(-1)\n",
    "\n",
    "# For the first row of each symbol, Return will be NaN; we'll handle later.\n",
    "print(df[['Date', 'Symbol', 'Close', 'Return', 'Target_Return_t+1']].head(10))\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- `pct_change()` calculates the percentage change from the previous row within each symbol group. This gives us today's return (based on yesterday's close).\n",
    "- We then shift that return backward to align today's features with tomorrow's return. So at row `t`, we have features from day `t` and the target is the return from day `t` to day `t+1`.\n",
    "- Returns are typically centered around zero and have more stable statistical properties than prices. Models predicting returns often generalize better across different market regimes.\n",
    "\n",
    "**Log returns** are often preferred because they are approximately normally distributed and additive over time:\n",
    "\n",
    "```python\n",
    "df['Log_Close'] = np.log(df['Close'])\n",
    "df['Log_Return'] = df.groupby('Symbol')['Log_Close'].diff()\n",
    "df['Target_LogReturn_t+1'] = df.groupby('Symbol')['Log_Return'].shift(-1)\n",
    "```\n",
    "\n",
    "Log returns are approximately equal to simple returns for small changes, but they have nicer mathematical properties.\n",
    "\n",
    "### **19.2.3 Predicting Direction**\n",
    "\n",
    "For many trading strategies, only the direction matters – whether the price will go up or down. This simplifies the problem to binary classification.\n",
    "\n",
    "```python\n",
    "# Binary direction: 1 if next day's close > today's close, else 0\n",
    "df['Target_Direction_t+1'] = (\n",
    "    df.groupby('Symbol')['Close'].shift(-1) > df['Close']\n",
    ").astype(int)\n",
    "\n",
    "# Check distribution\n",
    "print(df['Target_Direction_t+1'].value_counts(normalize=True))\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- The comparison `shift(-1) > df['Close']` creates a boolean Series. We convert it to integer (0/1).\n",
    "- This target ignores the magnitude of the move – a 0.1% increase is treated the same as a 10% increase. This can be both a strength (less sensitive to noise) and a weakness (doesn't differentiate between small and large moves).\n",
    "- Class imbalance: In trending markets, ups may outnumber downs, or vice versa. We may need to handle imbalance (e.g., via class weights or resampling).\n",
    "\n",
    "We could also create a ternary target: up, down, or no change (within a threshold). For example, define \"no change\" as absolute return < 0.5%.\n",
    "\n",
    "```python\n",
    "# Multi-class direction\n",
    "def direction_class(ret, threshold=0.005):\n",
    "    if ret > threshold:\n",
    "        return 2  # up\n",
    "    elif ret < -threshold:\n",
    "        return 0  # down\n",
    "    else:\n",
    "        return 1  # flat\n",
    "\n",
    "df['Target_Multi'] = df['Target_Return_t+1'].apply(lambda x: direction_class(x) if pd.notna(x) else np.nan)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **19.3 Time Horizon Selection**\n",
    "\n",
    "The prediction horizon determines how far into the future we are forecasting. The NEPSE data is daily, so natural horizons are:\n",
    "\n",
    "- **Short‑term:** 1 to 5 days ahead (next day to next week)\n",
    "- **Medium‑term:** 5 to 20 days ahead (up to one month)\n",
    "- **Long‑term:** 20+ days ahead (multi‑month)\n",
    "\n",
    "### **19.3.1 Short‑Term Horizons**\n",
    "\n",
    "For a day trader or swing trader, the focus is on 1‑ to 5‑day forecasts. These are the most common in machine learning for finance because patterns are more discernible over short periods.\n",
    "\n",
    "```python\n",
    "# Short-term: 1-day ahead (already shown)\n",
    "# 3-day ahead target (closing price in 3 days)\n",
    "df['Target_Close_t+3'] = df.groupby('Symbol')['Close'].shift(-3)\n",
    "\n",
    "# 3-day return\n",
    "df['Target_Return_t+3'] = (df.groupby('Symbol')['Close'].shift(-3) / df['Close']) - 1\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- `shift(-3)` aligns today's features with the closing price three trading days later. Note that weekends and holidays mean \"3 trading days\" may span more than 3 calendar days, but for a trading system that's exactly what we want.\n",
    "- The further we predict, the noisier and less accurate the forecasts tend to be.\n",
    "\n",
    "### **19.3.2 Medium‑Term Horizons**\n",
    "\n",
    "Medium‑term forecasts (e.g., 10 or 20 days) are relevant for position traders or portfolio rebalancing.\n",
    "\n",
    "```python\n",
    "# 10-day ahead return\n",
    "df['Target_Return_t+10'] = (df.groupby('Symbol')['Close'].shift(-10) / df['Close']) - 1\n",
    "```\n",
    "\n",
    "**Caution:** With longer horizons, the overlap between training and test periods in cross‑validation becomes more complex. We must ensure that our validation strategy respects that future information is not leaked.\n",
    "\n",
    "### **19.3.3 Multi‑Step Forecasting**\n",
    "\n",
    "If you need forecasts for multiple horizons simultaneously, you have two choices:\n",
    "\n",
    "1. **Direct approach:** Train separate models for each horizon (e.g., one model for t+1, another for t+2, etc.).\n",
    "2. **Recursive approach:** Train one model for t+1, then use its predictions as features to predict t+2, and so on.\n",
    "\n",
    "The direct approach is simpler and often more accurate, though it requires maintaining multiple models. The recursive approach can compound errors.\n",
    "\n",
    "```python\n",
    "# Direct multi-step example\n",
    "horizons = [1, 2, 3, 5, 10]\n",
    "targets = {}\n",
    "for h in horizons:\n",
    "    targets[f'Target_t+{h}'] = df.groupby('Symbol')['Close'].shift(-h)\n",
    "\n",
    "# Now you have separate columns, each can be used to train a dedicated model.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **19.4 Binary Classification Targets**\n",
    "\n",
    "Binary classification is widely used for directional forecasting. The target is typically 1 for \"up\" and 0 for \"down\". However, we must define what \"up\" means precisely.\n",
    "\n",
    "### **19.4.1 Simple Up/Down**\n",
    "\n",
    "The simplest definition: up if next close > current close.\n",
    "\n",
    "```python\n",
    "df['Target_Up'] = (df.groupby('Symbol')['Close'].shift(-1) > df['Close']).astype(int)\n",
    "```\n",
    "\n",
    "### **19.4.2 Threshold‑Based Up/Down**\n",
    "\n",
    "To avoid predicting tiny, random movements, we can define a threshold. Only moves larger than a certain percentage are considered \"up\" or \"down\"; moves within the threshold are discarded or treated as a third class.\n",
    "\n",
    "```python\n",
    "threshold = 0.01  # 1%\n",
    "future_return = (df.groupby('Symbol')['Close'].shift(-1) / df['Close']) - 1\n",
    "\n",
    "df['Target_Up_Threshold'] = 0\n",
    "df.loc[future_return > threshold, 'Target_Up_Threshold'] = 1\n",
    "df.loc[future_return < -threshold, 'Target_Up_Threshold'] = -1   # or 0 if binary\n",
    "\n",
    "# For binary classification, we might keep only rows with |return| > threshold\n",
    "# and map -1 to 0 for down.\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- This creates a cleaner signal, ignoring noise. However, it reduces the number of training samples and may discard valuable information if small moves are actually predictable.\n",
    "- In practice, you might experiment with different thresholds based on transaction costs – you only care about moves large enough to be profitable after costs.\n",
    "\n",
    "### **19.4.3 Event‑Based Targets**\n",
    "\n",
    "Sometimes you want to predict a specific event, such as hitting the upper circuit breaker (≥4% gain in NEPSE). This is a binary target.\n",
    "\n",
    "```python\n",
    "# Daily return (using Prev. Close if available, else compute)\n",
    "if 'Prev. Close' in df.columns:\n",
    "    df['Daily_Return'] = (df['Close'] - df['Prev. Close']) / df['Prev. Close']\n",
    "else:\n",
    "    df['Daily_Return'] = df.groupby('Symbol')['Close'].pct_change()\n",
    "\n",
    "# Target: 1 if tomorrow's return is >= 4% (upper circuit), else 0\n",
    "tomorrow_return = df.groupby('Symbol')['Daily_Return'].shift(-1)\n",
    "df['Target_UpperCircuit'] = (tomorrow_return >= 0.04).astype(int)\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- Circuit breaker events are rare (class imbalance). Predicting them is a classic rare‑event prediction problem. We would need special techniques (e.g., oversampling, cost‑sensitive learning) to handle the imbalance.\n",
    "\n",
    "---\n",
    "\n",
    "## **19.5 Regression Targets**\n",
    "\n",
    "Regression targets predict a continuous value. The most common are price, return, and volatility.\n",
    "\n",
    "### **19.5.1 Price Regression**\n",
    "\n",
    "Already covered in 19.2.1. One nuance: when predicting price, we often use log price to stabilize variance.\n",
    "\n",
    "```python\n",
    "df['Log_Close'] = np.log(df['Close'])\n",
    "df['Target_LogClose_t+1'] = df.groupby('Symbol')['Log_Close'].shift(-1)\n",
    "```\n",
    "\n",
    "After prediction, we can exponentiate to get price.\n",
    "\n",
    "### **19.5.2 Return Regression**\n",
    "\n",
    "Predicting the exact return (percentage change) is the standard approach in academic finance.\n",
    "\n",
    "```python\n",
    "df['Target_Return_t+1'] = df.groupby('Symbol')['Close'].pct_change().shift(-1)\n",
    "```\n",
    "\n",
    "**Why returns?** Returns are scale‑free and more stationary. They also align with financial theory (asset returns are often modeled as random walks plus drift).\n",
    "\n",
    "### **19.5.3 Volatility Regression**\n",
    "\n",
    "Volatility forecasting is crucial for risk management. We can define volatility as the standard deviation of returns over a future window, or as the daily price range.\n",
    "\n",
    "```python\n",
    "# Future 5-day realized volatility (standard deviation of daily returns)\n",
    "# First, compute daily returns\n",
    "df['Return'] = df.groupby('Symbol')['Close'].pct_change()\n",
    "\n",
    "# For each day, compute the standard deviation of returns over the next 5 days\n",
    "# This requires a rolling forward window – careful with lookahead\n",
    "def future_volatility(series, window=5):\n",
    "    return series.rolling(window).std().shift(-window)\n",
    "\n",
    "df['Target_Volatility_t+5'] = df.groupby('Symbol')['Return'].apply(\n",
    "    lambda x: future_volatility(x, 5)\n",
    ")\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- `future_volatility` computes the rolling standard deviation and then shifts it backward so that today's row contains the volatility of the next `window` days.\n",
    "- This target is useful for models that predict risk, not just return.\n",
    "\n",
    "---\n",
    "\n",
    "## **19.6 Multi‑Class Classification Targets**\n",
    "\n",
    "Sometimes binary up/down is too coarse, and regression is too detailed. Multi‑class offers a middle ground. Common classes:\n",
    "\n",
    "- Strong down, down, flat, up, strong up\n",
    "- Or based on quantiles of historical returns\n",
    "\n",
    "### **19.6.1 Quantile‑Based Classes**\n",
    "\n",
    "Divide the distribution of future returns into quantiles (e.g., quintiles).\n",
    "\n",
    "```python\n",
    "# For each symbol, compute future return quantiles\n",
    "future_return = df.groupby('Symbol')['Close'].pct_change().shift(-1)\n",
    "\n",
    "# Drop NaNs and compute quantile bins\n",
    "valid = future_return.dropna()\n",
    "quantiles = pd.qcut(valid, q=5, labels=['Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "\n",
    "# Map back to original index\n",
    "df['Target_Quintile'] = np.nan\n",
    "df.loc[valid.index, 'Target_Quintile'] = quantiles\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- This creates five classes of equal frequency. The model learns to predict which quintile the next return falls into.\n",
    "- This can be useful for strategies that differentiate between strong and weak moves, but the classes are relative to the historical distribution, which may shift over time.\n",
    "\n",
    "### **19.6.2 Fixed Threshold Classes**\n",
    "\n",
    "Define classes based on fixed economic thresholds, e.g.,:\n",
    "- Class 0: return < -2%\n",
    "- Class 1: -2% ≤ return < 0%\n",
    "- Class 2: 0% ≤ return < 2%\n",
    "- Class 3: return ≥ 2%\n",
    "\n",
    "```python\n",
    "def return_class(ret):\n",
    "    if pd.isna(ret):\n",
    "        return np.nan\n",
    "    if ret < -0.02:\n",
    "        return 0\n",
    "    elif ret < 0:\n",
    "        return 1\n",
    "    elif ret < 0.02:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "df['Target_Class'] = future_return.apply(return_class)\n",
    "```\n",
    "\n",
    "These thresholds are stable over time and interpretable.\n",
    "\n",
    "---\n",
    "\n",
    "## **19.7 Probability Targets**\n",
    "\n",
    "Sometimes we want the model to output a probability – e.g., probability that the return exceeds 2%, or probability of an up move. This can be achieved by:\n",
    "\n",
    "- Using a probabilistic model (e.g., logistic regression outputs probabilities).\n",
    "- Training a classifier and calibrating its outputs (e.g., Platt scaling).\n",
    "- Using quantile regression or distribution forecasting.\n",
    "\n",
    "For the NEPSE system, probability targets are useful for risk‑adjusted decision making.\n",
    "\n",
    "### **19.7.1 Binary Probability Target**\n",
    "\n",
    "If we define a binary event, a classifier can output the probability of that event. For example, probability of an up move.\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Assume X_train, y_train (binary) are ready\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get probabilities\n",
    "probs = model.predict_proba(X_test)[:, 1]  # probability of class 1\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- `predict_proba` returns an array of shape (n_samples, n_classes). For binary classification, the second column is the probability of the positive class.\n",
    "- These probabilities can be used directly for position sizing (e.g., Kelly criterion) or for ranking trades.\n",
    "\n",
    "### **19.7.2 Quantile Regression for Probabilistic Forecasts**\n",
    "\n",
    "Quantile regression predicts specific quantiles of the target distribution, giving a full probabilistic forecast without assuming a distributional form.\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Train a model to predict the 0.1 quantile (lower bound)\n",
    "model_lower = GradientBoostingRegressor(loss='quantile', alpha=0.1)\n",
    "model_lower.fit(X_train, y_train)  # y_train is return\n",
    "\n",
    "# Predict the 0.9 quantile (upper bound)\n",
    "model_upper = GradientBoostingRegressor(loss='quantile', alpha=0.9)\n",
    "model_upper.fit(X_train, y_train)\n",
    "\n",
    "lower = model_lower.predict(X_test)\n",
    "upper = model_upper.predict(X_test)\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- Gradient boosting with `loss='quantile'` directly estimates the conditional quantile. This gives us prediction intervals without any parametric assumptions.\n",
    "- The interval [lower, upper] should contain the true value 80% of the time (if the model is well‑calibrated).\n",
    "\n",
    "---\n",
    "\n",
    "## **19.8 Creating Labels from Raw Data**\n",
    "\n",
    "Labels are the actual values of the target variable for historical data. They must be created carefully to avoid using future information. The `shift` operation is the primary tool, but there are nuances.\n",
    "\n",
    "### **19.8.1 Using `shift` Correctly**\n",
    "\n",
    "Always use `groupby` to ensure shifts are within each symbol's time series. Also, be mindful of missing days (e.g., weekends, holidays). If your data includes only trading days, `shift` works perfectly. If there are gaps, you may need to reindex to a continuous calendar and then fill.\n",
    "\n",
    "```python\n",
    "# Correct: shift within each symbol\n",
    "df['Target'] = df.groupby('Symbol')['Close'].shift(-1)\n",
    "\n",
    "# Incorrect: global shift (mixes symbols)\n",
    "df['Target_wrong'] = df['Close'].shift(-1)  # WRONG\n",
    "```\n",
    "\n",
    "### **19.8.2 Handling Non‑Trading Days**\n",
    "\n",
    "If your dataset includes only trading days, there is no issue. But if you ever need to predict over calendar days (e.g., Monday from Friday's close), you must account for the weekend gap. In that case, you would reindex each symbol to a daily calendar and then shift.\n",
    "\n",
    "```python\n",
    "# Example: reindex to daily calendar for one symbol\n",
    "symbol_df = df[df['Symbol'] == 'NEPSE'].set_index('Date').asfreq('D')\n",
    "# Now shift works with calendar days, but you'll have many NaN rows for non‑trading days.\n",
    "```\n",
    "\n",
    "For most trading systems, using trading days is appropriate because that's when you can actually trade.\n",
    "\n",
    "### **19.8.3 Creating Multi‑Horizon Labels**\n",
    "\n",
    "For multi‑horizon forecasting, you create multiple target columns, each shifted by a different amount. Ensure you have enough data for the longest horizon (the last `h` rows of each symbol will have NaN targets and must be dropped).\n",
    "\n",
    "```python\n",
    "horizons = [1, 2, 3, 5, 10]\n",
    "for h in horizons:\n",
    "    df[f'Target_t+{h}'] = df.groupby('Symbol')['Close'].shift(-h)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **19.9 Target Leakage Prevention**\n",
    "\n",
    "Target leakage occurs when information from the future is inadvertently used to create the target or features. This is a critical pitfall in time‑series. For targets, the main leakage risk is using data that wouldn't be available at the \"prediction time\" to compute the target.\n",
    "\n",
    "### **19.9.1 Leakage in Target Creation**\n",
    "\n",
    "Consider using `Prev. Close` to compute today's return and then using that return as a target for tomorrow. That's fine because `Prev. Close` is known today. But if you use tomorrow's `High` to compute a target, that's leakage.\n",
    "\n",
    "```python\n",
    "# LEAKAGE EXAMPLE (WRONG)\n",
    "df['Target_Leaky'] = (df.groupby('Symbol')['High'].shift(-1) - df['Close']) / df['Close']\n",
    "# This uses tomorrow's High, which is not known today.\n",
    "```\n",
    "\n",
    "Always ensure your target uses only information that would be available at the time you are predicting. For a target like \"next day's close\", it's fine because you are explicitly using future data as the label – that's the definition of a target. The key is that when you train, you must not use any future information in the **features**. The target is allowed to be from the future because it's what you're trying to predict.\n",
    "\n",
    "### **19.9.2 Leakage in Feature Engineering for Target**\n",
    "\n",
    "Sometimes you might accidentally create features that include the target value. For example, if you compute a rolling mean that includes the current day's target, you leak.\n",
    "\n",
    "```python\n",
    "# LEAKAGE: using future data in feature\n",
    "df['SMA_5_leaky'] = df['Close'].rolling(5).mean()  # includes today's close\n",
    "# But if your target is tomorrow's close, today's close is valid as a feature.\n",
    "# However, if you were predicting today's close, using today's close would be leakage.\n",
    "```\n",
    "\n",
    "Always think about the temporal order: features must be from time `t` or earlier; target is from time `t+1` or later.\n",
    "\n",
    "### **19.9.3 Validation Leakage**\n",
    "\n",
    "When you split data, ensure that no target information from the validation set is used to create features for the training set. This is why we use time‑based splits and never random shuffles.\n",
    "\n",
    "---\n",
    "\n",
    "## **19.10 Target Validation**\n",
    "\n",
    "After creating your target, you should validate that it makes sense and is suitable for your modeling task.\n",
    "\n",
    "### **19.10.1 Basic Checks**\n",
    "\n",
    "- **Missing values:** After shifting, the last `h` rows for each symbol will be NaN. Check that you have enough data.\n",
    "- **Distribution:** Plot the target distribution. For returns, it should be roughly symmetric around zero. For binary classification, check class balance.\n",
    "- **Stationarity:** For regression targets, run an Augmented Dickey‑Fuller test to see if the target is stationary. Returns usually are; prices are not.\n",
    "\n",
    "```python\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Test stationarity of returns for one symbol\n",
    "returns = df[df['Symbol']=='NEPSE']['Return'].dropna()\n",
    "result = adfuller(returns)\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "if result[1] <= 0.05:\n",
    "    print(\"Series is stationary\")\n",
    "else:\n",
    "    print(\"Series is non-stationary\")\n",
    "```\n",
    "\n",
    "### **19.10.2 Persistence and Random Walk Baseline**\n",
    "\n",
    "For returns, the simplest baseline is the historical mean (zero). For direction, the persistence model (predict \"up\" if today was up) is a common baseline. Compare your target's predictability against these baselines.\n",
    "\n",
    "```python\n",
    "# Persistence baseline for direction\n",
    "df['Prev_Direction'] = df.groupby('Symbol')['Target_Direction_t+1'].shift(1)\n",
    "# This is not a valid model for future, but it gives a baseline accuracy.\n",
    "```\n",
    "\n",
    "### **19.10.3 Economic Significance**\n",
    "\n",
    "Ultimately, the target must align with a profitable trading strategy. For example, if you predict direction with 51% accuracy, you might still lose money after transaction costs. Consider designing targets that incorporate costs directly (e.g., only predict moves large enough to cover costs).\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "In this chapter, we explored the critical first step of any prediction system: defining the target variable. Using the NEPSE dataset as our example, we covered:\n",
    "\n",
    "- **Understanding the business goal** – the target must reflect what you actually want to achieve.\n",
    "- **Designing target types:** regression (price, return, volatility), classification (binary, multi‑class), and probability targets.\n",
    "- **Horizon selection:** short‑term (1‑5 days), medium‑term (5‑20 days), and long‑term.\n",
    "- **Creating labels correctly** using `groupby` and `shift` to align features with future values.\n",
    "- **Preventing target leakage** – ensuring no future information contaminates the training process.\n",
    "- **Validating targets** – checking stationarity, distribution, and baseline comparisons.\n",
    "\n",
    "### **Practical Takeaways for the NEPSE System:**\n",
    "\n",
    "- For most trading strategies, predicting **returns** (not raw prices) is preferable due to stationarity.\n",
    "- **Directional targets** simplify the problem and are sufficient for many strategies, but may ignore magnitude.\n",
    "- **Multi‑class targets** can differentiate between strong and weak moves.\n",
    "- Always use **time‑aware splits** and never shuffle when creating training and test sets.\n",
    "- Validate that your target is **predictable beyond a naive baseline** before investing in complex models.\n",
    "\n",
    "With well‑defined targets, we are ready to build models that learn meaningful patterns. In the next chapter, **Chapter 20: Data Splitting Strategies**, we will explore how to properly divide time‑series data for training, validation, and testing, ensuring our models are evaluated realistically.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 19**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
