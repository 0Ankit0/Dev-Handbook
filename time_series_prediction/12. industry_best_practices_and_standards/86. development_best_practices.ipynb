{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 86: Development Best Practices\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Understand the importance of code quality and maintainability in time\u2011series prediction systems.\n",
    "- Apply coding standards (PEP\u00a08, docstrings, type hints) to improve readability and reduce errors.\n",
    "- Implement a comprehensive testing strategy, including unit tests, integration tests, and data validation tests.\n",
    "- Establish an effective code review process that catches issues early and shares knowledge.\n",
    "- Write clear documentation for code, APIs, and models to ensure long\u2011term usability.\n",
    "- Use version control effectively with feature branches, commit conventions, and tagging.\n",
    "- Set up continuous integration and continuous deployment (CI/CD) pipelines for automated testing and deployment.\n",
    "- Recognise and manage technical debt to keep the system healthy.\n",
    "- Foster a culture of knowledge sharing and continuous improvement within the team.\n",
    "\n",
    "---\n",
    "\n",
    "## **86.1 Introduction to Development Best Practices**\n",
    "\n",
    "Building a time\u2011series prediction system, such as the NEPSE stock predictor, is not just about training a good model. The codebase must be robust, maintainable, and scalable. In a team environment, multiple developers contribute to the system over time. Without best practices, the code can become a tangled mess (often called \u201ctechnical debt\u201d), leading to bugs, slow development, and eventually system failure.\n",
    "\n",
    "Best practices are not one\u2011time activities but ongoing disciplines. They cover the entire software development lifecycle: writing code, testing, reviewing, documenting, deploying, and maintaining. In this chapter, we will cover the essential practices that every team working on a prediction system should adopt, with concrete examples drawn from the NEPSE project.\n",
    "\n",
    "---\n",
    "\n",
    "## **86.2 Code Quality Standards**\n",
    "\n",
    "### **86.2.1 PEP\u00a08 and Style Guides**\n",
    "\n",
    "Python code should follow **PEP\u00a08**, the official style guide. Consistent style makes code easier to read and maintain. Key points:\n",
    "\n",
    "- Use 4 spaces per indentation level.\n",
    "- Limit lines to 79 characters for code, 72 for docstrings.\n",
    "- Use blank lines to separate functions and classes.\n",
    "- Use descriptive variable names (`close_price` not `cp`).\n",
    "\n",
    "Tools like `flake8`, `pylint`, and `black` (auto\u2011formatter) help enforce these rules. Integrating them into the CI pipeline ensures that all code meets the standard.\n",
    "\n",
    "**Example: Inconsistent vs. Consistent Code**\n",
    "\n",
    "```python\n",
    "# Inconsistent (hard to read)\n",
    "def calc_mae(p,a): return sum(abs(p-a))/len(p)\n",
    "\n",
    "# Consistent (clear)\n",
    "def calculate_mean_absolute_error(predictions, actuals):\n",
    "    \"\"\"Calculate the mean absolute error between predictions and actuals.\"\"\"\n",
    "    errors = [abs(p - a) for p, a in zip(predictions, actuals)]\n",
    "    return sum(errors) / len(errors)\n",
    "```\n",
    "\n",
    "### **86.2.2 Docstrings and Comments**\n",
    "\n",
    "Docstrings describe what a function, class, or module does. Use the **Google** or **NumPy** style. For the NEPSE system, every public function should have a docstring.\n",
    "\n",
    "```python\n",
    "def fetch_nepse_data(date):\n",
    "    \"\"\"\n",
    "    Fetch raw NEPSE data for a given date.\n",
    "\n",
    "    Args:\n",
    "        date (datetime.date): The date for which to fetch data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns ['Symbol', 'Open', 'High', 'Low', 'Close', 'Vol'].\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no data is available for the given date.\n",
    "    \"\"\"\n",
    "    # implementation...\n",
    "```\n",
    "\n",
    "Comments should explain **why**, not **what**. The code itself should show what it does.\n",
    "\n",
    "### **86.2.3 Type Hints**\n",
    "\n",
    "Type hints improve code readability and allow static type checkers (e.g., `mypy`) to catch errors. Python 3.6+ supports them.\n",
    "\n",
    "```python\n",
    "from typing import List, Optional\n",
    "import pandas as pd\n",
    "\n",
    "def engineer_features(\n",
    "    df: pd.DataFrame,\n",
    "    symbols: Optional[List[str]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Engineer features from raw NEPSE data.\n",
    "    If symbols is provided, filter to those symbols.\n",
    "    \"\"\"\n",
    "    ...\n",
    "```\n",
    "\n",
    "**Benefits**: Better IDE autocompletion, fewer runtime type errors, and self\u2011documenting code.\n",
    "\n",
    "---\n",
    "\n",
    "## **86.3 Testing Strategies**\n",
    "\n",
    "Testing is essential to ensure that changes do not break existing functionality. For a prediction system, we need tests at multiple levels.\n",
    "\n",
    "### **86.3.1 Unit Tests**\n",
    "\n",
    "Unit tests verify individual functions or methods. They should be fast and isolated (no external dependencies like databases or APIs). Use `pytest` as the testing framework.\n",
    "\n",
    "**Example**: Testing a function that computes daily returns.\n",
    "\n",
    "```python\n",
    "# feature_engineering.py\n",
    "def compute_daily_return(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add a column 'daily_return' as percentage change of 'Close'.\"\"\"\n",
    "    df = df.copy()\n",
    "    df['daily_return'] = df['Close'].pct_change() * 100\n",
    "    return df\n",
    "\n",
    "# test_feature_engineering.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from feature_engineering import compute_daily_return\n",
    "\n",
    "def test_compute_daily_return():\n",
    "    data = pd.DataFrame({\n",
    "        'Close': [100, 105, 103, 108]\n",
    "    })\n",
    "    result = compute_daily_return(data)\n",
    "    expected = [np.nan, 5.0, -1.90476, 4.85437]  # approximate\n",
    "    pd.testing.assert_series_equal(\n",
    "        result['daily_return'],\n",
    "        pd.Series(expected, name='daily_return'),\n",
    "        check_less_precise=True\n",
    "    )\n",
    "```\n",
    "\n",
    "**Best practices**: Test edge cases (empty DataFrame, single row, missing values). Use parameterised tests to cover multiple scenarios.\n",
    "\n",
    "### **86.3.2 Integration Tests**\n",
    "\n",
    "Integration tests verify that components work together correctly, e.g., the feature engineering pipeline followed by model training. They may involve a test database or file system.\n",
    "\n",
    "**Example**: Test that the full pipeline from raw data to prediction does not crash.\n",
    "\n",
    "```python\n",
    "def test_end_to_end(tmp_path):\n",
    "    # Create a small synthetic dataset\n",
    "    raw_data = pd.DataFrame(...)\n",
    "    raw_path = tmp_path / \"raw.parquet\"\n",
    "    raw_data.to_parquet(raw_path)\n",
    "\n",
    "    # Run ingestion\n",
    "    ingest = NEPSEIngestion()\n",
    "    df = ingest.fetch_from_csv(raw_path)\n",
    "\n",
    "    # Run feature engineering\n",
    "    engineer = NEPSEFeatureEngineer()\n",
    "    features = engineer.compute_features(df)\n",
    "\n",
    "    # Train a tiny model\n",
    "    model = xgb.XGBRegressor(n_estimators=5)\n",
    "    X = features[engineer.feature_columns]\n",
    "    y = features['Close']\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Make a prediction\n",
    "    pred = model.predict(X.iloc[[0]])\n",
    "    assert pred is not None\n",
    "```\n",
    "\n",
    "Integration tests are slower, so run them less frequently (e.g., in CI but not on every save).\n",
    "\n",
    "### **86.3.3 Data Quality Tests**\n",
    "\n",
    "In a prediction system, data quality is critical. Tests should validate:\n",
    "\n",
    "- No missing values in critical columns.\n",
    "- Date ranges are as expected.\n",
    "- No duplicates (same symbol, same date).\n",
    "- Prices are positive, volume non\u2011negative.\n",
    "\n",
    "These can be implemented as assertions in the data ingestion or as separate test scripts.\n",
    "\n",
    "```python\n",
    "def test_data_quality(df):\n",
    "    assert df['Close'].min() > 0, \"Close prices must be positive\"\n",
    "    assert not df[['Symbol', 'Date']].duplicated().any(), \"Duplicate symbol-date pairs\"\n",
    "    # Check that dates are consecutive (no gaps)\n",
    "    date_diffs = df.groupby('Symbol')['Date'].diff().dt.days\n",
    "    assert (date_diffs.dropna() == 1).all(), \"Data should be daily with no gaps\"\n",
    "```\n",
    "\n",
    "### **86.3.4 Model Tests**\n",
    "\n",
    "Model tests ensure that trained models meet basic sanity checks:\n",
    "\n",
    "- Model can predict on a sample input.\n",
    "- Performance on a fixed validation set does not degrade beyond a threshold (regression testing).\n",
    "- Feature importance is not extreme (e.g., no single feature dominates).\n",
    "\n",
    "### **86.3.5 Test Coverage**\n",
    "\n",
    "Aim for high test coverage (e.g., >80%). Use `pytest-cov` to measure coverage. However, coverage is not a goal in itself; focus on testing critical paths.\n",
    "\n",
    "---\n",
    "\n",
    "## **86.4 Code Review Process**\n",
    "\n",
    "Code reviews are a powerful way to catch bugs, share knowledge, and maintain code quality.\n",
    "\n",
    "### **86.4.1 Review Checklist**\n",
    "\n",
    "A good code review checklist includes:\n",
    "\n",
    "- Does the code meet the style guide?\n",
    "- Are there unit tests for new functionality?\n",
    "- Is the logic correct? (Reviewer should understand the code.)\n",
    "- Are there any performance issues?\n",
    "- Is error handling appropriate?\n",
    "- Is documentation updated?\n",
    "\n",
    "### **86.4.2 Review Tools**\n",
    "\n",
    "Use platforms like GitHub, GitLab, or Bitbucket for pull requests. Require at least one approval before merging. Automated checks (linting, tests) should run and pass.\n",
    "\n",
    "### **86.4.3 Best Practices**\n",
    "\n",
    "- Keep pull requests small and focused (under 400 lines).\n",
    "- Be constructive and respectful in comments.\n",
    "- Explain *why* a change is needed in the description.\n",
    "- Rotate reviewers to spread knowledge.\n",
    "\n",
    "**Example PR description**:\n",
    "\n",
    "```\n",
    "## Description\n",
    "Adds a new feature: 14-day RSI to the feature engineering pipeline.\n",
    "- Implements RSI calculation as per technical analysis standard.\n",
    "- Adds unit tests for RSI on known data.\n",
    "- Updates feature list documentation.\n",
    "\n",
    "## Testing\n",
    "- Unit tests pass.\n",
    "- Ran end\u2011to\u2011end pipeline on one month of NEPSE data; RSI values look plausible.\n",
    "\n",
    "## Related Issue\n",
    "Closes #123\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **86.5 Documentation Strategies**\n",
    "\n",
    "Documentation is often neglected but vital for long\u2011term maintenance.\n",
    "\n",
    "### **86.5.1 Code Documentation**\n",
    "\n",
    "As covered earlier, use docstrings for all public modules, classes, and functions. Tools like Sphinx can generate HTML documentation from these docstrings.\n",
    "\n",
    "### **86.5.2 API Documentation**\n",
    "\n",
    "For services (e.g., prediction API), document endpoints, request/response formats, and error codes. FastAPI automatically generates OpenAPI (Swagger) docs.\n",
    "\n",
    "```python\n",
    "@app.post(\"/predict\", response_model=PredictionResponse)\n",
    "def predict(request: PredictionRequest):\n",
    "    \"\"\"\n",
    "    Predict the closing price for a given symbol and date.\n",
    "\n",
    "    The model uses features up to the day before the requested date.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "### **86.5.3 Architecture Documentation**\n",
    "\n",
    "Maintain high\u2011level documents describing the system architecture, data flow, and component interactions. Include diagrams (e.g., using C4 model) in a `docs/` folder.\n",
    "\n",
    "### **86.5.4 Model Documentation**\n",
    "\n",
    "For each model, create a **model card** (as introduced in Chapter 77). This card should include:\n",
    "\n",
    "- Model type and version.\n",
    "- Training data period and source.\n",
    "- Features used.\n",
    "- Performance metrics (overall and per subgroup).\n",
    "- Intended use and limitations.\n",
    "- Ethical considerations.\n",
    "\n",
    "**Example** (from Chapter 77):\n",
    "\n",
    "```markdown\n",
    "# Model Card: NEPSE Close Price Predictor v2.3\n",
    "\n",
    "## Description\n",
    "XGBoost regressor trained on daily NEPSE data from 2018\u20112022.\n",
    "\n",
    "## Performance\n",
    "- Overall MAE: 12.34\n",
    "- MAE on high\u2011volatility days (>3% change): 18.56\n",
    "- MAE on low\u2011volatility days: 8.21\n",
    "\n",
    "## Features\n",
    "Close_Lag_1, Close_Lag_5, SMA_20, RSI, Volume_Z_Score, ...\n",
    "\n",
    "## Limitations\n",
    "Not suitable for predicting during market holidays or after major policy announcements.\n",
    "```\n",
    "\n",
    "### **86.5.5 README and Onboarding**\n",
    "\n",
    "The repository `README.md` should explain how to set up the project, run tests, and contribute. Include a quick start guide for new team members.\n",
    "\n",
    "---\n",
    "\n",
    "## **86.6 Version Control**\n",
    "\n",
    "Git is the de facto standard. Best practices include:\n",
    "\n",
    "### **86.6.1 Branching Strategy**\n",
    "\n",
    "A common strategy is **GitHub Flow**:\n",
    "\n",
    "- `main` branch is always deployable.\n",
    "- Create feature branches from `main` (e.g., `feature/add\u2011rsi`).\n",
    "- Open a pull request to merge back.\n",
    "- After review, merge (usually squash merge to keep history clean).\n",
    "\n",
    "For larger teams, **Git Flow** with `develop` and release branches may be used, but for most ML projects, GitHub Flow is sufficient.\n",
    "\n",
    "### **86.6.2 Commit Messages**\n",
    "\n",
    "Follow the [Conventional Commits](https://www.conventionalcommits.org/) specification:\n",
    "\n",
    "```\n",
    "feat: add RSI feature\n",
    "fix: correct off-by-one error in lag calculation\n",
    "docs: update API documentation for /predict\n",
    "test: add unit tests for compute_daily_return\n",
    "```\n",
    "\n",
    "This makes it easy to generate changelogs and automate versioning.\n",
    "\n",
    "### **86.6.3 Tagging Releases**\n",
    "\n",
    "When a new version of the model or API is deployed, tag the commit with a version number (e.g., `v2.3.0`). This allows rolling back to a known state if needed.\n",
    "\n",
    "### **86.6.4 Ignoring Unnecessary Files**\n",
    "\n",
    "Use `.gitignore` to exclude virtual environments, notebooks with output, data files, and credentials.\n",
    "\n",
    "---\n",
    "\n",
    "## **86.7 CI/CD Pipelines**\n",
    "\n",
    "Continuous Integration (CI) automatically runs tests on every push. Continuous Deployment (CD) automatically deploys to staging or production after tests pass.\n",
    "\n",
    "### **86.7.1 CI Pipeline**\n",
    "\n",
    "A typical CI pipeline for a Python project includes:\n",
    "\n",
    "- Linting (`flake8`, `black --check`)\n",
    "- Type checking (`mypy`)\n",
    "- Unit tests (`pytest`)\n",
    "- Integration tests (if feasible)\n",
    "\n",
    "Use platforms like GitHub Actions, GitLab CI, or Jenkins.\n",
    "\n",
    "**Example GitHub Actions workflow** (`.github/workflows/ci.yml`):\n",
    "\n",
    "```yaml\n",
    "name: CI\n",
    "\n",
    "on: [push, pull_request]\n",
    "\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v3\n",
    "      - name: Set up Python\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: '3.9'\n",
    "      - name: Install dependencies\n",
    "        run: |\n",
    "          pip install poetry\n",
    "          poetry install\n",
    "      - name: Lint\n",
    "        run: poetry run flake8 .\n",
    "      - name: Type check\n",
    "        run: poetry run mypy .\n",
    "      - name: Test\n",
    "        run: poetry run pytest --cov=src\n",
    "```\n",
    "\n",
    "### **86.7.2 CD Pipeline**\n",
    "\n",
    "For the prediction service, CD could:\n",
    "\n",
    "- Build a Docker image.\n",
    "- Push to a container registry.\n",
    "- Deploy to a staging environment.\n",
    "- Run smoke tests.\n",
    "- If successful, deploy to production (maybe with a manual approval gate).\n",
    "\n",
    "**Example deployment to Kubernetes** (using `kubectl`):\n",
    "\n",
    "```yaml\n",
    "- name: Deploy to production\n",
    "  if: github.ref == 'refs/heads/main'\n",
    "  run: |\n",
    "    kubectl set image deployment/prediction-service prediction-service=${{ steps.build.outputs.image }}\n",
    "    kubectl rollout status deployment/prediction-service\n",
    "```\n",
    "\n",
    "### **86.7.3 Model Training Pipeline**\n",
    "\n",
    "For models, CI/CD may be replaced by a **Continuous Training (CT)** pipeline that retrains models periodically. This is often implemented with Airflow or a similar scheduler, and can be integrated with the same version control and testing principles.\n",
    "\n",
    "---\n",
    "\n",
    "## **86.8 Refactoring and Technical Debt**\n",
    "\n",
    "Technical debt refers to the cost of additional rework caused by choosing an easy solution now instead of a better approach that would take longer. It accumulates like financial debt, with interest (slower development, more bugs).\n",
    "\n",
    "### **86.8.1 Signs of Technical Debt**\n",
    "\n",
    "- Code is hard to understand or modify.\n",
    "- Tests are slow or flaky.\n",
    "- Duplicated code.\n",
    "- Many \u201cTODO\u201d comments.\n",
    "- Long functions or classes.\n",
    "- Fear of changing code because \u201cit might break something\u201d.\n",
    "\n",
    "### **86.8.2 Managing Technical Debt**\n",
    "\n",
    "- **Refactor regularly**: Allocate time in each sprint for small refactorings (e.g., \u201cboy scout rule\u201d \u2013 leave code cleaner than you found it).\n",
    "- **Automate**: Use tools like `pylint` to flag complexity.\n",
    "- **Document known debt**: Keep a list in the project\u2019s issue tracker.\n",
    "- **Prioritise**: Address debt in areas that change frequently or are critical.\n",
    "\n",
    "**Example refactoring**: Replace repeated code with a function.\n",
    "\n",
    "Before:\n",
    "```python\n",
    "sma_5 = df['Close'].rolling(5).mean()\n",
    "sma_10 = df['Close'].rolling(10).mean()\n",
    "sma_20 = df['Close'].rolling(20).mean()\n",
    "```\n",
    "\n",
    "After:\n",
    "```python\n",
    "def moving_average(series, window):\n",
    "    return series.rolling(window).mean()\n",
    "\n",
    "for w in [5, 10, 20]:\n",
    "    df[f'SMA_{w}'] = moving_average(df['Close'], w)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **86.9 Knowledge Sharing and Onboarding**\n",
    "\n",
    "### **86.9.1 Pair Programming**\n",
    "Pair programming (two developers working together) is excellent for sharing knowledge and catching mistakes in real time. It can be used for complex features or when onboarding a new team member.\n",
    "\n",
    "### **86.9.2 Tech Talks and Demos**\n",
    "Regularly schedule short presentations where team members share what they\u2019ve learned, demonstrate a new feature, or discuss a recent challenge.\n",
    "\n",
    "### **86.9.3 Onboarding Documentation**\n",
    "Create a `CONTRIBUTING.md` file that explains:\n",
    "\n",
    "- How to set up the development environment.\n",
    "- How to run tests and linting.\n",
    "- The branching strategy and pull request process.\n",
    "- Where to find documentation.\n",
    "\n",
    "Also maintain a `docs/onboarding.md` with a step\u2011by\u2011step guide for new developers.\n",
    "\n",
    "### **86.9.4 Wiki or Knowledge Base**\n",
    "Use a company wiki (Confluence, Notion) to store design documents, meeting notes, and post\u2011mortems. Keep it organised and up to date.\n",
    "\n",
    "---\n",
    "\n",
    "## **86.10 Continuous Improvement**\n",
    "\n",
    "Development best practices are not static; they should evolve as the team and project grow. Conduct **retrospectives** (e.g., after each sprint or release) to discuss:\n",
    "\n",
    "- What went well?\n",
    "- What could be improved?\n",
    "- What actions will we take?\n",
    "\n",
    "Implement the agreed\u2011upon improvements in the next cycle.\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "In this chapter, we covered the essential development best practices that ensure a time\u2011series prediction system (like the NEPSE stock predictor) remains robust, maintainable, and scalable. We discussed:\n",
    "\n",
    "- Code quality through style guides, docstrings, and type hints.\n",
    "- A multi\u2011level testing strategy including unit, integration, data quality, and model tests.\n",
    "- The importance of code reviews and how to conduct them effectively.\n",
    "- Documentation at the code, API, architecture, and model levels.\n",
    "- Version control best practices: branching, commit messages, and tagging.\n",
    "- CI/CD pipelines for automated testing and deployment.\n",
    "- Managing technical debt through regular refactoring.\n",
    "- Fostering a culture of knowledge sharing and continuous improvement.\n",
    "\n",
    "Adopting these practices may require upfront effort, but they pay off in reduced bugs, faster development, and happier teams. As you continue to develop and enhance your prediction system, make these practices an integral part of your daily work.\n",
    "\n",
    "In the next chapter, we will explore **Team Collaboration**, diving deeper into how teams structure themselves, communicate, and work together effectively.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 86**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='../11. advanced_implementation_patterns/85. distributed_systems.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='87. team_collaboration.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}