{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 94: Large Language Models for Time-Series\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Understand how large language models (LLMs) can be applied to time‑series data, beyond traditional numerical forecasting.\n",
    "- Design effective prompts for time‑series tasks such as forecasting, anomaly explanation, and trend summarisation.\n",
    "- Use few‑shot learning to adapt LLMs to specific time‑series datasets with minimal examples.\n",
    "- Apply chain‑of‑thought prompting to improve reasoning about temporal patterns.\n",
    "- Integrate LLMs with external tools (calculators, databases) to enhance numerical accuracy.\n",
    "- Build simple agents that can answer questions about time‑series data, such as “Why did the NEPSE index drop last week?”\n",
    "- Recognise the limitations of LLMs for time‑series, including token limits, hallucinations, and cost.\n",
    "- Evaluate when to use an LLM versus a traditional time‑series model.\n",
    "\n",
    "---\n",
    "\n",
    "## **94.1 Introduction to Large Language Models for Time‑Series**\n",
    "\n",
    "Large language models (LLMs) like GPT‑4, Claude, and Llama have revolutionised natural language processing. Their ability to understand context, reason, and generate human‑like text has led researchers and practitioners to explore their application to time‑series data. However, LLMs are not inherently numerical models; they are trained on text. So how can they help with time‑series?\n",
    "\n",
    "The answer lies in their ability to:\n",
    "\n",
    "- **Understand and generate textual descriptions** of time‑series (e.g., “sales peaked in December”).\n",
    "- **Reason about temporal patterns** when provided with numerical data in a textual format.\n",
    "- **Incorporate external knowledge** (e.g., news, events) that may affect the time series.\n",
    "- **Explain predictions** from black‑box models in natural language.\n",
    "- **Answer questions** about historical data or future trends.\n",
    "\n",
    "In the context of the NEPSE stock prediction system, an LLM could:\n",
    "\n",
    "- Summarise daily market movements: “The NEPSE index rose 2% today, driven by banking stocks.”\n",
    "- Explain a model's prediction: “The model predicted a drop because of high volatility and negative RSI divergence.”\n",
    "- Answer a trader's query: “What happened to NABIL stock on June 1st, and how does that compare to historical patterns?”\n",
    "- Generate synthetic news or sentiment to augment features.\n",
    "\n",
    "This chapter explores these capabilities, with practical examples using OpenAI's API and the LangChain framework.\n",
    "\n",
    "---\n",
    "\n",
    "## **94.2 LLM Capabilities Relevant to Time‑Series**\n",
    "\n",
    "Before diving into implementation, let's outline what LLMs can and cannot do well in the time‑series domain.\n",
    "\n",
    "### **94.2.1 Strengths**\n",
    "- **Language understanding**: They can parse questions about time‑series and generate coherent answers.\n",
    "- **Pattern recognition in text**: If time‑series data is presented as a sequence of numbers (e.g., “100, 105, 103, …”), LLMs can sometimes detect simple patterns (trends, seasonality) because they have seen similar sequences in their training data (e.g., stock prices in financial news).\n",
    "- **External knowledge integration**: They can incorporate news, earnings reports, or macroeconomic indicators that are not in the numerical data.\n",
    "- **Explainability**: They can generate human‑readable explanations for model outputs or data anomalies.\n",
    "- **Few‑shot learning**: With a few examples in the prompt, they can adapt to new tasks.\n",
    "\n",
    "### **94.2.2 Weaknesses**\n",
    "- **Numerical precision**: LLMs are not calculators. They may make arithmetic errors, especially with large numbers or complex operations.\n",
    "- **Token limits**: Time‑series can be long. Even with 128k context, you cannot feed years of hourly data.\n",
    "- **Hallucination**: They may invent facts or numbers that are not present in the data.\n",
    "- **Lack of temporal understanding**: While they can recognise patterns, they do not inherently understand concepts like autocorrelation or stationarity.\n",
    "- **Cost and latency**: API calls are slower and more expensive than traditional models.\n",
    "\n",
    "Given these trade‑offs, LLMs are best used as **assistants** to traditional forecasting systems, not as replacements.\n",
    "\n",
    "---\n",
    "\n",
    "## **94.3 Prompt Engineering for Time‑Series**\n",
    "\n",
    "The way you present data and instructions to an LLM dramatically affects the quality of the response. This is **prompt engineering**.\n",
    "\n",
    "### **94.3.1 Structuring Numerical Data**\n",
    "LLMs work with text, so we need to convert time‑series into a textual representation. Options include:\n",
    "\n",
    "- **List of values**: “Close prices for the last 10 days: 105.2, 106.1, 104.5, 107.3, 108.0, 109.2, 108.5, 110.1, 111.0, 112.3”\n",
    "- **Table format**: Use markdown tables for clarity.\n",
    "- **With dates**: “2024‑05‑01: 105.2, 2024‑05‑02: 106.1, …”\n",
    "\n",
    "For long series, summarise statistics instead of listing every point.\n",
    "\n",
    "### **94.3.2 Zero‑Shot Prompting**\n",
    "Simply ask the model to perform a task, with the data in the prompt.\n",
    "\n",
    "**Example**: Ask for a forecast.\n",
    "\n",
    "```\n",
    "You are a financial analyst. Given the last 10 days of closing prices for the NEPSE index, predict the next day's price. Prices: 105.2, 106.1, 104.5, 107.3, 108.0, 109.2, 108.5, 110.1, 111.0, 112.3.\n",
    "```\n",
    "\n",
    "The model might respond with a prediction and a brief rationale. However, zero‑shot may be unreliable.\n",
    "\n",
    "### **94.3.3 Few‑Shot Prompting**\n",
    "Provide a few examples of the task in the prompt, then ask for the new case.\n",
    "\n",
    "```\n",
    "You are a time‑series forecasting assistant. Given the last few days of prices, predict the next value.\n",
    "\n",
    "Example 1:\n",
    "Prices: 50, 52, 51, 53, 55\n",
    "Next: 56\n",
    "\n",
    "Example 2:\n",
    "Prices: 100, 102, 101, 104, 107\n",
    "Next: 108\n",
    "\n",
    "Now, predict for:\n",
    "Prices: 105.2, 106.1, 104.5, 107.3, 108.0, 109.2, 108.5, 110.1, 111.0, 112.3\n",
    "Next:\n",
    "```\n",
    "\n",
    "The model learns the pattern from the examples. This can improve accuracy.\n",
    "\n",
    "### **94.3.4 Role Prompting**\n",
    "Assign the model a persona to guide its response.\n",
    "\n",
    "```\n",
    "You are an expert stock market analyst with 20 years of experience. Analyse the following NEPSE price sequence and explain any notable patterns.\n",
    "```\n",
    "\n",
    "### **94.3.5 Instruction Formatting**\n",
    "Use clear delimiters (e.g., triple backticks) for data, and specify the desired output format (JSON, bullet points).\n",
    "\n",
    "```\n",
    "Given the following daily closing prices for NEPSE, provide a JSON object with fields: trend (up/down/sideways), volatility (low/medium/high), and next_day_prediction (a number).\n",
    "\n",
    "Data:\n",
    "```\n",
    "2024-05-20: 110.2\n",
    "2024-05-21: 111.5\n",
    "2024-05-22: 109.8\n",
    "2024-05-23: 112.0\n",
    "2024-05-24: 113.1\n",
    "```\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **94.4 Few‑Shot Learning for NEPSE**\n",
    "\n",
    "Let's implement a practical example using OpenAI's API to perform few‑shot forecasting on NEPSE data.\n",
    "\n",
    "```python\n",
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def few_shot_forecast(prices_series, n_examples=3):\n",
    "    \"\"\"\n",
    "    Use few‑shot prompting to forecast the next value.\n",
    "    prices_series: list of floats (recent prices)\n",
    "    \"\"\"\n",
    "    # Build few‑shot examples (these could be from historical data)\n",
    "    examples = [\n",
    "        ([50, 52, 51, 53, 55], 56),\n",
    "        ([100, 102, 101, 104, 107], 108),\n",
    "        ([200, 205, 203, 208, 210], 212),\n",
    "    ]\n",
    "    \n",
    "    prompt = \"You are a time‑series forecasting assistant. Given the last few days of prices, predict the next value.\\n\\n\"\n",
    "    \n",
    "    for prices, target in examples:\n",
    "        prompt += f\"Prices: {', '.join(map(str, prices))}\\nNext: {target}\\n\\n\"\n",
    "    \n",
    "    prompt += f\"Now, predict for:\\nPrices: {', '.join(map(str, prices_series))}\\nNext:\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that predicts the next number in a sequence. Provide only the number as your answer.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.0,  # low temperature for deterministic output\n",
    "        max_tokens=10\n",
    "    )\n",
    "    \n",
    "    prediction = response.choices[0].message.content.strip()\n",
    "    try:\n",
    "        return float(prediction)\n",
    "    except ValueError:\n",
    "        # If model returns extra text, we may need to parse\n",
    "        # In practice, you'd add instructions to output only number.\n",
    "        print(f\"Could not parse: {prediction}\")\n",
    "        return None\n",
    "\n",
    "# Example usage with NEPSE data\n",
    "recent_prices = [105.2, 106.1, 104.5, 107.3, 108.0, 109.2, 108.5, 110.1, 111.0, 112.3]\n",
    "pred = few_shot_forecast(recent_prices)\n",
    "print(f\"LLM forecast: {pred}\")\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- We provide a few examples of price sequences and their next values. The model infers the pattern (which appears to be a simple upward trend).\n",
    "- We set `temperature=0.0` for reproducibility.\n",
    "- The model returns a string; we attempt to convert to float.\n",
    "- In practice, you might need more examples or better examples tailored to NEPSE.\n",
    "\n",
    "This approach is surprisingly effective for simple patterns, but it will struggle with complex seasonality or noise.\n",
    "\n",
    "---\n",
    "\n",
    "## **94.5 Chain‑of‑Thought Prompting**\n",
    "\n",
    "Chain‑of‑thought (CoT) prompting encourages the model to reason step by step before giving an answer. This can improve accuracy for tasks that require intermediate reasoning.\n",
    "\n",
    "For time‑series, CoT might involve:\n",
    "\n",
    "- Describing the trend (e.g., “prices have been increasing over the last 5 days”).\n",
    "- Noting volatility.\n",
    "- Considering seasonality (e.g., “this is the end of the month”).\n",
    "- Then making a prediction.\n",
    "\n",
    "**Example prompt**:\n",
    "\n",
    "```\n",
    "You are a financial analyst. Given the following daily closing prices for NEPSE, think step by step and then predict the next day's price.\n",
    "\n",
    "Prices: 105.2, 106.1, 104.5, 107.3, 108.0, 109.2, 108.5, 110.1, 111.0, 112.3\n",
    "\n",
    "First, describe the overall trend.\n",
    "Second, note any recent volatility.\n",
    "Third, based on these observations, predict the next price.\n",
    "```\n",
    "\n",
    "The model might respond:\n",
    "\n",
    "```\n",
    "Step 1: The overall trend over the last 10 days is upward. The price started at 105.2 and ended at 112.3, an increase of about 6.7%.\n",
    "Step 2: There is some volatility; for example, a dip from 106.1 to 104.5 on day 3, but generally the movement is smooth.\n",
    "Step 3: Given the strong upward momentum and no signs of reversal, I predict the next price will be around 113.5.\n",
    "```\n",
    "\n",
    "CoT can be implemented by simply including these instructions in the prompt.\n",
    "\n",
    "---\n",
    "\n",
    "## **94.6 Tool Use: Augmenting LLMs with Calculators**\n",
    "\n",
    "LLMs are bad at arithmetic. To get accurate numerical results, we can give them access to tools. This is a key capability of modern LLM frameworks like LangChain.\n",
    "\n",
    "For example, we can let the LLM decide when to use a calculator to compute moving averages or percentage changes.\n",
    "\n",
    "```python\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.tools import BaseTool\n",
    "import math\n",
    "\n",
    "class CalculatorTool(BaseTool):\n",
    "    name = \"Calculator\"\n",
    "    description = \"Useful for arithmetic operations. Input should be a mathematical expression.\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        try:\n",
    "            # Safely evaluate expression (in production, use a safer evaluator)\n",
    "            result = eval(query)\n",
    "            return f\"Result: {result}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "\n",
    "    async def _arun(self, query: str):\n",
    "        return self._run(query)\n",
    "\n",
    "# Initialize LLM and agent\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = [CalculatorTool()]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=\"zero-shot-react-description\", verbose=True\n",
    ")\n",
    "\n",
    "# Ask a question that requires calculation\n",
    "query = \"\"\"\n",
    "Given the following NEPSE prices: 105.2, 106.1, 104.5, 107.3, 108.0.\n",
    "Compute the 3-day moving average of the last three prices, then add 2% to that value.\n",
    "\"\"\"\n",
    "\n",
    "response = agent.run(query)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- The agent can decide to call the `CalculatorTool` with an expression like `(107.3 + 108.0 + 108.5)/3 * 1.02`.\n",
    "- The tool returns the result, and the agent incorporates it into the final answer.\n",
    "- This overcomes the LLM's numerical weakness.\n",
    "\n",
    "In a time‑series context, you could provide tools for:\n",
    "\n",
    "- Fetching historical data from a database.\n",
    "- Computing technical indicators (RSI, MACD).\n",
    "- Running a pre‑trained forecasting model.\n",
    "\n",
    "This leads to **agentic systems** that can combine reasoning with computation.\n",
    "\n",
    "---\n",
    "\n",
    "## **94.7 Agents for Time‑Series Analysis**\n",
    "\n",
    "An agent is an LLM‑powered system that can use multiple tools to accomplish a goal. For the NEPSE system, an agent could answer complex user queries like:\n",
    "\n",
    "> “Compare the performance of banking stocks and hydropower stocks over the last month. Which sector had higher volatility?”\n",
    "\n",
    "The agent would need to:\n",
    "\n",
    "1. Query a database for stock prices.\n",
    "2. Compute returns and volatility per sector.\n",
    "3. Generate a comparative summary.\n",
    "\n",
    "We can build such an agent using LangChain.\n",
    "\n",
    "```python\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from typing import List, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define tools: one to fetch data, one to compute metrics\n",
    "class FetchDataTool(BaseTool):\n",
    "    name = \"FetchStockData\"\n",
    "    description = \"Fetches historical price data for a given symbol. Input: symbol (string). Returns: list of prices and dates.\"\n",
    "\n",
    "    def _run(self, symbol: str) -> str:\n",
    "        # In reality, query database. Here, we simulate.\n",
    "        # For demo, return a small sample.\n",
    "        data = {\n",
    "            'NABIL': [105.2, 106.1, 104.5, 107.3, 108.0],\n",
    "            'HRL': [210.0, 212.5, 209.0, 215.0, 218.0]\n",
    "        }\n",
    "        return str(data.get(symbol, []))\n",
    "\n",
    "class ComputeVolatilityTool(BaseTool):\n",
    "    name = \"ComputeVolatility\"\n",
    "    description = \"Computes the volatility (standard deviation of returns) for a list of prices. Input: list of prices. Returns: volatility value.\"\n",
    "\n",
    "    def _run(self, prices_str: str) -> str:\n",
    "        import ast\n",
    "        prices = ast.literal_eval(prices_str)\n",
    "        returns = np.diff(prices) / prices[:-1]\n",
    "        vol = np.std(returns)\n",
    "        return str(vol)\n",
    "\n",
    "# Create agent\n",
    "tools = [FetchDataTool(), ComputeVolatilityTool()]\n",
    "\n",
    "# Custom prompt template (simplified)\n",
    "prompt_template = \"\"\"\n",
    "You are a financial analyst assistant. Use the tools provided to answer the question.\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "You have access to the following tools: {tool_names}.\n",
    "Use them in a Thought/Action/Observation cycle.\n",
    "\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "# Build agent (details omitted for brevity, but standard LangChain pattern)\n",
    "# ...\n",
    "\n",
    "# Example query\n",
    "result = agent.run(\"Compare the volatility of NABIL and HRL over the last 5 days.\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- The agent decides which tools to call based on the query.\n",
    "- It fetches data for each symbol, then computes volatility.\n",
    "- Finally, it synthesises an answer: “NABIL had a volatility of X, HRL had Y, so HRL was more volatile.”\n",
    "- This demonstrates how LLMs can orchestrate multiple steps to answer complex questions.\n",
    "\n",
    "---\n",
    "\n",
    "## **94.8 Applications in the NEPSE System**\n",
    "\n",
    "Let's explore concrete applications of LLMs within our NEPSE prediction system.\n",
    "\n",
    "### **94.8.1 Generating Explanations for Predictions**\n",
    "After a traditional model (e.g., XGBoost) makes a prediction, we can use an LLM to explain it in plain language. Provide the model's input features and output, and ask the LLM to generate a rationale.\n",
    "\n",
    "```python\n",
    "def explain_prediction(features, prediction):\n",
    "    prompt = f\"\"\"\n",
    "    A machine learning model predicted the NEPSE closing price to be {prediction:.2f}.\n",
    "    The input features were:\n",
    "    - Lag 1 close: {features['lag_1']}\n",
    "    - 20-day SMA: {features['sma_20']}\n",
    "    - RSI: {features['rsi']}\n",
    "    - Volume Z-score: {features['volume_z']}\n",
    "    \n",
    "    Explain why the model might have made this prediction in simple terms.\n",
    "    \"\"\"\n",
    "    response = openai.ChatCompletion.create(...)\n",
    "    return response.choices[0].message.content\n",
    "```\n",
    "\n",
    "This can build trust with traders.\n",
    "\n",
    "### **94.8.2 Incorporating News Sentiment**\n",
    "LLMs can analyse news headlines or articles to generate sentiment scores that become features in the model.\n",
    "\n",
    "```python\n",
    "def sentiment_from_news(headline):\n",
    "    prompt = f\"Classify the sentiment of this headline as positive, negative, or neutral, and provide a score from -1 (very negative) to +1 (very positive).\\nHeadline: {headline}\"\n",
    "    # parse response\n",
    "    return sentiment_score\n",
    "```\n",
    "\n",
    "### **94.8.3 Answering Ad‑Hoc Questions**\n",
    "Create a chatbot that allows traders to ask natural language questions about the market, using the LLM to query the database and generate answers.\n",
    "\n",
    "### **94.8.4 Anomaly Explanation**\n",
    "When the monitoring system detects an anomaly (e.g., a sudden price spike), an LLM can suggest possible causes based on recent news or historical patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## **94.9 Limitations and Challenges**\n",
    "\n",
    "While LLMs are powerful, they come with significant caveats.\n",
    "\n",
    "### **94.9.1 Token Limits**\n",
    "Even with extended context windows (128k tokens for GPT‑4), you cannot feed years of daily data. For NEPSE, 10 years of daily data is about 3650 points. If each point is represented as \"2024-06-01: 110.2\", that's roughly 20 characters per point, totalling 73k characters, which is within limits. But if you need multiple stocks or higher frequency, it becomes challenging. Solutions include summarising (e.g., providing weekly aggregates) or using a retrieval system.\n",
    "\n",
    "### **94.9.2 Hallucination**\n",
    "LLMs may generate plausible‑sounding but incorrect numbers or facts. Always verify outputs, especially if used for trading decisions.\n",
    "\n",
    "### **94.9.3 Cost**\n",
    "API calls cost money. A single complex query might cost cents, but at scale it adds up. Fine‑tuning a smaller open‑source model (e.g., Llama) can reduce cost.\n",
    "\n",
    "### **94.9.4 Latency**\n",
    "LLM inference is slow (seconds) compared to traditional models (milliseconds). Not suitable for real‑time trading.\n",
    "\n",
    "### **94.9.5 Numerical Reasoning**\n",
    "Even with tools, the LLM must decide when to use them. This can fail if the tool choice is suboptimal.\n",
    "\n",
    "### **94.9.6 Data Privacy**\n",
    "Sending proprietary financial data to an external API (OpenAI) may violate policies. Consider using a local model (e.g., through Ollama) for sensitive data.\n",
    "\n",
    "---\n",
    "\n",
    "## **94.10 Future Directions**\n",
    "\n",
    "The intersection of LLMs and time‑series is an active research area. Expect to see:\n",
    "\n",
    "- **Fine‑tuned time‑series LLMs**: Models specifically trained on numerical sequences and financial text.\n",
    "- **Multimodal models**: Combining text, images (charts), and numbers.\n",
    "- **Improved tool use**: LLMs that can reliably call forecasting models, databases, and visualisation libraries.\n",
    "- **Lower latency**: Smaller, faster models for real‑time assistance.\n",
    "- **Integration with forecasting pipelines**: LLMs as a natural language interface to complex forecasting systems.\n",
    "\n",
    "For the NEPSE system, you might soon have an AI assistant that can:\n",
    "\n",
    "- “Show me the forecast for NABIL for the next week.”\n",
    "- “Why did the model change its prediction from yesterday?”\n",
    "- “What would happen if interest rates rise by 1%?”\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "In this chapter, we explored how large language models can complement traditional time‑series prediction systems. We covered:\n",
    "\n",
    "- The strengths and weaknesses of LLMs for time‑series tasks.\n",
    "- Prompt engineering techniques including zero‑shot, few‑shot, and chain‑of‑thought.\n",
    "- Practical implementation of few‑shot forecasting using OpenAI's API.\n",
    "- Tool use to overcome numerical limitations, with examples using LangChain.\n",
    "- Building agents that can answer complex questions by combining data fetching, computation, and reasoning.\n",
    "- Specific applications in the NEPSE system: explanation generation, sentiment analysis, and ad‑hoc query answering.\n",
    "- The limitations of LLMs: token limits, hallucinations, cost, and latency.\n",
    "- Future directions in this rapidly evolving field.\n",
    "\n",
    "LLMs are not a replacement for traditional forecasting models, but they are a powerful interface layer that can make time‑series insights more accessible and explainable. As the technology matures, we can expect even tighter integration between language and numbers.\n",
    "\n",
    "In the next chapter, we will explore **Automated Scientific Discovery**, where AI is used to uncover new knowledge from data, including causal relationships and physical laws.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 94**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
