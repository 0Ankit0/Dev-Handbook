{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 97: Quantum Machine Learning\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Understand the basic principles of quantum computing and how they differ from classical computing.\n",
    "- Identify potential applications of quantum machine learning (QML) to time‑series prediction problems.\n",
    "- Explain key quantum algorithms relevant to machine learning: quantum support vector machines, quantum neural networks, and variational quantum eigensolvers.\n",
    "- Recognise the current limitations of quantum hardware (noise, qubit count, coherence times) and their impact on practical QML.\n",
    "- Implement a simple quantum classifier using Qiskit and apply it to a synthetic time‑series classification problem.\n",
    "- Evaluate the potential advantages of QML for specific tasks (e.g., kernel methods, optimisation) and understand when classical approaches are still superior.\n",
    "- Stay informed about the rapidly evolving landscape of quantum computing and its implications for time‑series forecasting.\n",
    "\n",
    "---\n",
    "\n",
    "## **97.1 Introduction to Quantum Machine Learning**\n",
    "\n",
    "Quantum machine learning (QML) sits at the intersection of quantum computing and machine learning. It explores how quantum algorithms can be used to perform machine learning tasks more efficiently than classical algorithms, or how machine learning can be used to solve quantum problems.\n",
    "\n",
    "For time‑series prediction, QML is still largely experimental. However, certain aspects of quantum computing suggest potential advantages:\n",
    "\n",
    "- **Kernel methods**: Quantum computers can compute kernels that are hard to estimate classically, potentially improving support vector machines for complex datasets.\n",
    "- **Optimisation**: Many machine learning problems involve optimisation (e.g., training neural networks). Quantum algorithms like the Quantum Approximate Optimisation Algorithm (QAOA) might offer speedups.\n",
    "- **Sampling**: Quantum computers can sample from probability distributions that are difficult to model classically, which could benefit generative models.\n",
    "- **Feature mapping**: Quantum feature maps can project data into exponentially high‑dimensional Hilbert spaces, which might make certain patterns linearly separable.\n",
    "\n",
    "In this chapter, we will not build a production‑ready quantum model for NEPSE—quantum hardware is not yet there. Instead, we will explore the concepts, implement small‑scale examples using simulators, and discuss the roadmap to practical quantum advantage.\n",
    "\n",
    "---\n",
    "\n",
    "## **97.2 Quantum Computing Basics**\n",
    "\n",
    "To understand QML, we need a basic grasp of quantum computing concepts.\n",
    "\n",
    "### **97.2.1 Qubits and Superposition**\n",
    "\n",
    "A classical bit is either 0 or 1. A **qubit** can be in a superposition of both states: \n",
    "|ψ⟩ = α|0⟩ + β|1⟩, where α and β are complex numbers and |α|² + |β|² = 1.\n",
    "\n",
    "When measured, the qubit collapses to |0⟩ with probability |α|² and to |1⟩ with probability |β|².\n",
    "\n",
    "### **97.2.2 Entanglement**\n",
    "\n",
    "Entanglement is a quantum correlation between qubits. The state of one qubit cannot be described independently of the others. For example, the Bell state (|00⟩ + |11⟩)/√2: if you measure one qubit as 0, the other is guaranteed to be 0.\n",
    "\n",
    "### **97.2.3 Quantum Gates**\n",
    "\n",
    "Quantum gates manipulate qubits. Common gates:\n",
    "\n",
    "- **Hadamard (H)**: Creates superposition.\n",
    "- **Pauli-X, Y, Z**: Quantum analogues of NOT and rotations.\n",
    "- **CNOT**: A two‑qubit gate that flips the target qubit if the control is |1⟩.\n",
    "\n",
    "### **97.2.4 Quantum Circuits**\n",
    "\n",
    "A quantum circuit is a sequence of gates applied to qubits, followed by measurement. This is the quantum analogue of a classical circuit.\n",
    "\n",
    "### **97.2.5 Quantum Hardware Limitations**\n",
    "\n",
    "Current quantum computers (NISQ – Noisy Intermediate‑Scale Quantum) have:\n",
    "\n",
    "- **Limited qubits**: Typically 50‑100 qubits.\n",
    "- **Noise**: Gate errors and decoherence limit circuit depth.\n",
    "- **Short coherence times**: Qubits lose their quantum state quickly.\n",
    "\n",
    "These limitations mean that only small, shallow circuits can run reliably. QML algorithms must be designed to be noise‑resilient.\n",
    "\n",
    "---\n",
    "\n",
    "## **97.3 Quantum Machine Learning Algorithms**\n",
    "\n",
    "Several QML algorithms have been proposed. We'll review the most relevant.\n",
    "\n",
    "### **97.3.1 Quantum Support Vector Machines (QSVM)**\n",
    "\n",
    "Classical SVMs find a hyperplane that separates data. The kernel trick maps data to a higher‑dimensional space where separation is easier. Quantum computers can estimate kernels that are classically hard to compute.\n",
    "\n",
    "The **QSVM** algorithm uses a quantum circuit to compute the kernel matrix. For a dataset {xᵢ}, the kernel entry K(xᵢ, xⱼ) = |⟨φ(xᵢ)|φ(xⱼ)⟩|², where |φ(x)⟩ is a quantum state prepared by a feature map circuit.\n",
    "\n",
    "This kernel can be more expressive than classical kernels, potentially leading to better classification.\n",
    "\n",
    "### **97.3.2 Variational Quantum Circuits (VQC)**\n",
    "\n",
    "Variational quantum circuits are the quantum analogue of neural networks. They consist of:\n",
    "\n",
    "1. A **data encoding** circuit that embeds classical data into quantum states.\n",
    "2. A **variational** circuit with trainable parameters (rotation angles).\n",
    "3. Measurement of observables to produce an output.\n",
    "\n",
    "Training is done by a classical optimiser that adjusts the parameters to minimise a loss function. This hybrid approach (classical optimisation + quantum circuit) is the most promising for near‑term quantum advantage.\n",
    "\n",
    "### **97.3.3 Quantum Neural Networks (QNN)**\n",
    "\n",
    "QNNs extend VQCs with multiple layers and non‑linearities (though non‑linearity in quantum circuits is tricky; it often comes from measurement or repeated encoding).\n",
    "\n",
    "### **97.3.4 Quantum Generative Models**\n",
    "\n",
    "Quantum circuits can be trained to generate samples from probability distributions. This is the quantum analogue of generative adversarial networks (GANs) or variational autoencoders (VAEs). For time‑series, this could be used to generate realistic synthetic market data.\n",
    "\n",
    "### **97.3.5 Quantum Optimisation for Training**\n",
    "\n",
    "Training classical models often involves optimising a non‑convex loss function. Quantum optimisation algorithms (QAOA, quantum annealing) might find better minima faster, though this is still speculative.\n",
    "\n",
    "---\n",
    "\n",
    "## **97.4 Implementing a Simple Quantum Classifier with Qiskit**\n",
    "\n",
    "Let's implement a small quantum classifier using Qiskit, IBM's quantum computing framework. We'll apply it to a synthetic time‑series classification problem: classifying whether a stock's return tomorrow will be positive or negative based on the last 3 days of returns.\n",
    "\n",
    "**Note**: This example runs on a simulator. Running on real quantum hardware would require an IBM Quantum account and is subject to queue times and noise.\n",
    "\n",
    "```python\n",
    "# pip install qiskit qiskit-machine-learning qiskit-aer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic time‑series classification data\n",
    "# Features: returns from last 3 days\n",
    "# Target: sign of next day return (1 if positive, 0 otherwise)\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "n_features = 3\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=n_samples,\n",
    "    n_features=n_features,\n",
    "    n_redundant=0,\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Scale features to [-1, 1] (suitable for quantum encoding)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = np.clip(X_scaled, -1, 1)  # clip to range\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "```\n",
    "\n",
    "### **97.4.1 Quantum Kernel Method**\n",
    "\n",
    "First, we'll implement a quantum kernel estimator and use it with a classical SVM.\n",
    "\n",
    "```python\n",
    "from qiskit import Aer, QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "\n",
    "# Set seed for reproducibility\n",
    "algorithm_globals.random_seed = 42\n",
    "\n",
    "# Define a feature map (encodes classical data into quantum state)\n",
    "def create_feature_map(n_features):\n",
    "    params = ParameterVector('x', length=n_features)\n",
    "    qc = QuantumCircuit(n_features)\n",
    "    \n",
    "    # Encode data with angle encoding (Rx rotations)\n",
    "    for i in range(n_features):\n",
    "        qc.rx(params[i], i)\n",
    "    \n",
    "    # Add entanglement (CNOTs)\n",
    "    for i in range(n_features - 1):\n",
    "        qc.cx(i, i+1)\n",
    "    \n",
    "    return qc\n",
    "\n",
    "feature_map = create_feature_map(n_features)\n",
    "\n",
    "# Create quantum kernel\n",
    "quantum_kernel = FidelityQuantumKernel(\n",
    "    feature_map=feature_map,\n",
    "    quantum_instance=Aer.get_backend('statevector_simulator')\n",
    ")\n",
    "\n",
    "# Train QSVC\n",
    "qsvc = QSVC(quantum_kernel=quantum_kernel)\n",
    "qsvc.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = qsvc.score(X_test, y_test)\n",
    "print(f\"QSVC test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Compare with classical RBF SVM\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='rbf')\n",
    "svm.fit(X_train, y_train)\n",
    "print(f\"Classical SVM test accuracy: {svm.score(X_test, y_test):.4f}\")\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- We create a feature map circuit that encodes the 3 features using Rx rotations, then adds entanglement with CNOT gates.\n",
    "- The `FidelityQuantumKernel` computes the kernel matrix by running this circuit for each pair of data points and measuring the overlap.\n",
    "- `QSVC` is a quantum‑kernel version of a support vector classifier.\n",
    "- On this small synthetic dataset, the quantum kernel may perform similarly to a classical RBF kernel. The true test is on problems where the quantum kernel provides an advantage.\n",
    "\n",
    "### **97.4.2 Variational Quantum Classifier (VQC)**\n",
    "\n",
    "Now, we'll implement a variational quantum classifier, which trains a parameterised quantum circuit.\n",
    "\n",
    "```python\n",
    "from qiskit import Aer\n",
    "from qiskit.algorithms.optimizers import COBYLA\n",
    "from qiskit.circuit import ParameterVector, QuantumCircuit\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
    "\n",
    "algorithm_globals.random_seed = 42\n",
    "\n",
    "# Feature map (data encoding)\n",
    "feature_map = ZZFeatureMap(feature_dimension=n_features, reps=2)\n",
    "\n",
    "# Variational form (trainable circuit)\n",
    "var_form = RealAmplitudes(n_features, reps=3)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = COBYLA(maxiter=100)\n",
    "\n",
    "# Create VQC\n",
    "vqc = VQC(\n",
    "    feature_map=feature_map,\n",
    "    ansatz=var_form,\n",
    "    optimizer=optimizer,\n",
    "    quantum_instance=Aer.get_backend('statevector_simulator')\n",
    ")\n",
    "\n",
    "# Train\n",
    "vqc.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = vqc.score(X_test, y_test)\n",
    "print(f\"VQC test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Inspect the circuit\n",
    "print(vqc.ansatz.draw())\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- `ZZFeatureMap` encodes data using entangling ZZ interactions.\n",
    "- `RealAmplitudes` is a common variational form with parameterised Ry rotations and CNOTs.\n",
    "- The VQC trains these parameters to minimise the classification error.\n",
    "- This hybrid approach (classical optimisation + quantum circuit) is the most practical for near‑term quantum hardware.\n",
    "\n",
    "---\n",
    "\n",
    "## **97.5 Applying QML to Time‑Series**\n",
    "\n",
    "For the NEPSE system, we could imagine using QML for:\n",
    "\n",
    "- **Classification of market regimes** (bull/bear/sideways) based on recent price and volume patterns.\n",
    "- **Kernel methods** to find non‑linear relationships between stocks.\n",
    "- **Quantum generative models** to generate realistic synthetic market scenarios for stress testing.\n",
    "- **Optimisation** of portfolio allocation under constraints (a quantum‑amenable problem).\n",
    "\n",
    "However, with current hardware, these are research projects. The example above is on a tiny dataset (3 features, 200 samples). Real NEPSE data has many more features (lags, technical indicators) and samples, far beyond what current quantum computers can handle.\n",
    "\n",
    "---\n",
    "\n",
    "## **97.6 Current Limitations and Challenges**\n",
    "\n",
    "### **97.6.1 Hardware Constraints**\n",
    "- **Qubit count**: Even the largest quantum computers (e.g., IBM's Osprey with 433 qubits) cannot encode the hundreds of features typical in time‑series prediction.\n",
    "- **Noise**: Gate errors limit circuit depth. Our simple feature map and variational form may be too deep for current hardware.\n",
    "- **Coherence time**: Qubits lose their state quickly, limiting the length of computations.\n",
    "\n",
    "### **97.6.2 Encoding Classical Data**\n",
    "Mapping classical data to quantum states is non‑trivial. Amplitude encoding (using 2ⁿ amplitudes to encode n features) is efficient but requires complex state preparation. Angle encoding (as we used) is simpler but uses one qubit per feature, which doesn't scale.\n",
    "\n",
    "### **97.6.3 Readout and Measurement**\n",
    "Extracting results from quantum computers is probabilistic; many shots are needed to get accurate estimates, adding overhead.\n",
    "\n",
    "### **97.6.4 Classical Baselines**\n",
    "For most time‑series tasks, classical models (XGBoost, LSTM) are extremely good and run on cheap, readily available hardware. Quantum advantage must be significant to justify the cost and complexity.\n",
    "\n",
    "### **97.6.5 Algorithmic Maturity**\n",
    "QML is a young field. Many proposed algorithms lack rigorous proof of advantage, and empirical results are on small, synthetic problems.\n",
    "\n",
    "---\n",
    "\n",
    "## **97.7 Potential Advantages (When Might Quantum Help?)**\n",
    "\n",
    "Despite the challenges, there are scenarios where quantum could eventually shine:\n",
    "\n",
    "- **Kernel methods** for very high‑dimensional feature spaces that are classically intractable.\n",
    "- **Solving optimisation problems** that are part of training (e.g., finding global minima in non‑convex landscapes).\n",
    "- **Sampling from complex probability distributions** for generative models.\n",
    "- **Quantum neural networks** that exploit entanglement to represent correlations that classical networks cannot.\n",
    "\n",
    "For time‑series, this might mean discovering hidden patterns that are exponentially hard to find classically.\n",
    "\n",
    "---\n",
    "\n",
    "## **97.8 Tools and Frameworks**\n",
    "\n",
    "- **Qiskit**: IBM's open‑source framework for quantum computing. Includes `qiskit-machine-learning` for QML algorithms.\n",
    "- **Pennylane**: A library for differentiable quantum programming, integrates with PyTorch and TensorFlow.\n",
    "- **TensorFlow Quantum**: Google's library for hybrid quantum‑classical machine learning.\n",
    "- **Cirq**: Google's quantum programming framework.\n",
    "\n",
    "These tools allow you to design and simulate quantum circuits, and run them on real hardware (if you have access).\n",
    "\n",
    "---\n",
    "\n",
    "## **97.9 The Road Ahead**\n",
    "\n",
    "Quantum computing is advancing rapidly. Milestones to watch:\n",
    "\n",
    "- **Fault‑tolerant quantum computers**: With error correction, we could run much deeper circuits.\n",
    "- **Increased qubit counts**: 1000+ qubit machines may be available in the next few years.\n",
    "- **Quantum advantage demonstrations**: For specific problems, we may see clear speedups.\n",
    "\n",
    "For time‑series prediction, the first practical applications may be in **finance** (portfolio optimisation, risk analysis) and **scientific computing** (simulating physical systems that generate time‑series).\n",
    "\n",
    "---\n",
    "\n",
    "## **97.10 Best Practices for Staying Informed**\n",
    "\n",
    "1. **Follow key research groups**: IBM Quantum, Google Quantum AI, Xanadu, etc.\n",
    "2. **Read review papers**: \"Quantum Machine Learning: A Review\" (Biamonte et al.) is a good starting point.\n",
    "3. **Experiment with simulators**: Use Qiskit or Pennylane to get hands‑on experience.\n",
    "4. **Monitor hardware progress**: Keep an eye on quantum volume, qubit counts, and error rates.\n",
    "5. **Be sceptical**: Many claims of quantum advantage are overblown. Look for rigorous evidence.\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "In this chapter, we ventured into the speculative but exciting world of quantum machine learning. We covered:\n",
    "\n",
    "- The basics of quantum computing: qubits, superposition, entanglement, and gates.\n",
    "- Key QML algorithms: quantum kernel methods, variational quantum circuits, and quantum neural networks.\n",
    "- A practical implementation of a quantum classifier using Qiskit on a synthetic time‑series problem.\n",
    "- The severe limitations of current quantum hardware for real‑world time‑series tasks.\n",
    "- Potential future advantages and the importance of staying informed.\n",
    "\n",
    "For now, your NEPSE prediction system should stick with classical methods. But by understanding QML, you are prepared for a future where quantum computers may offer a genuine edge. This field is evolving rapidly, and the techniques you've learned in this chapter will help you evaluate and adopt new quantum algorithms as they mature.\n",
    "\n",
    "In the next chapter, we will discuss **Ethical AI and Responsible ML**, ensuring that our prediction systems are fair, transparent, and accountable.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 97**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
