{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 96: Edge AI and TinyML\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Understand the concepts of Edge AI and TinyML and their relevance to time\u2011series prediction systems.\n",
    "- Identify scenarios where deploying models on edge devices is advantageous over cloud\u2011based inference.\n",
    "- Apply model compression techniques such as quantization, pruning, and knowledge distillation to reduce model size and latency.\n",
    "- Use TensorFlow Lite to convert and optimise models for edge deployment.\n",
    "- Implement a TinyML application for real\u2011time anomaly detection on streaming sensor data, using a simulated NEPSE\u2011like data stream.\n",
    "- Evaluate the trade\u2011offs between model accuracy, size, inference time, and power consumption.\n",
    "- Explore the hardware landscape for edge AI, from microcontrollers to edge GPUs.\n",
    "- Understand the limitations and challenges of edge deployment, including hardware constraints and model updates.\n",
    "\n",
    "---\n",
    "\n",
    "## **96.1 Introduction to Edge AI and TinyML**\n",
    "\n",
    "**Edge AI** refers to the deployment of artificial intelligence models on devices at the edge of the network, close to where data is generated, rather than in a centralised cloud. **TinyML** is a subfield of Edge AI focused on running machine learning models on ultra\u2011low\u2011power devices such as microcontrollers, often with memory and compute constraints measured in kilobytes and megahertz.\n",
    "\n",
    "In the context of time\u2011series prediction systems like the NEPSE stock predictor, most of our work has been cloud\u2011centric: data is sent to a central server where models run. However, there are compelling reasons to move some intelligence to the edge:\n",
    "\n",
    "- **Latency**: Real\u2011time applications (e.g., high\u2011frequency trading, industrial control) require predictions within milliseconds; sending data to the cloud and back may be too slow.\n",
    "- **Bandwidth**: Streaming high\u2011frequency sensor data (e.g., from thousands of IoT devices) can overwhelm networks. Edge devices can process locally and only send summaries or anomalies.\n",
    "- **Privacy**: Sensitive data (e.g., medical or financial) can be processed locally without ever leaving the device.\n",
    "- **Reliability**: Edge devices can continue operating even when disconnected from the cloud.\n",
    "- **Energy efficiency**: TinyML models consume minimal power, enabling battery\u2011operated devices to run for years.\n",
    "\n",
    "For the NEPSE system, an edge scenario might involve a lightweight model running on a trader's smartphone, providing real\u2011time alerts based on streaming market data, or a sensor on a trading floor that detects unusual activity.\n",
    "\n",
    "This chapter will guide you through the process of taking a time\u2011series model, compressing it for edge deployment, and running it on a simulated edge device.\n",
    "\n",
    "---\n",
    "\n",
    "## **96.2 Why Edge for Time\u2011Series?**\n",
    "\n",
    "Time\u2011series data is often generated continuously and at high velocity. Consider these use cases where edge deployment shines:\n",
    "\n",
    "- **Predictive maintenance on industrial equipment**: Vibration sensors generate data at kHz rates. Sending all data to the cloud is impractical; an edge device runs an anomaly detection model and only alerts when a fault is imminent.\n",
    "- **Wearable health monitors**: Heart rate and ECG data are sensitive and require real\u2011time alerts for arrhythmias. Processing on the device protects privacy and ensures immediate response.\n",
    "- **Smart grids**: Real\u2011time load forecasting at substations can optimise local energy distribution without waiting for cloud commands.\n",
    "- **Financial trading terminals**: Low\u2011latency predictions for high\u2011frequency trading may be executed on FPGAs or GPUs near the exchange.\n",
    "\n",
    "In each case, the edge device must be capable of running a model with limited resources. This necessitates model compression and optimisation.\n",
    "\n",
    "---\n",
    "\n",
    "## **96.3 Model Compression Techniques**\n",
    "\n",
    "Deploying a model on an edge device often requires reducing its size and computational cost. The three main techniques are quantization, pruning, and knowledge distillation.\n",
    "\n",
    "### **96.3.1 Quantization**\n",
    "\n",
    "Quantization reduces the numerical precision of a model's weights and activations. For example, instead of 32\u2011bit floating point numbers, we can use 8\u2011bit integers (or even 1\u2011bit binary). This dramatically reduces model size and can speed up inference, especially on hardware with integer accelerators.\n",
    "\n",
    "**Types of quantization**:\n",
    "\n",
    "- **Post\u2011training quantization**: Convert a pre\u2011trained float model to int8 without retraining. This is easy but may cause accuracy loss.\n",
    "- **Quantization\u2011aware training**: Simulate quantization during training so the model learns to be robust to lower precision. This often yields better accuracy.\n",
    "\n",
    "**Example with TensorFlow**:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load a pre\u2011trained Keras model\n",
    "model = tf.keras.models.load_model('nepse_model.h5')\n",
    "\n",
    "# Convert to TensorFlow Lite with float16 quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the quantized model\n",
    "with open('model_float16.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# For int8 quantization, we need a representative dataset to calibrate\n",
    "def representative_dataset():\n",
    "    # Yield samples from the training set\n",
    "    for _ in range(100):\n",
    "        yield [np.random.randn(1, input_size).astype(np.float32)]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_int8_model = converter.convert()\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- We first convert a Keras model to TensorFlow Lite format.\n",
    "- Float16 quantization reduces model size by half with minimal accuracy loss.\n",
    "- Int8 quantization requires a representative dataset to determine the optimal scaling factors for each tensor. The `representative_dataset` function yields samples from the training data.\n",
    "- The resulting `.tflite` file can be deployed on edge devices, including microcontrollers.\n",
    "\n",
    "### **96.3.2 Pruning**\n",
    "\n",
    "Pruning removes less important connections (weights) from a neural network, creating a sparse model. This reduces storage and can accelerate inference on specialised hardware.\n",
    "\n",
    "**Example with TensorFlow Model Optimization Toolkit**:\n",
    "\n",
    "```python\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# Apply pruning to a model\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.0, final_sparsity=0.5, begin_step=0, end_step=1000)\n",
    "}\n",
    "model_to_prune = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# Compile and train with pruning\n",
    "model_to_prune.compile(...)\n",
    "model_to_prune.fit(x_train, y_train, callbacks=[tfmot.sparsity.keras.UpdatePruningStep()])\n",
    "\n",
    "# After training, strip pruning wrappers\n",
    "stripped_model = tfmot.sparsity.keras.strip_pruning(model_to_prune)\n",
    "\n",
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(stripped_model)\n",
    "tflite_model = converter.convert()\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- We wrap the model with `prune_low_magnitude`, which adds masking to the weights.\n",
    "- During training, weights below a threshold are masked (set to zero). The sparsity gradually increases according to the schedule.\n",
    "- After training, we strip the pruning wrappers to obtain a sparse model.\n",
    "- The sparse model can be converted to TFLite, which may be smaller and faster.\n",
    "\n",
    "### **96.3.3 Knowledge Distillation**\n",
    "\n",
    "Knowledge distillation trains a smaller \"student\" model to mimic the predictions of a larger \"teacher\" model. The student learns from the teacher's soft outputs (probabilities) rather than hard labels, often achieving better performance than training from scratch.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "# Teacher: a large, accurate model\n",
    "teacher = tf.keras.models.load_model('large_nepse_model.h5')\n",
    "\n",
    "# Student: a smaller model (e.g., with fewer layers)\n",
    "student = tf.keras.Sequential([...])\n",
    "\n",
    "# Distillation loss: combination of hard loss (true labels) and soft loss (teacher logits)\n",
    "def distillation_loss(y_true, y_pred, teacher_logits, temperature=3.0):\n",
    "    hard_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    soft_loss = tf.keras.losses.KLDivergence()(\n",
    "        tf.nn.softmax(teacher_logits / temperature),\n",
    "        tf.nn.softmax(y_pred / temperature)\n",
    "    )\n",
    "    return hard_loss + soft_loss * (temperature ** 2)\n",
    "\n",
    "# Training loop with teacher providing logits\n",
    "# ...\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- The student learns from both the true labels and the teacher's softened probabilities.\n",
    "- The temperature parameter controls the softness of the probability distribution.\n",
    "- Distillation can produce a compact model that retains much of the teacher's accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## **96.4 TinyML Frameworks and Tools**\n",
    "\n",
    "Several frameworks facilitate deployment on edge devices:\n",
    "\n",
    "### **96.4.1 TensorFlow Lite for Microcontrollers**\n",
    "\n",
    "TensorFlow Lite Micro is a lightweight interpreter designed to run on 32\u2011bit microcontrollers with only a few kilobytes of RAM. It supports a subset of TensorFlow operations and can execute quantized models.\n",
    "\n",
    "**Key features**:\n",
    "\n",
    "- Written in C++ 11, with a small code footprint (~16 KB for core interpreter).\n",
    "- Supports ARM Cortex\u2011M, ESP32, and other architectures.\n",
    "- No operating system required; runs bare\u2011metal.\n",
    "\n",
    "### **96.4.2 Edge Impulse**\n",
    "\n",
    "Edge Impulse is a platform that streamlines the entire TinyML workflow: data ingestion, model design, training, testing, and deployment. It supports many development boards and provides a web\u2011based studio.\n",
    "\n",
    "### **96.4.3 Other Frameworks**\n",
    "\n",
    "- **Apache TVM**: Compiles models for a wide range of hardware (CPUs, GPUs, FPGAs).\n",
    "- **ONNX Runtime**: Can run on edge devices with optimised backends.\n",
    "- **uTensor**: Another lightweight inference engine for microcontrollers.\n",
    "\n",
    "For our example, we will use TensorFlow Lite and simulate deployment on a microcontroller using the TFLite interpreter in Python (as a proxy).\n",
    "\n",
    "---\n",
    "\n",
    "## **96.5 Case Study: Deploying an Anomaly Detection Model on an Edge Device**\n",
    "\n",
    "We will build a simple anomaly detection model for a streaming time series, compress it, and simulate its deployment on an edge device.\n",
    "\n",
    "### **96.5.1 Problem Definition**\n",
    "\n",
    "Imagine a sensor that monitors the trading volume of a NEPSE stock in real time. Unusual volume spikes may indicate market manipulation or news events. We want to run an anomaly detection model on a low\u2011power device near the data source. The device should raise an alert when an anomaly is detected.\n",
    "\n",
    "We'll use a simple autoencoder model trained on normal volume patterns. The reconstruction error will be the anomaly score.\n",
    "\n",
    "### **96.5.2 Data Preparation**\n",
    "\n",
    "We'll generate synthetic volume data with occasional anomalies.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate normal volume data (log\u2011normal distribution)\n",
    "np.random.seed(42)\n",
    "n_normal = 10000\n",
    "normal_volume = np.random.lognormal(mean=12, sigma=1, size=n_normal)\n",
    "\n",
    "# Generate anomalous spikes (10x higher)\n",
    "n_anomaly = 100\n",
    "anomaly_volume = np.random.lognormal(mean=15, sigma=1, size=n_anomaly)\n",
    "\n",
    "# Combine for testing\n",
    "volume = np.concatenate([normal_volume, anomaly_volume])\n",
    "np.random.shuffle(volume)\n",
    "\n",
    "# Create sequences of 10 consecutive readings\n",
    "def create_sequences(data, seq_length=10):\n",
    "    xs = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        xs.append(data[i:i+seq_length])\n",
    "    return np.array(xs)\n",
    "\n",
    "X = create_sequences(normal_volume, seq_length=10)  # train on normal only\n",
    "X_test = create_sequences(volume, seq_length=10)\n",
    "\n",
    "# Normalize to [0,1]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X.reshape(-1,1)).reshape(X.shape)\n",
    "X_test_scaled = scaler.transform(X_test.reshape(-1,1)).reshape(X_test.shape)\n",
    "```\n",
    "\n",
    "### **96.5.3 Build and Train an Autoencoder**\n",
    "\n",
    "```python\n",
    "# Simple autoencoder\n",
    "input_dim = 10\n",
    "encoding_dim = 4\n",
    "\n",
    "input_layer = layers.Input(shape=(input_dim,))\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoded = layers.Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = keras.Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train\n",
    "history = autoencoder.fit(\n",
    "    X_scaled, X_scaled,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.title('Autoencoder Training')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### **96.5.4 Convert to TensorFlow Lite**\n",
    "\n",
    "We'll apply quantization to reduce model size.\n",
    "\n",
    "```python\n",
    "# Convert to float16 TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(autoencoder)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save\n",
    "with open('anomaly_autoencoder_float16.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"Original model size: {len(autoencoder.to_json()):,} bytes (plus weights)\")\n",
    "print(f\"TFLite model size: {len(tflite_model):,} bytes\")\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- The original Keras model (JSON + HDF5) might be hundreds of KB. The quantized TFLite model is typically much smaller.\n",
    "- Float16 quantization reduces weights to 16\u2011bit floats, roughly halving the size.\n",
    "\n",
    "### **96.5.5 Simulate Edge Deployment**\n",
    "\n",
    "We'll use the TFLite interpreter in Python to simulate inference on an edge device. In a real deployment, this code would run on a microcontroller with the TFLite Micro library.\n",
    "\n",
    "```python\n",
    "# Load TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Set threshold for anomaly detection\n",
    "threshold = 0.01  # chosen from validation set\n",
    "\n",
    "# Simulate streaming: process each window\n",
    "anomaly_scores = []\n",
    "for i in range(len(X_test_scaled)):\n",
    "    input_data = X_test_scaled[i].astype(np.float32).reshape(1, 10)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    reconstructed = interpreter.get_tensor(output_details[0]['index'])\n",
    "    mse = np.mean((input_data - reconstructed) ** 2)\n",
    "    anomaly_scores.append(mse)\n",
    "\n",
    "# Identify anomalies\n",
    "anomaly_flags = np.array(anomaly_scores) > threshold\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(anomaly_scores, label='Reconstruction Error')\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold')\n",
    "plt.plot(np.where(anomaly_flags)[0], np.array(anomaly_scores)[anomaly_flags], 'ro', label='Detected')\n",
    "plt.legend()\n",
    "plt.title('Anomaly Detection on Edge')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- We load the quantized TFLite model into an interpreter.\n",
    "- For each input window, we run inference and compute the reconstruction error.\n",
    "- If the error exceeds a threshold, we flag an anomaly.\n",
    "- This simulates what would happen on an edge device: the model runs locally and only sends alerts when anomalies occur.\n",
    "\n",
    "### **96.5.6 Deployment Considerations on Real Hardware**\n",
    "\n",
    "On a real microcontroller, you would:\n",
    "\n",
    "1. Include the TFLite Micro library in your firmware.\n",
    "2. Convert the `.tflite` file to a C byte array (using `xxd`).\n",
    "3. Write a simple C++ program that reads sensor data, runs inference, and triggers an alert (e.g., LED, message).\n",
    "\n",
    "**Example C byte array generation**:\n",
    "\n",
    "```bash\n",
    "xxd -i anomaly_autoencoder_float16.tflite > model_data.cpp\n",
    "```\n",
    "\n",
    "This creates a C array like `unsigned char anomaly_autoencoder_float16_tflite[] = {...}`.\n",
    "\n",
    "---\n",
    "\n",
    "## **96.6 Performance Evaluation**\n",
    "\n",
    "When deploying on edge, we must evaluate:\n",
    "\n",
    "- **Model size**: Does it fit in flash memory? (e.g., 128 KB for some microcontrollers)\n",
    "- **RAM usage**: Does inference exceed available RAM? (often a few KB to a few hundred KB)\n",
    "- **Inference time**: Can it keep up with the data rate? (e.g., 10 ms per inference for 100 Hz data)\n",
    "- **Accuracy**: How much accuracy is lost due to quantization/pruning?\n",
    "- **Power consumption**: Milliwatts or microwatts? Affects battery life.\n",
    "\n",
    "For our autoencoder, float16 quantization should have negligible accuracy loss. The model size (~a few KB) fits easily on most microcontrollers.\n",
    "\n",
    "---\n",
    "\n",
    "## **96.7 Challenges and Limitations**\n",
    "\n",
    "- **Hardware constraints**: Memory, compute, and power are severely limited.\n",
    "- **Operator support**: Not all TensorFlow operations are implemented in TFLite Micro. You may need to simplify your model.\n",
    "- **Floating point vs. integer**: Some microcontrollers have no FPU; integer\u2011only models are required.\n",
    "- **Model updates**: Updating models on deployed devices can be difficult (over\u2011the\u2011air updates require careful design).\n",
    "- **Security**: Edge devices can be physically tampered with; consider secure boot and encrypted storage.\n",
    "\n",
    "---\n",
    "\n",
    "## **96.8 Future Directions**\n",
    "\n",
    "- **TinyML with neural architecture search**: Automatically find efficient architectures for edge devices.\n",
    "- **On\u2011device learning**: Models that adapt to new data without cloud connectivity.\n",
    "- **Integration with embedded operating systems**: Better support in FreeRTOS, Zephyr, etc.\n",
    "- **Hardware advancements**: New ultra\u2011low\u2011power AI accelerators (e.g., ARM Ethos\u2011U, Syntiant).\n",
    "- **Federated learning**: Train across many edge devices without sharing raw data.\n",
    "\n",
    "---\n",
    "\n",
    "## **96.9 Chapter Summary**\n",
    "\n",
    "In this chapter, we explored Edge AI and TinyML, focusing on deploying time\u2011series models on resource\u2011constrained devices. We covered:\n",
    "\n",
    "- The motivation for edge deployment: latency, bandwidth, privacy, and reliability.\n",
    "- Model compression techniques: quantization, pruning, and knowledge distillation.\n",
    "- Frameworks like TensorFlow Lite for Microcontrollers and Edge Impulse.\n",
    "- A complete case study: building an autoencoder for anomaly detection on streaming volume data, converting it to a quantized TFLite model, and simulating edge inference.\n",
    "- Performance evaluation and the challenges of real\u2011world deployment.\n",
    "\n",
    "Edge AI is a rapidly growing field, and for time\u2011series applications, it enables a new class of intelligent, low\u2011power, and responsive systems. While the NEPSE example here is simplified, the same principles apply to many real\u2011world problems, from predictive maintenance to healthcare monitoring.\n",
    "\n",
    "In the next chapter, we will explore **Quantum Machine Learning**, a speculative but exciting frontier that may revolutionise computation for certain time\u2011series tasks.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 96**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='95. automated_scientific_discovery.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='97. quantum_machine_learning.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}