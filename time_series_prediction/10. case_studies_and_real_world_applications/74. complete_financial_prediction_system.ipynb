{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 74: Complete Financial Prediction System**\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Design the end‑to‑end architecture of a time‑series prediction system.\n",
    "- Integrate data collection, feature engineering, model training, backtesting, and deployment into a cohesive pipeline.\n",
    "- Implement a backtesting framework that respects temporal order and prevents look‑ahead bias.\n",
    "- Deploy the model as a REST API and as a batch prediction service.\n",
    "- Set up monitoring for model performance, data drift, and system health.\n",
    "- Analyse historical performance and extract actionable lessons.\n",
    "- Plan future improvements based on real‑world feedback.\n",
    "\n",
    "---\n",
    "\n",
    "## **74.1 System Architecture**\n",
    "\n",
    "A complete financial prediction system is not just a Jupyter notebook with a model. It is a set of interconnected components that work together to deliver reliable, maintainable, and actionable predictions. Figure 74.1 illustrates the high‑level architecture of our NEPSE prediction system.\n",
    "\n",
    "```\n",
    "┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐\n",
    "│                 │     │                 │     │                 │\n",
    "│  Data Sources   │────▶│  Data Ingestion │────▶│  Data Storage   │\n",
    "│  (NEPSE CSV,    │     │  (daily ETL)    │     │  (Parquet, DB)  │\n",
    "│   APIs, etc.)   │     │                 │     │                 │\n",
    "└─────────────────┘     └─────────────────┘     └─────────────────┘\n",
    "                                                           │\n",
    "                                                           ▼\n",
    "┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐\n",
    "│                 │     │                 │     │                 │\n",
    "│  Monitoring &   │◀────│  Prediction     │◀────│  Feature Store  │\n",
    "│  Alerting       │     │  Service        │     │  (engineered    │\n",
    "│  (Chapter 73)   │     │  (REST/batch)   │     │   features)     │\n",
    "└─────────────────┘     └─────────────────┘     └─────────────────┘\n",
    "         │                       │\n",
    "         ▼                       ▼\n",
    "┌─────────────────┐     ┌─────────────────┐\n",
    "│                 │     │                 │\n",
    "│  Drift Detector │     │  Model Registry │\n",
    "│  (concept/data) │     │  (MLflow)       │\n",
    "└─────────────────┘     └─────────────────┘\n",
    "```\n",
    "\n",
    "The architecture consists of several layers:\n",
    "\n",
    "1. **Data Layer**: Raw NEPSE data from CSV files (or APIs) is ingested and stored in a scalable format (Parquet) and optionally in a time‑series database for fast queries.\n",
    "2. **Feature Layer**: A feature engineering pipeline transforms raw data into model‑ready features. The results are stored in a **feature store** for reuse across training and inference.\n",
    "3. **Model Layer**: Models are trained, validated, and registered in a **model registry** (e.g., MLflow). The registry manages versions, metadata, and staging/production tags.\n",
    "4. **Prediction Layer**: A prediction service serves the model via REST API (real‑time) or as a batch job (daily).\n",
    "5. **Monitoring Layer**: System and model metrics are collected; alerts are triggered when anomalies or drifts are detected (Chapter 73).\n",
    "6. **Orchestration**: Workflow managers (Airflow, Prefect) schedule and coordinate the entire pipeline.\n",
    "\n",
    "In the following sections, we will implement each component, building on the code from previous chapters.\n",
    "\n",
    "---\n",
    "\n",
    "## **74.2 Data Collection Pipeline**\n",
    "\n",
    "The data collection pipeline is responsible for acquiring new data, validating it, and storing it in a consistent format. For our NEPSE system, the primary source is a daily CSV file, but the design should be extensible to APIs.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import io\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class NEPSEIngestion:\n",
    "    \"\"\"\n",
    "    Handles ingestion of NEPSE data from CSV or API.\n",
    "    \n",
    "    For demonstration, we assume a local CSV file is updated daily.\n",
    "    In production, you might pull from an API.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str = \"./data/raw\"):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def fetch_from_csv(self, file_path: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load raw NEPSE CSV and perform basic validation.\n",
    "        Expected columns (based on NEPSE format):\n",
    "        S.No,Symbol,Conf.,Open,High,Low,Close,LTP,Close - LTP,Close - LTP %,\n",
    "        VWAP,Vol,Prev. Close,Turnover,Trans.,Diff,Range,Diff %,Range %,VWAP %,\n",
    "        52 Weeks High,52 Weeks Low\n",
    "        \"\"\"\n",
    "        logger.info(f\"Loading data from {file_path}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Validate required columns\n",
    "        required = ['Symbol', 'Open', 'High', 'Low', 'Close', 'Vol']\n",
    "        missing = [col for col in required if col not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing columns: {missing}\")\n",
    "        \n",
    "        # Convert date: if no Date column, create from S.No (assuming daily sequence)\n",
    "        if 'Date' not in df.columns:\n",
    "            # Assume data starts from some start_date; for demo, use today - len(df)\n",
    "            start_date = datetime.now() - pd.Timedelta(days=len(df))\n",
    "            df['Date'] = pd.date_range(start_date, periods=len(df), freq='B')  # business days\n",
    "        else:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "        \n",
    "        # Sort by date (important for time series)\n",
    "        df = df.sort_values('Date')\n",
    "        \n",
    "        logger.info(f\"Loaded {len(df)} records from {df['Date'].min()} to {df['Date'].max()}\")\n",
    "        return df\n",
    "    \n",
    "    def fetch_from_api(self, api_url: str, params: dict = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Example API ingestion (hypothetical NEPSE API).\n",
    "        \"\"\"\n",
    "        logger.info(f\"Fetching from API: {api_url}\")\n",
    "        resp = requests.get(api_url, params=params)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        # Assume API returns list of dicts\n",
    "        df = pd.DataFrame(data)\n",
    "        # Convert date and sort\n",
    "        df['Date'] = pd.to_datetime(df['date'])\n",
    "        df = df.sort_values('Date')\n",
    "        return df\n",
    "    \n",
    "    def save_raw(self, df: pd.DataFrame, filename: str = None):\n",
    "        \"\"\"\n",
    "        Save raw data to Parquet (compressed, columnar format).\n",
    "        \"\"\"\n",
    "        if filename is None:\n",
    "            filename = f\"nepse_raw_{datetime.now().strftime('%Y%m%d')}.parquet\"\n",
    "        path = self.data_dir / filename\n",
    "        df.to_parquet(path, index=False)\n",
    "        logger.info(f\"Saved raw data to {path}\")\n",
    "        return path\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    ingestor = NEPSEIngestion()\n",
    "    # Simulate a new CSV arriving daily\n",
    "    df = ingestor.fetch_from_csv(\"nepse_latest.csv\")\n",
    "    ingestor.save_raw(df)\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- The `NEPSEIngestion` class abstracts the source of data. Currently, it supports CSV loading but can be extended to APIs.\n",
    "- CSV loading validates required columns and ensures a proper datetime index. If no `Date` column exists, it creates one based on the assumption of daily business-day data (Monday–Friday). This matches NEPSE’s trading days (Sunday–Thursday), but we use `freq='B'` as a simplification; for exact NEPSE calendar, a custom frequency would be needed.\n",
    "- Data is saved in **Parquet** format, which is compressed, columnar, and much faster than CSV for repeated reads. This is crucial for downstream feature engineering.\n",
    "- Logging statements provide visibility into the ingestion process.\n",
    "\n",
    "---\n",
    "\n",
    "## **74.3 Feature Engineering Pipeline**\n",
    "\n",
    "The feature engineering pipeline reads raw data, computes all the features we designed in Part III, and stores them in a **feature store**. The feature store allows us to retrieve features consistently for both training and inference.\n",
    "\n",
    "We will reuse and extend the `NEPSEFeatureEngineer` class from Chapter 10, but now we will separate the feature computation logic and add a storage layer.\n",
    "\n",
    "```python\n",
    "# feature_engineering.py\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class NEPSEFeatureEngineer:\n",
    "    \"\"\"\n",
    "    Feature engineering for NEPSE data.\n",
    "    Generates lag, rolling, technical, and domain‑specific features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feature_columns = []  # to be filled after computation\n",
    "    \n",
    "    def compute_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Main entry point: compute all features and return a DataFrame with the same index.\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Basic price transformations\n",
    "        df['Daily_Return'] = df['Close'].pct_change() * 100\n",
    "        df['Price_Range'] = df['High'] - df['Low']\n",
    "        df['Price_Change'] = df['Close'] - df['Open']\n",
    "        df['Upper_Shadow'] = df['High'] - df[['Close', 'Open']].max(axis=1)\n",
    "        df['Lower_Shadow'] = df[['Close', 'Open']].min(axis=1) - df['Low']\n",
    "        df['Body_Ratio'] = abs(df['Price_Change']) / (df['Price_Range'] + 1e-6)\n",
    "        \n",
    "        # Lag features\n",
    "        for lag in [1, 2, 3, 5, 10]:\n",
    "            df[f'Close_Lag_{lag}'] = df['Close'].shift(lag)\n",
    "            df[f'Return_Lag_{lag}'] = df['Daily_Return'].shift(lag)\n",
    "            df[f'Volume_Lag_{lag}'] = df['Vol'].shift(lag)\n",
    "        \n",
    "        # Rolling window features\n",
    "        for window in [5, 10, 20]:\n",
    "            # Trend\n",
    "            df[f'SMA_{window}'] = df['Close'].rolling(window).mean()\n",
    "            df[f'EMA_{window}'] = df['Close'].ewm(span=window).mean()\n",
    "            \n",
    "            # Volatility\n",
    "            df[f'Volatility_{window}'] = df['Close'].rolling(window).std()\n",
    "            df[f'ATR_{window}'] = (df['High'] - df['Low']).rolling(window).mean()\n",
    "            \n",
    "            # Volume\n",
    "            df[f'Volume_SMA_{window}'] = df['Vol'].rolling(window).mean()\n",
    "            df[f'Volume_Ratio_{window}'] = df['Vol'] / (df[f'Volume_SMA_{window}'] + 1e-6)\n",
    "            \n",
    "            # Price range\n",
    "            df[f'Range_Max_{window}'] = df['High'].rolling(window).max()\n",
    "            df[f'Range_Min_{window}'] = df['Low'].rolling(window).min()\n",
    "        \n",
    "        # Technical indicators\n",
    "        # RSI\n",
    "        delta = df['Close'].diff()\n",
    "        gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "        rs = gain / (loss + 1e-6)\n",
    "        df['RSI'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # MACD\n",
    "        ema_12 = df['Close'].ewm(span=12).mean()\n",
    "        ema_26 = df['Close'].ewm(span=26).mean()\n",
    "        df['MACD'] = ema_12 - ema_26\n",
    "        df['MACD_Signal'] = df['MACD'].ewm(span=9).mean()\n",
    "        df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        sma_20 = df['Close'].rolling(20).mean()\n",
    "        std_20 = df['Close'].rolling(20).std()\n",
    "        df['BB_Upper'] = sma_20 + 2 * std_20\n",
    "        df['BB_Lower'] = sma_20 - 2 * std_20\n",
    "        df['BB_Width'] = df['BB_Upper'] - df['BB_Lower']\n",
    "        df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Width'] + 1e-6)\n",
    "        \n",
    "        # NEPSE domain features (circuit breaker proximity, fiscal quarter, etc.)\n",
    "        # Fiscal calendar (simplified: month to quarter)\n",
    "        if 'Date' in df.columns:\n",
    "            df['Month'] = df['Date'].dt.month\n",
    "            df['Quarter'] = df['Date'].dt.quarter\n",
    "            # Fiscal year end (mid-July) approximation: July is month 7\n",
    "            df['Days_to_Fiscal_Year_End'] = (pd.to_datetime(df['Date'].dt.year.astype(str) + '-07-15') - df['Date']).dt.days\n",
    "        \n",
    "        # Circuit breaker proximity\n",
    "        if 'Prev. Close' in df.columns:\n",
    "            df['Daily_Change_Pct'] = ((df['Close'] - df['Prev. Close']) / df['Prev. Close']) * 100\n",
    "            df['Upper_Circuit_Proximity'] = 4 - df['Daily_Change_Pct']  # NEPSE first limit 4%\n",
    "            df['Lower_Circuit_Proximity'] = df['Daily_Change_Pct'] - (-4)\n",
    "        \n",
    "        # Volume Z‑score (anomaly detection)\n",
    "        vol_mean = df['Vol'].rolling(20).mean()\n",
    "        vol_std = df['Vol'].rolling(20).std()\n",
    "        df['Volume_Z_Score'] = (df['Vol'] - vol_mean) / (vol_std + 1e-6)\n",
    "        \n",
    "        # Drop rows with NaN created by shifts/rolling\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "        \n",
    "        # Store list of feature columns (exclude metadata and target)\n",
    "        exclude = ['Date', 'Symbol', 'S.No', 'Conf.', 'Close', 'Prev. Close', 'LTP', 'Turnover', 'Trans.']\n",
    "        self.feature_columns = [col for col in df.columns if col not in exclude]\n",
    "        \n",
    "        logger.info(f\"Computed {len(self.feature_columns)} features\")\n",
    "        return df\n",
    "\n",
    "class FeatureStore:\n",
    "    \"\"\"\n",
    "    Simple feature store that saves/loads feature DataFrames.\n",
    "    In production, this could be a database (Redis, Feast, etc.).\n",
    "    \"\"\"\n",
    "    def __init__(self, store_dir: str = \"./data/features\"):\n",
    "        self.store_dir = Path(store_dir)\n",
    "        self.store_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def save(self, df: pd.DataFrame, symbol: str, date: datetime):\n",
    "        \"\"\"\n",
    "        Save features for a given symbol and date.\n",
    "        For simplicity, we append to a single parquet file per symbol.\n",
    "        \"\"\"\n",
    "        file_path = self.store_dir / f\"{symbol}_features.parquet\"\n",
    "        # If file exists, read and append, else create new\n",
    "        if file_path.exists():\n",
    "            existing = pd.read_parquet(file_path)\n",
    "            # Avoid duplicates by date\n",
    "            combined = pd.concat([existing, df], ignore_index=True).drop_duplicates(subset=['Date'], keep='last')\n",
    "        else:\n",
    "            combined = df\n",
    "        combined.to_parquet(file_path, index=False)\n",
    "        logger.info(f\"Saved features for {symbol} to {file_path}\")\n",
    "    \n",
    "    def load(self, symbol: str, start_date: datetime = None, end_date: datetime = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load features for a symbol, optionally within a date range.\n",
    "        \"\"\"\n",
    "        file_path = self.store_dir / f\"{symbol}_features.parquet\"\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"No features for {symbol}\")\n",
    "        df = pd.read_parquet(file_path)\n",
    "        if start_date:\n",
    "            df = df[df['Date'] >= start_date]\n",
    "        if end_date:\n",
    "            df = df[df['Date'] <= end_date]\n",
    "        return df.sort_values('Date')\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- The `NEPSEFeatureEngineer.compute_features` method consolidates all feature creation logic from earlier chapters. It takes a raw DataFrame (with at least `Open`, `High`, `Low`, `Close`, `Vol`, and optionally `Date`) and returns a DataFrame with all engineered features.\n",
    "- Important: The method **does not** split the data; it simply computes features for whatever data is passed. It also drops rows with NaN values that result from lag and rolling operations. This ensures that downstream models receive a clean matrix.\n",
    "- The `feature_columns` attribute stores the names of all generated features, which can be used later for selection or model input.\n",
    "- The `FeatureStore` class provides a simple persistent storage for features. It saves features per symbol in Parquet format. In a real system, you might use a feature store like Feast or Tecton, but this lightweight version suffices for demonstration.\n",
    "- When saving, we check for duplicates by date and keep the latest, in case the pipeline is rerun for the same day.\n",
    "\n",
    "---\n",
    "\n",
    "## **74.4 Model Development**\n",
    "\n",
    "Now we move to model training. We will:\n",
    "\n",
    "1. Load historical features from the feature store.\n",
    "2. Split the data respecting time (no random shuffling).\n",
    "3. Train a model (we'll use XGBoost as a robust baseline).\n",
    "4. Register the model and its metadata in MLflow.\n",
    "5. Save the model for deployment.\n",
    "\n",
    "```python\n",
    "# model_training.py\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class NEPSEForecaster:\n",
    "    \"\"\"\n",
    "    Handles model training, validation, and registration.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature_store: FeatureStore, target_col: str = 'Close'):\n",
    "        self.feature_store = feature_store\n",
    "        self.target_col = target_col\n",
    "        self.model = None\n",
    "        self.feature_columns = None\n",
    "    \n",
    "    def prepare_training_data(self, symbol: str, start_date: datetime, end_date: datetime, \n",
    "                               feature_cols: List[str] = None):\n",
    "        \"\"\"\n",
    "        Load features and target from feature store.\n",
    "        \"\"\"\n",
    "        df = self.feature_store.load(symbol, start_date, end_date)\n",
    "        \n",
    "        if feature_cols is None:\n",
    "            # Use all features except target and metadata\n",
    "            exclude = ['Date', 'Symbol', self.target_col]\n",
    "            feature_cols = [c for c in df.columns if c not in exclude]\n",
    "        \n",
    "        X = df[feature_cols]\n",
    "        y = df[self.target_col]\n",
    "        \n",
    "        logger.info(f\"Prepared training data: X shape {X.shape}, y shape {y.shape}\")\n",
    "        return X, y, df['Date']\n",
    "    \n",
    "    def train_with_cv(self, X, y, dates, n_splits=5):\n",
    "        \"\"\"\n",
    "        Train with time‑series cross‑validation.\n",
    "        \"\"\"\n",
    "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "        \n",
    "        cv_scores = []\n",
    "        models = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            model = xgb.XGBRegressor(\n",
    "                n_estimators=300,\n",
    "                max_depth=5,\n",
    "                learning_rate=0.05,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_val, y_val)],\n",
    "                early_stopping_rounds=10,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            y_pred = model.predict(X_val)\n",
    "            mae = mean_absolute_error(y_val, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "            \n",
    "            cv_scores.append({'fold': fold, 'mae': mae, 'rmse': rmse})\n",
    "            models.append(model)\n",
    "            logger.info(f\"Fold {fold}: MAE={mae:.2f}, RMSE={rmse:.2f}\")\n",
    "        \n",
    "        # Select best model (lowest validation MAE)\n",
    "        best_idx = np.argmin([s['mae'] for s in cv_scores])\n",
    "        self.model = models[best_idx]\n",
    "        logger.info(f\"Best model from fold {best_idx} with MAE={cv_scores[best_idx]['mae']:.2f}\")\n",
    "        \n",
    "        return cv_scores\n",
    "    \n",
    "    def train_final(self, X, y):\n",
    "        \"\"\"\n",
    "        Train final model on all data (for production).\n",
    "        \"\"\"\n",
    "        self.model = xgb.XGBRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.model.fit(X, y)\n",
    "        logger.info(\"Final model trained on full dataset\")\n",
    "        return self.model\n",
    "    \n",
    "    def register_model(self, model_name: str, params: dict, metrics: dict, \n",
    "                       feature_cols: List[str], artifact_path: str = \"model\"):\n",
    "        \"\"\"\n",
    "        Log model to MLflow registry.\n",
    "        \"\"\"\n",
    "        with mlflow.start_run() as run:\n",
    "            # Log parameters\n",
    "            for key, value in params.items():\n",
    "                mlflow.log_param(key, value)\n",
    "            \n",
    "            # Log metrics\n",
    "            for key, value in metrics.items():\n",
    "                mlflow.log_metric(key, value)\n",
    "            \n",
    "            # Log feature list as an artifact\n",
    "            with open(\"feature_cols.txt\", \"w\") as f:\n",
    "                f.write(\"\\n\".join(feature_cols))\n",
    "            mlflow.log_artifact(\"feature_cols.txt\")\n",
    "            \n",
    "            # Log the model\n",
    "            mlflow.xgboost.log_model(self.model, artifact_path, registered_model_name=model_name)\n",
    "            \n",
    "            run_id = run.info.run_id\n",
    "            logger.info(f\"Model registered in MLflow run {run_id}\")\n",
    "            return run_id\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Assume feature store already populated\n",
    "    store = FeatureStore()\n",
    "    forecaster = NEPSEForecaster(store)\n",
    "    \n",
    "    # Define date range for training (e.g., last 3 years)\n",
    "    end = datetime.now()\n",
    "    start = end - timedelta(days=3*365)\n",
    "    \n",
    "    X, y, dates = forecaster.prepare_training_data('NEPSE', start, end)\n",
    "    \n",
    "    # Cross‑validation\n",
    "    cv_scores = forecaster.train_with_cv(X, y, dates)\n",
    "    \n",
    "    # Compute average metrics\n",
    "    avg_mae = np.mean([s['mae'] for s in cv_scores])\n",
    "    avg_rmse = np.mean([s['rmse'] for s in cv_scores])\n",
    "    \n",
    "    # Train final model on all data (or optionally on the best fold's training data)\n",
    "    forecaster.train_final(X, y)\n",
    "    \n",
    "    # Register model\n",
    "    params = {\n",
    "        'n_estimators': 300,\n",
    "        'max_depth': 5,\n",
    "        'learning_rate': 0.05,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8\n",
    "    }\n",
    "    metrics = {'cv_mae': avg_mae, 'cv_rmse': avg_rmse}\n",
    "    forecaster.register_model('NEPSE_Close_Predictor', params, metrics, X.columns.tolist())\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- We use `TimeSeriesSplit` from scikit‑learn to perform time‑based cross‑validation. This respects the temporal order and prevents future data from leaking into past folds.\n",
    "- XGBoost is chosen for its robustness with tabular data and ability to handle missing values. We set `early_stopping_rounds` to avoid overfitting.\n",
    "- The best model from cross‑validation is selected based on validation MAE.\n",
    "- For production, we then retrain on the full dataset (or you could keep the best fold model). This final model is saved.\n",
    "- **MLflow** is used for experiment tracking and model registry. We log parameters, metrics, and the list of features used (critical for inference). The model is registered under a name, making it easy to deploy later.\n",
    "- The code is modular: `prepare_training_data` loads features from the store, so the same pipeline can be used for different symbols or date ranges.\n",
    "\n",
    "---\n",
    "\n",
    "## **74.5 Backtesting**\n",
    "\n",
    "Backtesting evaluates how the model would have performed historically if it had been used for trading. This is more rigorous than simple validation because it simulates a trading strategy (e.g., buy when predicted price increase > 1%, sell when < -1%).\n",
    "\n",
    "We'll implement a simple backtester that:\n",
    "\n",
    "- Uses walk‑forward validation (train on expanding window, predict on next day/week).\n",
    "- Computes trading signals based on predicted returns.\n",
    "- Calculates performance metrics: total return, Sharpe ratio, max drawdown.\n",
    "\n",
    "```python\n",
    "# backtesting.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "class NEPSEBacktester:\n",
    "    \"\"\"\n",
    "    Walk‑forward backtesting with a simple trading strategy.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, feature_columns: List[str], initial_capital: float = 100000):\n",
    "        self.model = model\n",
    "        self.feature_columns = feature_columns\n",
    "        self.initial_capital = initial_capital\n",
    "    \n",
    "    def run(self, X: pd.DataFrame, y_true: pd.Series, dates: pd.Series) -> Dict:\n",
    "        \"\"\"\n",
    "        Simulate trading day by day.\n",
    "        Strategy: If predicted return > threshold, buy; if < -threshold, sell.\n",
    "        For simplicity, we assume we can only be long or flat (no short).\n",
    "        \"\"\"\n",
    "        # Ensure X contains only the features the model expects\n",
    "        X = X[self.feature_columns]\n",
    "        \n",
    "        # Get predictions\n",
    "        y_pred = self.model.predict(X)\n",
    "        \n",
    "        # Compute predicted returns (as percentage of current price)\n",
    "        # Since model predicts absolute close price, we convert to return\n",
    "        pred_return = (y_pred / y_true.values - 1) * 100\n",
    "        \n",
    "        # Generate signals: 1 = buy, -1 = sell (go flat), 0 = hold\n",
    "        # Simple threshold: 1% predicted return\n",
    "        signals = np.zeros(len(X))\n",
    "        signals[pred_return > 1.0] = 1     # buy\n",
    "        signals[pred_return < -1.0] = -1   # sell (go flat)\n",
    "        \n",
    "        # Simulate portfolio\n",
    "        portfolio = pd.DataFrame(index=dates)\n",
    "        portfolio['price'] = y_true.values\n",
    "        portfolio['signal'] = signals\n",
    "        portfolio['position'] = portfolio['signal'].replace({-1: 0, 1: 1, 0: np.nan}).ffill().fillna(0)\n",
    "        portfolio['returns'] = portfolio['price'].pct_change()\n",
    "        portfolio['strategy_returns'] = portfolio['position'].shift(1) * portfolio['returns']\n",
    "        \n",
    "        # Calculate cumulative wealth\n",
    "        portfolio['cumulative_market'] = (1 + portfolio['returns']).cumprod()\n",
    "        portfolio['cumulative_strategy'] = (1 + portfolio['strategy_returns']).cumprod() * self.initial_capital\n",
    "        \n",
    "        # Performance metrics\n",
    "        total_return = (portfolio['cumulative_strategy'].iloc[-1] / self.initial_capital - 1) * 100\n",
    "        sharpe = portfolio['strategy_returns'].mean() / portfolio['strategy_returns'].std() * np.sqrt(252)\n",
    "        max_drawdown = (portfolio['cumulative_strategy'] / portfolio['cumulative_strategy'].cummax() - 1).min()\n",
    "        \n",
    "        metrics = {\n",
    "            'total_return_pct': total_return,\n",
    "            'sharpe_ratio': sharpe,\n",
    "            'max_drawdown_pct': max_drawdown * 100,\n",
    "            'num_trades': (signals != 0).sum(),\n",
    "        }\n",
    "        \n",
    "        return metrics, portfolio\n",
    "\n",
    "# Usage within the training pipeline\n",
    "def backtest_model(model, X, y, dates):\n",
    "    bt = NEPSEBacktester(model, X.columns.tolist())\n",
    "    metrics, portfolio = bt.run(X, y, dates)\n",
    "    print(\"Backtest Metrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v:.2f}\")\n",
    "    return metrics, portfolio\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- The backtester uses the trained model to generate predictions on historical data, then simulates a simple trading strategy. This is a **walk‑forward** simulation because we are using the model as if it were making predictions day by day.\n",
    "- To avoid look‑ahead, we must ensure that the model was trained only on data prior to each prediction. Our `run` method assumes that the model was trained on data ending before the first date in `dates`. This is true if we use a walk‑forward training scheme (not shown here but can be implemented with a loop).\n",
    "- The strategy: if predicted return > 1%, buy (go long); if predicted return < -1%, sell (go flat). We hold the position until a new signal arrives.\n",
    "- Metrics: total return (percentage), Sharpe ratio (risk‑adjusted return), maximum drawdown, and number of trades.\n",
    "- The `portfolio` DataFrame is returned for further analysis (e.g., plotting equity curve).\n",
    "\n",
    "---\n",
    "\n",
    "## **74.6 Production Deployment**\n",
    "\n",
    "In production, we need to serve predictions both in **batch** mode (e.g., daily after market close) and **real‑time** (e.g., via API). We will build two services:\n",
    "\n",
    "1. **Batch prediction service**: runs daily, loads new features, generates predictions, and stores them in a database or sends them to a dashboard.\n",
    "2. **REST API**: allows on‑demand prediction for a given stock.\n",
    "\n",
    "### **74.6.1 Batch Prediction Service**\n",
    "\n",
    "```python\n",
    "# batch_predictor.py\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import mlflow.pyfunc\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class BatchPredictor:\n",
    "    \"\"\"\n",
    "    Daily batch prediction job.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, model_stage: str = \"Production\", \n",
    "                 feature_store: FeatureStore = None):\n",
    "        \"\"\"\n",
    "        Load model from MLflow registry.\n",
    "        \"\"\"\n",
    "        self.model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_stage}\")\n",
    "        self.feature_store = feature_store or FeatureStore()\n",
    "        # Retrieve feature list (should be stored as artifact during training)\n",
    "        # In practice, you'd store this in the model's metadata.\n",
    "        self.feature_columns = self._load_feature_columns(model_name)\n",
    "    \n",
    "    def _load_feature_columns(self, model_name):\n",
    "        # Dummy implementation – in reality, fetch from MLflow artifact\n",
    "        # For now, assume we saved a file with the model\n",
    "        # ...\n",
    "        return ['Close_Lag_1', 'SMA_20', 'RSI', ...]  # placeholder\n",
    "    \n",
    "    def predict_for_date(self, symbol: str, date: datetime) -> float:\n",
    "        \"\"\"\n",
    "        Generate prediction for a single date using the latest available features.\n",
    "        \"\"\"\n",
    "        # Load features for the symbol up to the day before (since we can't know today's close yet)\n",
    "        # For simplicity, assume we have features up to date-1\n",
    "        df = self.feature_store.load(symbol, end_date=date - timedelta(days=1))\n",
    "        if df.empty:\n",
    "            raise ValueError(f\"No features available for {symbol} before {date}\")\n",
    "        latest = df.iloc[-1:]\n",
    "        X = latest[self.feature_columns]\n",
    "        pred = self.model.predict(X)[0]\n",
    "        return pred\n",
    "    \n",
    "    def run_daily(self, symbols: List[str], target_date: datetime = None):\n",
    "        \"\"\"\n",
    "        Run batch prediction for all symbols on target_date.\n",
    "        \"\"\"\n",
    "        if target_date is None:\n",
    "            target_date = datetime.now().date()\n",
    "        results = []\n",
    "        for symbol in symbols:\n",
    "            try:\n",
    "                pred = self.predict_for_date(symbol, target_date)\n",
    "                results.append({'symbol': symbol, 'date': target_date, 'predicted_close': pred})\n",
    "                logger.info(f\"Predicted {symbol} close: {pred:.2f}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed for {symbol}: {e}\")\n",
    "        # Save results (to CSV, database, etc.)\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_csv(f\"predictions_{target_date}.csv\", index=False)\n",
    "        logger.info(f\"Batch predictions saved for {target_date}\")\n",
    "        return df\n",
    "```\n",
    "\n",
    "### **74.6.2 REST API Service**\n",
    "\n",
    "We'll build a simple REST API using FastAPI.\n",
    "\n",
    "```python\n",
    "# api_service.py\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import mlflow.pyfunc\n",
    "import logging\n",
    "\n",
    "app = FastAPI(title=\"NEPSE Prediction API\")\n",
    "\n",
    "# Global model and feature store (loaded at startup)\n",
    "model = None\n",
    "feature_store = None\n",
    "feature_columns = None\n",
    "\n",
    "class PredictionRequest(BaseModel):\n",
    "    symbol: str\n",
    "    date: date  # The date for which we want prediction (usually today)\n",
    "\n",
    "class PredictionResponse(BaseModel):\n",
    "    symbol: str\n",
    "    date: date\n",
    "    predicted_close: float\n",
    "    model_version: str\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "def load_model():\n",
    "    global model, feature_store, feature_columns\n",
    "    model = mlflow.pyfunc.load_model(\"models:/NEPSE_Close_Predictor/Production\")\n",
    "    feature_store = FeatureStore()\n",
    "    # Load feature columns from somewhere (e.g., from model's run artifacts)\n",
    "    # Here we hardcode for demonstration\n",
    "    feature_columns = ['Close_Lag_1', 'SMA_20', 'RSI', 'Volume_Z_Score']  # example\n",
    "    logging.info(\"Model loaded successfully\")\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\"status\": \"healthy\"}\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictionResponse)\n",
    "def predict(request: PredictionRequest):\n",
    "    # Get features for the symbol up to the day before request.date\n",
    "    # (since we cannot use future data)\n",
    "    end_date = request.date - pd.Timedelta(days=1)\n",
    "    df = feature_store.load(request.symbol, end_date=end_date)\n",
    "    if df.empty:\n",
    "        raise HTTPException(status_code=404, detail=\"No features found for symbol/date\")\n",
    "    latest = df.iloc[-1:]\n",
    "    X = latest[feature_columns]\n",
    "    pred = model.predict(X)[0]\n",
    "    return PredictionResponse(\n",
    "        symbol=request.symbol,\n",
    "        date=request.date,\n",
    "        predicted_close=float(pred),\n",
    "        model_version=\"1.0.0\"  # in practice, fetch from model metadata\n",
    "    )\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- The batch predictor loads the model from MLflow (by stage, e.g., \"Production\") and uses the feature store to retrieve the latest features. It then predicts the next day's close price.\n",
    "- The REST API is built with FastAPI, which automatically generates OpenAPI documentation. It loads the model at startup and provides an endpoint `/predict` that accepts a symbol and date.\n",
    "- Both services ensure that no future data is used: they only access features up to the day before the prediction date.\n",
    "- In production, you would containerise these services (Docker) and deploy them using Kubernetes or a cloud platform.\n",
    "\n",
    "---\n",
    "\n",
    "## **74.7 Monitoring**\n",
    "\n",
    "Monitoring is crucial to detect when the model's performance degrades. We'll implement:\n",
    "\n",
    "- **Prediction monitoring**: store predictions and actuals, compute daily/weekly error metrics.\n",
    "- **Data drift monitoring**: compare distributions of key features between training and recent data using statistical tests (e.g., Kolmogorov–Smirnov).\n",
    "- **System health monitoring**: track API latency, error rates, and data freshness.\n",
    "\n",
    "We can reuse the alerting framework from Chapter 73 to notify when metrics exceed thresholds.\n",
    "\n",
    "```python\n",
    "# monitoring.py\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ModelMonitor:\n",
    "    \"\"\"\n",
    "    Monitors prediction accuracy and data drift.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature_store: FeatureStore, \n",
    "                 prediction_store_path: str = \"./data/predictions.parquet\"):\n",
    "        self.feature_store = feature_store\n",
    "        self.prediction_store_path = prediction_store_path\n",
    "        self.alerts = []  # or integrate with AlertManager\n",
    "    \n",
    "    def log_prediction(self, symbol: str, date: datetime, predicted: float, actual: float = None):\n",
    "        \"\"\"\n",
    "        Store a prediction; actual can be updated later when known.\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame([{\n",
    "            'symbol': symbol,\n",
    "            'date': date,\n",
    "            'predicted': predicted,\n",
    "            'actual': actual,\n",
    "            'timestamp': datetime.now()\n",
    "        }])\n",
    "        if Path(self.prediction_store_path).exists():\n",
    "            existing = pd.read_parquet(self.prediction_store_path)\n",
    "            df = pd.concat([existing, df], ignore_index=True)\n",
    "        df.to_parquet(self.prediction_store_path, index=False)\n",
    "    \n",
    "    def update_actual(self, symbol: str, date: datetime, actual: float):\n",
    "        \"\"\"\n",
    "        Update the actual value for a past prediction.\n",
    "        \"\"\"\n",
    "        df = pd.read_parquet(self.prediction_store_path)\n",
    "        mask = (df['symbol'] == symbol) & (df['date'] == date)\n",
    "        df.loc[mask, 'actual'] = actual\n",
    "        df.to_parquet(self.prediction_store_path, index=False)\n",
    "    \n",
    "    def compute_daily_errors(self, date: datetime = None):\n",
    "        \"\"\"\n",
    "        Compute error metrics for predictions where actual is available.\n",
    "        \"\"\"\n",
    "        df = pd.read_parquet(self.prediction_store_path)\n",
    "        if date is not None:\n",
    "            df = df[df['date'] == date]\n",
    "        df = df.dropna(subset=['actual'])\n",
    "        if df.empty:\n",
    "            return {}\n",
    "        errors = df['predicted'] - df['actual']\n",
    "        mae = np.abs(errors).mean()\n",
    "        rmse = np.sqrt((errors**2).mean())\n",
    "        mape = (np.abs(errors) / df['actual']).mean() * 100\n",
    "        return {'mae': mae, 'rmse': rmse, 'mape': mape}\n",
    "    \n",
    "    def detect_data_drift(self, symbol: str, reference_start: datetime, \n",
    "                          reference_end: datetime, current_start: datetime,\n",
    "                          current_end: datetime, features: List[str], \n",
    "                          p_threshold: float = 0.05):\n",
    "        \"\"\"\n",
    "        Use Kolmogorov‑Smirnov test to detect drift in feature distributions.\n",
    "        \"\"\"\n",
    "        ref_df = self.feature_store.load(symbol, reference_start, reference_end)\n",
    "        curr_df = self.feature_store.load(symbol, current_start, current_end)\n",
    "        \n",
    "        drift_report = {}\n",
    "        for f in features:\n",
    "            if f not in ref_df or f not in curr_df:\n",
    "                continue\n",
    "            ref_vals = ref_df[f].dropna()\n",
    "            curr_vals = curr_df[f].dropna()\n",
    "            if len(ref_vals) == 0 or len(curr_vals) == 0:\n",
    "                continue\n",
    "            ks_stat, p_value = ks_2samp(ref_vals, curr_vals)\n",
    "            drift_detected = p_value < p_threshold\n",
    "            drift_report[f] = {\n",
    "                'ks_statistic': ks_stat,\n",
    "                'p_value': p_value,\n",
    "                'drift_detected': drift_detected\n",
    "            }\n",
    "            if drift_detected:\n",
    "                logger.warning(f\"Drift detected in feature '{f}' (p={p_value:.4f})\")\n",
    "                # Optionally trigger an alert\n",
    "        return drift_report\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- `ModelMonitor` logs predictions and, when actual values become available (e.g., next day's close), updates them.\n",
    "- `compute_daily_errors` calculates MAE, RMSE, and MAPE for any day where actuals exist.\n",
    "- `detect_data_drift` compares feature distributions between a reference period (typically training period) and a recent window using the two‑sample Kolmogorov–Smirnov test. A low p‑value indicates that the distributions have changed, which may signal that the model's assumptions are no longer valid.\n",
    "- This drift detection can be scheduled to run weekly and integrated with the alert manager from Chapter 73 to notify the team.\n",
    "\n",
    "---\n",
    "\n",
    "## **74.8 Performance Analysis**\n",
    "\n",
    "After running the system for a period, we need to analyse its performance. This includes:\n",
    "\n",
    "- Comparing predicted vs actual prices over time.\n",
    "- Analysing error distribution and identifying systematic biases (e.g., always under‑predicting during bull runs).\n",
    "- Segmenting performance by market conditions (high/low volatility, circuit breaker days, etc.).\n",
    "- Reviewing alert history and incident response.\n",
    "\n",
    "We'll create a simple analysis notebook that loads prediction logs and feature store data.\n",
    "\n",
    "```python\n",
    "# analysis.py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_prediction_logs(path: str = \"./data/predictions.parquet\") -> pd.DataFrame:\n",
    "    df = pd.read_parquet(path)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values(['symbol', 'date'])\n",
    "    df['error'] = df['predicted'] - df['actual']\n",
    "    df['abs_error'] = df['error'].abs()\n",
    "    df['error_pct'] = (df['error'] / df['actual']) * 100\n",
    "    return df\n",
    "\n",
    "def plot_error_over_time(df, symbol='NEPSE'):\n",
    "    sym_df = df[df['symbol'] == symbol]\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(sym_df['date'], sym_df['error'], label='Prediction Error')\n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    plt.title(f'Prediction Errors Over Time for {symbol}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Error (NPR)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def error_distribution(df):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(df['error'], bins=50, kde=True)\n",
    "    plt.title('Error Distribution')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=df['error'])\n",
    "    plt.title('Error Boxplot')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def performance_by_volatility(df, feature_store, symbol='NEPSE'):\n",
    "    # Merge with volatility feature\n",
    "    vol_df = feature_store.load(symbol, df['date'].min(), df['date'].max())\n",
    "    vol_df = vol_df[['Date', 'Volatility_20']]\n",
    "    merged = pd.merge(df, vol_df, left_on='date', right_on='Date', how='inner')\n",
    "    # Create volatility buckets\n",
    "    merged['vol_bucket'] = pd.cut(merged['Volatility_20'], bins=4, labels=['Low', 'Med-Low', 'Med-High', 'High'])\n",
    "    perf = merged.groupby('vol_bucket')['abs_error'].agg(['mean', 'std', 'count'])\n",
    "    return perf\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- `load_prediction_logs` reads the stored predictions and adds error columns.\n",
    "- `plot_error_over_time` visualises errors to spot trends or seasonal patterns.\n",
    "- `error_distribution` helps understand if errors are normally distributed or skewed.\n",
    "- `performance_by_volatility` joins with the feature store to get a volatility measure and then segments error by volatility regime. This can reveal if the model struggles in high‑volatility periods.\n",
    "\n",
    "---\n",
    "\n",
    "## **74.9 Lessons Learned**\n",
    "\n",
    "Running a real‑world prediction system teaches valuable lessons. Here are some we would likely encounter with the NEPSE system:\n",
    "\n",
    "1. **Data quality is paramount** – Missing values, corporate actions (splits, dividends), and data entry errors can severely degrade performance. Implement robust validation and anomaly detection.\n",
    "2. **Feature selection must be revisited** – Some features that worked well historically may lose predictive power due to market regime changes. Regular feature importance analysis and periodic retraining are essential.\n",
    "3. **Overfitting to noise** – In a volatile market like NEPSE, models can easily fit to random fluctuations. Walk‑forward validation and simple models (like linear models) sometimes outperform complex ones.\n",
    "4. **Alert fatigue** – Too many alerts lead to ignored notifications. Fine‑tune thresholds and cooldowns; use severity levels wisely.\n",
    "5. **Infrastructure matters** – A slow API or unreliable batch job can ruin user trust. Invest in monitoring and scalable deployment.\n",
    "6. **Regulatory compliance** – In financial applications, you must document everything: data provenance, feature definitions, model versions, and decision rationale. This is not optional.\n",
    "\n",
    "---\n",
    "\n",
    "## **74.10 Future Improvements**\n",
    "\n",
    "The system we built is functional but can be enhanced in many ways:\n",
    "\n",
    "- **Incorporate alternative data** – News sentiment, social media trends, macroeconomic indicators.\n",
    "- **Multi‑step forecasting** – Predict not only next day but also 5‑day ahead.\n",
    "- **Deep learning models** – LSTM or Transformer‑based models might capture longer‑range dependencies.\n",
    "- **Automated retraining** – Use drift detection to trigger retraining automatically.\n",
    "- **A/B testing** – Deploy two models simultaneously and compare performance with live trades.\n",
    "- **Explainability** – Integrate SHAP or LIME to provide explanations for each prediction (important for trader trust).\n",
    "- **Real‑time streaming** – Move from daily batch to intra‑day predictions using tick data.\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "In this final chapter, we assembled all the components of a complete time‑series prediction system, using NEPSE as our guiding example. We covered:\n",
    "\n",
    "- The overall architecture, separating data, features, models, prediction, and monitoring layers.\n",
    "- A robust data ingestion pipeline that handles CSV sources and stores raw data in Parquet.\n",
    "- A feature engineering pipeline that computes a wide array of features and persists them in a feature store.\n",
    "- Model development with time‑series cross‑validation and MLflow tracking.\n",
    "- Backtesting that simulates a simple trading strategy.\n",
    "- Production deployment as a batch job and a REST API.\n",
    "- Monitoring for prediction accuracy and data drift, integrated with the alerting system from Chapter 73.\n",
    "- Performance analysis techniques to evaluate model behaviour over time.\n",
    "- Real‑world lessons and a roadmap for future enhancements.\n",
    "\n",
    "You now have a blueprint for building your own time‑series prediction system, whether for stocks, retail sales, weather, or any other domain. The principles and code patterns are transferable; only the domain‑specific features need adaptation.\n",
    "\n",
    "Congratulations on completing this journey through the **Time‑Series Prediction System** handbook. May your predictions be accurate and your systems robust!\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 74**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
