{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 38: From Development to Production\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Understand the key differences between a development environment and a production environment\n",
    "- Identify the challenges that arise when moving a machine learning model from a notebook to a live system\n",
    "- Organize code into modular, reusable components for maintainability\n",
    "- Manage configuration settings (e.g., file paths, model parameters) using environment variables and configuration files\n",
    "- Handle dependencies and environment reproducibility using virtual environments and containerization\n",
    "- Implement logging and monitoring to track model performance and system health in production\n",
    "- Design robust error handling and retry logic for real\u2011world data pipelines\n",
    "- Write unit tests and integration tests for data processing and model inference\n",
    "- Document the system architecture and APIs for team collaboration\n",
    "- Adopt best practices for version control, CI/CD, and deployment\n",
    "\n",
    "---\n",
    "\n",
    "## **38.1 Introduction: The Development\u2011Production Gap**\n",
    "\n",
    "In the earlier chapters, we focused on building and evaluating models in a Jupyter notebook or a local Python script. This is the **development** phase: we explore data, engineer features, experiment with algorithms, and tune hyperparameters. However, a model that performs well in a notebook is not ready for live use. The **production** environment has different requirements:\n",
    "\n",
    "- **Scalability:** The system must handle requests (e.g., predictions for many stocks) reliably and quickly.\n",
    "- **Reliability:** It must run 24/7, handle errors gracefully, and recover from failures.\n",
    "- **Maintainability:** Code must be organized, tested, and documented so that other team members (or your future self) can understand and modify it.\n",
    "- **Reproducibility:** The exact environment (Python version, library versions) must be captured to avoid \"it works on my machine\" problems.\n",
    "- **Monitoring:** You need to know if the model's performance degrades over time (data drift, concept drift) or if the system is down.\n",
    "\n",
    "Bridging this gap requires engineering discipline. In this chapter, we will walk through the steps to productionize the NEPSE prediction system.\n",
    "\n",
    "---\n",
    "\n",
    "## **38.2 Production Requirements**\n",
    "\n",
    "Before writing any production code, we must define the requirements. For the NEPSE system, typical requirements might be:\n",
    "\n",
    "- **Input:** Daily receives new data (CSV or API) at market close.\n",
    "- **Output:** Generates predictions for the next day's return for each stock, stored in a database or delivered via API.\n",
    "- **Frequency:** Batch job runs once per day after data arrives.\n",
    "- **Latency:** Not critical for batch, but if real\u2011time, could be < 1 second.\n",
    "- **Accuracy:** Must maintain validation performance; if performance drops, alert.\n",
    "- **Failover:** If a step fails, retry or fallback to a simple model.\n",
    "\n",
    "These requirements guide the architecture.\n",
    "\n",
    "---\n",
    "\n",
    "## **38.3 Code Organization**\n",
    "\n",
    "A Jupyter notebook is great for exploration but terrible for production. We need to refactor the code into a structured Python project.\n",
    "\n",
    "A typical project layout might look like:\n",
    "\n",
    "```\n",
    "nepse_prediction/\n",
    "\u251c\u2500\u2500 config/\n",
    "\u2502   \u2514\u2500\u2500 config.yaml          # configuration parameters\n",
    "\u251c\u2500\u2500 data/\n",
    "\u2502   \u251c\u2500\u2500 raw/                  # raw input data\n",
    "\u2502   \u251c\u2500\u2500 processed/             # cleaned/featured data\n",
    "\u2502   \u2514\u2500\u2500 models/                # saved model artifacts\n",
    "\u251c\u2500\u2500 src/\n",
    "\u2502   \u251c\u2500\u2500 __init__.py\n",
    "\u2502   \u251c\u2500\u2500 data/\n",
    "\u2502   \u2502   \u251c\u2500\u2500 collector.py       # data ingestion (API, CSV)\n",
    "\u2502   \u2502   \u251c\u2500\u2500 cleaner.py         # data cleaning\n",
    "\u2502   \u2502   \u2514\u2500\u2500 features.py        # feature engineering\n",
    "\u2502   \u251c\u2500\u2500 models/\n",
    "\u2502   \u2502   \u251c\u2500\u2500 train.py           # model training script\n",
    "\u2502   \u2502   \u251c\u2500\u2500 predict.py         # prediction script\n",
    "\u2502   \u2502   \u2514\u2500\u2500 utils.py           # common utilities (scaling, etc.)\n",
    "\u2502   \u251c\u2500\u2500 evaluation/\n",
    "\u2502   \u2502   \u2514\u2500\u2500 metrics.py         # custom metrics\n",
    "\u2502   \u2514\u2500\u2500 monitoring/\n",
    "\u2502       \u2514\u2500\u2500 drift_detection.py  # data drift checks\n",
    "\u251c\u2500\u2500 tests/\n",
    "\u2502   \u251c\u2500\u2500 test_data.py\n",
    "\u2502   \u251c\u2500\u2500 test_features.py\n",
    "\u2502   \u2514\u2500\u2500 test_model.py\n",
    "\u251c\u2500\u2500 notebooks/                  # exploration notebooks (not for production)\n",
    "\u251c\u2500\u2500 requirements.txt            # dependencies\n",
    "\u251c\u2500\u2500 setup.py                    # installable package (optional)\n",
    "\u251c\u2500\u2500 Dockerfile                  # container definition\n",
    "\u251c\u2500\u2500 .env                        # environment variables (not committed)\n",
    "\u2514\u2500\u2500 README.md\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "Separating concerns into modules makes the code easier to test, maintain, and scale. Each module has a clear responsibility.\n",
    "\n",
    "---\n",
    "\n",
    "## **38.4 Configuration Management**\n",
    "\n",
    "Hard\u2011coding parameters (file paths, model hyperparameters, API keys) is a recipe for disaster. Instead, use configuration files and environment variables.\n",
    "\n",
    "### **38.4.1 Using YAML Configuration**\n",
    "\n",
    "Create a `config/config.yaml` file:\n",
    "\n",
    "```yaml\n",
    "data:\n",
    "  raw_path: \"data/raw/nepse_{date}.csv\"\n",
    "  processed_path: \"data/processed/features_{date}.parquet\"\n",
    "  model_path: \"data/models/model.pkl\"\n",
    "\n",
    "features:\n",
    "  lag_list: [1, 2, 3, 5]\n",
    "  windows: [5, 10, 20]\n",
    "  technical_indicators: [\"RSI\", \"MACD\"]\n",
    "\n",
    "model:\n",
    "  name: \"RandomForest\"\n",
    "  params:\n",
    "    n_estimators: 100\n",
    "    max_depth: 5\n",
    "    random_state: 42\n",
    "\n",
    "training:\n",
    "  test_size: 0.2\n",
    "  cv_splits: 3\n",
    "\n",
    "api:\n",
    "  host: \"0.0.0.0\"\n",
    "  port: 8000\n",
    "```\n",
    "\n",
    "Load it in Python:\n",
    "\n",
    "```python\n",
    "import yaml\n",
    "\n",
    "with open(\"config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "raw_path = config[\"data\"][\"raw_path\"]\n",
    "model_params = config[\"model\"][\"params\"]\n",
    "```\n",
    "\n",
    "### **38.4.2 Environment Variables for Secrets**\n",
    "\n",
    "Sensitive information (database passwords, API keys) should never be in the config file. Use environment variables.\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "if DB_PASSWORD is None:\n",
    "    raise ValueError(\"DB_PASSWORD environment variable not set\")\n",
    "```\n",
    "\n",
    "You can use a `.env` file for local development (loaded via `python-dotenv`), but never commit it.\n",
    "\n",
    "---\n",
    "\n",
    "## **38.5 Dependency and Environment Management**\n",
    "\n",
    "Reproducibility is critical. You must capture the exact versions of all libraries.\n",
    "\n",
    "### **38.5.1 Virtual Environments**\n",
    "\n",
    "Use `venv` or `conda` to create an isolated environment.\n",
    "\n",
    "```bash\n",
    "python -m venv venv\n",
    "source venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### **38.5.2 requirements.txt**\n",
    "\n",
    "Generate a comprehensive list of dependencies:\n",
    "\n",
    "```bash\n",
    "pip freeze > requirements.txt\n",
    "```\n",
    "\n",
    "But this includes all packages, even transitive ones. Better to manually specify top\u2011level packages with versions, and let the installer resolve dependencies. Tools like `pip-tools` can help.\n",
    "\n",
    "### **38.5.3 Docker**\n",
    "\n",
    "Containers encapsulate the entire environment, including the operating system. A `Dockerfile` might look like:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY src/ ./src/\n",
    "COPY config/ ./config/\n",
    "\n",
    "CMD [\"python\", \"src/models/predict.py\"]\n",
    "```\n",
    "\n",
    "Then build and run:\n",
    "\n",
    "```bash\n",
    "docker build -t nepse-predictor .\n",
    "docker run nepse-predictor\n",
    "```\n",
    "\n",
    "This ensures the exact same environment runs anywhere.\n",
    "\n",
    "---\n",
    "\n",
    "## **38.6 Modular Architecture**\n",
    "\n",
    "### **38.6.1 Data Ingestion Module**\n",
    "\n",
    "`src/data/collector.py` handles loading raw data from CSV or API.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "class DataCollector:\n",
    "    def __init__(self, data_url=None):\n",
    "        self.data_url = data_url\n",
    "    \n",
    "    def from_csv(self, filepath):\n",
    "        return pd.read_csv(filepath)\n",
    "    \n",
    "    def from_api(self, date):\n",
    "        # Example: fetch data from some API\n",
    "        response = requests.get(f\"{self.data_url}?date={date}\")\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def save_raw(self, df, path):\n",
    "        df.to_csv(path, index=False)\n",
    "```\n",
    "\n",
    "### **38.6.2 Feature Engineering Module**\n",
    "\n",
    "`src/data/features.py` contains functions to create features from raw data.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class FeatureEngineer:\n",
    "    def __init__(self, config):\n",
    "        self.lag_list = config[\"features\"][\"lag_list\"]\n",
    "        self.windows = config[\"features\"][\"windows\"]\n",
    "    \n",
    "    def create_features(self, df):\n",
    "        df = df.copy()\n",
    "        df['Return'] = df['Close'].pct_change() * 100\n",
    "        for lag in self.lag_list:\n",
    "            df[f'Return_Lag{lag}'] = df['Return'].shift(lag)\n",
    "        for w in self.windows:\n",
    "            df[f'MA_{w}'] = df['Close'].rolling(w).mean()\n",
    "            df[f'Volatility_{w}'] = df['Return'].rolling(w).std()\n",
    "        # ... more features\n",
    "        return df.dropna()\n",
    "```\n",
    "\n",
    "### **38.6.3 Model Training Module**\n",
    "\n",
    "`src/models/train.py` trains and saves the model.\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from src.data.features import FeatureEngineer\n",
    "from src.data.collector import DataCollector\n",
    "\n",
    "def train_model(config):\n",
    "    # Load data\n",
    "    collector = DataCollector()\n",
    "    df_raw = collector.from_csv(config[\"data\"][\"raw_path\"])\n",
    "    \n",
    "    # Engineer features\n",
    "    engineer = FeatureEngineer(config)\n",
    "    df_features = engineer.create_features(df_raw)\n",
    "    \n",
    "    # Prepare X, y\n",
    "    feature_cols = [c for c in df_features.columns if c not in ['Target', 'Date']]\n",
    "    X = df_features[feature_cols]\n",
    "    y = df_features['Target']\n",
    "    \n",
    "    # Train\n",
    "    model = RandomForestRegressor(**config[\"model\"][\"params\"])\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Save\n",
    "    joblib.dump(model, config[\"data\"][\"model_path\"])\n",
    "    return model\n",
    "```\n",
    "\n",
    "### **38.6.4 Prediction Module**\n",
    "\n",
    "`src/models/predict.py` loads the model and makes predictions on new data.\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from src.data.features import FeatureEngineer\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, model_path, config):\n",
    "        self.model = joblib.load(model_path)\n",
    "        self.engineer = FeatureEngineer(config)\n",
    "        self.feature_cols = None  # would be stored with model\n",
    "    \n",
    "    def predict(self, df_raw):\n",
    "        df_features = self.engineer.create_features(df_raw)\n",
    "        # Ensure features are in the same order as training\n",
    "        X = df_features[self.feature_cols]\n",
    "        return self.model.predict(X)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **38.7 Logging and Monitoring**\n",
    "\n",
    "Production systems must log events and metrics for debugging and performance tracking.\n",
    "\n",
    "### **38.7.1 Logging**\n",
    "\n",
    "Use Python's `logging` module instead of `print`.\n",
    "\n",
    "```python\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def predict():\n",
    "    logger.info(\"Starting prediction for date %s\", date)\n",
    "    try:\n",
    "        # ... prediction code\n",
    "        logger.info(\"Prediction completed\")\n",
    "    except Exception as e:\n",
    "        logger.error(\"Prediction failed: %s\", str(e), exc_info=True)\n",
    "        raise\n",
    "```\n",
    "\n",
    "Logs should be written to a file or sent to a centralized logging system (e.g., ELK stack, Splunk).\n",
    "\n",
    "### **38.7.2 Monitoring Model Performance**\n",
    "\n",
    "Track metrics over time to detect drift. For example, after each batch prediction, if we receive actual returns the next day, we can compute error metrics and compare to a baseline.\n",
    "\n",
    "```python\n",
    "def monitor_performance(y_true, y_pred, threshold=1.5):\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    baseline_rmse = ...  # from training\n",
    "    logger.info(f\"Current RMSE: {rmse:.4f}, Baseline: {baseline_rmse:.4f}\")\n",
    "    if rmse > threshold * baseline_rmse:\n",
    "        logger.warning(\"Performance degradation detected!\")\n",
    "        # send alert (email, Slack, etc.)\n",
    "```\n",
    "\n",
    "We can also monitor feature distributions (data drift) using statistical tests (e.g., Kolmogorov\u2011Smirnov).\n",
    "\n",
    "---\n",
    "\n",
    "## **38.8 Error Handling and Retry Logic**\n",
    "\n",
    "Real\u2011world data pipelines encounter failures: network timeouts, corrupted files, missing data. Build robustness with retries and fallbacks.\n",
    "\n",
    "```python\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def retry(max_attempts=3, delay=1):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for attempt in range(max_attempts):\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Attempt {attempt+1} failed: {e}\")\n",
    "                    if attempt == max_attempts - 1:\n",
    "                        raise\n",
    "                    time.sleep(delay * (2 ** attempt))  # exponential backoff\n",
    "            return None\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "class DataCollector:\n",
    "    @retry(max_attempts=3, delay=2)\n",
    "    def from_api(self, date):\n",
    "        # ...\n",
    "```\n",
    "\n",
    "For critical failures, implement a fallback (e.g., use yesterday's data, or a simple mean model).\n",
    "\n",
    "---\n",
    "\n",
    "## **38.9 Testing Strategies**\n",
    "\n",
    "Testing ensures that code behaves as expected and that changes do not break existing functionality.\n",
    "\n",
    "### **38.9.1 Unit Tests**\n",
    "\n",
    "Test individual functions in isolation. For example, test that feature engineering produces expected columns.\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "import pandas as pd\n",
    "from src.data.features import FeatureEngineer\n",
    "\n",
    "def test_create_features():\n",
    "    df = pd.DataFrame({'Close': [100, 101, 102], 'Date': pd.date_range('2023-01-01', periods=3)})\n",
    "    engineer = FeatureEngineer(config)\n",
    "    result = engineer.create_features(df)\n",
    "    assert 'Return' in result.columns\n",
    "    assert len(result) == 2  # after dropping NaN\n",
    "```\n",
    "\n",
    "Run tests with `pytest`.\n",
    "\n",
    "### **38.9.2 Integration Tests**\n",
    "\n",
    "Test the entire pipeline end\u2011to\u2011end on a small sample of data.\n",
    "\n",
    "```python\n",
    "def test_prediction_pipeline():\n",
    "    # Use a tiny dataset\n",
    "    df = pd.read_csv('tests/sample_data.csv')\n",
    "    predictor = Predictor(model_path='tests/test_model.pkl', config=test_config)\n",
    "    preds = predictor.predict(df)\n",
    "    assert len(preds) == len(df) - min_lookback\n",
    "```\n",
    "\n",
    "### **38.9.3 Model Tests**\n",
    "\n",
    "Test that the model's performance on a holdout set meets a minimum threshold. This can be part of CI/CD to prevent deploying a bad model.\n",
    "\n",
    "```python\n",
    "def test_model_performance():\n",
    "    model = joblib.load('models/prod_model.pkl')\n",
    "    X_test, y_test = load_test_data()\n",
    "    rmse = np.sqrt(np.mean((model.predict(X_test) - y_test)**2))\n",
    "    assert rmse < 1.0  # acceptable threshold\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **38.10 Documentation**\n",
    "\n",
    "Good documentation is essential for team collaboration and future maintenance.\n",
    "\n",
    "- **README.md:** Overview, setup instructions, how to run.\n",
    "- **API documentation:** If exposing a REST API, document endpoints, request/response formats (e.g., using Swagger/OpenAPI).\n",
    "- **Model card:** Describe the model, its intended use, performance, limitations (as in Chapter 66).\n",
    "- **Code comments:** Explain why, not what (the code shows what). Use docstrings for modules, classes, and functions.\n",
    "\n",
    "Example docstring:\n",
    "\n",
    "```python\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Generate time\u2011series features from raw OHLCV data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Raw data with columns: Date, Open, High, Low, Close, Vol.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with added features (lags, rolling stats, RSI, etc.),\n",
    "        with rows containing NaN values dropped.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **38.11 Version Control and CI/CD**\n",
    "\n",
    "### **38.11.1 Git**\n",
    "\n",
    "Use Git for version control. Commit often, with meaningful messages. Use `.gitignore` to exclude sensitive files and large data.\n",
    "\n",
    "### **38.11.2 Continuous Integration (CI)**\n",
    "\n",
    "Automate testing on every push using GitHub Actions, GitLab CI, or Jenkins. Example GitHub Actions workflow:\n",
    "\n",
    "```yaml\n",
    "name: CI\n",
    "on: [push]\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v2\n",
    "      - name: Set up Python\n",
    "        uses: actions/setup-python@v2\n",
    "        with:\n",
    "          python-version: '3.9'\n",
    "      - name: Install dependencies\n",
    "        run: pip install -r requirements.txt\n",
    "      - name: Run tests\n",
    "        run: pytest tests/\n",
    "```\n",
    "\n",
    "### **38.11.3 Continuous Deployment (CD)**\n",
    "\n",
    "After tests pass, automatically deploy to a staging or production environment. For a batch job, this might mean updating a Docker image or triggering a cloud function.\n",
    "\n",
    "---\n",
    "\n",
    "## **38.12 Deployment Options**\n",
    "\n",
    "Depending on infrastructure, you can deploy as:\n",
    "\n",
    "- **Batch job** scheduled via cron, Airflow, or cloud scheduler.\n",
    "- **REST API** using Flask, FastAPI, or Django.\n",
    "- **Serverless function** (AWS Lambda, Google Cloud Functions) for low\u2011frequency inference.\n",
    "- **Containerized service** running on Kubernetes or a VM.\n",
    "\n",
    "For the NEPSE system, a daily batch job is appropriate. We'll illustrate a simple scheduled script.\n",
    "\n",
    "```python\n",
    "# run_daily.py\n",
    "import schedule\n",
    "import time\n",
    "from src.models.predict import run_prediction_pipeline\n",
    "\n",
    "def job():\n",
    "    logger.info(\"Starting daily prediction job\")\n",
    "    try:\n",
    "        run_prediction_pipeline()\n",
    "        logger.info(\"Job completed successfully\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Job failed: {e}\")\n",
    "        # send alert\n",
    "\n",
    "schedule.every().day.at(\"18:00\").do(job)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **38.13 Chapter Summary**\n",
    "\n",
    "In this chapter, we covered the essential steps to transition a machine learning model from development to production, using the NEPSE prediction system as a guiding example.\n",
    "\n",
    "- **Production requirements** differ from development: reliability, scalability, maintainability.\n",
    "- **Code organization** into modules (data, features, models, monitoring) improves maintainability.\n",
    "- **Configuration management** with YAML files and environment variables separates code from settings.\n",
    "- **Environment reproducibility** via virtual environments, `requirements.txt`, and Docker ensures consistent execution.\n",
    "- **Logging and monitoring** track system health and model performance, alerting on degradation.\n",
    "- **Error handling and retries** make the pipeline robust to transient failures.\n",
    "- **Testing** at unit, integration, and model levels prevents regressions.\n",
    "- **Documentation** (README, API docs, model cards) facilitates collaboration.\n",
    "- **Version control and CI/CD** automate testing and deployment.\n",
    "- **Deployment options** range from batch jobs to APIs; choose based on requirements.\n",
    "\n",
    "### **Practical Takeaways for the NEPSE System:**\n",
    "\n",
    "- Refactor your notebook code into a structured Python package.\n",
    "- Use configuration files for all parameters that may change.\n",
    "- Containerize the application with Docker to ensure consistent runs.\n",
    "- Set up logging and monitor daily predictions.\n",
    "- Implement retry logic for data ingestion.\n",
    "- Write tests for critical functions (feature engineering, data loading).\n",
    "- Use Git and a CI pipeline to run tests automatically.\n",
    "- Schedule the daily prediction job using cron or Airflow.\n",
    "\n",
    "With these practices, your model is ready for reliable, maintainable production deployment. In the next chapter, **Chapter 39: Model Serialization and Storage**, we will dive deeper into saving and versioning models, including formats like Pickle, ONNX, and using model registries.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 38**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='../5. model_evaluation_and_validation/37. error_analysis.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='39. model_serialization_and_storage.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}