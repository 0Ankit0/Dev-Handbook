{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 39: Model Serialization and Storage\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Understand the importance of model serialization for deployment and reproducibility\n",
    "- Compare different serialization formats (Pickle, Joblib, ONNX, SavedModel) and choose the right one for your use case\n",
    "- Save and load scikit\u2011learn models using Pickle and Joblib\n",
    "- Export TensorFlow/Keras models in the SavedModel format\n",
    "- Convert models to ONNX for cross\u2011framework compatibility\n",
    "- Implement model versioning to track changes over time\n",
    "- Use a model registry (MLflow, Weights & Biases, custom) to organize and manage models\n",
    "- Store model metadata (hyperparameters, performance metrics, training data hash) alongside the model\n",
    "- Manage model artifacts (scalers, encoders, feature lists) as part of the model package\n",
    "- Choose appropriate storage backends (local filesystem, cloud storage, databases)\n",
    "- Implement backup and recovery strategies for model artifacts\n",
    "- Address security considerations (encryption, access control) for stored models\n",
    "- Adopt best practices for model serialization and storage in production\n",
    "\n",
    "---\n",
    "\n",
    "## **39.1 Introduction to Model Serialization**\n",
    "\n",
    "After training a model, we need to save it to disk so that it can be loaded later for prediction without retraining. This process is called **serialization** (or pickling, in Python). Proper serialization ensures that:\n",
    "\n",
    "- The model can be deployed to a production environment.\n",
    "- The model can be shared with other team members.\n",
    "- The model can be versioned and archived for reproducibility.\n",
    "- The model can be loaded quickly for inference.\n",
    "\n",
    "For the NEPSE prediction system, we will have multiple models (one per stock, or a single model for all stocks), and we need to save them along with any preprocessing artifacts (scalers, feature lists) so that predictions can be made consistently.\n",
    "\n",
    "---\n",
    "\n",
    "## **39.2 Serialization Formats**\n",
    "\n",
    "Different libraries use different serialization formats. Choosing the right format depends on the model type, the deployment environment, and compatibility requirements.\n",
    "\n",
    "### **39.2.1 Pickle**\n",
    "\n",
    "Python's built\u2011in `pickle` module can serialize almost any Python object, including scikit\u2011learn models. It is simple and widely used.\n",
    "\n",
    "**Advantages:** Simple, no extra dependencies.\n",
    "**Disadvantages:** Not secure (can execute arbitrary code), Python\u2011only, can be slow for large models, may break across Python versions.\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train a model\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save with pickle\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Load later\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(X_test)\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "The model is saved as a binary file. When loading, we must ensure the same environment (library versions) to avoid errors. Pickle is convenient for prototyping but has security implications \u2013 never load untrusted pickle files.\n",
    "\n",
    "### **39.2.2 Joblib**\n",
    "\n",
    "Joblib is part of the scikit\u2011learn ecosystem and is optimized for saving large NumPy arrays. It is often faster and more efficient than pickle for models with large arrays (e.g., random forests).\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "\n",
    "# Save\n",
    "joblib.dump(model, 'model.joblib')\n",
    "\n",
    "# Load\n",
    "loaded_model = joblib.load('model.joblib')\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "Joblib is the recommended way to save scikit\u2011learn models. It uses pickle under the hood but with better compression and handling of large data.\n",
    "\n",
    "### **39.2.3 TensorFlow SavedModel**\n",
    "\n",
    "For TensorFlow/Keras models, the native format is **SavedModel**. It saves the model architecture, weights, and training configuration in a directory.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assume we have a Keras model\n",
    "model = tf.keras.Sequential([...])\n",
    "model.compile(...)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save in SavedModel format\n",
    "model.save('my_model')\n",
    "\n",
    "# Load\n",
    "loaded_model = tf.keras.models.load_model('my_model')\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "SavedModel is a directory containing assets, variables, and a saved_model.pb file. It is portable and can be used with TensorFlow Serving for production deployment.\n",
    "\n",
    "### **39.2.4 ONNX (Open Neural Network Exchange)**\n",
    "\n",
    "ONNX is an open format for representing machine learning models. It allows models to be transferred between different frameworks (e.g., scikit\u2011learn to PyTorch, or to specialized inference engines).\n",
    "\n",
    "```python\n",
    "import skl2onnx\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# Convert a scikit-learn model to ONNX\n",
    "initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]\n",
    "onx = convert_sklearn(model, initial_types=initial_type)\n",
    "\n",
    "# Save\n",
    "with open(\"model.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())\n",
    "\n",
    "# Load and predict with ONNX runtime\n",
    "import onnxruntime as ort\n",
    "sess = ort.InferenceSession(\"model.onnx\")\n",
    "input_name = sess.get_inputs()[0].name\n",
    "pred_onx = sess.run(None, {input_name: X_test.astype(np.float32)})[0]\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "ONNX is useful when you need to deploy models in environments that may not support the original framework (e.g., mobile, edge devices). It also enables optimizations like quantization and graph transformations.\n",
    "\n",
    "### **39.2.5 Comparison Table**\n",
    "\n",
    "| Format   | Framework        | Use Case                          | Pros                          | Cons                          |\n",
    "|----------|------------------|-----------------------------------|-------------------------------|-------------------------------|\n",
    "| Pickle   | Python (any)     | Quick saving, prototyping         | Simple, built\u2011in              | Security risk, Python\u2011only    |\n",
    "| Joblib   | scikit\u2011learn     | Large NumPy arrays                | Efficient, fast               | Python\u2011only                   |\n",
    "| SavedModel | TensorFlow/Keras | TensorFlow models                 | Complete, TF Serving ready    | TensorFlow\u2011specific           |\n",
    "| ONNX     | Cross\u2011framework  | Model interoperability            | Framework\u2011agnostic, optimized | Conversion complexity         |\n",
    "\n",
    "For the NEPSE system, we will likely use Joblib for scikit\u2011learn models and SavedModel for neural networks. If we need to deploy on edge devices, we might convert to ONNX.\n",
    "\n",
    "---\n",
    "\n",
    "## **39.3 Model Versioning**\n",
    "\n",
    "As we iterate on models, we need to keep track of different versions. Versioning helps with:\n",
    "\n",
    "- Reproducing past results\n",
    "- Rolling back to a previous version if a new model performs poorly\n",
    "- A/B testing different models\n",
    "- Auditing and compliance\n",
    "\n",
    "A simple versioning scheme is to include a version number in the filename, e.g., `model_v1.2.joblib`. Better yet, use a model registry that stores metadata along with the model.\n",
    "\n",
    "### **39.3.1 Manual Versioning**\n",
    "\n",
    "```python\n",
    "import datetime\n",
    "\n",
    "version = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"models/rf_{version}.joblib\"\n",
    "joblib.dump(model, filename)\n",
    "```\n",
    "\n",
    "This creates files like `rf_20250315_143022.joblib`. It's simple but does not store any metadata.\n",
    "\n",
    "### **39.3.2 Storing Metadata**\n",
    "\n",
    "Along with the model, save a metadata file (JSON or YAML) containing:\n",
    "\n",
    "- Model version\n",
    "- Training date\n",
    "- Hyperparameters\n",
    "- Performance metrics (validation RMSE, etc.)\n",
    "- Feature list\n",
    "- Hash of training data (to detect data drift)\n",
    "- Git commit hash of the code\n",
    "\n",
    "```python\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "metadata = {\n",
    "    'version': '1.2.0',\n",
    "    'date': '2025-03-15',\n",
    "    'model_type': 'RandomForest',\n",
    "    'params': model.get_params(),\n",
    "    'metrics': {'val_rmse': 0.85},\n",
    "    'features': list(X_train.columns),\n",
    "    'data_hash': hashlib.md5(pd.util.hash_pandas_object(X_train).values).hexdigest(),\n",
    "    'git_commit': 'a1b2c3d4'\n",
    "}\n",
    "\n",
    "with open('models/rf_v1.2.0_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **39.4 Model Registry**\n",
    "\n",
    "A model registry is a centralized system for storing, versioning, and managing models. It provides a UI/API to track experiments, compare models, and promote models to production.\n",
    "\n",
    "### **39.4.1 MLflow**\n",
    "\n",
    "MLflow is an open\u2011source platform for the machine learning lifecycle. It includes a model registry.\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Set tracking URI (e.g., local directory or database)\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "\n",
    "# Start an experiment run\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_params(model.get_params())\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    \n",
    "    # Register the model\n",
    "    mlflow.register_model(f\"runs:/{mlflow.active_run().info.run_id}/model\", \"NEPSE_RandomForest\")\n",
    "```\n",
    "\n",
    "Later, you can load a model by its stage (Staging, Production, Archived):\n",
    "\n",
    "```python\n",
    "model = mlflow.pyfunc.load_model(model_uri=\"models:/NEPSE_RandomForest/Production\")\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "MLflow tracks runs, logs parameters and metrics, and stores models. The registry allows promoting models through stages.\n",
    "\n",
    "### **39.4.2 Weights & Biases (W&B)**\n",
    "\n",
    "W&B is another popular platform that includes model versioning.\n",
    "\n",
    "```python\n",
    "import wandb\n",
    "\n",
    "wandb.init(project=\"nepse-forecast\")\n",
    "wandb.config.update(model.get_params())\n",
    "wandb.log({\"rmse\": rmse})\n",
    "wandb.save('model.joblib')  # saves as artifact\n",
    "```\n",
    "\n",
    "### **39.4.3 Custom Registry**\n",
    "\n",
    "If you cannot use third\u2011party tools, you can build a simple registry using a database and file storage. For example, store model metadata in a SQLite database and model files in a structured directory.\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "import json\n",
    "\n",
    "conn = sqlite3.connect('model_registry.db')\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS models\n",
    "             (id INTEGER PRIMARY KEY, name TEXT, version TEXT, \n",
    "              path TEXT, metrics TEXT, created_at TIMESTAMP)''')\n",
    "\n",
    "def register_model(name, version, path, metrics):\n",
    "    c.execute(\"INSERT INTO models (name, version, path, metrics, created_at) VALUES (?,?,?,?, datetime('now'))\",\n",
    "              (name, version, path, json.dumps(metrics)))\n",
    "    conn.commit()\n",
    "```\n",
    "\n",
    "This gives you full control but requires more maintenance.\n",
    "\n",
    "---\n",
    "\n",
    "## **39.5 Artifact Management**\n",
    "\n",
    "Models often depend on artifacts like scalers, encoders, and feature lists. These must be saved alongside the model to ensure consistent preprocessing.\n",
    "\n",
    "### **39.5.1 Saving Preprocessing Objects**\n",
    "\n",
    "```python\n",
    "# Assume we have a scaler fitted on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, 'models/scaler.joblib')\n",
    "\n",
    "# Save feature list (could be just the column names)\n",
    "feature_list = X_train.columns.tolist()\n",
    "with open('models/features.json', 'w') as f:\n",
    "    json.dump(feature_list, f)\n",
    "```\n",
    "\n",
    "### **39.5.2 Packaging Everything Together**\n",
    "\n",
    "You can create a single archive (e.g., ZIP) containing the model, scaler, and metadata.\n",
    "\n",
    "```python\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "with zipfile.ZipFile('model_package.zip', 'w') as z:\n",
    "    z.write('models/model.joblib', 'model.joblib')\n",
    "    z.write('models/scaler.joblib', 'scaler.joblib')\n",
    "    z.write('models/features.json', 'features.json')\n",
    "    z.write('models/metadata.json', 'metadata.json')\n",
    "```\n",
    "\n",
    "Then, in production, unzip and load each component.\n",
    "\n",
    "### **39.5.3 Using a Pipeline Object**\n",
    "\n",
    "Scikit\u2011learn's `Pipeline` can encapsulate preprocessing and the model. Saving the pipeline saves everything in one object.\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "joblib.dump(pipeline, 'pipeline.joblib')\n",
    "\n",
    "# Later\n",
    "loaded_pipeline = joblib.load('pipeline.joblib')\n",
    "predictions = loaded_pipeline.predict(X_test)\n",
    "```\n",
    "\n",
    "**Explanation:**  \n",
    "The pipeline ensures that the same scaling is applied during inference. This is the recommended approach for scikit\u2011learn.\n",
    "\n",
    "---\n",
    "\n",
    "## **39.6 Storage Backends**\n",
    "\n",
    "Where you store your models depends on your infrastructure.\n",
    "\n",
    "### **39.6.1 Local Filesystem**\n",
    "\n",
    "Simplest, but not scalable or shared across servers. Use for development.\n",
    "\n",
    "### **39.6.2 Network File System (NFS)**\n",
    "\n",
    "Shared storage accessible by multiple servers. Good for small teams.\n",
    "\n",
    "### **39.6.3 Cloud Storage**\n",
    "\n",
    "- **AWS S3:** Scalable, durable, accessible from anywhere.\n",
    "- **Google Cloud Storage**\n",
    "- **Azure Blob Storage**\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.upload_file('model.joblib', 'my-bucket', 'models/nepse/model.joblib')\n",
    "\n",
    "# To download\n",
    "s3.download_file('my-bucket', 'models/nepse/model.joblib', 'model.joblib')\n",
    "```\n",
    "\n",
    "### **39.6.4 Database BLOBs**\n",
    "\n",
    "You can store models as binary large objects (BLOBs) in a database. This simplifies backup but can be slower.\n",
    "\n",
    "```python\n",
    "# Store model in PostgreSQL\n",
    "import psycopg2\n",
    "import pickle\n",
    "\n",
    "conn = psycopg2.connect(...)\n",
    "cur = conn.cursor()\n",
    "model_binary = pickle.dumps(model)\n",
    "cur.execute(\"INSERT INTO models (name, model_data) VALUES (%s, %s)\", ('rf_v1', model_binary))\n",
    "conn.commit()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **39.7 Data Partitioning Strategies**\n",
    "\n",
    "When you have many models (e.g., one per stock), you need an organizational strategy.\n",
    "\n",
    "- **One file per model:** `models/rf_NEPSE.joblib`, `models/rf_HRL.joblib`, etc.\n",
    "- **Subdirectories:** `models/NEPSE/v1/model.joblib`, `models/HRL/v1/model.joblib`\n",
    "- **Database index:** Store model paths in a database keyed by symbol and version.\n",
    "\n",
    "For the NEPSE system with many stocks, a directory structure like:\n",
    "\n",
    "```\n",
    "models/\n",
    "\u251c\u2500\u2500 NEPSE/\n",
    "\u2502   \u251c\u2500\u2500 v1/\n",
    "\u2502   \u2502   \u251c\u2500\u2500 model.joblib\n",
    "\u2502   \u2502   \u2514\u2500\u2500 metadata.json\n",
    "\u2502   \u2514\u2500\u2500 v2/\n",
    "\u2502       \u251c\u2500\u2500 model.joblib\n",
    "\u2502       \u2514\u2500\u2500 metadata.json\n",
    "\u251c\u2500\u2500 HRL/\n",
    "\u2502   \u251c\u2500\u2500 v1/\n",
    "\u2502   \u2502   \u251c\u2500\u2500 model.joblib\n",
    "\u2502   \u2502   \u2514\u2500\u2500 metadata.json\n",
    "...\n",
    "```\n",
    "\n",
    "This keeps things organized and allows easy retrieval by symbol and version.\n",
    "\n",
    "---\n",
    "\n",
    "## **39.8 Data Archival and Retention**\n",
    "\n",
    "Not all models need to be kept forever. Define a retention policy:\n",
    "\n",
    "- Keep all models for a certain period (e.g., 1 year).\n",
    "- Archive older models to cheaper storage (e.g., S3 Glacier).\n",
    "- Delete models that are no longer needed.\n",
    "\n",
    "Automate this with scripts or lifecycle policies on cloud storage.\n",
    "\n",
    "---\n",
    "\n",
    "## **39.9 Backup and Recovery**\n",
    "\n",
    "Model files are critical; they represent the result of expensive training. Ensure they are backed up.\n",
    "\n",
    "- Use version control (Git) for metadata, but not for large model files.\n",
    "- Regularly back up the model storage location to another region or service.\n",
    "- Test recovery by restoring from backup periodically.\n",
    "\n",
    "---\n",
    "\n",
    "## **39.10 Security Considerations**\n",
    "\n",
    "### **39.10.1 Encryption**\n",
    "\n",
    "- Encrypt model files at rest, especially if they contain sensitive information (e.g., trained on proprietary data).\n",
    "- Use S3 server\u2011side encryption, or encrypt before uploading.\n",
    "\n",
    "### **39.10.2 Access Control**\n",
    "\n",
    "- Restrict access to model storage using IAM roles/permissions.\n",
    "- Use separate buckets/directories for different environments (dev, staging, prod).\n",
    "\n",
    "### **39.10.3 Model Theft Prevention**\n",
    "\n",
    "- Models are intellectual property. Limit download access.\n",
    "- Consider watermarking or encryption if models are distributed to untrusted environments.\n",
    "\n",
    "### **39.10.4 Secure Deserialization**\n",
    "\n",
    "- Never load pickle files from untrusted sources. Use safer formats (ONNX, SavedModel) when possible.\n",
    "- If you must use pickle, ensure the source is trusted and files are integrity\u2011checked (e.g., using checksums).\n",
    "\n",
    "---\n",
    "\n",
    "## **39.11 Best Practices**\n",
    "\n",
    "1. **Always save preprocessing artifacts** with the model.\n",
    "2. **Use pipelines** to encapsulate the entire preprocessing and modeling steps.\n",
    "3. **Version your models** with semantic versioning or timestamps.\n",
    "4. **Store metadata** (params, metrics, date) alongside the model.\n",
    "5. **Use a model registry** for tracking and promoting models.\n",
    "6. **Back up models** regularly.\n",
    "7. **Secure model storage** with encryption and access controls.\n",
    "8. **Test model loading** in a fresh environment to ensure no missing dependencies.\n",
    "9. **Document the storage structure** in a README.\n",
    "\n",
    "---\n",
    "\n",
    "## **39.12 Chapter Summary**\n",
    "\n",
    "In this chapter, we covered the critical aspects of model serialization and storage for the NEPSE prediction system.\n",
    "\n",
    "- **Serialization formats:** Pickle (simple), Joblib (efficient for scikit\u2011learn), SavedModel (TensorFlow), ONNX (cross\u2011framework).\n",
    "- **Model versioning:** Use version numbers, timestamps, and metadata to track changes.\n",
    "- **Model registry:** Tools like MLflow and W&B help organize models and promote them through stages.\n",
    "- **Artifact management:** Save scalers, encoders, and feature lists alongside the model, preferably in a Pipeline.\n",
    "- **Storage backends:** Local, network, cloud (S3), or databases.\n",
    "- **Organizational strategies:** Directory structures for multiple models.\n",
    "- **Backup and security:** Encrypt, control access, and test recovery.\n",
    "\n",
    "### **Practical Takeaways for the NEPSE System:**\n",
    "\n",
    "- For scikit\u2011learn models, use Joblib to save `Pipeline` objects containing the scaler and model.\n",
    "- For neural networks, use TensorFlow's SavedModel format.\n",
    "- Store models in a structured directory: `models/{symbol}/{version}/`.\n",
    "- Maintain a metadata JSON file in each model directory.\n",
    "- Use a simple SQLite database as a lightweight model registry if MLflow is overkill.\n",
    "- Back up the models directory to cloud storage regularly.\n",
    "- Set up IAM roles to restrict access in production.\n",
    "\n",
    "With these practices, your models are safely stored, versioned, and ready for deployment. In the next chapter, **Chapter 40: Building Prediction Services**, we will explore how to expose these models via REST APIs and other service interfaces.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Chapter 39**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='38. from_development_to_production.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='40. building_prediction_services.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}