{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 24: Concurrency and Parallelism\n",
    "\n",
    "Modern applications often need to perform multiple operations simultaneously to improve responsiveness and throughput. Whether it's processing large datasets, handling multiple client requests, or keeping a UI responsive while performing background work, understanding concurrency and parallelism is essential.\n",
    "\n",
    "In this chapter, you'll learn:\n",
    "\n",
    "- The difference between **concurrency** and **parallelism**.\n",
    "- The **threading model** in .NET and how to work with threads.\n",
    "- The **Task Parallel Library (TPL)** – `Parallel` class, PLINQ, and `Task` for data and task parallelism.\n",
    "- **Concurrent collections** (`ConcurrentDictionary`, `ConcurrentQueue`, etc.) for safe access from multiple threads.\n",
    "- How to avoid common pitfalls: **race conditions**, **deadlocks**, and **thread safety** issues.\n",
    "- When to use `lock`, `Interlocked`, and other synchronization primitives.\n",
    "- A practical example: parallel image processing.\n",
    "- Best practices for concurrent programming.\n",
    "\n",
    "By the end, you'll be able to write efficient, safe multi‑threaded code that scales with your hardware.\n",
    "\n",
    "---\n",
    "\n",
    "## 24.1 Concurrency vs. Parallelism\n",
    "\n",
    "These terms are often confused:\n",
    "\n",
    "- **Concurrency** is about dealing with many things at once. It's the composition of independently executing tasks. Concurrency can be achieved on a single‑core machine by time‑slicing (tasks take turns). The goal is often responsiveness (e.g., a UI thread remains responsive while background work is done).\n",
    "\n",
    "- **Parallelism** is about doing many things at once. It requires multiple cores or processors. The goal is performance – completing a large task faster by splitting it into smaller chunks that run simultaneously.\n",
    "\n",
    "In .NET, you can achieve concurrency with asynchronous programming (`async`/`await`) and parallelism with the Task Parallel Library (TPL). This chapter focuses on parallelism.\n",
    "\n",
    "---\n",
    "\n",
    "## 24.2 The .NET Threading Model\n",
    "\n",
    "A **thread** is the smallest unit of execution within a process. The operating system schedules threads on available cores.\n",
    "\n",
    "### Creating Threads Manually (Legacy)\n",
    "\n",
    "You can create a thread directly using the `Thread` class:\n",
    "\n",
    "```csharp\n",
    "Thread thread = new Thread(() =>\n",
    "{\n",
    "    Console.WriteLine(\"Running on a separate thread\");\n",
    "});\n",
    "thread.Start();\n",
    "```\n",
    "\n",
    "However, manual thread management is cumbersome and inefficient for many scenarios. The `ThreadPool` provides a pool of worker threads, but the Task Parallel Library is the recommended approach.\n",
    "\n",
    "### Thread Pool\n",
    "\n",
    "The thread pool manages a set of threads that can be reused for multiple tasks. You can queue work items:\n",
    "\n",
    "```csharp\n",
    "ThreadPool.QueueUserWorkItem(state =>\n",
    "{\n",
    "    Console.WriteLine(\"Work from thread pool\");\n",
    "});\n",
    "```\n",
    "\n",
    "But the TPL (`Task`) provides a richer, more convenient abstraction over the thread pool.\n",
    "\n",
    "---\n",
    "\n",
    "## 24.3 The Task Parallel Library (TPL)\n",
    "\n",
    "The TPL is a set of public types and APIs in the `System.Threading.Tasks` namespace. Its purpose is to make developers more productive by simplifying the process of adding parallelism and concurrency to applications.\n",
    "\n",
    "### `Parallel` Class\n",
    "\n",
    "The `Parallel` class provides static methods for parallel loops and regions.\n",
    "\n",
    "#### `Parallel.For`\n",
    "\n",
    "```csharp\n",
    "int[] data = Enumerable.Range(0, 100).ToArray();\n",
    "Parallel.For(0, data.Length, i =>\n",
    "{\n",
    "    data[i] = data[i] * data[i]; // some CPU‑intensive work\n",
    "});\n",
    "```\n",
    "\n",
    "This loop partitions the range and executes iterations in parallel. The degree of parallelism is automatically managed.\n",
    "\n",
    "#### `Parallel.ForEach`\n",
    "\n",
    "```csharp\n",
    "var numbers = Enumerable.Range(0, 100).ToList();\n",
    "Parallel.ForEach(numbers, n =>\n",
    "{\n",
    "    Console.WriteLine($\"Processing {n} on thread {Thread.CurrentThread.ManagedThreadId}\");\n",
    "});\n",
    "```\n",
    "\n",
    "#### `Parallel.Invoke`\n",
    "\n",
    "Executes multiple actions in parallel:\n",
    "\n",
    "```csharp\n",
    "Parallel.Invoke(\n",
    "    () => DoWork1(),\n",
    "    () => DoWork2(),\n",
    "    () => DoWork3()\n",
    ");\n",
    "```\n",
    "\n",
    "**Important:** The work inside parallel loops should be **CPU‑bound** (not I/O bound) and independent (no shared state modifications without synchronization). If you need to combine results, use thread‑safe collections or locking.\n",
    "\n",
    "### PLINQ (Parallel LINQ)\n",
    "\n",
    "PLINQ is a parallel implementation of LINQ. You can turn any LINQ query into a parallel query by calling `AsParallel()`.\n",
    "\n",
    "```csharp\n",
    "var numbers = Enumerable.Range(1, 10000000);\n",
    "var evenSquares = numbers.AsParallel()\n",
    "                         .Where(n => n % 2 == 0)\n",
    "                         .Select(n => n * n)\n",
    "                         .ToArray();\n",
    "```\n",
    "\n",
    "PLINQ automatically partitions the data and executes the query in parallel. You can control the degree of parallelism with `WithDegreeOfParallelism()`.\n",
    "\n",
    "PLINQ is great for data‑parallel operations on collections. However, be cautious with order‑preserving operations (`AsOrdered()`), as they can reduce parallelism.\n",
    "\n",
    "---\n",
    "\n",
    "## 24.4 Concurrent Collections\n",
    "\n",
    "When multiple threads access a shared collection, you must ensure thread safety. The standard collections (`List<T>`, `Dictionary<TKey, TValue>`) are **not** thread‑safe. If one thread modifies a collection while another enumerates it, exceptions or data corruption can occur.\n",
    "\n",
    "The `System.Collections.Concurrent` namespace provides thread‑safe collections designed for concurrent access:\n",
    "\n",
    "| Collection | Description |\n",
    "|------------|-------------|\n",
    "| `ConcurrentDictionary<TKey, TValue>` | Thread‑safe dictionary, optimized for concurrent reads and writes. |\n",
    "| `ConcurrentQueue<T>` | Thread‑safe FIFO queue. |\n",
    "| `ConcurrentStack<T>` | Thread‑safe LIFO stack. |\n",
    "| `ConcurrentBag<T>` | Unordered collection for scenarios where order doesn't matter. |\n",
    "| `BlockingCollection<T>` | Bounded or unbounded collection that blocks producers/consumers. |\n",
    "\n",
    "### Example: Using `ConcurrentDictionary`\n",
    "\n",
    "```csharp\n",
    "var dict = new ConcurrentDictionary<string, int>();\n",
    "\n",
    "// Add or update safely\n",
    "dict.AddOrUpdate(\"key\", 1, (k, old) => old + 1);\n",
    "\n",
    "// Try get\n",
    "if (dict.TryGetValue(\"key\", out int value))\n",
    "{\n",
    "    Console.WriteLine(value);\n",
    "}\n",
    "```\n",
    "\n",
    "### Example: Producer‑Consumer with `ConcurrentQueue` and `BlockingCollection`\n",
    "\n",
    "```csharp\n",
    "var queue = new BlockingCollection<int>(boundedCapacity: 5);\n",
    "\n",
    "// Producer task\n",
    "Task.Run(() =>\n",
    "{\n",
    "    for (int i = 0; i < 10; i++)\n",
    "    {\n",
    "        queue.Add(i);\n",
    "        Console.WriteLine($\"Produced {i}\");\n",
    "    }\n",
    "    queue.CompleteAdding();\n",
    "});\n",
    "\n",
    "// Consumer task\n",
    "Task.Run(() =>\n",
    "{\n",
    "    foreach (var item in queue.GetConsumingEnumerable())\n",
    "    {\n",
    "        Console.WriteLine($\"Consumed {item}\");\n",
    "        Thread.Sleep(100); // simulate work\n",
    "    }\n",
    "});\n",
    "```\n",
    "\n",
    "`GetConsumingEnumerable` blocks when the queue is empty and completes when `CompleteAdding` is called.\n",
    "\n",
    "---\n",
    "\n",
    "## 24.5 Synchronization Primitives\n",
    "\n",
    "Even with concurrent collections, you may need to coordinate access to shared resources. The `lock` statement is the simplest synchronization tool.\n",
    "\n",
    "### `lock`\n",
    "\n",
    "```csharp\n",
    "private readonly object _lock = new object();\n",
    "private int _counter;\n",
    "\n",
    "public void Increment()\n",
    "{\n",
    "    lock (_lock)\n",
    "    {\n",
    "        _counter++;\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "`lock` ensures that only one thread can execute the enclosed code at a time. Always lock on a private, readonly object; never lock on `this` or a public field.\n",
    "\n",
    "### `Interlocked`\n",
    "\n",
    "For simple atomic operations on integers, `Interlocked` provides faster, lock‑free methods:\n",
    "\n",
    "```csharp\n",
    "Interlocked.Increment(ref _counter);\n",
    "Interlocked.Add(ref _counter, 5);\n",
    "Interlocked.Exchange(ref _counter, 10);\n",
    "Interlocked.CompareExchange(ref _counter, 100, 50); // if _counter == 50, set to 100\n",
    "```\n",
    "\n",
    "### `Monitor`, `Mutex`, `Semaphore`, `ReaderWriterLockSlim`\n",
    "\n",
    "These offer more advanced synchronization scenarios. For example:\n",
    "\n",
    "- `ReaderWriterLockSlim` allows multiple concurrent readers but exclusive writers.\n",
    "- `Semaphore` limits the number of threads accessing a resource.\n",
    "- `Mutex` works across processes.\n",
    "\n",
    "Use them when `lock` or `Interlocked` is insufficient.\n",
    "\n",
    "---\n",
    "\n",
    "## 24.6 Common Pitfalls: Race Conditions and Deadlocks\n",
    "\n",
    "### Race Condition\n",
    "\n",
    "A **race condition** occurs when the outcome depends on the non‑deterministic timing of threads. Example:\n",
    "\n",
    "```csharp\n",
    "int counter = 0;\n",
    "Task.Run(() => counter++);\n",
    "Task.Run(() => counter++);\n",
    "```\n",
    "\n",
    "The final value could be 1 or 2 because `counter++` is not atomic. Always synchronize access or use `Interlocked`.\n",
    "\n",
    "### Deadlock\n",
    "\n",
    "A **deadlock** occurs when two or more threads are waiting for each other to release resources, and none can proceed. Classic example:\n",
    "\n",
    "```csharp\n",
    "object lock1 = new object();\n",
    "object lock2 = new object();\n",
    "\n",
    "Task.Run(() =>\n",
    "{\n",
    "    lock (lock1)\n",
    "    {\n",
    "        Thread.Sleep(100); // simulate work\n",
    "        lock (lock2) { } // waits for lock2\n",
    "    }\n",
    "});\n",
    "\n",
    "Task.Run(() =>\n",
    "{\n",
    "    lock (lock2)\n",
    "    {\n",
    "        Thread.Sleep(100);\n",
    "        lock (lock1) { } // waits for lock1\n",
    "    }\n",
    "});\n",
    "```\n",
    "\n",
    "Both tasks will wait forever. To avoid deadlocks:\n",
    "\n",
    "- Acquire locks in a consistent order.\n",
    "- Use `Monitor.TryEnter` with a timeout.\n",
    "- Avoid holding locks while calling external code.\n",
    "\n",
    "---\n",
    "\n",
    "## 24.7 Putting It All Together: Parallel Image Processing\n",
    "\n",
    "Let's simulate processing a batch of images. We'll use `Parallel.ForEach` to process multiple images concurrently, with a thread‑safe collection to store results.\n",
    "\n",
    "```csharp\n",
    "using System.Collections.Concurrent;\n",
    "\n",
    "public class ImageProcessor\n",
    "{\n",
    "    public void ProcessImages(string[] imagePaths)\n",
    "    {\n",
    "        var results = new ConcurrentBag<string>();\n",
    "\n",
    "        Parallel.ForEach(imagePaths, path =>\n",
    "        {\n",
    "            // Simulate CPU‑intensive image processing\n",
    "            string result = ProcessImage(path);\n",
    "            results.Add(result);\n",
    "            Console.WriteLine($\"Processed {path} on thread {Thread.CurrentThread.ManagedThreadId}\");\n",
    "        });\n",
    "\n",
    "        Console.WriteLine($\"Total processed: {results.Count}\");\n",
    "    }\n",
    "\n",
    "    private string ProcessImage(string path)\n",
    "    {\n",
    "        // Simulate work\n",
    "        Thread.Sleep(100);\n",
    "        return $\"Processed {path}\";\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "If we needed to collect metrics, we could use `Interlocked`:\n",
    "\n",
    "```csharp\n",
    "int _processedCount = 0;\n",
    "\n",
    "Parallel.ForEach(imagePaths, path =>\n",
    "{\n",
    "    ProcessImage(path);\n",
    "    Interlocked.Increment(ref _processedCount);\n",
    "});\n",
    "```\n",
    "\n",
    "For more advanced scenarios, consider using `Parallel.For` with thread‑local data to reduce contention.\n",
    "\n",
    "---\n",
    "\n",
    "## 24.8 Best Practices for Concurrent Programming\n",
    "\n",
    "### 1. Prefer Higher‑Level Abstractions\n",
    "\n",
    "Use `Parallel` loops, PLINQ, and `Task` instead of manual thread management. They are optimized and handle partitioning, load balancing, and cancellation.\n",
    "\n",
    "### 2. Keep Work Independent\n",
    "\n",
    "Ensure tasks in parallel loops do not interfere. If they must share data, use concurrent collections or synchronization.\n",
    "\n",
    "### 3. Avoid Shared Mutable State\n",
    "\n",
    "Shared mutable state is the root of many threading bugs. Try to design your algorithms to avoid it – e.g., by using immutable data or functional transformations.\n",
    "\n",
    "### 4. Use `lock` Sparingly and Correctly\n",
    "\n",
    "Locking reduces parallelism. Keep critical sections short. Always lock on a private object, never on a public or a string.\n",
    "\n",
    "### 5. Be Aware of Thread Safety\n",
    "\n",
    "Know which types are thread‑safe. For instance, `Random` is not thread‑safe; use `ThreadLocal<Random>`.\n",
    "\n",
    "### 6. Handle Cancellation\n",
    "\n",
    "Support cancellation in parallel operations by passing a `CancellationToken`.\n",
    "\n",
    "```csharp\n",
    "var cts = new CancellationTokenSource();\n",
    "ParallelOptions options = new ParallelOptions { CancellationToken = cts.Token };\n",
    "try\n",
    "{\n",
    "    Parallel.For(0, 100, options, i => { ... });\n",
    "}\n",
    "catch (OperationCanceledException) { ... }\n",
    "```\n",
    "\n",
    "### 7. Don't Assume Parallelism Always Improves Performance\n",
    "\n",
    "Parallelism adds overhead. For small datasets or trivial work, a sequential loop may be faster. Measure with `Stopwatch`.\n",
    "\n",
    "### 8. Watch Out for Thread Pool Starvation\n",
    "\n",
    "If you use `Task.Run` for long‑running operations, you can exhaust the thread pool. For I/O‑bound work, prefer `async`/`await`. For CPU‑bound, `Parallel` or `Task.Run` is appropriate.\n",
    "\n",
    "### 9. Test Thoroughly Under Load\n",
    "\n",
    "Concurrency bugs are often hard to reproduce. Use tools like `Task` and `Parallel` to simulate high concurrency and test with `Thread.Sleep` to expose race conditions.\n",
    "\n",
    "### 10. Consider Using Immutable Data Structures\n",
    "\n",
    "Immutable objects are inherently thread‑safe and can be shared without locks. C# records are a great example.\n",
    "\n",
    "---\n",
    "\n",
    "## 24.9 Chapter Summary\n",
    "\n",
    "In this chapter, you've learned how to write parallel and concurrent code in C#:\n",
    "\n",
    "- **Concurrency** is about managing multiple tasks, while **parallelism** is about executing tasks simultaneously on multiple cores.\n",
    "- The **Task Parallel Library (TPL)** provides high‑level abstractions like `Parallel.For` and `Parallel.ForEach`.\n",
    "- **PLINQ** offers a declarative way to parallelize LINQ queries.\n",
    "- **Concurrent collections** (`ConcurrentDictionary`, `ConcurrentQueue`, etc.) allow safe access from multiple threads.\n",
    "- **Synchronization primitives** (`lock`, `Interlocked`) protect shared data.\n",
    "- You must avoid **race conditions** and **deadlocks** by careful design.\n",
    "- A practical example demonstrated parallel image processing.\n",
    "- Best practices guide you to write efficient, safe concurrent code.\n",
    "\n",
    "With these tools, you can leverage multi‑core processors to boost performance and build responsive applications.\n",
    "\n",
    "In the next chapter, **Designing for Performance**, we'll explore techniques for writing high‑performance C# code, including `Span<T>`, `ref struct`, benchmarking, and profiling. You'll learn how to identify bottlenecks and optimize memory usage.\n",
    "\n",
    "**Exercises:**\n",
    "\n",
    "1. Write a program that uses `Parallel.For` to compute the sum of squares of a large array. Compare the time with a sequential loop.\n",
    "2. Implement a producer‑consumer pattern using `BlockingCollection<T>`. Have one producer generate numbers and two consumers process them (e.g., compute prime factors).\n",
    "3. Create a simple web crawler that downloads multiple pages in parallel using `Parallel.ForEach` and `HttpClient`. Be mindful of thread safety.\n",
    "4. Simulate a bank transfer system where multiple threads transfer money between accounts. Use `lock` to prevent race conditions and ensure consistency.\n",
    "5. Use PLINQ to find all prime numbers up to 10 million. Compare performance with and without `AsParallel()`.\n",
    "\n",
    "Now, prepare to dive into performance optimization in Chapter 25!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
