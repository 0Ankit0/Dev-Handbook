{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **Chapter 11: Performance Optimization**\n",
    "\n",
    "---\n",
    "\n",
    "## **Learning Objectives**\n",
    "\n",
    "By the end of this chapter, you will be able to:\n",
    "\n",
    "- Identify and solve the N+1 query problem using DataLoader\n",
    "- Implement batching and caching strategies for database queries\n",
    "- Configure server-side response caching and CDN integration\n",
    "- Implement cursor-based pagination following the Relay specification\n",
    "- Analyze and limit query complexity to prevent Denial of Service attacks\n",
    "- Optimize resolver execution for high-throughput applications\n",
    "\n",
    "---\n",
    "\n",
    "## **Prerequisites**\n",
    "\n",
    "- Completed Chapter 7: Building a GraphQL Server\n",
    "- Understanding of database query execution (SQL/NoSQL)\n",
    "- Familiarity with caching concepts (TTL, cache keys)\n",
    "- Basic knowledge of pagination mechanisms\n",
    "\n",
    "---\n",
    "\n",
    "## **11.1 The N+1 Problem: Understanding the Performance Killer**\n",
    "\n",
    "The N+1 problem is the most notorious performance anti-pattern in GraphQL applications. It occurs when a resolver makes a database query for every item in a collection, resulting in one query for the parent (N) plus one query for each child (1 \u00d7 N).\n",
    "\n",
    "### **The Problem in Practice**\n",
    "\n",
    "Consider this schema:\n",
    "\n",
    "```graphql\n",
    "type Author {\n",
    "  id: ID!\n",
    "  name: String!\n",
    "  books: [Book!]!\n",
    "}\n",
    "\n",
    "type Query {\n",
    "  authors: [Author!]!\n",
    "}\n",
    "```\n",
    "\n",
    "**The Query:**\n",
    "\n",
    "```graphql\n",
    "query GetAuthorsWithBooks {\n",
    "  authors {\n",
    "    id\n",
    "    name\n",
    "    books {\n",
    "      title\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**The Resolver (Naive Implementation):**\n",
    "\n",
    "```javascript\n",
    "const resolvers = {\n",
    "  Query: {\n",
    "    authors: () => {\n",
    "      // Query 1: SELECT * FROM authors\n",
    "      return db.query('SELECT * FROM authors');\n",
    "    }\n",
    "  },\n",
    "  Author: {\n",
    "    books: (parent) => {\n",
    "      // Query 2, 3, 4...N: SELECT * FROM books WHERE author_id = ?\n",
    "      // This runs ONCE for EACH author!\n",
    "      return db.query('SELECT * FROM books WHERE author_id = ?', [parent.id]);\n",
    "    }\n",
    "  }\n",
    "};\n",
    "```\n",
    "\n",
    "**The Execution:**\n",
    "If you have 100 authors, you will execute:\n",
    "1.  1 query to get all authors\n",
    "2.  100 queries to get books for each author\n",
    "\n",
    "**Total: 101 database queries**\n",
    "\n",
    "This scales linearly and will crash your database under moderate load.\n",
    "\n",
    "---\n",
    "\n",
    "## **11.2 DataLoader: Batching and Caching Database Requests**\n",
    "\n",
    "**DataLoader**, created by Facebook, is the industry-standard solution for the N+1 problem. It provides a consistent API over various data fetching strategies, including batching and caching.\n",
    "\n",
    "### **11.2.1 How DataLoader Works**\n",
    "\n",
    "DataLoader operates on a simple principle: **Batching**. Instead of fetching data immediately when requested, it collects all keys requested during a single event loop tick, then fetches them all at once in a single batch.\n",
    "\n",
    "**Conceptual Flow:**\n",
    "\n",
    "1.  **Tick 1:** Resolver asks for `User:1`\n",
    "2.  **Tick 1:** Resolver asks for `User:2`\n",
    "3.  **Tick 1:** Resolver asks for `User:3`\n",
    "4.  **End of Tick:** DataLoader receives `[1, 2, 3]` and executes: `SELECT * FROM users WHERE id IN (1, 2, 3)`\n",
    "5.  **Result:** Returns the appropriate user to each resolver.\n",
    "\n",
    "### **11.2.2 Implementing DataLoader per Request**\n",
    "\n",
    "DataLoader instances should be created **per request** to avoid caching stale data between different users.\n",
    "\n",
    "**Setup:**\n",
    "\n",
    "```javascript\n",
    "const DataLoader = require('dataloader');\n",
    "\n",
    "// Batch function: Receives an array of keys, returns a Promise of values\n",
    "const batchUsers = async (userIds) => {\n",
    "  console.log('Batch loading users:', userIds);\n",
    "  \n",
    "  // Single query for all IDs\n",
    "  const users = await db.query(\n",
    "    'SELECT * FROM users WHERE id IN (?)', \n",
    "    [userIds]\n",
    "  );\n",
    "  \n",
    "  // IMPORTANT: Return users in the SAME ORDER as the keys\n",
    "  const userMap = new Map(users.map(u => [u.id, u]));\n",
    "  return userIds.map(id => userMap.get(id) || null);\n",
    "};\n",
    "\n",
    "// Create a factory function\n",
    "const createUserLoader = () => new DataLoader(batchUsers);\n",
    "```\n",
    "\n",
    "**Integration with Apollo Context:**\n",
    "\n",
    "```javascript\n",
    "const server = new ApolloServer({\n",
    "  typeDefs,\n",
    "  resolvers,\n",
    "  context: () => {\n",
    "    return {\n",
    "      // Create a new DataLoader instance for this request\n",
    "      userLoader: createUserLoader(),\n",
    "    };\n",
    "  }\n",
    "});\n",
    "```\n",
    "\n",
    "**Using in Resolvers:**\n",
    "\n",
    "```javascript\n",
    "const resolvers = {\n",
    "  Query: {\n",
    "    author: (parent, { id }, { userLoader }) => {\n",
    "      // DataLoader handles the batching automatically\n",
    "      return userLoader.load(id);\n",
    "    }\n",
    "  },\n",
    "  \n",
    "  // Solving the N+1 for Author.books\n",
    "  Author: {\n",
    "    books: async (parent, args, context) => {\n",
    "      // If we need to batch book loading, we'd create a bookLoader similarly\n",
    "      // For now, assuming we have a bookLoader in context\n",
    "      return context.bookLoader.loadMany(parent.bookIds);\n",
    "    }\n",
    "  }\n",
    "};\n",
    "```\n",
    "\n",
    "**Key Benefits:**\n",
    "*   **Automatic Batching:** Multiple `.load()` calls in the same tick are automatically batched.\n",
    "*   **Caching:** If the same key is requested twice in one request, DataLoader caches the result and returns it immediately without hitting the database again.\n",
    "*   **Order Preservation:** The batch function must return results in the same order as the input keys.\n",
    "\n",
    "### **Multiple DataLoaders Pattern**\n",
    "\n",
    "In a real application, you'll have loaders for every entity type:\n",
    "\n",
    "```javascript\n",
    "const createLoaders = () => ({\n",
    "  user: new DataLoader(batchUsers),\n",
    "  book: new DataLoader(batchBooks),\n",
    "  review: new DataLoader(batchReviews),\n",
    "});\n",
    "\n",
    "// In context\n",
    "context: () => ({\n",
    "  loaders: createLoaders()\n",
    "})\n",
    "\n",
    "// Usage\n",
    "context.loaders.user.load(id)\n",
    "context.loaders.book.loadMany(author.bookIds)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **11.3 Caching Strategies**\n",
    "\n",
    "GraphQL provides unique caching challenges because every query can be different. However, the specification provides mechanisms for fine-grained cache control.\n",
    "\n",
    "### **11.3.1 Server-Side Response Caching**\n",
    "\n",
    "Apollo Server supports automatic response caching based on schema directives.\n",
    "\n",
    "**Setup:**\n",
    "\n",
    "```javascript\n",
    "const { ApolloServer, PluginDefinition } = require('apollo-server');\n",
    "const { InMemoryLRUCache } = require('apollo-server-caching');\n",
    "\n",
    "const server = new ApolloServer({\n",
    "  typeDefs,\n",
    "  resolvers,\n",
    "  plugins: [\n",
    "    // Enable response caching\n",
    "    require('apollo-server-plugin-response-cache')({\n",
    "      // Cache configuration\n",
    "      defaultMaxAge: 300, // 5 minutes default\n",
    "    })\n",
    "  ],\n",
    "  // Provide a cache backend (Redis for production)\n",
    "  cache: new InMemoryLRUCache({\n",
    "    maxSize: 1000000, // ~1MB\n",
    "  }),\n",
    "});\n",
    "```\n",
    "\n",
    "**Schema-Level Control:**\n",
    "\n",
    "```graphql\n",
    "directive @cacheControl(maxAge: Int, scope: CacheControlScope) on FIELD_DEFINITION | OBJECT | INTERFACE\n",
    "\n",
    "enum CacheControlScope {\n",
    "  PUBLIC\n",
    "  PRIVATE\n",
    "}\n",
    "\n",
    "type Query {\n",
    "  # Public data - cache for 1 hour\n",
    "  products: [Product!]! @cacheControl(maxAge: 3600)\n",
    "  \n",
    "  # Private data - cache per user for 5 minutes\n",
    "  me: User @cacheControl(maxAge: 300, scope: PRIVATE)\n",
    "}\n",
    "\n",
    "type Product @cacheControl(maxAge: 3600) {\n",
    "  id: ID!\n",
    "  name: String!\n",
    "  # Expensive computation - cache longer\n",
    "  popularityScore: Float @cacheControl(maxAge: 86400)\n",
    "}\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "*   **`@cacheControl`**: Tells Apollo which fields can be cached and for how long.\n",
    "*   **`scope: PRIVATE`**: Ensures the cache is segmented by user (using the session ID or JWT), preventing user A from seeing user B's data.\n",
    "*   **CALCULATED CACHE KEY**: Apollo calculates a cache key based on the query structure and variables. Identical queries hit the cache.\n",
    "\n",
    "### **11.3.2 CDN Caching with `cache-control` Headers**\n",
    "\n",
    "To allow CDNs (like Cloudflare, Fastly) to cache your GraphQL responses, you must ensure the HTTP response includes proper `Cache-Control` headers.\n",
    "\n",
    "**Apollo Configuration:**\n",
    "\n",
    "```javascript\n",
    "const server = new ApolloServer({\n",
    "  typeDefs,\n",
    "  resolvers,\n",
    "  plugins: [\n",
    "    require('apollo-server-plugin-response-cache')({\n",
    "      // This ensures headers are set for CDN caching\n",
    "      sessionId: (requestContext) => {\n",
    "        // Return null for public queries, user ID for private\n",
    "        const user = requestContext.context.user;\n",
    "        return user ? user.id : null;\n",
    "      }\n",
    "    })\n",
    "  ]\n",
    "});\n",
    "```\n",
    "\n",
    "**The HTTP Response:**\n",
    "\n",
    "```http\n",
    "HTTP/1.1 200 OK\n",
    "Content-Type: application/json\n",
    "Cache-Control: max-age=300, public\n",
    "Age: 0\n",
    "\n",
    "{\n",
    "  \"data\": { ... }\n",
    "}\n",
    "```\n",
    "\n",
    "**Important:** For CDN caching to work, you typically need to use `GET` requests (not `POST`) for queries, or configure your CDN to cache POST requests (which many modern CDNs support).\n",
    "\n",
    "### **11.3.3 Client-Side Caching Normalization**\n",
    "\n",
    "We covered Apollo Client cache in Chapter 10, but for server performance, it's crucial that the server supports **cache hints** so the client knows when to invalidate.\n",
    "\n",
    "**Sending Cache Hints:**\n",
    "\n",
    "Apollo Server automatically includes cache metadata in the response extensions if you use the response cache plugin. The client can read this to manage its own cache TTL.\n",
    "\n",
    "---\n",
    "\n",
    "## **11.4 Pagination Strategies**\n",
    "\n",
    "Fetching thousands of records at once is a performance death sentence. Pagination is essential.\n",
    "\n",
    "### **11.4.1 Offset vs. Cursor-Based Pagination**\n",
    "\n",
    "**Offset Pagination (The SQL Way):**\n",
    "\n",
    "```graphql\n",
    "type Query {\n",
    "  users(limit: Int = 10, offset: Int = 0): [User!]!\n",
    "}\n",
    "\n",
    "# Usage\n",
    "query GetPage2 {\n",
    "  users(limit: 10, offset: 10)\n",
    "}\n",
    "```\n",
    "\n",
    "**Pros:** Simple, easy to jump to any page.\n",
    "**Cons:** \n",
    "*   **Inconsistent results:** If a new user is inserted between page 1 and page 2, user 10 appears on both pages.\n",
    "*   **Performance:** `OFFSET` in SQL is slow for large datasets because the database must scan and discard all offset rows.\n",
    "\n",
    "**Cursor-Based Pagination (The GraphQL Way):**\n",
    "\n",
    "Instead of asking for \"page 2,\" you ask for \"the 10 items after item X.\"\n",
    "\n",
    "```graphql\n",
    "type PageInfo {\n",
    "  hasNextPage: Boolean!\n",
    "  endCursor: String\n",
    "}\n",
    "\n",
    "type UserEdge {\n",
    "  node: User!\n",
    "  cursor: String!\n",
    "}\n",
    "\n",
    "type UserConnection {\n",
    "  edges: [UserEdge!]!\n",
    "  pageInfo: PageInfo!\n",
    "  totalCount: Int\n",
    "}\n",
    "\n",
    "type Query {\n",
    "  users(first: Int, after: String): UserConnection!\n",
    "}\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "*   **Stable:** Insertions don't cause duplicates or skips.\n",
    "*   **Performance:** Uses indexed `WHERE id > cursor` queries, which are O(log n) instead of O(n).\n",
    "*   **Infinite Scroll:** Natural fit for modern UIs.\n",
    "\n",
    "### **11.4.2 The Relay Cursor Connections Specification**\n",
    "\n",
    "Facebook's Relay specification is the industry standard for cursor pagination in GraphQL. It standardizes the `Connection`, `Edge`, and `PageInfo` types we saw above.\n",
    "\n",
    "**Complete Implementation:**\n",
    "\n",
    "**Schema:**\n",
    "\n",
    "```graphql\n",
    "type Query {\n",
    "  users(\n",
    "    first: Int\n",
    "    after: String\n",
    "    last: Int\n",
    "    before: String\n",
    "  ): UserConnection!\n",
    "}\n",
    "\n",
    "type UserConnection {\n",
    "  edges: [UserEdge!]!\n",
    "  pageInfo: PageInfo!\n",
    "}\n",
    "\n",
    "type UserEdge {\n",
    "  cursor: String!\n",
    "  node: User!\n",
    "}\n",
    "\n",
    "type PageInfo {\n",
    "  hasNextPage: Boolean!\n",
    "  hasPreviousPage: Boolean!\n",
    "  startCursor: String\n",
    "  endCursor: String\n",
    "}\n",
    "```\n",
    "\n",
    "**Resolver Implementation:**\n",
    "\n",
    "```javascript\n",
    "const resolvers = {\n",
    "  Query: {\n",
    "    users: async (_, { first, after, last, before }, { db }) => {\n",
    "      // Decode cursor (usually base64 encoded ID)\n",
    "      const cursorId = after ? Buffer.from(after, 'base64').toString('ascii') : null;\n",
    "      \n",
    "      // Build query\n",
    "      let query = db.query('SELECT * FROM users');\n",
    "      \n",
    "      if (cursorId) {\n",
    "        query = query.where('id', '>', cursorId);\n",
    "      }\n",
    "      \n",
    "      // Fetch one extra record to determine if there's a next page\n",
    "      const users = await query.limit(first + 1).orderBy('id', 'asc');\n",
    "      \n",
    "      const hasNextPage = users.length > first;\n",
    "      const nodes = hasNextPage ? users.slice(0, -1) : users; // Remove extra\n",
    "      \n",
    "      const edges = nodes.map(user => ({\n",
    "        cursor: Buffer.from(user.id).toString('base64'),\n",
    "        node: user\n",
    "      }));\n",
    "      \n",
    "      return {\n",
    "        edges,\n",
    "        pageInfo: {\n",
    "          hasNextPage,\n",
    "          hasPreviousPage: !!cursorId,\n",
    "          startCursor: edges.length > 0 ? edges[0].cursor : null,\n",
    "          endCursor: edges.length > 0 ? edges[edges.length - 1].cursor : null,\n",
    "        }\n",
    "      };\n",
    "    }\n",
    "  }\n",
    "};\n",
    "```\n",
    "\n",
    "**Usage (Infinite Scroll):**\n",
    "\n",
    "```javascript\n",
    "const GET_USERS = gql`\n",
    "  query GetUsers($first: Int, $after: String) {\n",
    "    users(first: $first, after: $after) {\n",
    "      edges {\n",
    "        cursor\n",
    "        node {\n",
    "          id\n",
    "          name\n",
    "        }\n",
    "      }\n",
    "      pageInfo {\n",
    "        hasNextPage\n",
    "        endCursor\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "`;\n",
    "\n",
    "function UserList() {\n",
    "  const { data, loading, fetchMore } = useQuery(GET_USERS, {\n",
    "    variables: { first: 10 }\n",
    "  });\n",
    "\n",
    "  const loadMore = () => {\n",
    "    fetchMore({\n",
    "      variables: {\n",
    "        after: data.users.pageInfo.endCursor\n",
    "      }\n",
    "    });\n",
    "  };\n",
    "\n",
    "  return (\n",
    "    <div>\n",
    "      {data?.users.edges.map(({ node }) => (\n",
    "        <UserCard key={node.id} user={node} />\n",
    "      ))}\n",
    "      \n",
    "      {data?.users.pageInfo.hasNextPage && (\n",
    "        <button onClick={loadMore} disabled={loading}>\n",
    "          Load More\n",
    "        </button>\n",
    "      )}\n",
    "    </div>\n",
    "  );\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **11.5 Query Complexity Analysis and Cost**\n",
    "\n",
    "GraphQL's flexibility is a double-edged sword. A malicious user can request deeply nested data that crashes your server.\n",
    "\n",
    "**Dangerous Query:**\n",
    "\n",
    "```graphql\n",
    "query Attack {\n",
    "  users {  # 1000 users\n",
    "    friends {  # Each has 1000 friends\n",
    "      friends {  # Each has 1000 friends\n",
    "        friends {  # Each has 1000 friends\n",
    "          name\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "# Potential result: 1,000,000,000,000 objects!\n",
    "```\n",
    "\n",
    "### **Implementing Complexity Limiting**\n",
    "\n",
    "We use the `graphql-query-complexity` package to analyze queries before execution.\n",
    "\n",
    "**Setup:**\n",
    "\n",
    "```javascript\n",
    "const { createComplexityLimitRule } = require('graphql-query-complexity');\n",
    "\n",
    "const complexityLimit = 1000; // Arbitrary complexity units\n",
    "\n",
    "const server = new ApolloServer({\n",
    "  typeDefs,\n",
    "  resolvers,\n",
    "  validationRules: [\n",
    "    createComplexityLimitRule(complexityLimit, {\n",
    "      onComplete: (complexity) => {\n",
    "        console.log('Query complexity:', complexity);\n",
    "      },\n",
    "      onComplete: (complexity) => {\n",
    "        if (complexity > complexityLimit) {\n",
    "          throw new Error(`Query too complex: ${complexity}. Max allowed: ${complexityLimit}`);\n",
    "        }\n",
    "      }\n",
    "    })\n",
    "  ],\n",
    "  // Define complexity for each field\n",
    "  fieldExtensionsEstimator(), // Estimates based on field definitions\n",
    "});\n",
    "```\n",
    "\n",
    "**Defining Field Complexity:**\n",
    "\n",
    "```javascript\n",
    "const resolvers = {\n",
    "  Query: {\n",
    "    users: {\n",
    "      resolve: () => db.getUsers(),\n",
    "      extensions: {\n",
    "        complexity: ({ args, childComplexity }) => {\n",
    "          // Base cost + (limit * child complexity)\n",
    "          return 10 + (args.first || 10) * childComplexity;\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  User: {\n",
    "    friends: {\n",
    "      resolve: (user) => db.getFriends(user.id),\n",
    "      extensions: {\n",
    "        complexity: ({ args, childComplexity }) => {\n",
    "          return 5 + (args.first || 10) * childComplexity;\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "};\n",
    "```\n",
    "\n",
    "**Best Practices:**\n",
    "*   Set a maximum depth limit (e.g., 10 levels deep).\n",
    "*   Set a maximum complexity score.\n",
    "*   Require pagination limits (don't allow `first: 10000`).\n",
    "\n",
    "---\n",
    "\n",
    "## **Chapter Summary**\n",
    "\n",
    "Performance optimization separates hobby projects from production systems. This chapter covered the critical techniques for scaling GraphQL APIs.\n",
    "\n",
    "### **Key Takeaways:**\n",
    "\n",
    "1.  **N+1 Problem:** The #1 performance killer in GraphQL, solved by DataLoader's batching mechanism.\n",
    "2.  **DataLoader:** Create instances per request. Batch loads within a single event loop tick. Cache results per request to avoid duplicate DB hits.\n",
    "3.  **Caching Layers:**\n",
    "    *   **Server Response Caching:** Cache expensive resolver results using `@cacheControl`.\n",
    "    *   **CDN Caching:** Enable HTTP cache headers for static/public data.\n",
    "    *   **Client Caching:** Normalized stores prevent refetching.\n",
    "4.  **Pagination:** Prefer Cursor-based pagination (Relay spec) over Offset pagination for stability and performance at scale.\n",
    "5.  **Complexity Analysis:** Protect your server from expensive queries by analyzing complexity and depth before execution.\n",
    "\n",
    "---\n",
    "\n",
    "### **\ud83d\ude80 Next Up: Chapter 12 - Security Hardening**\n",
    "\n",
    "**Summary:** Performance is meaningless without security. In Chapter 12, we will fortify our GraphQL API against attacks. We will learn about disabling introspection in production, implementing query depth limiting, using persisted queries to prevent injection, and setting up rate limiting to protect against denial of service attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='../4. client_side_mastery/10. the_client_ecosystem.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='12. security_hardening.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}