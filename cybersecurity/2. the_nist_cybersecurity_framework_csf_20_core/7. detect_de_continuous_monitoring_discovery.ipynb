{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: DETECT (DE) \u2013 Continuous Monitoring & Discovery\n",
    "\n",
    "In Chapter 6, we constructed comprehensive protective controls\u2014fortifying identities with MFA, encrypting data at rest and in transit, hardening applications, and institutionalizing secure development practices. These defenses are robust, but the reality of cybersecurity is that prevention eventually fails. Zero-day vulnerabilities emerge, credentials are compromised through phishing, and sophisticated adversaries find ways to bypass even the most stringent controls. The assumption of breach is fundamental to modern security architecture.\n",
    "\n",
    "The **DETECT** function of the NIST CSF 2.0 establishes the capabilities to identify cybersecurity events in a timely manner. Detection is the bridge between protection and response; it is the alarm system that alerts us when an intruder has bypassed our locks, the anomaly detection that spots the insider threat, and the forensic logging that reconstructs the timeline of a breach. Without detection, breaches linger undiscovered for months (the average dwell time in 2025 was 194 days), allowing adversaries to exfiltrate data, establish persistence, and move laterally with impunity.\n",
    "\n",
    "For developers, detection is often misunderstood as purely an operations or SOC (Security Operations Center) function. This chapter dispels that myth. We will explore how to instrument applications to produce security-relevant telemetry, how to structure logs for machine analysis, how to integrate runtime protection directly into applications, and how anomaly detection algorithms identify compromised accounts and insider threats. By the end, you will understand that security is not just about building walls, but about installing sensors, cameras, and tripwires throughout your digital estate.\n",
    "\n",
    "---\n",
    "\n",
    "## 7.1 Security Logging: What, When, and How to Log Effectively (OWASP A09)\n",
    "\n",
    "Logging and monitoring failures (OWASP A09: 2021) are a critical vulnerability. Without logs, we cannot detect breaches, debug security incidents, or meet compliance requirements. However, logging everything creates noise; logging too little creates blind spots.\n",
    "\n",
    "### 7.1.1 What to Log: The Security Event Taxonomy\n",
    "Not all events are security-relevant. Focus on the **5 Ws** of security logging:\n",
    "\n",
    "**Authentication Events:**\n",
    "*   Successful and failed login attempts\n",
    "*   Password changes and resets\n",
    "*   MFA challenges and outcomes\n",
    "*   Session creation, validation, and destruction\n",
    "*   Privilege escalation attempts\n",
    "\n",
    "**Authorization Events:**\n",
    "*   Access to sensitive resources (read/write/delete)\n",
    "*   Permission changes (RBAC modifications)\n",
    "*   Access denials (indicates potential reconnaissance)\n",
    "\n",
    "**Data Events:**\n",
    "*   Creation, modification, and deletion of sensitive data\n",
    "*   Bulk data access (potential exfiltration)\n",
    "*   Data classification changes\n",
    "\n",
    "**System Events:**\n",
    "*   Configuration changes (firewall rules, security group modifications)\n",
    "*   Software installations and updates\n",
    "*   Service starts and stops\n",
    "*   Administrative actions\n",
    "\n",
    "**Network Events:**\n",
    "*   Inbound connections from unusual geographies\n",
    "*   Outbound connections to command-and-control (C2) servers\n",
    "*   Port scanning activities\n",
    "\n",
    "### 7.1.2 Log Format: Structured Logging\n",
    "Unstructured logs (plain text) are difficult to parse and correlate. **Structured logging** (JSON) enables automated analysis and SIEM ingestion.\n",
    "\n",
    "**Implementation: Python Structured Security Logging**\n",
    "```python\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pythonjsonlogger import jsonlogger\n",
    "\n",
    "class SecurityLogger:\n",
    "    def __init__(self, service_name):\n",
    "        self.logger = logging.getLogger(\"security_audit\")\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        \n",
    "        # JSON formatter for SIEM ingestion\n",
    "        logHandler = logging.StreamHandler()\n",
    "        formatter = jsonlogger.JsonFormatter(\n",
    "            '%(timestamp)s %(level)s %(service)s %(event_type)s %(user_id)s '\n",
    "            '%(resource)s %(action)s %(result)s %(ip_address)s %(session_id)s '\n",
    "            '%(message)s',\n",
    "            rename_fields={'levelname': 'severity'}\n",
    "        )\n",
    "        logHandler.setFormatter(formatter)\n",
    "        self.logger.addHandler(logHandler)\n",
    "        \n",
    "        self.service_name = service_name\n",
    "    \n",
    "    def log_auth_event(self, event_type, user_id, result, ip_address, \n",
    "                      session_id=None, additional_context=None):\n",
    "        \"\"\"\n",
    "        Standardized authentication logging\n",
    "        \"\"\"\n",
    "        log_data = {\n",
    "            \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "            \"service\": self.service_name,\n",
    "            \"event_type\": event_type,  # LOGIN_SUCCESS, LOGIN_FAILURE, LOGOUT, etc.\n",
    "            \"user_id\": self._hash_user_id(user_id),  # Privacy protection\n",
    "            \"resource\": \"authentication_service\",\n",
    "            \"action\": event_type,\n",
    "            \"result\": result,  # SUCCESS, FAILURE, DENIED\n",
    "            \"ip_address\": ip_address,\n",
    "            \"session_id\": session_id or \"N/A\",\n",
    "            \"user_agent\": additional_context.get('user_agent') if additional_context else None,\n",
    "            \"mfa_used\": additional_context.get('mfa_used', False) if additional_context else False\n",
    "        }\n",
    "        \n",
    "        # Include failure reason for failed attempts (but not sensitive data)\n",
    "        if result == \"FAILURE\" and additional_context:\n",
    "            log_data[\"failure_reason\"] = additional_context.get('reason', 'Unknown')\n",
    "        \n",
    "        self.logger.info(\"Authentication event\", extra=log_data)\n",
    "        \n",
    "        # Critical: Log to tamper-resistant store (WORM storage) for compliance\n",
    "        self._write_to_immutable_store(log_data)\n",
    "    \n",
    "    def log_data_access(self, user_id, resource, action, classification, \n",
    "                       records_accessed, ip_address):\n",
    "        \"\"\"\n",
    "        Log access to sensitive data for DLP and privacy compliance\n",
    "        \"\"\"\n",
    "        log_data = {\n",
    "            \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "            \"service\": self.service_name,\n",
    "            \"event_type\": \"DATA_ACCESS\",\n",
    "            \"user_id\": self._hash_user_id(user_id),\n",
    "            \"resource\": resource,\n",
    "            \"action\": action,  # READ, WRITE, DELETE, EXPORT\n",
    "            \"data_classification\": classification,  # RESTRICTED, CONFIDENTIAL, etc.\n",
    "            \"records_count\": records_accessed,\n",
    "            \"ip_address\": ip_address,\n",
    "            \"anomaly_score\": self._calculate_anomaly_score(user_id, resource)\n",
    "        }\n",
    "        \n",
    "        # High-volume access alerts\n",
    "        if records_accessed > 1000:\n",
    "            log_data[\"alert\"] = \"BULK_ACCESS_DETECTED\"\n",
    "        \n",
    "        self.logger.info(\"Data access event\", extra=log_data)\n",
    "    \n",
    "    def _hash_user_id(self, user_id):\n",
    "        \"\"\"One-way hash of user ID for privacy in logs (pseudonymization)\"\"\"\n",
    "        import hashlib\n",
    "        return hashlib.sha256(user_id.encode()).hexdigest()[:16]\n",
    "    \n",
    "    def _write_to_immutable_store(self, log_data):\n",
    "        \"\"\"Write to Write-Once-Read-Many (WORM) storage for forensic integrity\"\"\"\n",
    "        # Implementation would write to AWS S3 Glacier WORM or similar\n",
    "        pass\n",
    "\n",
    "# Usage\n",
    "sec_logger = SecurityLogger(\"customer_portal\")\n",
    "sec_logger.log_auth_event(\n",
    "    event_type=\"LOGIN_ATTEMPT\",\n",
    "    user_id=\"user@example.com\",\n",
    "    result=\"FAILURE\",\n",
    "    ip_address=\"203.0.113.45\",\n",
    "    additional_context={\n",
    "        \"reason\": \"INVALID_PASSWORD\",\n",
    "        \"mfa_used\": False,\n",
    "        \"user_agent\": \"Mozilla/5.0...\"\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "### 7.1.3 Secure Logging: Protecting the Logs\n",
    "Logs are high-value targets; attackers delete logs to cover tracks.\n",
    "\n",
    "**Protection Measures:**\n",
    "*   **Integrity:** Cryptographic signing of log entries (hash chains).\n",
    "*   **Confidentiality:** Encrypt logs containing sensitive data (PII).\n",
    "*   **Availability:** Forward to centralized, append-only storage immediately.\n",
    "*   **Access Control:** Principle of least privilege; developers can read, not delete.\n",
    "\n",
    "**Implementation: Log Integrity with Hash Chains**\n",
    "```python\n",
    "import hashlib\n",
    "import hmac\n",
    "\n",
    "class TamperEvidentLogger:\n",
    "    def __init__(self, secret_key):\n",
    "        self.previous_hash = \"0\" * 64  # Genesis hash\n",
    "        self.secret_key = secret_key\n",
    "    \n",
    "    def create_log_entry(self, message):\n",
    "        \"\"\"\n",
    "        Creates a tamper-evident log entry using hash chaining\n",
    "        Similar to blockchain integrity mechanism\n",
    "        \"\"\"\n",
    "        timestamp = datetime.utcnow().isoformat()\n",
    "        \n",
    "        # Concatenate previous hash with current message\n",
    "        entry_data = f\"{self.previous_hash}|{timestamp}|{message}\"\n",
    "        \n",
    "        # HMAC for integrity (not just SHA256 to prevent length extension attacks)\n",
    "        current_hash = hmac.new(\n",
    "            self.secret_key.encode(),\n",
    "            entry_data.encode(),\n",
    "            hashlib.sha256\n",
    "        ).hexdigest()\n",
    "        \n",
    "        entry = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"message\": message,\n",
    "            \"previous_hash\": self.previous_hash,\n",
    "            \"entry_hash\": current_hash\n",
    "        }\n",
    "        \n",
    "        self.previous_hash = current_hash\n",
    "        return entry\n",
    "    \n",
    "    def verify_chain(self, log_entries):\n",
    "        \"\"\"\n",
    "        Verify integrity of log chain\n",
    "        Returns: (is_valid, first_invalid_index)\n",
    "        \"\"\"\n",
    "        expected_hash = \"0\" * 64\n",
    "        \n",
    "        for i, entry in enumerate(log_entries):\n",
    "            reconstructed = f\"{entry['previous_hash']}|{entry['timestamp']}|{entry['message']}\"\n",
    "            calculated_hash = hmac.new(\n",
    "                self.secret_key.encode(),\n",
    "                reconstructed.encode(),\n",
    "                hashlib.sha256\n",
    "            ).hexdigest()\n",
    "            \n",
    "            if calculated_hash != entry['entry_hash']:\n",
    "                return False, i\n",
    "            \n",
    "            expected_hash = entry['entry_hash']\n",
    "        \n",
    "        return True, -1\n",
    "```\n",
    "\n",
    "### 7.1.4 Logging in Cloud-Native Environments\n",
    "Cloud services generate their own logs that must be aggregated:\n",
    "\n",
    "*   **AWS:** CloudTrail (API calls), VPC Flow Logs (network), S3 Access Logs.\n",
    "*   **Azure:** Activity Logs, Diagnostic Logs, NSG Flow Logs.\n",
    "*   **GCP:** Cloud Audit Logs, VPC Flow Logs.\n",
    "\n",
    "**Centralized Logging Architecture:**\n",
    "```\n",
    "Application Logs \u2192 Fluentd/Fluent Bit \u2192 Kafka \u2192 Logstash \u2192 Elasticsearch/ClickHouse \u2192 Kibana/Grafana\n",
    "CloudWatch Logs \u2192 S3 \u2192 Lambda Processing \u2192 SIEM\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 7.2 SIEM Fundamentals: Aggregation, Correlation, and Alerting\n",
    "\n",
    "A **Security Information and Event Management (SIEM)** system is the central nervous system of detection, aggregating logs from across the enterprise to identify patterns indicative of attacks.\n",
    "\n",
    "### 7.2.1 SIEM Architecture\n",
    "1.  **Collection:** Log forwarders (agents) on endpoints, network taps, cloud APIs.\n",
    "2.  **Normalization:** Parsing diverse formats into a common schema (Common Event Format - CEF, or JSON).\n",
    "3.  **Enrichment:** Adding context (GeoIP, threat intelligence, asset criticality).\n",
    "4.  **Correlation:** Matching events across time and systems (e.g., \"5 failed logins followed by a successful login from a new location\").\n",
    "5.  **Storage:** Hot storage (recent, fast queries) and cold storage (archival, compliance).\n",
    "6.  **Analysis:** Dashboards, alerting, and investigation workflows.\n",
    "\n",
    "### 7.2.2 Correlation Rules and Use Cases\n",
    "**Example Correlation Rules:**\n",
    "\n",
    "**Brute Force Detection:**\n",
    "```\n",
    "Event: Authentication Failure\n",
    "Threshold: 5 failures within 5 minutes from same IP\n",
    "Action: Alert SOC, block IP at firewall\n",
    "```\n",
    "\n",
    "**Lateral Movement Detection:**\n",
    "```\n",
    "Event Sequence:\n",
    "1. Login to Workstation A (User: Alice)\n",
    "2. Within 1 hour: SMB connection from Workstation A to Server B (User: Alice)\n",
    "3. Server B never accessed by Alice before\n",
    "Action: Alert potential lateral movement\n",
    "```\n",
    "\n",
    "**Impossible Travel:**\n",
    "```\n",
    "Event: Login from New York at 09:00 EST\n",
    "Event: Login from Tokyo at 09:30 EST (30 minutes later)\n",
    "Physics: Impossible to travel 6,700 miles in 30 minutes\n",
    "Action: Alert potential credential theft or VPN bypass\n",
    "```\n",
    "\n",
    "**Implementation: Sigma Rules (Generic SIEM Signatures)**\n",
    "Sigma is a generic signature format for SIEM systems (Splunk, Elastic, etc.).\n",
    "\n",
    "```yaml\n",
    "# Detects suspicious PowerShell execution (often used in malware)\n",
    "title: Suspicious PowerShell Execution\n",
    "status: stable\n",
    "description: Detects suspicious PowerShell execution with encoded commands or bypass flags\n",
    "logsource:\n",
    "    category: process_creation\n",
    "    product: windows\n",
    "detection:\n",
    "    selection:\n",
    "        CommandLine|contains:\n",
    "            - '-enc '\n",
    "            - '-encodedcommand '\n",
    "            - 'bypass'\n",
    "            - '-nop'\n",
    "            - 'hidden'\n",
    "        Image|endswith: '\\powershell.exe'\n",
    "    condition: selection\n",
    "falsepositives:\n",
    "    - Administrative scripts\n",
    "level: high\n",
    "tags:\n",
    "    - attack.execution\n",
    "    - attack.t1059.001  # MITRE ATT&CK: PowerShell\n",
    "```\n",
    "\n",
    "### 7.2.3 Alert Fatigue and Tuning\n",
    "The greatest enemy of detection is **alert fatigue**\u2014too many false positives causing analysts to ignore real threats.\n",
    "\n",
    "**Best Practices:**\n",
    "*   **Baseline:** Establish normal behavior before alerting on anomalies.\n",
    "*   **Severity:** Only \"Critical\" and \"High\" alerts wake people up at night.\n",
    "*   **Automation:** Low-risk alerts trigger automated responses (blocking IPs), not human investigation.\n",
    "*   **Threat-Centric:** Tune rules to your threat model (financial sector cares about wire fraud, healthcare about PHI access).\n",
    "\n",
    "---\n",
    "\n",
    "## 7.3 Application Security Monitoring (ASM) and RASP\n",
    "\n",
    "While network and host monitoring are essential, applications require specialized monitoring that understands code-level behavior.\n",
    "\n",
    "### 7.3.1 Application Security Monitoring (ASM)\n",
    "ASM focuses on the application layer:\n",
    "*   **Business Logic Abuse:** Detecting abuse of legitimate features (coupon fraud, scraping, fake account creation).\n",
    "*   **API Abuse:** Unusual patterns in API calls (sequencing attacks, parameter tampering).\n",
    "*   **User Behavior:** Session hijacking indicators (sudden change in user agent, location, or behavior patterns).\n",
    "\n",
    "### 7.3.2 Runtime Application Self-Protection (RASP)\n",
    "RASP embeds security controls within the application runtime, intercepting calls to the OS, databases, and file systems to detect and block attacks in real-time.\n",
    "\n",
    "**How RASP Works:**\n",
    "1.  Instruments the runtime (JVM, .NET CLR, Python interpreter, or Node.js).\n",
    "2.  Intercepts all I/O operations (database queries, file reads, network connections).\n",
    "3.  Applies security policies (e.g., \"this query looks like SQL injection\").\n",
    "4.  Blocks malicious requests and logs the attempt.\n",
    "\n",
    "**Implementation: Conceptual RASP Hook (Python Monkey-Patching Example)**\n",
    "```python\n",
    "import functools\n",
    "import re\n",
    "\n",
    "class RASPMonitor:\n",
    "    \"\"\"\n",
    "    Conceptual RASP implementation using function wrapping\n",
    "    Real RASP uses runtime instrumentation (e.g., Java agents, Python sys.settrace)\n",
    "    \"\"\"\n",
    "    \n",
    "    SQLI_PATTERNS = [\n",
    "        r\"(\\%27)|(\\')|(\\-\\-)|(\\%23)|(#)\",  # Basic SQL meta-characters\n",
    "        r\"((\\%3D)|(=))[^\\n]*((\\%27)|(\\')|(\\-\\-)|(\\%3B)|(;))\",  # Equals followed by quotes\n",
    "        r\"\\w*((\\%27)|(\\'))((\\%6F)|o|(\\%4F))((\\%72)|r|(\\%52))\",  # 'or' variations\n",
    "    ]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.blocked_attempts = []\n",
    "    \n",
    "    def protect_db_cursor(self, cursor_class):\n",
    "        \"\"\"\n",
    "        Wrap database cursor execute method to detect SQL injection\n",
    "        \"\"\"\n",
    "        original_execute = cursor_class.execute\n",
    "        \n",
    "        @functools.wraps(original_execute)\n",
    "        def secure_execute(self_cursor, query, parameters=None):\n",
    "            # Check for SQL injection in raw query\n",
    "            if isinstance(query, str):\n",
    "                for pattern in RASPMonitor.SQLI_PATTERNS:\n",
    "                    if re.search(pattern, query, re.IGNORECASE):\n",
    "                        self._alert_and_block(\"SQL_INJECTION_DETECTED\", query)\n",
    "                        raise SecurityException(\"Malicious query blocked by RASP\")\n",
    "            \n",
    "            # Check for second-order injection (parameters)\n",
    "            if parameters:\n",
    "                param_str = str(parameters)\n",
    "                for pattern in RASPMonitor.SQLI_PATTERNS:\n",
    "                    if re.search(pattern, param_str, re.IGNORECASE):\n",
    "                        self._alert_and_block(\"SQLI_IN_PARAMETER\", param_str)\n",
    "                        raise SecurityException(\"Malicious parameters blocked\")\n",
    "            \n",
    "            return original_execute(self_cursor, query, parameters)\n",
    "        \n",
    "        cursor_class.execute = secure_execute\n",
    "        return cursor_class\n",
    "    \n",
    "    def _alert_and_block(self, attack_type, payload):\n",
    "        \"\"\"\n",
    "        Log and alert on blocked attack\n",
    "        \"\"\"\n",
    "        alert = {\n",
    "            \"timestamp\": datetime.utcnow().isoformat(),\n",
    "            \"severity\": \"CRITICAL\",\n",
    "            \"attack_type\": attack_type,\n",
    "            \"payload_hash\": hashlib.sha256(payload.encode()).hexdigest(),\n",
    "            \"action\": \"BLOCKED\",\n",
    "            \"stack_trace\": traceback.format_exc()\n",
    "        }\n",
    "        \n",
    "        # Send to SIEM immediately\n",
    "        siem_client.send_alert(alert)\n",
    "        \n",
    "        # Increment metrics for monitoring\n",
    "        metrics.increment(f\"rasp.blocked.{attack_type}\")\n",
    "\n",
    "# Usage: Initialize RASP protection\n",
    "# RASPMonitor().protect_db_cursor(psycopg2.extensions.cursor)\n",
    "```\n",
    "\n",
    "**RASP vs WAF:**\n",
    "*   **WAF (Web Application Firewall):** Network perimeter, inspects HTTP traffic. Can be bypassed with encoding.\n",
    "*   **RASP:** Inside the application, sees decoded, processed data. Cannot be bypassed by network tricks, but consumes application resources.\n",
    "\n",
    "### 7.3.3 Interactive Application Security Testing (IAST)\n",
    "IAST combines SAST (static) and DAST (dynamic) by instrumenting the application during testing to detect vulnerabilities in real-time with full code context (line numbers, data flow).\n",
    "\n",
    "---\n",
    "\n",
    "## 7.4 Threat Intelligence Feeds: Integrating External Context\n",
    "\n",
    "Threat intelligence provides context about external threats\u2014who is attacking, what tools they use, and what infrastructure they command.\n",
    "\n",
    "### 7.4.1 Types of Threat Intelligence\n",
    "**Tactical:** IOCs (Indicators of Compromise) - IPs, domains, file hashes.\n",
    "**Operational:** TTPs (Tactics, Techniques, and Procedures) - how attackers operate.\n",
    "**Strategic:** High-level trends (ransomware group activities, nation-state APT campaigns).\n",
    "\n",
    "### 7.4.2 IOCs and Enrichment\n",
    "**IOC Types:**\n",
    "*   **Network:** IP addresses, C2 domains, URLs.\n",
    "*   **Host:** File hashes (MD5, SHA256), registry keys, mutex names.\n",
    "*   **Email:** Sender addresses, subject lines, attachment hashes.\n",
    "\n",
    "**Implementation: Threat Intelligence Integration**\n",
    "```python\n",
    "class ThreatIntelEnricher:\n",
    "    def __init__(self):\n",
    "        # Connect to threat intel feeds (MISP, VirusTotal, AlienVault OTX)\n",
    "        self.misp_client = MISPClient(api_key=os.environ['MISP_KEY'])\n",
    "        self.vt_client = VirusTotalClient(api_key=os.environ['VT_KEY'])\n",
    "    \n",
    "    def check_ip_reputation(self, ip_address):\n",
    "        \"\"\"\n",
    "        Check if IP is known malicious\n",
    "        \"\"\"\n",
    "        reputation = {\n",
    "            \"ip\": ip_address,\n",
    "            \"is_malicious\": False,\n",
    "            \"sources\": [],\n",
    "            \"confidence\": 0\n",
    "        }\n",
    "        \n",
    "        # Check MISP (Malware Information Sharing Platform)\n",
    "        misp_result = self.misp_client.search_ip(ip_address)\n",
    "        if misp_result:\n",
    "            reputation[\"is_malicious\"] = True\n",
    "            reputation[\"sources\"].append(\"MISP\")\n",
    "            reputation[\"confidence\"] = max(reputation[\"confidence\"], misp_result['confidence'])\n",
    "        \n",
    "        # Check VirusTotal\n",
    "        vt_result = self.vt_client.get_ip_report(ip_address)\n",
    "        if vt_result['malicious_votes'] > 5:\n",
    "            reputation[\"is_malicious\"] = True\n",
    "            reputation[\"sources\"].append(\"VirusTotal\")\n",
    "            reputation[\"confidence\"] = max(\n",
    "                reputation[\"confidence\"], \n",
    "                vt_result['malicious_votes'] / vt_result['total_votes']\n",
    "            )\n",
    "        \n",
    "        return reputation\n",
    "    \n",
    "    def enrich_log_entry(self, log_entry):\n",
    "        \"\"\"\n",
    "        Enrich log entry with threat intelligence\n",
    "        \"\"\"\n",
    "        if 'ip_address' in log_entry:\n",
    "            ip_rep = self.check_ip_reputation(log_entry['ip_address'])\n",
    "            log_entry['threat_intel'] = ip_rep\n",
    "            \n",
    "            # Auto-escalate if malicious\n",
    "            if ip_rep['is_malicious'] and log_entry['result'] == 'SUCCESS':\n",
    "                log_entry['alert_level'] = 'CRITICAL'\n",
    "                log_entry['alert_reason'] = 'Login from known malicious IP'\n",
    "        \n",
    "        return log_entry\n",
    "```\n",
    "\n",
    "### 7.4.3 MITRE ATT&CK Mapping\n",
    "Map detection rules to **MITRE ATT&CK** techniques to identify coverage gaps.\n",
    "\n",
    "**Example Mapping:**\n",
    "*   **Detection:** \"PowerShell with encoded command\"\n",
    "*   **ATT&CK:** T1059.001 (Command and Scripting Interpreter: PowerShell)\n",
    "*   **Tactic:** Execution\n",
    "\n",
    "**Benefits:**\n",
    "*   Identify which techniques you can detect vs. which you cannot.\n",
    "*   Report to management: \"We detect 85% of Initial Access techniques but only 40% of Persistence techniques.\"\n",
    "\n",
    "---\n",
    "\n",
    "## 7.5 Anomaly Detection: Network, User, and Entity Behavior Analytics (UEBA)\n",
    "\n",
    "Signature-based detection (known bad patterns) cannot catch novel attacks. **Anomaly detection** (behavioral analysis) establishes baselines of normal activity and flags deviations.\n",
    "\n",
    "### 7.5.1 UEBA Concepts\n",
    "**UEBA** analyzes:\n",
    "*   **Users:** What resources do they access? When? From where?\n",
    "*   **Entities:** Servers, databases, applications\u2014what do they connect to?\n",
    "*   **Peers:** Is this user behaving like their peer group?\n",
    "\n",
    "**Anomaly Types:**\n",
    "*   **Time-based:** Activity at unusual hours (3 AM login for 9-5 worker).\n",
    "*   **Volume-based:** Downloading 100x normal data volume.\n",
    "*   **Pattern-based:** Accessing resources never touched before (new department files).\n",
    "*   **Graph-based:** Unusual connection patterns (hub-and-spoke lateral movement).\n",
    "\n",
    "### 7.5.2 Statistical Anomaly Detection\n",
    "Using statistical methods to identify outliers.\n",
    "\n",
    "**Implementation: Simple Statistical Anomaly Detector**\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "\n",
    "class BehavioralAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Store baselines: user -> metric -> historical values\n",
    "        self.baselines = defaultdict(lambda: defaultdict(list))\n",
    "        self.window_size = 30  # 30 days of history\n",
    "    \n",
    "    def update_baseline(self, user_id, metric, value):\n",
    "        \"\"\"\n",
    "        Update user's behavioral baseline\n",
    "        \"\"\"\n",
    "        history = self.baselines[user_id][metric]\n",
    "        history.append(value)\n",
    "        \n",
    "        # Keep only recent history (sliding window)\n",
    "        if len(history) > self.window_size:\n",
    "            history.pop(0)\n",
    "    \n",
    "    def is_anomalous(self, user_id, metric, current_value, threshold=3.0):\n",
    "        \"\"\"\n",
    "        Detect anomaly using Z-score (standard deviations from mean)\n",
    "        threshold=3.0 means 99.7% confidence interval\n",
    "        \"\"\"\n",
    "        history = self.baselines[user_id][metric]\n",
    "        \n",
    "        if len(history) < 5:  # Insufficient data\n",
    "            return False, 0\n",
    "        \n",
    "        mean = np.mean(history)\n",
    "        std = np.std(history)\n",
    "        \n",
    "        if std == 0:  # No variation in history\n",
    "            return current_value != mean, 0\n",
    "        \n",
    "        z_score = (current_value - mean) / std\n",
    "        \n",
    "        # Also check for sudden drop (possible account abandonment)\n",
    "        is_anomaly = abs(z_score) > threshold\n",
    "        \n",
    "        return is_anomaly, z_score\n",
    "    \n",
    "    def detect_data_exfiltration(self, user_id, bytes_transferred, files_accessed):\n",
    "        \"\"\"\n",
    "        Specific detection for potential data exfiltration\n",
    "        \"\"\"\n",
    "        alerts = []\n",
    "        \n",
    "        # Check volume anomaly\n",
    "        volume_anomaly, volume_z = self.is_anomalous(\n",
    "            user_id, 'daily_bytes', bytes_transferred, threshold=3\n",
    "        )\n",
    "        \n",
    "        if volume_anomaly and bytes_transferred > 100000000:  # >100MB\n",
    "            alerts.append({\n",
    "                'type': 'VOLUME_ANOMALY',\n",
    "                'severity': 'HIGH',\n",
    "                'z_score': volume_z,\n",
    "                'details': f\"User transferred {bytes_transferred} bytes (normal: {np.mean(self.baselines[user_id]['daily_bytes'])})\"\n",
    "            })\n",
    "        \n",
    "        # Check file access diversity (accessing many different files)\n",
    "        file_anomaly, file_z = self.is_anomalous(\n",
    "            user_id, 'files_accessed_count', files_accessed, threshold=2.5\n",
    "        )\n",
    "        \n",
    "        if file_anomaly:\n",
    "            alerts.append({\n",
    "                'type': 'SCOPE_ANOMALY',\n",
    "                'severity': 'MEDIUM',\n",
    "                'details': f\"Accessed {files_accessed} unique files (unusual breadth)\"\n",
    "            })\n",
    "        \n",
    "        # Check for access outside business hours (time anomaly)\n",
    "        hour = datetime.now().hour\n",
    "        if hour < 7 or hour > 19:  # Before 7 AM or after 7 PM\n",
    "            if not self._is_oncall(user_id):  # Check if scheduled\n",
    "                alerts.append({\n",
    "                    'type': 'TIME_ANOMALY',\n",
    "                    'severity': 'MEDIUM',\n",
    "                    'details': f\"Activity at {hour}:00 (outside normal hours)\"\n",
    "                })\n",
    "        \n",
    "        return alerts\n",
    "    \n",
    "    def _is_oncall(self, user_id):\n",
    "        # Integration with PagerDuty/Opsgenie API\n",
    "        return False  # Simplified\n",
    "\n",
    "# Usage\n",
    "# analyzer = BehavioralAnalyzer()\n",
    "# analyzer.update_baseline('user123', 'daily_bytes', 5000000)  # 5MB normal\n",
    "# \n",
    "# # Later, check current activity\n",
    "# is_anomaly, z = analyzer.is_anomalous('user123', 'daily_bytes', 500000000)  # 500MB\n",
    "# if is_anomaly:\n",
    "#     alert_security_team()\n",
    "```\n",
    "\n",
    "### 7.5.3 Machine Learning for Anomaly Detection\n",
    "Advanced UEBA uses ML:\n",
    "*   **Clustering:** Grouping similar users; flagging outliers.\n",
    "*   **Graph Analysis:** Detecting unusual connection paths (lateral movement).\n",
    "*   **Deep Learning:** Autoencoders that learn complex normal patterns and flag reconstruction errors.\n",
    "\n",
    "**Challenges:**\n",
    "*   **False Positives:** Novel but legitimate behavior (new project) triggers alerts.\n",
    "*   **Adversarial Adaptation:** Attackers learn to mimic normal behavior (\"low and slow\").\n",
    "*   **Explainability:** ML models must explain why something is anomalous for SOC analysts to act.\n",
    "\n",
    "---\n",
    "\n",
    "### Chapter Summary\n",
    "\n",
    "In this chapter, we implemented the **DETECT** function, establishing comprehensive visibility into our security posture. We implemented **structured security logging** with tamper-evident hash chains, ensuring forensic integrity while protecting user privacy through pseudonymization. We explored **SIEM architecture**, understanding how correlation rules transform isolated events into actionable intelligence, while managing the critical challenge of alert fatigue through risk-based tuning. We examined **Application Security Monitoring** and **RASP**, embedding detection capabilities directly within applications to block attacks that bypass perimeter defenses. We integrated **Threat Intelligence** to contextualize internal events with external adversary knowledge, mapping our detections to the **MITRE ATT&CK** framework to identify coverage gaps. Finally, we implemented **UEBA** statistical anomaly detection to identify compromised accounts and insider threats through behavioral baselines.\n",
    "\n",
    "Detection alerts us to the presence of adversaries, but detection alone cannot contain damage. When the alarm sounds\u2014when the RASP blocks an SQL injection attempt, when the SIEM correlates a lateral movement pattern, when the UEBA flags an impossible travel scenario\u2014we must act. We must contain the threat, eradicate the presence, and restore services. We transition from observation to intervention, from the SOC analyst's dashboard to the incident responder's playbook.\n",
    "\n",
    "**Next Up: Chapter 8: RESPOND (RS) \u2013 Incident Management**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='6. protect_pr_safeguards_implementation.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='8. respond_rs_incident_management.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}