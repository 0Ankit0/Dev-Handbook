{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 15: DevSecOps & Automation**\n",
    "\n",
    "## Introduction: The Velocity-Security Convergence\n",
    "\n",
    "In Chapter 14, we secured artificial intelligence systemsâ€”implementing differential privacy, federated learning, and agentic guardrails. Yet these controls remain theoretical until embedded within the software delivery pipeline. Manual security reviews cannot match the velocity of modern development, where AI models deploy multiple times daily and infrastructure scales elastically in response to traffic.\n",
    "\n",
    "**DevSecOps** represents the philosophical and technical integration of security practices within the DevOps lifecycle. It is not merely \"DevOps plus security tools\" but a cultural transformation where security becomes a shared responsibility across development, operations, and security teams. The goal is **\"shifting security left\"**â€”detecting vulnerabilities at the design and coding phases rather than in productionâ€”while simultaneously **\"shifting right\"** through runtime protection and continuous monitoring.\n",
    "\n",
    "This chapter operationalizes the security controls from previous chapters. You will learn to automate the scanning of container images for CVEs, enforce security policies through code, implement **SLSA (Supply Chain Levels for Software Artifacts)** compliance for artifact provenance, and orchestrate incident response through **SOAR (Security Orchestration, Automation, and Response)** platforms.\n",
    "\n",
    "By the end, you will architect a CI/CD pipeline where every commit triggers security validation, every artifact is cryptographically signed, and every deployment includes runtime protectionâ€”achieving both velocity and resilience.\n",
    "\n",
    "---\n",
    "\n",
    "## 15.1 Integrating Security into CI/CD Pipelines\n",
    "\n",
    "Continuous Integration/Continuous Deployment (CI/CD) pipelines are the arteries of modern software delivery. Integrating security into these pipelines requires balancing speed with rigorâ€”blocking critical vulnerabilities while avoiding \"alert fatigue\" that leads developers to bypass controls.\n",
    "\n",
    "### Pipeline Architecture and Security Gates\n",
    "\n",
    "A secure CI/CD pipeline implements multiple verification stages, failing fast when possible to minimize compute waste.\n",
    "\n",
    "**Secure Pipeline Stages:**\n",
    "\n",
    "1. **Pre-commit**: Git hooks, secrets scanning, linting\n",
    "2. **Build**: SAST (Static Application Security Testing), dependency scanning, license compliance\n",
    "3. **Test**: Unit tests with security assertions, IAST (Interactive Application Security Testing)\n",
    "4. **Package**: Container image scanning, artifact signing, SBOM generation\n",
    "5. **Staging**: DAST (Dynamic Application Security Testing), infrastructure scanning\n",
    "6. **Deploy**: Policy validation, runtime configuration checks\n",
    "7. **Production**: Continuous monitoring, drift detection\n",
    "\n",
    "### GitHub Actions Implementation\n",
    "\n",
    "GitHub Actions provides native CI/CD with extensive security tooling integration.\n",
    "\n",
    "**Comprehensive Security Workflow:**\n",
    "```yaml\n",
    "# .github/workflows/secure-pipeline.yml\n",
    "name: Secure CI/CD Pipeline\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [main, develop]\n",
    "  pull_request:\n",
    "    branches: [main]\n",
    "\n",
    "env:\n",
    "  REGISTRY: ghcr.io\n",
    "  IMAGE_NAME: ${{ github.repository }}\n",
    "  # Fail pipeline on critical vulnerabilities\n",
    "  SEVERITY_THRESHOLD: critical\n",
    "\n",
    "jobs:\n",
    "  # Stage 1: Secrets and Credential Scanning\n",
    "  secrets-scan:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "        with:\n",
    "          fetch-depth: 0  # Full history for secret scanning\n",
    "      \n",
    "      - name: Detect Secrets with Gitleaks\n",
    "        uses: gitleaks/gitleaks-action@v2\n",
    "        env:\n",
    "          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "          GITLEAKS_LICENSE: ${{ secrets.GITLEAKS_LICENSE }}\n",
    "      \n",
    "      - name: Scan for Hardcoded Credentials\n",
    "        uses: trufflesecurity/trufflehog@main\n",
    "        with:\n",
    "          path: ./\n",
    "          base: main\n",
    "          head: HEAD\n",
    "          extra_args: --debug --only-verified\n",
    "\n",
    "  # Stage 2: Static Analysis (SAST)\n",
    "  sast-analysis:\n",
    "    runs-on: ubuntu-latest\n",
    "    needs: secrets-scan\n",
    "    strategy:\n",
    "      matrix:\n",
    "        language: ['javascript', 'python', 'go']\n",
    "    \n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "      \n",
    "      - name: Initialize CodeQL\n",
    "        uses: github/codeql-action/init@v3\n",
    "        with:\n",
    "          languages: ${{ matrix.language }}\n",
    "          queries: security-extended,security-and-quality\n",
    "      \n",
    "      - name: Autobuild\n",
    "        uses: github/codeql-action/autobuild@v3\n",
    "      \n",
    "      - name: Perform CodeQL Analysis\n",
    "        uses: github/codeql-action/analyze@v3\n",
    "        with:\n",
    "          category: \"/language:${{matrix.language}}\"\n",
    "      \n",
    "      # Additional SonarCloud for code quality and security hotspots\n",
    "      - name: SonarCloud Scan\n",
    "        uses: SonarSource/sonarcloud-github-action@master\n",
    "        env:\n",
    "          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n",
    "\n",
    "  # Stage 3: Dependency and Supply Chain Security\n",
    "  dependency-check:\n",
    "    runs-on: ubuntu-latest\n",
    "    needs: secrets-scan\n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "      \n",
    "      - name: Setup Node.js\n",
    "        uses: actions/setup-node@v4\n",
    "        with:\n",
    "          node-version: '20'\n",
    "          cache: 'npm'\n",
    "      \n",
    "      - name: Install dependencies\n",
    "        run: npm ci\n",
    "      \n",
    "      # NPM Audit with custom config\n",
    "      - name: NPM Audit\n",
    "        run: |\n",
    "          npm audit --audit-level=moderate --production\n",
    "          if [ $? -ne 0 ]; then\n",
    "            echo \"::error::Vulnerabilities found in dependencies\"\n",
    "            exit 1\n",
    "          fi\n",
    "      \n",
    "      # Snyk for comprehensive SCA\n",
    "      - name: Snyk Security Scan\n",
    "        uses: snyk/actions/node@master\n",
    "        continue-on-error: true  # Don't block, just report\n",
    "        env:\n",
    "          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}\n",
    "        with:\n",
    "          args: --severity-threshold=high --sarif-file-output=snyk.sarif\n",
    "      \n",
    "      - name: Upload Snyk results to GitHub Security Tab\n",
    "        uses: github/codeql-action/upload-sarif@v2\n",
    "        if: always()\n",
    "        with:\n",
    "          sarif_file: snyk.sarif\n",
    "      \n",
    "      # Generate and store SBOM\n",
    "      - name: Generate SBOM\n",
    "        uses: anchore/sbom-action@v0\n",
    "        with:\n",
    "          format: spdx-json\n",
    "          output-file: sbom.spdx.json\n",
    "      \n",
    "      - name: Upload SBOM\n",
    "        uses: actions/upload-artifact@v3\n",
    "        with:\n",
    "          name: sbom\n",
    "          path: sbom.spdx.json\n",
    "\n",
    "  # Stage 4: Build and Container Security\n",
    "  build-and-scan:\n",
    "    runs-on: ubuntu-latest\n",
    "    needs: [sast-analysis, dependency-check]\n",
    "    permissions:\n",
    "      contents: read\n",
    "      packages: write\n",
    "      id-token: write  # For Cosign signing\n",
    "    \n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "      \n",
    "      - name: Set up Docker Buildx\n",
    "        uses: docker/setup-buildx-action@v3\n",
    "      \n",
    "      - name: Log in to Container Registry\n",
    "        uses: docker/login-action@v3\n",
    "        with:\n",
    "          registry: ${{ env.REGISTRY }}\n",
    "          username: ${{ github.actor }}\n",
    "          password: ${{ secrets.GITHUB_TOKEN }}\n",
    "      \n",
    "      # Build image with security scanning\n",
    "      - name: Build and export to Docker\n",
    "        uses: docker/build-push-action@v5\n",
    "        with:\n",
    "          context: .\n",
    "          load: true\n",
    "          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\n",
    "      \n",
    "      # Scan with Trivy before pushing\n",
    "      - name: Scan image with Trivy\n",
    "        uses: aquasecurity/trivy-action@master\n",
    "        with:\n",
    "          image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\n",
    "          format: 'sarif'\n",
    "          output: 'trivy-results.sarif'\n",
    "          severity: ${{ env.SEVERITY_THRESHOLD }}\n",
    "          exit-code: '1'  # Fail build on critical CVEs\n",
    "      \n",
    "      - name: Upload Trivy scan results\n",
    "        uses: github/codeql-action/upload-sarif@v2\n",
    "        if: always()\n",
    "        with:\n",
    "          sarif_file: 'trivy-results.sarif'\n",
    "      \n",
    "      # Push only if scan passes\n",
    "      - name: Push image\n",
    "        uses: docker/build-push-action@v5\n",
    "        with:\n",
    "          context: .\n",
    "          push: true\n",
    "          tags: |\n",
    "            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\n",
    "            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest\n",
    "      \n",
    "      # Sign image with Cosign (keyless)\n",
    "      - name: Install Cosign\n",
    "        uses: sigstore/cosign-installer@v3\n",
    "      \n",
    "      - name: Sign image\n",
    "        run: |\n",
    "          cosign sign --yes \\\n",
    "            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\n",
    "\n",
    "  # Stage 5: Infrastructure as Code Scanning\n",
    "  iac-security:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "      \n",
    "      - name: Run Checkov\n",
    "        uses: bridgecrewio/checkov-action@master\n",
    "        with:\n",
    "          directory: .\n",
    "          framework: terraform,dockerfile,kubernetes\n",
    "          output_format: sarif\n",
    "          output_file_path: reports/checkov.sarif\n",
    "      \n",
    "      - name: Upload Checkov results\n",
    "        uses: github/codeql-action/upload-sarif@v2\n",
    "        if: always()\n",
    "        with:\n",
    "          sarif_file: reports/checkov.sarif\n",
    "      \n",
    "      # Terraform specific scanning\n",
    "      - name: Terraform Security Scan\n",
    "        uses: aquasecurity/tfsec-action@v1.0.0\n",
    "        with:\n",
    "          soft_fail: true\n",
    "\n",
    "  # Stage 6: Dynamic Testing (DAST) - Post-deployment to staging\n",
    "  dast:\n",
    "    runs-on: ubuntu-latest\n",
    "    needs: deploy-staging\n",
    "    if: github.ref == 'refs/heads/main'\n",
    "    steps:\n",
    "      - name: ZAP Full Scan\n",
    "        uses: zaproxy/action-full-scan@v0.9.0\n",
    "        with:\n",
    "          target: 'https://staging.example.com'\n",
    "          rules_file_name: '.zap/rules.tsv'\n",
    "          cmd_options: '-a'\n",
    "      \n",
    "      - name: Upload ZAP results\n",
    "        uses: actions/upload-artifact@v3\n",
    "        with:\n",
    "          name: zap-report\n",
    "          path: report_*.html\n",
    "```\n",
    "\n",
    "### GitLab CI Implementation\n",
    "\n",
    "For organizations using GitLab, the pipeline structure follows similar principles with different syntax:\n",
    "\n",
    "```yaml\n",
    "# .gitlab-ci.yml\n",
    "stages:\n",
    "  - validate\n",
    "  - build\n",
    "  - test\n",
    "  - security\n",
    "  - deploy\n",
    "\n",
    "variables:\n",
    "  DOCKER_DRIVER: overlay2\n",
    "  DOCKER_TLS_CERTDIR: \"/certs\"\n",
    "  SAST_ANALYZER_IMAGE_TAG: \"latest\"\n",
    "  SAST_EXCLUDED_PATHS: \"spec, test, tests, tmp\"\n",
    "\n",
    "# Template for security scanning\n",
    ".secrets_scan:\n",
    "  stage: validate\n",
    "  image: alpine/git\n",
    "  script:\n",
    "    - apk add --no-cache gitleaks\n",
    "    - gitleaks detect --source . --verbose --redact\n",
    "  rules:\n",
    "    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n",
    "    - if: $CI_COMMIT_BRANCH == \"main\"\n",
    "\n",
    "# SAST using GitLab's built-in analyzer\n",
    "sast:\n",
    "  stage: security\n",
    "  image: returntocorp/semgrep\n",
    "  script:\n",
    "    - semgrep --config=auto --json --output=semgrep-report.json .\n",
    "  artifacts:\n",
    "    reports:\n",
    "      sast: semgrep-report.json\n",
    "    paths:\n",
    "      - semgrep-report.json\n",
    "  rules:\n",
    "    - if: $CI_COMMIT_BRANCH\n",
    "\n",
    "# Container Scanning with Trivy\n",
    "container_scanning:\n",
    "  stage: security\n",
    "  image: docker:stable\n",
    "  services:\n",
    "    - docker:dind\n",
    "  variables:\n",
    "    IMAGE: \"$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\"\n",
    "  script:\n",
    "    - docker pull $IMAGE\n",
    "    - docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \n",
    "      aquasec/trivy image --exit-code 1 --severity HIGH,CRITICAL $IMAGE\n",
    "  allow_failure: false\n",
    "  rules:\n",
    "    - if: $CI_COMMIT_BRANCH == \"main\"\n",
    "\n",
    "# Dependency Checking\n",
    "dependency_scanning:\n",
    "  stage: security\n",
    "  image: node:18-alpine\n",
    "  script:\n",
    "    - npm audit --audit-level moderate\n",
    "    - npx audit-ci --moderate\n",
    "  artifacts:\n",
    "    reports:\n",
    "      dependency_scanning: dependency-scan-report.json\n",
    "\n",
    "# DAST using OWASP ZAP\n",
    "dast:\n",
    "  stage: security\n",
    "  image: owasp/zap2docker-stable\n",
    "  script:\n",
    "    - mkdir /zap/wrk/\n",
    "    - zap-baseline.py -t https://staging.example.com -g gen.conf -r testreport.html\n",
    "  artifacts:\n",
    "    when: always\n",
    "    paths:\n",
    "      - /zap/wrk/testreport.html\n",
    "  rules:\n",
    "    - if: $CI_COMMIT_BRANCH == \"main\"\n",
    "```\n",
    "\n",
    "### Jenkins Pipeline (Enterprise Environments)\n",
    "\n",
    "For organizations maintaining Jenkins infrastructure:\n",
    "\n",
    "```groovy\n",
    "// Jenkinsfile\n",
    "pipeline {\n",
    "    agent any\n",
    "    \n",
    "    environment {\n",
    "        DOCKER_REGISTRY = 'registry.company.com'\n",
    "        IMAGE_NAME = 'secure-app'\n",
    "        SNYK_TOKEN = credentials('snyk-api-token')\n",
    "    }\n",
    "    \n",
    "    stages {\n",
    "        stage('Checkout') {\n",
    "            steps {\n",
    "                checkout scm\n",
    "                sh 'git clean -fdx'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stage('Pre-commit Checks') {\n",
    "            parallel {\n",
    "                stage('Secrets Scan') {\n",
    "                    steps {\n",
    "                        sh '''\n",
    "                            docker run --rm -v $(pwd):/code \\\n",
    "                            zricethezav/gitleaks:latest detect \\\n",
    "                            --source /code --verbose --redact\n",
    "                        '''\n",
    "                    }\n",
    "                }\n",
    "                stage('Linting') {\n",
    "                    steps {\n",
    "                        sh 'npm run lint'\n",
    "                        sh 'npm run security-lint'  // ESLint security plugin\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stage('SAST') {\n",
    "            steps {\n",
    "                script {\n",
    "                    // SonarQube analysis\n",
    "                    withSonarQubeEnv('SonarQube') {\n",
    "                        sh 'npm run sonar'\n",
    "                    }\n",
    "                    \n",
    "                    // Wait for SonarQube quality gate\n",
    "                    timeout(time: 10, unit: 'MINUTES') {\n",
    "                        waitForQualityGate abortPipeline: true\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stage('Dependency Check') {\n",
    "            steps {\n",
    "                sh 'npm audit --production --audit-level=moderate'\n",
    "                \n",
    "                // OWASP Dependency-Check\n",
    "                dependencyCheck additionalArguments: '''\n",
    "                    -o ./dependency-check-report\n",
    "                    -s ./package.json\n",
    "                    -f XML\n",
    "                    --enableExperimental''', \n",
    "                    odcInstallation: 'OWASP-Dependency-Check'\n",
    "                \n",
    "                dependencyCheckPublisher pattern: 'dependency-check-report/dependency-check-report.xml'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stage('Build') {\n",
    "            steps {\n",
    "                script {\n",
    "                    def image = docker.build(\"${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER}\")\n",
    "                    \n",
    "                    // Scan before pushing\n",
    "                    sh \"\"\"\n",
    "                        docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \\\\\n",
    "                        aquasec/trivy image --exit-code 1 --severity CRITICAL \\\\\n",
    "                        ${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER}\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    docker.withRegistry(\"https://${DOCKER_REGISTRY}\", 'registry-credentials') {\n",
    "                        image.push()\n",
    "                        image.push('latest')\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stage('IaC Scan') {\n",
    "            when {\n",
    "                changeset \"terraform/**/*\"\n",
    "            }\n",
    "            steps {\n",
    "                sh '''\n",
    "                    docker run --rm -v $(pwd):/tf bridgecrew/checkov \\\n",
    "                    --directory /tf/terraform \\\n",
    "                    --compact\n",
    "                '''\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stage('Deploy to Staging') {\n",
    "            steps {\n",
    "                sh 'kubectl apply -f k8s/staging/'\n",
    "                sh 'kubectl rollout status deployment/app -n staging'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        stage('DAST') {\n",
    "            steps {\n",
    "                sh '''\n",
    "                    docker run --rm -v $(pwd):/zap/wrk/:rw \\\n",
    "                    -t owasp/zap2docker-stable zap-baseline.py \\\n",
    "                    -t https://staging.app.company.com \\\n",
    "                    -r dast-report.html\n",
    "                '''\n",
    "                publishHTML([allowMissing: false, alwaysLinkToLastBuild: true, \n",
    "                    keepAll: true, reportDir: '.', reportFiles: 'dast-report.html', \n",
    "                    reportName: 'DAST Report'])\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    post {\n",
    "        always {\n",
    "            // Clean workspace\n",
    "            cleanWs()\n",
    "            \n",
    "            // Notify security team of critical findings\n",
    "            script {\n",
    "                if (currentBuild.result == 'FAILURE') {\n",
    "                    emailext (\n",
    "                        subject: \"Security Pipeline Failed: ${env.JOB_NAME} - ${env.BUILD_NUMBER}\",\n",
    "                        body: \"Critical security issues detected. Check console output.\",\n",
    "                        to: \"${env.CHANGE_AUTHOR_EMAIL}, security-team@company.com\"\n",
    "                    )\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 15.2 Security as Code: Policy-as-Code and Infrastructure-as-Code\n",
    "\n",
    "**Security as Code (SaC)** treats security policies as version-controlled, testable, and automated artifactsâ€”just like application code. This eliminates manual configuration drift and ensures consistent enforcement across environments.\n",
    "\n",
    "### Open Policy Agent (OPA)\n",
    "\n",
    "OPA is a general-purpose policy engine that enables unified policy enforcement across the stackâ€”from Kubernetes admission control to API authorization.\n",
    "\n",
    "**Rego Policy Language Basics:**\n",
    "\n",
    "```rego\n",
    "# kubernetes-security.rego\n",
    "package kubernetes.admission\n",
    "\n",
    "import future.keywords.if\n",
    "import future.keywords.in\n",
    "\n",
    "# Deny containers running as root\n",
    "deny[msg] if {\n",
    "    input.request.kind.kind == \"Pod\"\n",
    "    container := input.request.object.spec.containers[_]\n",
    "    not container.securityContext.runAsNonRoot\n",
    "    msg := sprintf(\"Container %s must set runAsNonRoot: true\", [container.name])\n",
    "}\n",
    "\n",
    "# Deny privileged containers\n",
    "deny[msg] if {\n",
    "    input.request.kind.kind == \"Pod\"\n",
    "    container := input.request.object.spec.containers[_]\n",
    "    container.securityContext.privileged\n",
    "    msg := sprintf(\"Container %s must not be privileged\", [container.name])\n",
    "}\n",
    "\n",
    "# Require resource limits\n",
    "deny[msg] if {\n",
    "    input.request.kind.kind == \"Pod\"\n",
    "    container := input.request.object.spec.containers[_]\n",
    "    not container.resources.limits.memory\n",
    "    msg := sprintf(\"Container %s must have memory limits defined\", [container.name])\n",
    "}\n",
    "\n",
    "# Enforce image registry whitelist\n",
    "allowed_registries := {\"registry.company.com\", \"gcr.io/company-project\"}\n",
    "\n",
    "deny[msg] if {\n",
    "    input.request.kind.kind == \"Pod\"\n",
    "    container := input.request.object.spec.containers[_]\n",
    "    image := container.image\n",
    "    not starts_with_allowed_registry(image)\n",
    "    msg := sprintf(\"Container %s uses image from unauthorized registry: %s\", [container.name, image])\n",
    "}\n",
    "\n",
    "starts_with_allowed_registry(image) if {\n",
    "    registry := allowed_registries[_]\n",
    "    startswith(image, registry)\n",
    "}\n",
    "```\n",
    "\n",
    "**Kubernetes Admission Controller Integration:**\n",
    "\n",
    "```yaml\n",
    "# OPA Gatekeeper deployment\n",
    "apiVersion: config.gatekeeper.sh/v1alpha1\n",
    "kind: Config\n",
    "metadata:\n",
    "  name: config\n",
    "  namespace: gatekeeper-system\n",
    "spec:\n",
    "  sync:\n",
    "    syncOnly:\n",
    "      - group: \"\"\n",
    "        version: \"v1\"\n",
    "        kind: \"Namespace\"\n",
    "      - group: \"\"\n",
    "        version: \"v1\"\n",
    "        kind: \"Pod\"\n",
    "---\n",
    "apiVersion: templates.gatekeeper.sh/v1beta1\n",
    "kind: ConstraintTemplate\n",
    "metadata:\n",
    "  name: k8srequiredlabels\n",
    "spec:\n",
    "  crd:\n",
    "    spec:\n",
    "      names:\n",
    "        kind: K8sRequiredLabels\n",
    "      validation:\n",
    "        openAPIV3Schema:\n",
    "          properties:\n",
    "            labels:\n",
    "              type: array\n",
    "              items: string\n",
    "  targets:\n",
    "    - target: admission.k8s.gatekeeper.sh\n",
    "      rego: |\n",
    "        package k8srequiredlabels\n",
    "        violation[{\"msg\": msg}] {\n",
    "          provided := {label | input.review.object.metadata.labels[label]}\n",
    "          required := {label | label := input.parameters.labels[_]}\n",
    "          missing := required - provided\n",
    "          count(missing) > 0\n",
    "          msg := sprintf(\"Missing required labels: %v\", [missing])\n",
    "        }\n",
    "---\n",
    "# Apply constraint\n",
    "apiVersion: constraints.gatekeeper.sh/v1beta1\n",
    "kind: K8sRequiredLabels\n",
    "metadata:\n",
    "  name: require-security-labels\n",
    "spec:\n",
    "  match:\n",
    "    kinds:\n",
    "      - apiGroups: [\"\"]\n",
    "        kinds: [\"Pod\"]\n",
    "  parameters:\n",
    "    labels: [\"app.kubernetes.io/name\", \"security-level\"]\n",
    "```\n",
    "\n",
    "### Terraform Policy as Code (Sentinel/OPA)\n",
    "\n",
    "For cloud infrastructure, enforce security before resource creation:\n",
    "\n",
    "```hcl\n",
    "# sentinel.hcl - HashiCorp Sentinel configuration\n",
    "policy \"enforce-encryption\" {\n",
    "    enforcement_level = \"hard-mandatory\"\n",
    "}\n",
    "\n",
    "policy \"restrict-instance-types\" {\n",
    "    enforcement_level = \"soft-mandatory\"\n",
    "}\n",
    "```\n",
    "\n",
    "```python\n",
    "# enforce-encryption.sentinel\n",
    "import \"tfplan\"\n",
    "\n",
    "# Check if S3 buckets have encryption enabled\n",
    "main = rule {\n",
    "    all tfplan.resources.aws_s3_bucket as _, buckets {\n",
    "        all buckets as _, bucket {\n",
    "            bucket.applied.server_side_encryption_configuration is not null\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Check EBS volumes are encrypted\n",
    "ebs_encrypted = rule {\n",
    "    all tfplan.resources.aws_ebs_volume as _, volumes {\n",
    "        all volumes as _, volume {\n",
    "            volume.applied.encrypted is true\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Using OPA with Terraform:**\n",
    "\n",
    "```rego\n",
    "# terraform.rego\n",
    "package terraform.analysis\n",
    "\n",
    "import input.tfplan as plan\n",
    "\n",
    "# Deny public S3 buckets\n",
    "deny[msg] {\n",
    "    resource := plan.resource_changes[_]\n",
    "    resource.type == \"aws_s3_bucket\"\n",
    "    resource.change.after.acl == \"public-read\"\n",
    "    msg := sprintf(\"S3 bucket %s must not be public\", [resource.name])\n",
    "}\n",
    "\n",
    "# Require specific instance types\n",
    "allowed_instance_types := {\"t3.micro\", \"t3.small\", \"m5.large\"}\n",
    "\n",
    "deny[msg] {\n",
    "    resource := plan.resource_changes[_]\n",
    "    resource.type == \"aws_instance\"\n",
    "    instance_type := resource.change.after.instance_type\n",
    "    not allowed_instance_types[instance_type]\n",
    "    msg := sprintf(\"Instance type %s not allowed\", [instance_type])\n",
    "}\n",
    "\n",
    "# Enforce tags for cost tracking\n",
    "deny[msg] {\n",
    "    resource := plan.resource_changes[_]\n",
    "    resource.type == \"aws_instance\"\n",
    "    not resource.change.after.tags[\"Environment\"]\n",
    "    msg := \"All instances must have Environment tag\"\n",
    "}\n",
    "```\n",
    "\n",
    "### CI/CD Policy Enforcement\n",
    "\n",
    "Enforcing security gates in pipelines through code:\n",
    "\n",
    "```yaml\n",
    "# policy-check.yml\n",
    "security_policies:\n",
    "  - name: \"No Critical CVEs\"\n",
    "    description: \"Container images must not contain critical vulnerabilities\"\n",
    "    check: \"trivy_scan\"\n",
    "    severity_threshold: \"CRITICAL\"\n",
    "    action: \"block\"\n",
    "  \n",
    "  - name: \"Signed Commits\"\n",
    "    description: \"All commits must be GPG signed\"\n",
    "    check: \"git_verify\"\n",
    "    action: \"block\"\n",
    "  \n",
    "  - name: \"Branch Protection\"\n",
    "    description: \"Main branch requires pull request reviews\"\n",
    "    check: \"github_branch_protection\"\n",
    "    action: \"warn\"\n",
    "  \n",
    "  - name: \"Secrets Scan Clean\"\n",
    "    description: \"No hardcoded secrets in codebase\"\n",
    "    check: \"gitleaks\"\n",
    "    action: \"block\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 15.3 Automated Security Testing in CI/CD\n",
    "\n",
    "Modern DevSecOps pipelines integrate multiple testing methodologies, each detecting different vulnerability classes.\n",
    "\n",
    "### SAST (Static Application Security Testing)\n",
    "\n",
    "SAST analyzes source code without execution, identifying vulnerabilities like SQL injection, XSS, and buffer overflows.\n",
    "\n",
    "**Semgrep (Lightweight, fast SAST):**\n",
    "\n",
    "```yaml\n",
    "# .semgrep.yml\n",
    "rules:\n",
    "  - id: sql-injection\n",
    "    languages: [python]\n",
    "    message: \"Potential SQL injection detected\"\n",
    "    pattern-either:\n",
    "      - pattern: |\n",
    "          query = \"...\" + $X\n",
    "          ...\n",
    "          cursor.execute(query)\n",
    "      - pattern: |\n",
    "          query = f\"...{$X}...\"\n",
    "          ...\n",
    "          cursor.execute(query)\n",
    "    severity: ERROR\n",
    "  \n",
    "  - id: hardcoded-credentials\n",
    "    languages: [python, javascript, go]\n",
    "    pattern-regex: (?i)(password|passwd|pwd)\\s*=\\s*['\"][^'\"]+['\"]\n",
    "    message: \"Hardcoded credential detected\"\n",
    "    severity: WARNING\n",
    "  \n",
    "  - id: insecure-random\n",
    "    languages: [python]\n",
    "    pattern: random.random()\n",
    "    fix: secrets.SystemRandom().random()\n",
    "    message: \"Insecure random number generator\"\n",
    "```\n",
    "\n",
    "**Bandit (Python-specific):**\n",
    "\n",
    "```bash\n",
    "# Run bandit with specific tests\n",
    "bandit -r ./src -f json -o bandit-report.json \\\n",
    "  --skip B101,B102 \\\n",
    "  --severity-level medium \\\n",
    "  --confidence-level medium\n",
    "```\n",
    "\n",
    "### DAST (Dynamic Application Security Testing)\n",
    "\n",
    "DAST tests running applications externally, simulating attacker behavior.\n",
    "\n",
    "**OWASP ZAP Automation:**\n",
    "\n",
    "```python\n",
    "# zap_automation.py\n",
    "from zapv2 import ZAPv2\n",
    "import time\n",
    "import sys\n",
    "\n",
    "class ZAPSecurityScanner:\n",
    "    def __init__(self, api_key, target_url):\n",
    "        self.zap = ZAPv2(apikey=api_key)\n",
    "        self.target = target_url\n",
    "        self.scan_policy = \"Default Policy\"\n",
    "        \n",
    "    def spider_scan(self):\n",
    "        \"\"\"Crawl the application\"\"\"\n",
    "        scan_id = self.zap.spider.scan(self.target)\n",
    "        while int(self.zap.spider.status(scan_id)) < 100:\n",
    "            time.sleep(5)\n",
    "        print(f\"Spider completed. Found {len(self.zap.spider.results(scan_id))} URLs\")\n",
    "    \n",
    "    def active_scan(self):\n",
    "        \"\"\"Attack discovered URLs\"\"\"\n",
    "        scan_id = self.zap.ascan.scan(self.target, scanpolicyname=self.scan_policy)\n",
    "        while int(self.zap.ascan.status(scan_id)) < 100:\n",
    "            progress = self.zap.ascan.status(scan_id)\n",
    "            print(f\"Active scan progress: {progress}%\")\n",
    "            time.sleep(10)\n",
    "    \n",
    "    def check_risks(self):\n",
    "        \"\"\"Verify no high risks before deployment\"\"\"\n",
    "        alerts = self.zap.core.alerts(baseurl=self.target)\n",
    "        high_risks = [alert for alert in alerts if alert['risk'] == 'High']\n",
    "        medium_risks = [alert for alert in alerts if alert['risk'] == 'Medium']\n",
    "        \n",
    "        print(f\"High Risk Issues: {len(high_risks)}\")\n",
    "        print(f\"Medium Risk Issues: {len(medium_risks)}\")\n",
    "        \n",
    "        # Fail CI if high risks found\n",
    "        if len(high_risks) > 0:\n",
    "            for alert in high_risks:\n",
    "                print(f\"CRITICAL: {alert['name']} - {alert['description']}\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "        return len(high_risks) == 0\n",
    "\n",
    "# Usage in CI pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    scanner = ZAPSecurityScanner(\n",
    "        api_key=\"changeme\",\n",
    "        target_url=\"https://staging.example.com\"\n",
    "    )\n",
    "    scanner.spider_scan()\n",
    "    scanner.active_scan()\n",
    "    scanner.check_risks()\n",
    "```\n",
    "\n",
    "### SCA (Software Composition Analysis)\n",
    "\n",
    "SCA identifies vulnerabilities in open-source dependencies and checks license compliance.\n",
    "\n",
    "**Dependency-Check Configuration:**\n",
    "\n",
    "```xml\n",
    "<!-- dependency-check-config.xml -->\n",
    "<configuration>\n",
    "    <failBuildOnCVSS>7</failBuildOnCVSS>\n",
    "    <suppressionFiles>\n",
    "        <suppressionFile>dependency-check-suppressions.xml</suppressionFile>\n",
    "    </suppressionFiles>\n",
    "    <analyzers>\n",
    "        <assemblyAnalyzerEnabled>false</assemblyAnalyzerEnabled>\n",
    "        <nugetconfAnalyzerEnabled>true</nugetconfAnalyzerEnabled>\n",
    "    </analyzers>\n",
    "    <retireJs>\n",
    "        <filterNonVulnerable>true</filterNonVulnerable>\n",
    "    </retireJs>\n",
    "</configuration>\n",
    "```\n",
    "\n",
    "**Snyk Policy File:**\n",
    "\n",
    "```yaml\n",
    "# .snyk\n",
    "version: v1.25.0\n",
    "ignore:\n",
    "  'SNYK-JS-LODASH-1018905':\n",
    "    - '*':\n",
    "        reason: 'No fix available, not exploitable in our context'\n",
    "        expires: 2024-12-31T00:00:00.000Z\n",
    "patch: {}\n",
    "```\n",
    "\n",
    "### IAST (Interactive Application Security Testing)\n",
    "\n",
    "IAST instruments applications during testing, combining SAST and DAST advantages with minimal false positives.\n",
    "\n",
    "**Contrast Security (Java Example):**\n",
    "\n",
    "```xml\n",
    "<!-- pom.xml -->\n",
    "<plugin>\n",
    "    <groupId>com.contrastsecurity</groupId>\n",
    "    <artifactId>contrast-maven-plugin</artifactId>\n",
    "    <version>2.13.0</version>\n",
    "    <configuration>\n",
    "        <username>${contrast.username}</username>\n",
    "        <apiKey>${contrast.apiKey}</apiKey>\n",
    "        <serviceKey>${contrast.serviceKey}</serviceKey>\n",
    "        <orgUuid>${contrast.orgUuid}</orgUuid>\n",
    "        <applicationName>SecureApp</applicationName>\n",
    "        <serverName>CI-Server</serverName>\n",
    "    </configuration>\n",
    "</plugin>\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Run tests with IAST agent\n",
    "mvn contrast:verify test\n",
    "```\n",
    "\n",
    "### Secrets Scanning\n",
    "\n",
    "Prevent credential leakage through automated scanning:\n",
    "\n",
    "**GitLeaks Configuration:**\n",
    "\n",
    "```toml\n",
    "# .gitleaks.toml\n",
    "title = \"GitLeaks Config\"\n",
    "\n",
    "[[rules]]\n",
    "id = \"AWS Access Key\"\n",
    "description = \"AWS Access Key\"\n",
    "regex = '''(A3T[A-Z0-9]|AKIA|AGPA|AIDA|AROA|AIPA|ANPA|ANVA|ASIA)[A-Z0-9]{16}'''\n",
    "tags = [\"key\", \"AWS\"]\n",
    "\n",
    "[[rules]]\n",
    "id = \"Generic API Key\"\n",
    "description = \"Generic API Key\"\n",
    "regex = '''[aA][pP][iI]_?[kK][eE][yY].*['|\\\"][0-9a-zA-Z]{32,45}['|\\\"]'''\n",
    "secretGroup = 1\n",
    "entropy = 3.7\n",
    "\n",
    "[allowlist]\n",
    "description = \"Allowlisted files\"\n",
    "paths = [\n",
    "    '''gitleaks.toml''',\n",
    "    '''(.*?)(jpg|gif|doc|pdf|bin)$'''\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 15.4 Orchestration and Automation Tools for Security (SOAR)\n",
    "\n",
    "**SOAR (Security Orchestration, Automation and Response)** platforms automate incident response workflows, threat intelligence management, and security tool integration. They reduce mean time to respond (MTTR) by eliminating manual coordination.\n",
    "\n",
    "### SOAR Architecture Components\n",
    "\n",
    "1. **Orchestration**: Connecting disparate security tools (SIEM, EDR, firewalls)\n",
    "2. **Automation**: Playbooks that execute response actions without human intervention\n",
    "3. **Response**: Case management, evidence collection, and remediation tracking\n",
    "\n",
    "### Practical SOAR Implementation\n",
    "\n",
    "Using open-source tools like Shuffle or Node-RED, or enterprise platforms like Splunk SOAR:\n",
    "\n",
    "**Incident Response Playbook (Python-based SOAR):**\n",
    "\n",
    "```python\n",
    "# soar_playbook.py\n",
    "from typing import Dict, List\n",
    "import asyncio\n",
    "import json\n",
    "\n",
    "class IncidentResponseOrchestrator:\n",
    "    def __init__(self):\n",
    "        self.siem = SIEMConnector()\n",
    "        self.edr = EDRConnector()\n",
    "        self.firewall = FirewallConnector()\n",
    "        self.ticketing = JiraConnector()\n",
    "        self.slack = SlackNotifier()\n",
    "    \n",
    "    async def handle_phishing_alert(self, alert: Dict):\n",
    "        \"\"\"\n",
    "        Automated phishing response workflow\n",
    "        \"\"\"\n",
    "        incident_id = await self.create_incident(alert)\n",
    "        \n",
    "        # Enrichment phase\n",
    "        await self.slack.notify(f\"Investigating phishing alert: {incident_id}\")\n",
    "        \n",
    "        # Gather threat intelligence\n",
    "        sender_ip = alert['sender_ip']\n",
    "        reputation = await self.check_ip_reputation(sender_ip)\n",
    "        \n",
    "        if reputation['malicious_score'] > 0.8:\n",
    "            # Automated containment\n",
    "            await self.firewall.block_ip(sender_ip)\n",
    "            await self.edr.isolate_endpoint(alert['recipient_endpoint'])\n",
    "            \n",
    "            # Forensic collection\n",
    "            await self.edr.collect_memory_dump(alert['recipient_endpoint'])\n",
    "            await self.siem.export_logs(\n",
    "                query=f\"source_ip={sender_ip}\",\n",
    "                time_range=\"24h\"\n",
    "            )\n",
    "            \n",
    "            # Update incident\n",
    "            await self.update_incident(incident_id, {\n",
    "                \"status\": \"Contained\",\n",
    "                \"actions_taken\": [\"IP blocked\", \"Endpoint isolated\"],\n",
    "                \"threat_intel\": reputation\n",
    "            })\n",
    "            \n",
    "            await self.slack.notify(\n",
    "                f\"ðŸš¨ Phishing incident {incident_id} contained automatically\"\n",
    "            )\n",
    "        else:\n",
    "            await self.ticketing.create_task(\n",
    "                assignee=\"security-analyst\",\n",
    "                description=f\"Review low-confidence phishing alert: {incident_id}\"\n",
    "            )\n",
    "    \n",
    "    async def handle_malware_detection(self, alert: Dict):\n",
    "        \"\"\"\n",
    "        Malware outbreak response\n",
    "        \"\"\"\n",
    "        hash_value = alert['file_hash']\n",
    "        \n",
    "        # Check if hash known malicious\n",
    "        vt_results = await self.virustotal_lookup(hash_value)\n",
    "        \n",
    "        if vt_results['positives'] > 10:\n",
    "            # Search for all instances across enterprise\n",
    "            infected_hosts = await self.edr.hunt_ioc(hash_value)\n",
    "            \n",
    "            # Mass containment\n",
    "            containment_tasks = [\n",
    "                self.edr.isolate_endpoint(host) \n",
    "                for host in infected_hosts\n",
    "            ]\n",
    "            await asyncio.gather(*containment_tasks)\n",
    "            \n",
    "            # YARA rule deployment\n",
    "            yara_rule = await self.generate_yara_rule(alert['file_sample'])\n",
    "            await self.edr.deploy_yara_rule(yara_rule)\n",
    "            \n",
    "            # Notification\n",
    "            await self.slack.notify(\n",
    "                f\"Malware {hash_value} contained on {len(infected_hosts)} hosts\"\n",
    "            )\n",
    "\n",
    "class AutomatedVulnerabilityRemediation:\n",
    "    \"\"\"\n",
    "    Auto-remediation for low-risk vulnerabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    async def patch_container_cve(self, image_tag: str, cve_id: str):\n",
    "        \"\"\"\n",
    "        Rebuild container with patched base image\n",
    "        \"\"\"\n",
    "        # Check if auto-remediation approved for this CVE\n",
    "        if not await self.is_approved_for_auto_remediation(cve_id):\n",
    "            return False\n",
    "        \n",
    "        # Trigger rebuild pipeline\n",
    "        await self.ci_cd.trigger_build(\n",
    "            component=image_tag,\n",
    "            base_image_update=True,\n",
    "            security_patch=cve_id\n",
    "        )\n",
    "        \n",
    "        # Verify fix in new image\n",
    "        scan_results = await self.scanner.scan_image(f\"{image_tag}-patched\")\n",
    "        if cve_id not in scan_results['vulnerabilities']:\n",
    "            await self.deploy_to_staging(image_tag)\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    async def rotate_exposed_credentials(self, leak_alert: Dict):\n",
    "        \"\"\"\n",
    "        Automated credential rotation on secret leak detection\n",
    "        \"\"\"\n",
    "        secret_id = leak_alert['secret_id']\n",
    "        \n",
    "        # 1. Revoke immediately\n",
    "        await self.vault.revoke_secret(secret_id)\n",
    "        \n",
    "        # 2. Generate new credential\n",
    "        new_secret = await self.vault.generate_dynamic_credential(\n",
    "            service=leak_alert['service'],\n",
    "            ttl=\"90d\"\n",
    "        )\n",
    "        \n",
    "        # 3. Update CI/CD secrets\n",
    "        await self.ci_cd.update_secret(\n",
    "            secret_name=leak_alert['secret_name'],\n",
    "            new_value=new_secret\n",
    "        )\n",
    "        \n",
    "        # 4. Restart affected services\n",
    "        await self.kubernetes.rolling_restart(\n",
    "            label_selector=f\"uses-secret={leak_alert['secret_name']}\"\n",
    "        )\n",
    "        \n",
    "        # 5. Audit trail\n",
    "        await self.audit.log_credential_rotation(\n",
    "            secret_id=secret_id,\n",
    "            reason=\"Exposed in commit\",\n",
    "            automated=True\n",
    "        )\n",
    "```\n",
    "\n",
    "### Threat Intelligence Automation\n",
    "\n",
    "```python\n",
    "# threat_intel_automation.py\n",
    "class ThreatIntelProcessor:\n",
    "    def __init__(self):\n",
    "        self.misp = MISPConnector()\n",
    "        self.splunk = SplunkConnector()\n",
    "        self.firewalls = [PaloAltoConnector(), CloudflareConnector()]\n",
    "    \n",
    "    async def ingest_ioc_feed(self, feed_url: str):\n",
    "        \"\"\"\n",
    "        Automated IOC ingestion and blocking\n",
    "        \"\"\"\n",
    "        iocs = await self.download_feed(feed_url)\n",
    "        \n",
    "        for ioc in iocs:\n",
    "            # Deduplicate\n",
    "            if await self.misp.check_exists(ioc['value']):\n",
    "                continue\n",
    "            \n",
    "            # Enrich\n",
    "            enrichment = await self.enrich_ioc(ioc)\n",
    "            \n",
    "            # Score\n",
    "            risk_score = self.calculate_risk(enrichment)\n",
    "            \n",
    "            if risk_score > 70:\n",
    "                # Auto-block on firewalls\n",
    "                for fw in self.firewalls:\n",
    "                    await fw.add_blocklist(ioc['value'], ioc['type'])\n",
    "                \n",
    "                # Hunt in logs\n",
    "                hits = await self.splunk.hunt(ioc['value'])\n",
    "                if hits > 0:\n",
    "                    await self.create_incident(\n",
    "                        title=f\"Active IOC detected: {ioc['value']}\",\n",
    "                        severity=\"High\",\n",
    "                        hits=hits\n",
    "                    )\n",
    "            \n",
    "            # Store in MISP\n",
    "            await self.misp.create_event(ioc, enrichment, risk_score)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 15.5 Case Studies: Building a DevSecOps Pipeline from Scratch\n",
    "\n",
    "### Case Study 1: Cloud-Native Microservices Platform\n",
    "\n",
    "**Scenario**: Building a secure pipeline for a Kubernetes-based microservices architecture handling financial data (PCI-DSS requirements).\n",
    "\n",
    "**Architecture:**\n",
    "```yaml\n",
    "# complete-pipeline-example.yml\n",
    "stages:\n",
    "  - preflight\n",
    "  - build\n",
    "  - security-gates\n",
    "  - deploy-staging\n",
    "  - dast\n",
    "  - deploy-production\n",
    "\n",
    "preflight:\n",
    "  script:\n",
    "    - gitleaks detect --source .\n",
    "    - trufflehog filesystem .\n",
    "    - checkov --file Dockerfile --framework dockerfile\n",
    "\n",
    "build:\n",
    "  script:\n",
    "    - docker build --target builder -t app:build .\n",
    "    - docker run --rm app:build npm test\n",
    "    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .\n",
    "\n",
    "security-gates:\n",
    "  parallel:\n",
    "    - job: sast\n",
    "      script:\n",
    "        - semgrep --config=auto --json --output=semgrep.json .\n",
    "        - sonar-scanner -Dsonar.qualitygate.wait=true\n",
    "    \n",
    "    - job: sca\n",
    "      script:\n",
    "        - npm audit --audit-level moderate\n",
    "        - snyk test --severity-threshold=high\n",
    "    \n",
    "    - job: container-scan\n",
    "      script:\n",
    "        - trivy image --exit-code 1 --severity HIGH,CRITICAL $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n",
    "        - trivy image --format cyclonedx --output sbom.json $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n",
    "    \n",
    "    - job: iac-scan\n",
    "      script:\n",
    "        - checkov --directory terraform/ --framework terraform\n",
    "        - terraform plan -out=tfplan\n",
    "        - opa eval --data policy.rego --input tfplan \"data.terraform.analysis.deny\"\n",
    "\n",
    "deploy-staging:\n",
    "  script:\n",
    "    - helm upgrade --install app ./helm-chart \n",
    "        --set image.tag=$CI_COMMIT_SHA\n",
    "        --values values-staging.yaml\n",
    "    - kubectl rollout status deployment/app -n staging\n",
    "\n",
    "dast:\n",
    "  script:\n",
    "    - zap-full-scan.py -t https://staging.app.com -g gen.conf\n",
    "    - nikto -h https://staging.app.com -o nikto.html\n",
    "\n",
    "deploy-production:\n",
    "  when: manual\n",
    "  script:\n",
    "    - cosign verify --key cosign.pub $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n",
    "    - helm upgrade --install app ./helm-chart \n",
    "        --set image.tag=$CI_COMMIT_SHA\n",
    "        --values values-prod.yaml\n",
    "    - kubectl apply -f network-policies/\n",
    "```\n",
    "\n",
    "### Case Study 2: AI/ML Model Deployment Pipeline\n",
    "\n",
    "**Scenario**: Secure pipeline for deploying Chapter 14's agentic AI systems with model validation.\n",
    "\n",
    "```python\n",
    "# mlsec_pipeline.py\n",
    "class MLSecurePipeline:\n",
    "    \"\"\"\n",
    "    DevSecOps pipeline for AI/ML models\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model_scanner = ModelScanner()\n",
    "        self.bias_detector = BiasDetector()\n",
    "        self.adversarial_tester = AdversarialTester()\n",
    "    \n",
    "    def stage_1_model_validation(self, model_path: str):\n",
    "        \"\"\"\n",
    "        Security checks specific to ML models\n",
    "        \"\"\"\n",
    "        # Check for model serialization attacks\n",
    "        if model_path.endswith('.pkl'):\n",
    "            raise SecurityException(\"Pickle format not allowed. Use SafeTensors.\")\n",
    "        \n",
    "        # Verify model signature\n",
    "        if not self.verify_model_signature(model_path):\n",
    "            raise SecurityException(\"Model signature invalid\")\n",
    "        \n",
    "        # Scan for adversarial vulnerabilities\n",
    "        robustness_score = self.adversarial_tester.test_robustness(model_path)\n",
    "        if robustness_score < 0.8:\n",
    "            raise SecurityException(f\"Model fails robustness tests: {robustness_score}\")\n",
    "    \n",
    "    def stage_2_data_provenance(self, training_data_manifest: str):\n",
    "        \"\"\"\n",
    "        Verify training data integrity (from Chapter 14)\n",
    "        \"\"\"\n",
    "        with open(training_data_manifest) as f:\n",
    "            manifest = json.load(f)\n",
    "        \n",
    "        # Verify dataset hash matches expected\n",
    "        current_hash = self.compute_dataset_hash(manifest['dataset_path'])\n",
    "        if current_hash != manifest['expected_hash']:\n",
    "            raise SecurityException(\"Training data tampering detected\")\n",
    "        \n",
    "        # Check for poisoning via anomaly detection\n",
    "        anomalies = self.detect_training_anomalies(manifest['dataset_path'])\n",
    "        if anomalies > 0.01:  # 1% anomaly threshold\n",
    "            raise SecurityException(f\"Potential data poisoning: {anomalies*100}% anomalies\")\n",
    "    \n",
    "    def stage_3_bias_testing(self, model_path: str, test_data: str):\n",
    "        \"\"\"\n",
    "        Fairness and bias validation\n",
    "        \"\"\"\n",
    "        bias_report = self.bias_detector.analyze(model_path, test_data)\n",
    "        \n",
    "        # Check demographic parity\n",
    "        for group, metrics in bias_report['demographic_parity'].items():\n",
    "            if metrics['disparate_impact'] < 0.8:  # 80% rule\n",
    "                raise SecurityException(\n",
    "                    f\"Bias detected in group {group}: DI={metrics['disparate_impact']}\"\n",
    "                )\n",
    "    \n",
    "    def deploy_with_canary(self, model_path: str):\n",
    "        \"\"\"\n",
    "        Canary deployment with adversarial monitoring\n",
    "        \"\"\"\n",
    "        # Deploy to 5% traffic\n",
    "        self.kubernetes.canary_deploy(model_path, traffic_percent=5)\n",
    "        \n",
    "        # Monitor for adversarial inputs\n",
    "        time.sleep(300)  # 5 minutes observation\n",
    "        attack_rate = self.monitor.adversarial_detection_rate()\n",
    "        \n",
    "        if attack_rate > 0.001:  # 0.1% threshold\n",
    "            self.kubernetes.rollback()\n",
    "            raise SecurityException(f\"Adversarial attack rate too high: {attack_rate}\")\n",
    "        \n",
    "        # Gradual rollout\n",
    "        self.kubernetes.scale_canary(100)\n",
    "```\n",
    "\n",
    "### Implementation Checklist\n",
    "\n",
    "**Phase 1: Foundation (Weeks 1-2)**\n",
    "- [ ] Implement Git pre-commit hooks (secrets scanning)\n",
    "- [ ] Configure SAST tools (Semgrep/SonarQube)\n",
    "- [ ] Set up dependency scanning (Snyk/Dependabot)\n",
    "- [ ] Enforce branch protection rules\n",
    "\n",
    "**Phase 2: Integration (Weeks 3-4)**\n",
    "- [ ] Container image scanning in CI\n",
    "- [ ] SBOM generation for all artifacts\n",
    "- [ ] Image signing with Cosign\n",
    "- [ ] IaC scanning (Checkov)\n",
    "\n",
    "**Phase 3: Advanced (Weeks 5-6)**\n",
    "- [ ] DAST integration in staging\n",
    "- [ ] OPA policies for Kubernetes\n",
    "- [ ] Automated compliance checks (CIS benchmarks)\n",
    "- [ ] SOAR playbooks for incident response\n",
    "\n",
    "**Phase 4: Optimization (Ongoing)**\n",
    "- [ ] False positive tuning\n",
    "- [ ] Pipeline performance optimization\n",
    "- [ ] Developer security training integration\n",
    "- [ ] Metrics dashboard (MTTR, vulnerability density)\n",
    "\n",
    "---\n",
    "\n",
    "## Summary and Transition to Chapter 16\n",
    "\n",
    "In this chapter, we operationalized security, transforming theoretical controls into automated, enforceable pipeline stages. You learned that **DevSecOps** is not a tool but a methodologyâ€”one that embeds security verification into every commit, build, and deployment.\n",
    "\n",
    "Through **CI/CD integration**, you implemented security gates that fail fast: secrets scanning prevents credential leakage at commit time; SAST identifies code vulnerabilities before compilation; SCA manages dependency risks; container scanning ensures deployment artifacts are hardened; and DAST validates runtime security post-deployment. The combination of **Security as Code**â€”using OPA for Kubernetes admission control and Sentinel for Terraform policy enforcementâ€”ensures that security constraints follow infrastructure wherever it scales.\n",
    "\n",
    "We explored **SOAR** platforms that orchestrate incident response, automating the containment of phishing attacks, the isolation of malware-infected endpoints, and the rotation of exposed credentialsâ€”reducing response times from hours to seconds. The case studies demonstrated practical implementations: a PCI-DSS compliant microservices pipeline with cryptographic artifact verification, and a specialized MLOps pipeline extending Chapter 14's AI security controls into automated bias testing and adversarial robustness validation.\n",
    "\n",
    "However, not all systems fit the cloud-native, CI/CD-deployed model we have focused on thus far. Critical infrastructureâ€”power grids, manufacturing systems, medical devicesâ€”operates under constraints of legacy protocols, real-time requirements, and physical safety implications that demand specialized security architectures. These **Operational Technology (OT)** and **Industrial Control Systems (ICS)** environments face unique threats: air-gap jumping malware like Stuxnet, protocol-specific attacks against Modbus or OPC-UA, and the convergence of IT and OT networks.\n",
    "\n",
    "In **Chapter 16: Specialized Security Domains**, we venture beyond enterprise software into **Industrial Control Systems (ICS/SCADA)** security, following the ISA/IEC 62443 standards for industrial automation. We will examine **Mobile Application Security** for iOS and Android platforms, addressing sandbox escapes and app store security. We explore **IoT Security** for resource-constrained devices, and finally **Blockchain and Web3 Security**, investigating smart contract vulnerabilities and consensus attacks. Each domain requires adapting the DevSecOps principles from this chapter to unique operational constraintsâ€”whether that means air-gapped deployments, battery-powered sensors, or immutable ledger transactions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
