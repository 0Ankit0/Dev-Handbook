{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VIII: Asynchronous Programming\n",
    "\n",
    "## Chapter 17: Mastering Async/Await\n",
    "\n",
    "FastAPI's exceptional performance stems from its async-native architecture. However, simply using `async def` doesn't automatically make code non-blocking. Understanding when to use synchronous versus asynchronous functions, identifying blocking operations, and properly offloading CPU-intensive work is crucial for building high-performance applications. This chapter demystifies Python's async model in the context of FastAPI, ensuring you leverage the full power of the event loop.\n",
    "\n",
    "---\n",
    "\n",
    "### 17.1 `def` vs `async def`: When to Use Which\n",
    "\n",
    "FastAPI supports both synchronous (`def`) and asynchronous (`async def`) path operation functions. Choosing incorrectly can block the event loop and destroy performance, or introduce unnecessary complexity.\n",
    "\n",
    "#### The Event Loop and Thread Pool Architecture\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502           FastAPI Request Handling Architecture                  \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Incoming Request                                                \u2502\n",
    "\u2502       \u2502                                                          \u2502\n",
    "\u2502       \u25bc                                                          \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n",
    "\u2502  \u2502              Main Thread (Event Loop)                    \u2502    \u2502\n",
    "\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502    \u2502\n",
    "\u2502  \u2502  \u2502 async def endpoints                                \u2502 \u2502    \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 Database queries (asyncpg, aiomysql)            \u2502 \u2502    \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 HTTP client (httpx, aiohttp)                    \u2502 \u2502    \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 WebSocket operations                             \u2502 \u2502    \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 FastAPI dependencies (async)                     \u2502 \u2502    \u2502\n",
    "\u2502  \u2502  \u2502                                                    \u2502 \u2502    \u2502\n",
    "\u2502  \u2502  \u2502  \u2193 Await points allow other requests to run        \u2502 \u2502    \u2502\n",
    "\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502    \u2502\n",
    "\u2502  \u2502                          \u2502                               \u2502    \u2502\n",
    "\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502    \u2502\n",
    "\u2502  \u2502  \u2502 def endpoints (run in thread pool)                 \u2502 \u2502    \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 CPU-intensive calculations                       \u2502 \u2502    \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 Blocking I/O (pandas, requests, time.sleep)      \u2502 \u2502    \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 File operations (open(), read())                 \u2502 \u2502    \u2502\n",
    "\u2502  \u2502  \u2502                                                    \u2502 \u2502    \u2502\n",
    "\u2502  \u2502  \u2502  \u2193 Runs in separate thread, loop continues         \u2502 \u2502    \u2502\n",
    "\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502    \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Thread Pool ( Starlette manages this )                         \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502\n",
    "\u2502  \u2502 Thread 1\u2502 \u2502 Thread 2\u2502 \u2502 Thread 3\u2502 ...                       \u2502\n",
    "\u2502  \u2502 (def)   \u2502 \u2502 (def)   \u2502 \u2502 (def)   \u2502                           \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Rule of Thumb:                                                  \u2502\n",
    "\u2502  \u2022 Use async def for I/O-bound async libraries                   \u2502\n",
    "\u2502  \u2022 Use def for CPU-bound or blocking synchronous code             \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "#### Decision Framework\n",
    "\n",
    "```python\n",
    "# async_vs_sync.py - Decision examples\n",
    "\n",
    "from fastapi import FastAPI, Depends\n",
    "import asyncio\n",
    "import time\n",
    "import httpx\n",
    "import requests\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# USE async def WHEN:\n",
    "# Working with async libraries (database, HTTP clients)\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "@app.get(\"/db-async\")\n",
    "async def get_from_database():\n",
    "    \"\"\"\n",
    "    CORRECT: async def with async database driver.\n",
    "    \n",
    "    The 'await' yields control back to the event loop,\n",
    "    allowing other requests to be processed while waiting\n",
    "    for the database response.\n",
    "    \"\"\"\n",
    "    # SQLAlchemy async session\n",
    "    result = await db.execute(select(User).where(User.id == 1))\n",
    "    # During the await above, the event loop handles other requests\n",
    "    return result.scalar_one()\n",
    "\n",
    "\n",
    "@app.get(\"/http-async\")\n",
    "async def fetch_external_api():\n",
    "    \"\"\"\n",
    "    CORRECT: async def with async HTTP client (httpx).\n",
    "    \n",
    "    Non-blocking HTTP request.\n",
    "    \"\"\"\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(\"https://api.example.com/data\")\n",
    "        # Event loop continues during network wait\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# USE def WHEN:\n",
    "# CPU-intensive work or blocking synchronous libraries\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "@app.get(\"/cpu-intensive\")\n",
    "def cpu_bound_calculation(n: int = 1000000):\n",
    "    \"\"\"\n",
    "    CORRECT: def for CPU-intensive work.\n",
    "    \n",
    "    FastAPI runs this in a thread pool automatically.\n",
    "    If this were async def, it would block the event loop!\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i ** 2  # CPU-bound calculation\n",
    "    return {\"result\": total}\n",
    "\n",
    "\n",
    "@app.get(\"/blocking-http\")\n",
    "def blocking_external_api():\n",
    "    \"\"\"\n",
    "    CORRECT: def with blocking library (requests).\n",
    "    \n",
    "    requests.get() is synchronous and would block the event loop\n",
    "    if used in async def. Using def puts it in a thread pool.\n",
    "    \"\"\"\n",
    "    # This blocks the thread, but not the event loop\n",
    "    response = requests.get(\"https://api.example.com/slow\", timeout=30)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "@app.get(\"/file-read\")\n",
    "def read_large_file():\n",
    "    \"\"\"\n",
    "    CORRECT: def for file I/O.\n",
    "    \n",
    "    open() and read() are blocking system calls.\n",
    "    \"\"\"\n",
    "    with open(\"large_file.txt\", \"r\") as f:\n",
    "        content = f.read()  # Blocks thread, not event loop\n",
    "    return {\"content_length\": len(content)}\n",
    "\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# INCORRECT PATTERNS (Anti-patterns)\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "@app.get(\"/wrong-db\")\n",
    "async def bad_database_access():\n",
    "    \"\"\"\n",
    "    WRONG: async def with synchronous database driver.\n",
    "    \n",
    "    psycopg2 (sync) inside async def blocks the event loop.\n",
    "    Use asyncpg with SQLAlchemy async instead.\n",
    "    \"\"\"\n",
    "    import psycopg2  # Synchronous library!\n",
    "    conn = psycopg2.connect(DATABASE_URL)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT * FROM users\")  # BLOCKS EVENT LOOP!\n",
    "    return cursor.fetchall()\n",
    "\n",
    "\n",
    "@app.get(\"/wrong-cpu\")\n",
    "async def bad_cpu_bound():\n",
    "    \"\"\"\n",
    "    WRONG: async def with CPU-intensive work.\n",
    "    \n",
    "    No await means no yield point. The event loop is blocked\n",
    "    and cannot handle other requests during calculation.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for i in range(10000000):  # Blocks for seconds!\n",
    "        total += i\n",
    "    return {\"total\": total}\n",
    "\n",
    "\n",
    "@app.get(\"/wrong-sleep\")\n",
    "async def bad_sleep():\n",
    "    \"\"\"\n",
    "    WRONG: async def with blocking time.sleep.\n",
    "    \n",
    "    Use asyncio.sleep instead for async functions.\n",
    "    \"\"\"\n",
    "    time.sleep(5)  # BLOCKS EVENT LOOP - BAD!\n",
    "    return {\"message\": \"Done\"}\n",
    "\n",
    "\n",
    "@app.get(\"/correct-sleep\")\n",
    "async def good_sleep():\n",
    "    \"\"\"\n",
    "    CORRECT: asyncio.sleep yields control.\n",
    "    \"\"\"\n",
    "    await asyncio.sleep(5)  # Non-blocking - event loop continues\n",
    "    return {\"message\": \"Done\"}\n",
    "```\n",
    "\n",
    "**Decision Matrix:**\n",
    "\n",
    "| Operation Type | Library Examples | Use `def` or `async def` | Why |\n",
    "|---|---|---|---|\n",
    "| Database queries | asyncpg, aiomysql, SQLAlchemy 2.0 async | `async def` | Native async support, non-blocking I/O |\n",
    "| Database queries | psycopg2, pymysql (sync) | `def` | Blocking I/O, run in thread pool |\n",
    "| HTTP requests | httpx, aiohttp | `async def` | Native async, connection pooling |\n",
    "| HTTP requests | requests, urllib | `def` | Blocking, run in thread pool |\n",
    "| CPU-intensive | pandas, numpy, calculations | `def` | Releases GIL or runs in thread |\n",
    "| File operations | Standard open(), pathlib | `def` | System calls block |\n",
    "| File operations | aiofiles | `async def` | Async wrapper for files |\n",
    "| Caching/Redis | redis-py (async) | `async def` | Async redis client |\n",
    "\n",
    "---\n",
    "\n",
    "### 17.2 Blocking vs Non-Blocking: Identifying Performance Bottlenecks\n",
    "\n",
    "Not all `await` calls are equal, and not all \"async\" code is truly non-blocking. Understanding what happens under the hood helps identify bottlenecks.\n",
    "\n",
    "#### Identifying Blocking Operations\n",
    "\n",
    "```python\n",
    "# blocking_detection.py - Identifying what blocks\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from fastapi import FastAPI, Request\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Middleware to detect blocking operations\n",
    "@app.middleware(\"http\")\n",
    "async def detect_blocking(request: Request, call_next):\n",
    "    \"\"\"\n",
    "    Middleware that warns if endpoint blocks for too long.\n",
    "    \n",
    "    Useful for development to catch accidentally blocking code.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create task to check if we're blocking\n",
    "    loop = asyncio.get_event_loop()\n",
    "    warning_threshold = 0.1  # 100ms\n",
    "    \n",
    "    async def check_blocking():\n",
    "        \"\"\"Check if event loop is responsive.\"\"\"\n",
    "        await asyncio.sleep(warning_threshold)\n",
    "        # If we get here, the loop isn't blocked\n",
    "        return False\n",
    "    \n",
    "    # Run check and endpoint concurrently\n",
    "    endpoint_task = asyncio.create_task(call_next(request))\n",
    "    check_task = asyncio.create_task(check_blocking())\n",
    "    \n",
    "    done, pending = await asyncio.wait(\n",
    "        [endpoint_task, check_task],\n",
    "        return_when=asyncio.FIRST_COMPLETED\n",
    "    )\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    # If endpoint finished before check, it might be blocking\n",
    "    if endpoint_task in done and check_task in pending:\n",
    "        check_task.cancel()\n",
    "        if duration > warning_threshold:\n",
    "            process = psutil.Process(os.getpid())\n",
    "            print(f\"\u26a0\ufe0f  WARNING: Potentially blocking endpoint \"\n",
    "                  f\"{request.url.path} took {duration:.2f}s\")\n",
    "    \n",
    "    response = await endpoint_task\n",
    "    return response\n",
    "\n",
    "\n",
    "# Examples of blocking vs non-blocking\n",
    "\n",
    "@app.get(\"/non-blocking-async\")\n",
    "async def truly_non_blocking():\n",
    "    \"\"\"\n",
    "    Truly non-blocking: await yields control immediately.\n",
    "    \n",
    "    The event loop can process hundreds of other requests\n",
    "    during this 2-second wait.\n",
    "    \"\"\"\n",
    "    print(\"Starting non-blocking wait...\")\n",
    "    await asyncio.sleep(2)  # Immediately yields control\n",
    "    print(\"Finished non-blocking wait\")\n",
    "    return {\"type\": \"non-blocking\"}\n",
    "\n",
    "\n",
    "@app.get(\"/blocking-sync\")\n",
    "def blocking_function():\n",
    "    \"\"\"\n",
    "    Blocking: occupies a thread but releases event loop.\n",
    "    \n",
    "    FastAPI runs this in a thread pool. The main thread\n",
    "    (event loop) remains free to accept new connections.\n",
    "    However, this consumes one thread from the pool.\n",
    "    \"\"\"\n",
    "    print(\"Starting blocking sleep...\")\n",
    "    time.sleep(2)  # Blocks this thread only\n",
    "    print(\"Finished blocking sleep\")\n",
    "    return {\"type\": \"blocking-thread\"}\n",
    "\n",
    "\n",
    "@app.get(\"/cpu-intensive-def\")\n",
    "def cpu_bound():\n",
    "    \"\"\"\n",
    "    CPU-intensive in def: Runs in thread, may release GIL.\n",
    "    \n",
    "    If the calculation releases the GIL (numpy, pandas),\n",
    "    other threads can run. If not (pure Python), it hogs\n",
    "    the thread but doesn't block the event loop.\n",
    "    \"\"\"\n",
    "    # Pure Python - hogs CPU but in separate thread\n",
    "    total = sum(i**2 for i in range(10_000_000))\n",
    "    return {\"result\": total}\n",
    "\n",
    "\n",
    "@app.get(\"/cpu-intensive-async\")\n",
    "async def cpu_bound_bad():\n",
    "    \"\"\"\n",
    "    CPU-intensive in async: BLOCKS EVENT LOOP!\n",
    "    \n",
    "    This freezes the entire application for all users\n",
    "    while the calculation runs. Never do this.\n",
    "    \"\"\"\n",
    "    # BAD: Blocks the event loop\n",
    "    total = sum(i**2 for i in range(10_000_000))\n",
    "    return {\"result\": total}\n",
    "\n",
    "\n",
    "# Testing concurrency\n",
    "async def make_request(client, endpoint):\n",
    "    \"\"\"Helper to time requests.\"\"\"\n",
    "    start = time.time()\n",
    "    response = await client.get(endpoint)\n",
    "    duration = time.time() - start\n",
    "    return endpoint, duration, response.status_code\n",
    "\n",
    "\n",
    "@app.get(\"/test-concurrency\")\n",
    "async def test_concurrency():\n",
    "    \"\"\"\n",
    "    Test to demonstrate the difference between blocking\n",
    "    and non-blocking endpoints.\n",
    "    \"\"\"\n",
    "    from httpx import AsyncClient\n",
    "    \n",
    "    async with AsyncClient(app=app, base_url=\"http://test\") as client:\n",
    "        # Time 5 concurrent requests to non-blocking endpoint\n",
    "        tasks = [make_request(client, \"/non-blocking-async\") for _ in range(5)]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        # If truly non-blocking, all should complete in ~2 seconds total\n",
    "        # If blocking, would take ~10 seconds (2s * 5 sequential)\n",
    "        \n",
    "        total_time = max(r[1] for r in results)\n",
    "        return {\n",
    "            \"endpoint\": \"non-blocking-async\",\n",
    "            \"concurrent_requests\": 5,\n",
    "            \"max_time\": total_time,\n",
    "            \"results\": [{\"endpoint\": r[0], \"time\": r[1]} for r in results]\n",
    "        }\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 17.3 Running Blocking Code: `run_in_threadpool`\n",
    "\n",
    "When you must use blocking libraries (pandas, sklearn, requests) inside `async def` endpoints, you need to explicitly run them in a thread pool to avoid blocking the event loop.\n",
    "\n",
    "#### Using run_in_threadpool\n",
    "\n",
    "```python\n",
    "# threadpool.py - Offloading blocking code\n",
    "\n",
    "from fastapi import FastAPI, Depends\n",
    "from starlette.concurrency import run_in_threadpool\n",
    "import asyncio\n",
    "import time\n",
    "import pandas as pd  # Blocking library\n",
    "import numpy as np   # Blocking library (releases GIL)\n",
    "import requests      # Blocking library\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Pattern 1: Simple offloading with run_in_threadpool\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "@app.post(\"/process-csv\")\n",
    "async def process_csv_async(file_path: str):\n",
    "    \"\"\"\n",
    "    Run pandas (blocking) in thread pool.\n",
    "    \n",
    "    run_in_threadpool schedules the function in Starlette's\n",
    "    thread pool executor and awaits the result without\n",
    "    blocking the event loop.\n",
    "    \"\"\"\n",
    "    # This runs in a thread pool\n",
    "    df = await run_in_threadpool(pd.read_csv, file_path)\n",
    "    \n",
    "    # Process in thread pool too\n",
    "    result = await run_in_threadpool(lambda: df.describe().to_dict())\n",
    "    \n",
    "    return {\"statistics\": result}\n",
    "\n",
    "\n",
    "async def heavy_calculation(data: list):\n",
    "    \"\"\"CPU-intensive function to offload.\"\"\"\n",
    "    # Simulate heavy work\n",
    "    time.sleep(2)  # Blocking!\n",
    "    return sum(x ** 2 for x in data)\n",
    "\n",
    "\n",
    "@app.post(\"/calculate\")\n",
    "async def calculate_endpoint(data: list[int]):\n",
    "    \"\"\"\n",
    "    Offload CPU work to thread pool.\n",
    "    \n",
    "    Without run_in_threadpool, this would freeze the API.\n",
    "    \"\"\"\n",
    "    # Offload to thread\n",
    "    result = await run_in_threadpool(heavy_calculation, data)\n",
    "    \n",
    "    # Event loop is free during calculation\n",
    "    return {\"result\": result}\n",
    "\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Pattern 2: Multiple concurrent blocking operations\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "@app.post(\"/fetch-multiple\")\n",
    "async def fetch_multiple_urls(urls: list[str]):\n",
    "    \"\"\"\n",
    "    Fetch multiple URLs concurrently using thread pool.\n",
    "    \n",
    "    Even though requests is synchronous, we can run multiple\n",
    "    instances concurrently in the thread pool.\n",
    "    \"\"\"\n",
    "    # Create tasks for concurrent execution\n",
    "    tasks = [\n",
    "        run_in_threadpool(requests.get, url, timeout=30)\n",
    "        for url in urls\n",
    "    ]\n",
    "    \n",
    "    # Gather results concurrently\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "    \n",
    "    return {\n",
    "        \"results\": [\n",
    "            {\"url\": url, \"status\": r.status_code}\n",
    "            for url, r in zip(urls, responses)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Pattern 3: Custom ThreadPoolExecutor for heavy workloads\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import functools\n",
    "\n",
    "# Custom executor for CPU-intensive tasks\n",
    "cpu_executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix=\"cpu_worker\")\n",
    "\n",
    "@app.post(\"/ml-predict\")\n",
    "async def ml_prediction(data: dict):\n",
    "    \"\"\"\n",
    "    Machine learning inference (CPU-bound).\n",
    "    \n",
    "    Uses custom executor to isolate heavy CPU work.\n",
    "    \"\"\"\n",
    "    # Load model (blocking I/O)\n",
    "    model = await run_in_threadpool(load_model, \"model.pkl\")\n",
    "    \n",
    "    # Prediction (CPU-intensive)\n",
    "    # Use custom executor for better control\n",
    "    loop = asyncio.get_event_loop()\n",
    "    result = await loop.run_in_executor(\n",
    "        cpu_executor,\n",
    "        functools.partial(model.predict, data)\n",
    "    )\n",
    "    \n",
    "    return {\"prediction\": result.tolist()}\n",
    "\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Pattern 4: Database operations with sync drivers\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "import psycopg2  # Synchronous database driver\n",
    "\n",
    "def sync_db_query(user_id: int):\n",
    "    \"\"\"Synchronous database operation.\"\"\"\n",
    "    conn = psycopg2.connect(DATABASE_URL)\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))\n",
    "            return cur.fetchone()\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "@app.get(\"/users-sync/{user_id}\")\n",
    "async def get_user_sync_driver(user_id: int):\n",
    "    \"\"\"\n",
    "    Use synchronous database driver in async endpoint.\n",
    "    \n",
    "    Not recommended for production (use asyncpg instead),\n",
    "    but useful for legacy code migration.\n",
    "    \"\"\"\n",
    "    user = await run_in_threadpool(sync_db_query, user_id)\n",
    "    if not user:\n",
    "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
    "    return {\"user\": user}\n",
    "\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Pattern 5: File I/O with async facade\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "@app.post(\"/upload-process\")\n",
    "async def upload_and_process(file: UploadFile):\n",
    "    \"\"\"\n",
    "    Read file and process with blocking library.\n",
    "    \"\"\"\n",
    "    # Read file content (async)\n",
    "    content = await file.read()\n",
    "    \n",
    "    # Process in thread pool (blocking)\n",
    "    def process_content(data: bytes):\n",
    "        # Simulate processing with pandas/numpy\n",
    "        import io\n",
    "        df = pd.read_csv(io.BytesIO(data))\n",
    "        return df.head(100).to_json()\n",
    "    \n",
    "    result = await run_in_threadpool(process_content, content)\n",
    "    \n",
    "    return {\"processed\": result}\n",
    "\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Cleanup on shutdown\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "@app.on_event(\"shutdown\")\n",
    "async def shutdown_event():\n",
    "    \"\"\"Cleanup thread pools on application shutdown.\"\"\"\n",
    "    cpu_executor.shutdown(wait=True)\n",
    "```\n",
    "\n",
    "**Key Points about run_in_threadpool:**\n",
    "\n",
    "1. **Starlette's Default Pool**: FastAPI/Starlette maintains a default thread pool. You don't need to create one for simple use cases.\n",
    "2. **Context Matters**: `run_in_threadpool` is for `async def` endpoints. If you use `def`, FastAPI already runs it in a thread pool automatically.\n",
    "3. **GIL Considerations**: For pure Python CPU work, threads don't provide true parallelism (due to GIL). For numpy/pandas operations that release the GIL, threads do provide parallelism.\n",
    "4. **Process Pool**: For heavy pure-Python CPU work, consider `ProcessPoolExecutor` instead of `ThreadPoolExecutor` to bypass the GIL.\n",
    "\n",
    "---\n",
    "\n",
    "### 17.4 Background Tasks: `BackgroundTasks` for Fire-and-Forget\n",
    "\n",
    "Some operations shouldn't delay the HTTP response. Sending emails, processing images, or logging can run after the response is sent using FastAPI's `BackgroundTasks`.\n",
    "\n",
    "#### Background Tasks Implementation\n",
    "\n",
    "```python\n",
    "# background_tasks.py - Fire-and-forget operations\n",
    "\n",
    "from fastapi import FastAPI, BackgroundTasks, Depends\n",
    "from fastapi.mail import FastMail, MessageSchema\n",
    "from sqlalchemy.ext.asyncio import AsyncSession\n",
    "import asyncio\n",
    "import logging\n",
    "\n",
    "app = FastAPI()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Basic Background Tasks\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "def send_email_sync(email: str, subject: str, body: str):\n",
    "    \"\"\"\n",
    "    Synchronous email sending function.\n",
    "    \n",
    "    Runs in background thread after response is sent.\n",
    "    \"\"\"\n",
    "    # Simulate slow email sending\n",
    "    import time\n",
    "    time.sleep(2)\n",
    "    logger.info(f\"Email sent to {email}: {subject}\")\n",
    "\n",
    "\n",
    "@app.post(\"/register\")\n",
    "async def register_user(\n",
    "    user_data: UserCreate,\n",
    "    background_tasks: BackgroundTasks,\n",
    "    db: AsyncSession = Depends(get_db)\n",
    "):\n",
    "    \"\"\"\n",
    "    Register user and send welcome email in background.\n",
    "    \n",
    "    The response returns immediately (201 Created).\n",
    "    The email sends after the response is sent.\n",
    "    \"\"\"\n",
    "    # Create user (blocking, but fast)\n",
    "    user = await create_user(db, user_data)\n",
    "    \n",
    "    # Add email task to background\n",
    "    background_tasks.add_task(\n",
    "        send_email_sync,\n",
    "        email=user.email,\n",
    "        subject=\"Welcome!\",\n",
    "        body=f\"Hello {user.username}, welcome to our platform!\"\n",
    "    )\n",
    "    \n",
    "    # Return immediately - email sends after this\n",
    "    return {\"id\": user.id, \"message\": \"User created\"}\n",
    "\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Async Background Tasks\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "async def process_image_async(image_path: str, user_id: str):\n",
    "    \"\"\"\n",
    "    Async background task.\n",
    "    \n",
    "    Can use await because BackgroundTasks supports both\n",
    "    sync and async functions.\n",
    "    \"\"\"\n",
    "    # Simulate async image processing\n",
    "    await asyncio.sleep(5)\n",
    "    \n",
    "    # Update database\n",
    "    async with AsyncSessionLocal() as db:\n",
    "        await db.execute(\n",
    "            update(User)\n",
    "            .where(User.id == user_id)\n",
    "            .values(avatar_processed=True)\n",
    "        )\n",
    "        await db.commit()\n",
    "    \n",
    "    logger.info(f\"Image processed for user {user_id}\")\n",
    "\n",
    "\n",
    "@app.post(\"/upload-avatar\")\n",
    "async def upload_avatar(\n",
    "    file: UploadFile,\n",
    "    background_tasks: BackgroundTasks,\n",
    "    current_user: CurrentUser\n",
    "):\n",
    "    \"\"\"\n",
    "    Upload avatar and process in background.\n",
    "    \n",
    "    User gets immediate confirmation while image\n",
    "    is resized/optimized asynchronously.\n",
    "    \"\"\"\n",
    "    # Save file immediately (fast)\n",
    "    file_path = f\"/uploads/{current_user.id}_{file.filename}\"\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        content = await file.read()\n",
    "        f.write(content)\n",
    "    \n",
    "    # Process in background\n",
    "    background_tasks.add_task(\n",
    "        process_image_async,\n",
    "        image_path=file_path,\n",
    "        user_id=current_user.id\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"message\": \"Avatar uploaded, processing in background\",\n",
    "        \"path\": file_path\n",
    "    }\n",
    "\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Chaining Background Tasks\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "def log_activity_sync(user_id: str, action: str):\n",
    "    \"\"\"Log to external analytics (sync).\"\"\"\n",
    "    import requests\n",
    "    requests.post(\n",
    "        \"https://analytics.example.com/track\",\n",
    "        json={\"user_id\": user_id, \"action\": action}\n",
    "    )\n",
    "\n",
    "async def update_cache_async(user_id: str):\n",
    "    \"\"\"Update cache (async).\"\"\"\n",
    "    await redis.set(f\"user:{user_id}\", \"updated\", ex=3600)\n",
    "\n",
    "@app.post(\"/perform-action\")\n",
    "async def perform_action(\n",
    "    action: str,\n",
    "    background_tasks: BackgroundTasks,\n",
    "    current_user: CurrentUser\n",
    "):\n",
    "    \"\"\"\n",
    "    Chain multiple background tasks.\n",
    "    \n",
    "    Tasks run sequentially in the order added.\n",
    "    \"\"\"\n",
    "    # Primary action\n",
    "    result = await do_action(current_user.id, action)\n",
    "    \n",
    "    # Add multiple background tasks\n",
    "    background_tasks.add_task(\n",
    "        log_activity_sync,\n",
    "        current_user.id,\n",
    "        action\n",
    "    )\n",
    "    \n",
    "    background_tasks.add_task(\n",
    "        update_cache_async,\n",
    "        current_user.id\n",
    "    )\n",
    "    \n",
    "    background_tasks.add_task(\n",
    "        notify_followers,\n",
    "        current_user.id,\n",
    "        action\n",
    "    )\n",
    "    \n",
    "    return {\"status\": \"success\", \"result\": result}\n",
    "\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Error Handling in Background Tasks\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "async def risky_background_task(data: str):\n",
    "    \"\"\"\n",
    "    Background task with error handling.\n",
    "    \n",
    "    Errors in background tasks don't affect the HTTP response\n",
    "    but should be logged and monitored.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Risky operation\n",
    "        result = await external_api_call(data)\n",
    "        await save_to_db(result)\n",
    "    except Exception as e:\n",
    "        # Log error - response already sent\n",
    "        logger.error(f\"Background task failed: {e}\", exc_info=True)\n",
    "        \n",
    "        # Could send alert to monitoring\n",
    "        await send_alert_to_ops(f\"Task failed for data: {data}\")\n",
    "\n",
    "\n",
    "@app.post(\"/process-risky\")\n",
    "async def process_risky(\n",
    "    data: str,\n",
    "    background_tasks: BackgroundTasks\n",
    "):\n",
    "    \"\"\"\n",
    "    Fire risky operation in background.\n",
    "    \n",
    "    User gets 202 Accepted immediately.\n",
    "    Success/failure handled separately.\n",
    "    \"\"\"\n",
    "    background_tasks.add_task(risky_background_task, data)\n",
    "    \n",
    "    return {\n",
    "        \"status\": \"accepted\",\n",
    "        \"message\": \"Processing in background\"\n",
    "    }\n",
    "\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Task Dependencies (Advanced)\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "def get_task_function(task_type: str) -> Callable:\n",
    "    \"\"\"Factory for background task functions.\"\"\"\n",
    "    tasks = {\n",
    "        \"email\": send_email_sync,\n",
    "        \"process_image\": process_image_async,\n",
    "        \"log\": log_activity_sync\n",
    "    }\n",
    "    return tasks.get(task_type, lambda x: None)\n",
    "\n",
    "@app.post(\"/generic-task/{task_type}\")\n",
    "async def generic_task(\n",
    "    task_type: str,\n",
    "    payload: dict,\n",
    "    background_tasks: BackgroundTasks\n",
    "):\n",
    "    \"\"\"Dynamic background task selection.\"\"\"\n",
    "    task_func = get_task_function(task_type)\n",
    "    \n",
    "    background_tasks.add_task(task_func, **payload)\n",
    "    \n",
    "    return {\"task\": task_type, \"status\": \"queued\"}\n",
    "\n",
    "\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "# Important Limitations\n",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "\"\"\"\n",
    "IMPORTANT LIMITATIONS:\n",
    "\n",
    "1. No Result Access: You cannot get the return value of a\n",
    "   background task. If you need results, use Celery or RQ.\n",
    "\n",
    "2. No Retry: If a background task fails, it's gone.\n",
    "   For critical operations, use a proper task queue.\n",
    "\n",
    "3. Process Bound: If the process restarts, pending\n",
    "   background tasks are lost. Not for critical data.\n",
    "\n",
    "4. Sequential Execution: Tasks added to BackgroundTasks\n",
    "   run sequentially, not in parallel.\n",
    "\n",
    "For production-heavy workloads, use Celery, RQ, or ARQ instead.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Background Tasks vs Celery:**\n",
    "\n",
    "| Feature | BackgroundTasks | Celery/ARQ |\n",
    "|---------|----------------|------------|\n",
    "| **Complexity** | Built-in, simple | Requires broker (Redis/RabbitMQ) |\n",
    "| **Persistence** | In-memory only | Persistent queue |\n",
    "| **Retries** | No | Yes, with exponential backoff |\n",
    "| **Result storage** | No | Yes, with result backend |\n",
    "| **Monitoring** | Logs only | Web UI, detailed metrics |\n",
    "| **Distributed** | Single process | Multi-worker, multi-server |\n",
    "| **Use case** | Simple post-processing | Heavy async workloads |\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "In this chapter, you mastered Python's async model in the context of FastAPI:\n",
    "\n",
    "1. **`def` vs `async def`**: Use `async def` with native async libraries (databases, HTTP clients) to yield control to the event loop. Use `def` for CPU-bound work or blocking synchronous libraries (pandas, requests), letting FastAPI run them in thread pools automatically.\n",
    "\n",
    "2. **Blocking Identification**: Recognized that `time.sleep`, synchronous file I/O, and pure Python CPU calculations block the event loop if used in `async def`. Learned to detect blocking code through timing analysis and middleware.\n",
    "\n",
    "3. **`run_in_threadpool`**: Used `starlette.concurrency.run_in_threadpool` to explicitly offload blocking operations (database queries with sync drivers, ML inference, file processing) to thread pools within async endpoints, preventing event loop blockage.\n",
    "\n",
    "4. **Background Tasks**: Implemented fire-and-forget operations using FastAPI's `BackgroundTasks` for non-critical post-processing (emails, logging, cache warming) that shouldn't delay HTTP responses.\n",
    "\n",
    "**Performance Checklist:**\n",
    "- Profile endpoints to detect blocking code\n",
    "- Use `async def` only with truly async libraries\n",
    "- Offload blocking code with `run_in_threadpool`\n",
    "- Use `def` for CPU-intensive endpoints\n",
    "- Use BackgroundTasks for non-critical post-processing\n",
    "- For heavy workloads, migrate to Celery/ARQ\n",
    "\n",
    "---\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**Chapter 18: WebSockets** will cover:\n",
    "- **WebSocket Basics**: Establishing persistent, full-duplex connections between client and server for real-time communication\n",
    "- **Handling Messages**: Implementing bidirectional message sending and receiving with proper connection state management\n",
    "- **Broadcasting**: Broadcasting messages to multiple connected clients using connection managers and pub/sub patterns (Redis)\n",
    "- **WebSockets vs SSE**: Choosing between WebSockets (bidirectional) and Server-Sent Events (unidirectional) based on use case requirements\n",
    "\n",
    "This next chapter enables you to build real-time features like chat applications, live notifications, and collaborative editing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='../7. testing_and_quality_assurance/16. code_quality.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='18. websockets.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}