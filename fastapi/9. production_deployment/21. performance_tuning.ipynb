{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IX: Production Deployment\n",
    "\n",
    "## Chapter 21: Performance Tuning\n",
    "\n",
    "Deploying to production is only the beginning. To handle real-world traffic efficiently, you must tune concurrency settings, implement strategic caching, and optimize connection pooling. This chapter covers the quantitative adjustments that transform a working application into a high-performance system capable of handling thousands of concurrent requests.\n",
    "\n",
    "---\n",
    "\n",
    "### 21.1 Concurrency Settings: Workers, Threads, and Limits\n",
    "\n",
    "Concurrency tuning balances resource utilization against throughput and latency. The optimal configuration depends on your workload: I/O-bound (database/API calls) vs CPU-bound (calculations, data processing).\n",
    "\n",
    "#### Understanding Concurrency Models\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│              Concurrency Model Comparison                          │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                  │\n",
    "│  Synchronous Workers (sync)                                     │\n",
    "│  ┌─────────┐ ┌─────────┐ ┌─────────┐                           │\n",
    "│  │ Worker 1│ │ Worker 2│ │ Worker 3│                           │\n",
    "│  │ [====]  │ │ [====]  │ │ [====]  │                           │\n",
    "│  │ Request │ │ Request │ │ Request │                           │\n",
    "│  │ (blocks)│ │ (blocks)│ │ (blocks)│                           │\n",
    "│  └─────────┘ └─────────┘ └─────────┘                           │\n",
    "│                                                                  │\n",
    "│  • One request per worker at a time                             │\n",
    "│  • Worker blocked during I/O (database, API calls)                │\n",
    "│  • Need many workers for I/O-bound workloads                      │\n",
    "│  • Memory overhead per worker                                     │\n",
    "│                                                                  │\n",
    "│  ─────────────────────────────────────────────────────────────  │\n",
    "│                                                                  │\n",
    "│  Async Workers (Uvicorn)                                          │\n",
    "│  ┌─────────────────────────────────────────────────────────┐    │\n",
    "│  │                    Event Loop                            │    │\n",
    "│  │  ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐       │    │\n",
    "│  │  │ Req │ │ Req │ │ Req │ │ Req │ │ Req │ │ Req │       │    │\n",
    "│  │  │ [==│ │ [==│ │ [==│ │ [==│ │ [==│ │ [==│       │    │\n",
    "│  │  │await│ │await│ │await│ │await│ │await│ │await│       │    │\n",
    "│  │  └─────┘ └─────┘ └─────┘ └─────┘ └─────┘ └─────┘       │    │\n",
    "│  │                                                          │    │\n",
    "│  │  Single worker handles hundreds of concurrent requests   │    │\n",
    "│  │  Event loop switches during await (I/O operations)       │    │\n",
    "│  └─────────────────────────────────────────────────────────┘    │\n",
    "│                                                                  │\n",
    "│  • Thousands of concurrent connections per worker               │\n",
    "│  • Efficient for I/O-bound workloads                            │\n",
    "│  • Lower memory footprint                                         │\n",
    "│  • Requires async libraries (asyncpg, httpx, etc.)              │\n",
    "│                                                                  │\n",
    "│  ─────────────────────────────────────────────────────────────  │\n",
    "│                                                                  │\n",
    "│  Hybrid: Gunicorn + Uvicorn Workers                               │\n",
    "│  ┌─────────────────────────────────────────────────────────┐    │\n",
    "│  │                    Gunicorn (Master)                     │    │\n",
    "│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐       │    │\n",
    "│  │  │   Worker 1  │ │   Worker 2  │ │   Worker 3  │       │    │\n",
    "│  │  │  (Uvicorn)  │ │  (Uvicorn)  │ │  (Uvicorn)  │       │    │\n",
    "│  │  │  Event Loop │ │  Event Loop │ │  Event Loop │       │    │\n",
    "│  │  │  + App      │ │  + App      │ │  + App      │       │    │\n",
    "│  │  └─────────────┘ └─────────────┘ └─────────────┘       │    │\n",
    "│  └─────────────────────────────────────────────────────────┘    │\n",
    "│                                                                  │\n",
    "│  Best of both worlds:                                            │\n",
    "│  • Gunicorn manages worker processes (restarts, load balancing) │\n",
    "│  • Uvicorn workers handle async concurrency efficiently         │\n",
    "│  • Multiple workers utilize all CPU cores                        │\n",
    "│                                                                  │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "#### Tuning Formulas and Configuration\n",
    "\n",
    "```python\n",
    "# tuning_config.py - Production tuning guide\n",
    "\n",
    "\"\"\"\n",
    "Tuning Formulas:\n",
    "\n",
    "1. Worker Count (Gunicorn):\n",
    "   - CPU-bound: workers = CPU cores\n",
    "   - I/O-bound: workers = (2 x CPU cores) + 1\n",
    "   - With threads: workers = CPU cores, threads = 2-4 per worker\n",
    "\n",
    "2. Uvicorn Workers (within Gunicorn):\n",
    "   - Each Uvicorn worker runs one event loop\n",
    "   - Handles hundreds of concurrent connections\n",
    "   - Limited by memory (each worker loads full app)\n",
    "\n",
    "3. Database Pool Size:\n",
    "   - pool_size = (workers x threads) + buffer\n",
    "   - Example: 4 workers x 2 threads = 8 + 2 buffer = 10\n",
    "\n",
    "4. Connection Limits:\n",
    "   - Nginx worker_connections: 1024-4096 per worker\n",
    "   - System file descriptors: ulimit -n 65535\n",
    "\"\"\"\n",
    "\n",
    "# gunicorn_prod.conf.py - Production tuning\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "# Server socket\n",
    "bind = \"0.0.0.0:8000\"\n",
    "\n",
    "# Worker configuration\n",
    "workers = int(os.getenv(\"GUNICORN_WORKERS\", multiprocessing.cpu_count() * 2 + 1))\n",
    "worker_class = \"uvicorn.workers.UvicornWorker\"\n",
    "worker_connections = 1000\n",
    "\n",
    "# Thread configuration (for gthread worker, not UvicornWorker)\n",
    "# threads = 4\n",
    "\n",
    "# Worker lifecycle\n",
    "max_requests = 10000  # Restart workers after this many requests\n",
    "max_requests_jitter = 100  # Randomize to prevent thundering herd\n",
    "timeout = 120  # Seconds before killing silent worker\n",
    "graceful_timeout = 30  # Seconds to wait for graceful shutdown\n",
    "keepalive = 5  # Seconds to keep connection alive\n",
    "\n",
    "# Preload application (saves memory with copy-on-write)\n",
    "preload_app = True\n",
    "\n",
    "# Logging\n",
    "accesslog = \"-\"  # stdout\n",
    "errorlog = \"-\"   # stdout\n",
    "loglevel = os.getenv(\"LOG_LEVEL\", \"info\")\n",
    "access_log_format = '%(h)s %(l)s %(u)s %(t)s \"%(r)s\" %(s)s %(b)s \"%(f)s\" \"%(a)s\" %(D)s'\n",
    "\n",
    "# Process naming\n",
    "proc_name = \"fastapi_prod\"\n",
    "\n",
    "# Server mechanics\n",
    "daemon = False\n",
    "pidfile = \"/tmp/gunicorn.pid\"\n",
    "\n",
    "# SSL (handled by load balancer, but configurable)\n",
    "forwarded_allow_ips = \"*\"\n",
    "\n",
    "# Worker temporary directory\n",
    "worker_tmp_dir = \"/dev/shm\"\n",
    "\n",
    "# Hooks\n",
    "def on_starting(server):\n",
    "    \"\"\"Log startup configuration.\"\"\"\n",
    "    print(f\"Starting Gunicorn with {workers} workers\")\n",
    "\n",
    "def when_ready(server):\n",
    "    \"\"\"Called when workers are spawned.\"\"\"\n",
    "    print(\"Gunicorn is ready to accept connections\")\n",
    "\n",
    "def worker_int(worker):\n",
    "    \"\"\"Handle worker interrupt.\"\"\"\n",
    "    print(f\"Worker {worker.pid} interrupted\")\n",
    "\n",
    "def on_exit(server):\n",
    "    \"\"\"Cleanup on shutdown.\"\"\"\n",
    "    print(\"Gunicorn shutting down\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 20.2 Reverse Proxies: Nginx Configuration for FastAPI\n",
    "\n",
    "Nginx serves as the entry point to your application, handling SSL termination, static files, load balancing, and protection against slow clients.\n",
    "\n",
    "#### Complete Nginx Production Config\n",
    "\n",
    "```nginx\n",
    "# /etc/nginx/nginx.conf - Main configuration\n",
    "user nginx;\n",
    "worker_processes auto;  # Auto-detect CPU cores\n",
    "error_log /var/log/nginx/error.log warn;\n",
    "pid /var/run/nginx.pid;\n",
    "\n",
    "# Load modules\n",
    "load_module modules/ngx_http_headers_more_filter_module.so;\n",
    "\n",
    "events {\n",
    "    worker_connections 4096;  # Per worker\n",
    "    use epoll;  # Linux-specific, efficient\n",
    "    multi_accept on;\n",
    "}\n",
    "\n",
    "http {\n",
    "    # MIME types\n",
    "    include /etc/nginx/mime.types;\n",
    "    default_type application/octet-stream;\n",
    "\n",
    "    # Logging format with detailed timing\n",
    "    log_format main '$remote_addr - $remote_user [$time_local] \"$request\" '\n",
    "                    '$status $body_bytes_sent \"$http_referer\" '\n",
    "                    '\"$http_user_agent\" \"$http_x_forwarded_for\" '\n",
    "                    'rt=$request_time uct=\"$upstream_connect_time\" '\n",
    "                    'uht=\"$upstream_header_time\" urt=\"$upstream_response_time\"';\n",
    "\n",
    "    access_log /var/log/nginx/access.log main;\n",
    "\n",
    "    # Performance tuning\n",
    "    sendfile on;\n",
    "    tcp_nopush on;\n",
    "    tcp_nodelay on;\n",
    "    keepalive_timeout 65;\n",
    "    types_hash_max_size 2048;\n",
    "    server_tokens off;  # Hide nginx version\n",
    "\n",
    "    # Gzip compression\n",
    "    gzip on;\n",
    "    gzip_vary on;\n",
    "    gzip_proxied any;\n",
    "    gzip_comp_level 6;\n",
    "    gzip_min_length 1000;\n",
    "    gzip_types\n",
    "        text/plain\n",
    "        text/css\n",
    "        text/xml\n",
    "        text/javascript\n",
    "        application/json\n",
    "        application/javascript\n",
    "        application/xml+rss\n",
    "        application/rss+xml\n",
    "        font/truetype\n",
    "        font/opentype\n",
    "        application/vnd.ms-fontobject\n",
    "        image/svg+xml;\n",
    "\n",
    "    # Rate limiting zones\n",
    "    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;\n",
    "    limit_req_zone $binary_remote_addr zone=login:10m rate=1r/s;\n",
    "    limit_conn_zone $binary_remote_addr zone=addr:10m;\n",
    "\n",
    "    # Upstream (Gunicorn backend)\n",
    "    upstream fastapi_app {\n",
    "        least_conn;  # Load balancing method\n",
    "        \n",
    "        # Multiple app instances for horizontal scaling\n",
    "        server app:8000 weight=5;\n",
    "        # server app2:8000 weight=5;  # If running multiple containers\n",
    "        \n",
    "        keepalive 32;\n",
    "    }\n",
    "\n",
    "    # HTTP to HTTPS redirect\n",
    "    server {\n",
    "        listen 80;\n",
    "        server_name api.example.com;\n",
    "        return 301 https://$server_name$request_uri;\n",
    "    }\n",
    "\n",
    "    # HTTPS Server\n",
    "    server {\n",
    "        listen 443 ssl http2;\n",
    "        server_name api.example.com;\n",
    "\n",
    "        # SSL certificates (Let's Encrypt or commercial)\n",
    "        ssl_certificate /etc/nginx/ssl/fullchain.pem;\n",
    "        ssl_certificate_key /etc/nginx/ssl/privkey.pem;\n",
    "        ssl_trusted_certificate /etc/nginx/ssl/chain.pem;\n",
    "\n",
    "        # Modern SSL configuration\n",
    "        ssl_protocols TLSv1.2 TLSv1.3;\n",
    "        ssl_prefer_server_ciphers off;\n",
    "        ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384;\n",
    "        ssl_session_timeout 1d;\n",
    "        ssl_session_cache shared:SSL:50m;\n",
    "        ssl_stapling on;\n",
    "        ssl_stapling_verify on;\n",
    "\n",
    "        # Security headers\n",
    "        add_header X-Frame-Options \"SAMEORIGIN\" always;\n",
    "        add_header X-Content-Type-Options \"nosniff\" always;\n",
    "        add_header X-XSS-Protection \"1; mode=block\" always;\n",
    "        add_header Referrer-Policy \"strict-origin-when-cross-origin\" always;\n",
    "        add_header Permissions-Policy \"geolocation=(), microphone=(), camera=()\" always;\n",
    "        add_header Strict-Transport-Security \"max-age=63072000; includeSubDomains; preload\" always;\n",
    "\n",
    "        # Hide server version\n",
    "        more_clear_headers Server;\n",
    "\n",
    "        # Static files (if serving from FastAPI)\n",
    "        location /static {\n",
    "            alias /var/www/static;\n",
    "            expires 1y;\n",
    "            add_header Cache-Control \"public, immutable\";\n",
    "            access_log off;\n",
    "        }\n",
    "\n",
    "        # Health check (bypass rate limiting)\n",
    "        location /health {\n",
    "            access_log off;\n",
    "            proxy_pass http://fastapi_app;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "        }\n",
    "\n",
    "        # Main API location\n",
    "        location / {\n",
    "            # Rate limiting\n",
    "            limit_req zone=api burst=20 nodelay;\n",
    "            limit_conn addr 10;\n",
    "\n",
    "            # Proxy to Gunicorn\n",
    "            proxy_pass http://fastapi_app;\n",
    "            proxy_http_version 1.1;\n",
    "\n",
    "            # Headers\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "            proxy_set_header X-Request-ID $request_id;\n",
    "\n",
    "            # Timeouts\n",
    "            proxy_connect_timeout 30s;\n",
    "            proxy_send_timeout 30s;\n",
    "            proxy_read_timeout 30s;\n",
    "\n",
    "            # Buffering\n",
    "            proxy_buffering on;\n",
    "            proxy_buffer_size 4k;\n",
    "            proxy_buffers 8 4k;\n",
    "            proxy_busy_buffers_size 8k;\n",
    "\n",
    "            # WebSocket support\n",
    "            proxy_set_header Upgrade $http_upgrade;\n",
    "            proxy_set_header Connection \"upgrade\";\n",
    "        }\n",
    "\n",
    "        # Error pages\n",
    "        error_page 500 502 503 504 /50x.html;\n",
    "        location = /50x.html {\n",
    "            root /var/www/errors;\n",
    "            internal;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "In this chapter, you deployed FastAPI to production environments:\n",
    "\n",
    "1. **Process Managers**: Configured Gunicorn with Uvicorn workers, calculated optimal worker counts using `(2 x CPU) + 1` formula, set up graceful shutdown handling, and configured logging and health monitoring.\n",
    "\n",
    "2. **Reverse Proxies**: Deployed Nginx for SSL termination, static file serving with proper caching headers, rate limiting to prevent abuse, and load balancing across multiple Gunicorn workers with proper timeout and buffering configuration.\n",
    "\n",
    "3. **Cloud Deployment**: Deployed to AWS ECS with Fargate for serverless containers, Google Cloud Run for automatic scaling to zero, and modern platforms like Render and Fly.io for simplified developer experience with global edge deployment.\n",
    "\n",
    "4. **CI/CD Pipelines**: Built GitHub Actions workflows for automated testing, Docker image building with layer caching, container registry publishing, database migrations with Alembic, and zero-downtime deployment with health verification and automatic rollback.\n",
    "\n",
    "**Production Readiness Checklist:**\n",
    "- [ ] Gunicorn with Uvicorn workers (not development server)\n",
    "- [ ] Nginx reverse proxy with SSL termination\n",
    "- [ ] Database migrations run before code deployment\n",
    "- [ ] Health check endpoints implemented\n",
    "- [ ] Environment variables for all configuration (12-factor)\n",
    "- [ ] Logging aggregation (CloudWatch, Stackdriver, etc.)\n",
    "- [ ] Monitoring and alerting (CPU, memory, response times)\n",
    "- [ ] Database connection pooling configured\n",
    "- [ ] Redis/caching layer for hot data\n",
    "- [ ] Backup strategy for database and file storage\n",
    "\n",
    "---\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**Chapter 22: Error Handling** will cover:\n",
    "- **HTTPException**: Raising structured HTTP errors with appropriate status codes and detail messages\n",
    "- **Custom Exception Handlers**: Global error handling with consistent JSON error responses, logging integration, and user-friendly messages\n",
    "- **Structured Logging**: Implementing production-grade logging with correlation IDs, log levels, and centralized log aggregation\n",
    "\n",
    "This next chapter ensures your application handles failures gracefully and provides observability for debugging production issues."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
