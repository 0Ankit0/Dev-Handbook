{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VI: Database Integration\n",
    "\n",
    "## Chapter 14: NoSQL and ORMs\n",
    "\n",
    "While SQL databases excel at structured, relational data, modern applications often require flexible schemas, horizontal scalability, or specific data models that NoSQL databases provide. This chapter covers MongoDB integration for document-based storage, SQLModel for reduced boilerplate in SQL operations, and Alembic for managing database schema evolution\u2014completing your database toolkit for production FastAPI applications.\n",
    "\n",
    "---\n",
    "\n",
    "### 14.1 MongoDB with Motor/Beanie: Async Integration\n",
    "\n",
    "MongoDB is a document-oriented NoSQL database that stores data in flexible, JSON-like documents. Unlike SQL's rigid schemas, MongoDB allows varying fields per document, making it ideal for unstructured data, content management, real-time analytics, and rapid prototyping.\n",
    "\n",
    "#### Why MongoDB for FastAPI?\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502              SQL vs MongoDB: When to Use Which                   \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Use SQL (PostgreSQL/MySQL) when:                               \u2502\n",
    "\u2502  \u2713 Data relationships are complex and normalized                \u2502\n",
    "\u2502  \u2713 Strong ACID transactions across multiple collections       \u2502\n",
    "\u2502  \u2713 Strict schema enforcement is required                        \u2502\n",
    "\u2502  \u2713 Complex JOINs and aggregations are common                    \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Use MongoDB when:                                              \u2502\n",
    "\u2502  \u2713 Schema flexibility is needed (varying fields per document)    \u2502\n",
    "\u2502  \u2713 Rapid iteration with frequent schema changes                 \u2502\n",
    "\u2502  \u2713 Horizontal scaling (sharding) is required                    \u2502\n",
    "\u2502  \u2713 Storing hierarchical/nested data naturally                    \u2502\n",
    "\u2502  \u2713 High write throughput with eventual consistency acceptable   \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Hybrid Approach (Production Recommended):                        \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n",
    "\u2502  \u2502 PostgreSQL  \u2502    \u2502   MongoDB   \u2502    \u2502    Redis    \u2502        \u2502\n",
    "\u2502  \u2502 (Users,     \u2502    \u2502 (Logs,      \u2502    \u2502 (Cache,     \u2502        \u2502\n",
    "\u2502  \u2502  Transactions)\u2502    \u2502  Analytics, \u2502    \u2502  Sessions)  \u2502        \u2502\n",
    "\u2502  \u2502             \u2502    \u2502  Content)   \u2502    \u2502             \u2502        \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "#### Setting Up Motor (Async MongoDB Driver)\n",
    "\n",
    "Motor is the official async Python driver for MongoDB, built on top of asyncio and PyMongo.\n",
    "\n",
    "```python\n",
    "# mongodb_setup.py\n",
    "from motor.motor_asyncio import AsyncIOMotorClient, AsyncIOMotorDatabase\n",
    "from fastapi import FastAPI\n",
    "from contextlib import asynccontextmanager\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# MongoDB connection string\n",
    "# Format: mongodb://username:password@host:port/database?options\n",
    "MONGODB_URL = \"mongodb://localhost:27017\"\n",
    "DATABASE_NAME = \"fastapi_app\"\n",
    "\n",
    "# Global client (initialized in lifespan)\n",
    "mongo_client: AsyncIOMotorClient | None = None\n",
    "\n",
    "\n",
    "class MongoDB:\n",
    "    \"\"\"\n",
    "    MongoDB connection manager.\n",
    "    \n",
    "    Encapsulates client and database access with proper lifecycle management.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, url: str, db_name: str):\n",
    "        self.url = url\n",
    "        self.db_name = db_name\n",
    "        self.client: AsyncIOMotorClient | None = None\n",
    "        self.database: AsyncIOMotorDatabase | None = None\n",
    "    \n",
    "    async def connect(self):\n",
    "        \"\"\"Initialize connection to MongoDB.\"\"\"\n",
    "        logger.info(f\"Connecting to MongoDB at {self.url}\")\n",
    "        \n",
    "        self.client = AsyncIOMotorClient(\n",
    "            self.url,\n",
    "            # Connection pool settings\n",
    "            maxPoolSize=10,      # Max connections in pool\n",
    "            minPoolSize=1,       # Min connections maintained\n",
    "            maxIdleTimeMS=60000, # Close idle connections after 60s\n",
    "            waitQueueTimeoutMS=5000, # Timeout waiting for connection\n",
    "        )\n",
    "        \n",
    "        self.database = self.client[self.db_name]\n",
    "        \n",
    "        # Verify connection\n",
    "        await self.client.admin.command('ping')\n",
    "        logger.info(\"MongoDB connected successfully\")\n",
    "    \n",
    "    async def disconnect(self):\n",
    "        \"\"\"Close MongoDB connection.\"\"\"\n",
    "        if self.client:\n",
    "            logger.info(\"Closing MongoDB connection\")\n",
    "            self.client.close()\n",
    "    \n",
    "    def get_collection(self, collection_name: str):\n",
    "        \"\"\"Get a collection (table equivalent).\"\"\"\n",
    "        if not self.database:\n",
    "            raise RuntimeError(\"Database not initialized\")\n",
    "        return self.database[collection_name]\n",
    "\n",
    "\n",
    "# Global instance\n",
    "mongodb = MongoDB(MONGODB_URL, DATABASE_NAME)\n",
    "\n",
    "\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    \"\"\"Application lifespan handler for MongoDB.\"\"\"\n",
    "    await mongodb.connect()\n",
    "    yield\n",
    "    await mongodb.disconnect()\n",
    "\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI(lifespan=lifespan)\n",
    "\n",
    "\n",
    "# Dependency to get database\n",
    "async def get_mongodb() -> AsyncIOMotorDatabase:\n",
    "    \"\"\"Dependency that provides MongoDB database.\"\"\"\n",
    "    if not mongodb.database:\n",
    "        raise RuntimeError(\"MongoDB not initialized\")\n",
    "    return mongodb.database\n",
    "\n",
    "\n",
    "# Alternative: get specific collection\n",
    "async def get_users_collection():\n",
    "    \"\"\"Get users collection.\"\"\"\n",
    "    return mongodb.get_collection(\"users\")\n",
    "```\n",
    "\n",
    "**Motor Configuration Explained:**\n",
    "\n",
    "1. **`AsyncIOMotorClient`**: The async client for MongoDB. Unlike synchronous PyMongo, this uses asyncio for non-blocking I/O.\n",
    "2. **Connection Pooling**: `maxPoolSize` and `minPoolSize` manage connections similarly to SQLAlchemy's engine pool.\n",
    "3. **`get_collection`**: MongoDB uses \"collections\" (equivalent to SQL tables) that store \"documents\" (equivalent to rows).\n",
    "4. **Ping Command**: Verifies connectivity by sending the admin ping command.\n",
    "\n",
    "#### Beanie ODM: Object Document Mapper\n",
    "\n",
    "Beanie is an asynchronous Python ODM (Object Document Mapper) for MongoDB, built on top of Motor and Pydantic. It provides SQLAlchemy-like functionality for MongoDB.\n",
    "\n",
    "```python\n",
    "# beanie_models.py\n",
    "from beanie import Document, Indexed, Insert, Replace, Before\n",
    "from pydantic import BaseModel, Field, EmailStr\n",
    "from typing import Optional, List\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "# Embedded documents (sub-documents)\n",
    "class Address(BaseModel):\n",
    "    \"\"\"Embedded address document.\"\"\"\n",
    "    street: str\n",
    "    city: str\n",
    "    state: str\n",
    "    zip_code: str\n",
    "    country: str = \"USA\"\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"street\": \"123 Main St\",\n",
    "                \"city\": \"New York\",\n",
    "                \"state\": \"NY\",\n",
    "                \"zip_code\": \"10001\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "class Profile(BaseModel):\n",
    "    \"\"\"Embedded profile document.\"\"\"\n",
    "    bio: Optional[str] = None\n",
    "    avatar_url: Optional[str] = None\n",
    "    social_links: dict[str, str] = Field(default_factory=dict)\n",
    "    preferences: dict = Field(default_factory=dict)\n",
    "\n",
    "\n",
    "# Main Document (equivalent to SQL table)\n",
    "class User(Document):\n",
    "    \"\"\"\n",
    "    User document model using Beanie.\n",
    "    \n",
    "    Documents in MongoDB are similar to JSON objects with flexible schemas.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Beanie automatically uses _id field, but we can customize\n",
    "    id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n",
    "    \n",
    "    # Indexed fields for query performance\n",
    "    # Indexed creates MongoDB index automatically\n",
    "    username: Indexed(str, unique=True)  # Unique index\n",
    "    email: Indexed(EmailStr, unique=True)  # Email with unique index\n",
    "    \n",
    "    # Hashed password\n",
    "    hashed_password: str\n",
    "    \n",
    "    # Optional fields\n",
    "    full_name: Optional[str] = None\n",
    "    \n",
    "    # Embedded documents (nested objects)\n",
    "    address: Optional[Address] = None\n",
    "    profile: Profile = Field(default_factory=Profile)\n",
    "    \n",
    "    # Lists\n",
    "    tags: List[str] = Field(default_factory=list)\n",
    "    roles: List[str] = Field(default=[\"user\"])\n",
    "    \n",
    "    # Timestamps\n",
    "    created_at: datetime = Field(default_factory=datetime.utcnow)\n",
    "    updated_at: Optional[datetime] = None\n",
    "    is_active: bool = True\n",
    "    \n",
    "    # Settings for the collection\n",
    "    class Settings:\n",
    "        name = \"users\"  # Collection name\n",
    "        indexes = [\n",
    "            # Compound index example\n",
    "            [(\"username\", 1), (\"email\", 1)],  # 1 = ascending\n",
    "            # Text index for search\n",
    "            [(\"profile.bio\", \"text\"), (\"full_name\", \"text\")]\n",
    "        ]\n",
    "    \n",
    "    # Event hooks (similar to SQLAlchemy events)\n",
    "    @Before([Insert, Replace])\n",
    "    async def update_timestamp(self):\n",
    "        \"\"\"Update timestamp before insert or replace.\"\"\"\n",
    "        self.updated_at = datetime.utcnow()\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"username\": \"alice\",\n",
    "                \"email\": \"alice@example.com\",\n",
    "                \"full_name\": \"Alice Wonderland\",\n",
    "                \"tags\": [\"developer\", \"python\"],\n",
    "                \"roles\": [\"user\"]\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "class Item(Document):\n",
    "    \"\"\"Item document referencing User.\"\"\"\n",
    "    \n",
    "    id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n",
    "    title: Indexed(str)  # Index for search performance\n",
    "    description: Optional[str] = None\n",
    "    \n",
    "    # Reference to User (similar to ForeignKey but flexible)\n",
    "    # In MongoDB, references are just stored as IDs\n",
    "    owner_id: Indexed(str)  # Store user ID as string reference\n",
    "    \n",
    "    # Embedded sub-documents (denormalization)\n",
    "    # Storing owner snapshot reduces queries but needs syncing\n",
    "    owner_snapshot: Optional[dict] = None\n",
    "    \n",
    "    # Array of embedded documents\n",
    "    metadata: dict = Field(default_factory=dict)\n",
    "    tags: List[str] = Field(default_factory=list)\n",
    "    \n",
    "    created_at: datetime = Field(default_factory=datetime.utcnow)\n",
    "    updated_at: Optional[datetime] = None\n",
    "    \n",
    "    class Settings:\n",
    "        name = \"items\"\n",
    "        indexes = [\n",
    "            [(\"owner_id\", 1), (\"created_at\", -1)],  # Compound index\n",
    "        ]\n",
    "    \n",
    "    @Before([Insert, Replace])\n",
    "    async def update_timestamp(self):\n",
    "        self.updated_at = datetime.utcnow()\n",
    "\n",
    "\n",
    "# Initialize Beanie with FastAPI\n",
    "async def init_beanie():\n",
    "    \"\"\"Initialize Beanie with document models.\"\"\"\n",
    "    from beanie import init_beanie\n",
    "    \n",
    "    await init_beanie(\n",
    "        database=mongodb.database,\n",
    "        document_models=[User, Item]  # Register all models\n",
    "    )\n",
    "```\n",
    "\n",
    "**Beanie Concepts Explained:**\n",
    "\n",
    "1. **`Document`**: Base class for MongoDB collections. Unlike SQLAlchemy tables, documents can have varying fields\u2014some users might have `phone`, others might not.\n",
    "2. **`Indexed`**: Creates MongoDB indexes automatically. MongoDB indexes are crucial for query performance, similar to SQL.\n",
    "3. **Embedded Documents**: `Address` and `Profile` are Pydantic models stored directly inside the User document. This is \"denormalization\"\u2014storing related data together to avoid joins.\n",
    "4. **Event Hooks**: `@Before([Insert, Replace])` runs before saving, similar to SQLAlchemy's `@event.listens_for`.\n",
    "5. **References**: MongoDB references are manual (just storing IDs). Unlike SQL foreign keys, there's no automatic enforcement\u2014you must query separately or use embedded documents.\n",
    "\n",
    "#### CRUD Operations with Beanie\n",
    "\n",
    "```python\n",
    "# mongodb_crud.py\n",
    "from fastapi import APIRouter, HTTPException, status, Query\n",
    "from beanie import PydanticObjectId\n",
    "from typing import List, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "router = APIRouter(prefix=\"/mongo/users\", tags=[\"mongodb\"])\n",
    "\n",
    "# CREATE\n",
    "@router.post(\"/\", response_model=User, status_code=201)\n",
    "async def create_user(user_data: UserCreate):\n",
    "    \"\"\"\n",
    "    Create new user in MongoDB.\n",
    "    \n",
    "    Unlike SQL, we don't need to commit\u2014insert is immediate.\n",
    "    \"\"\"\n",
    "    # Check existing (unique indexes enforce this, but check for better error)\n",
    "    existing = await User.find_one(\n",
    "        {\"$or\": [{\"email\": user_data.email}, {\"username\": user_data.username}]}\n",
    "    )\n",
    "    if existing:\n",
    "        raise HTTPException(\n",
    "            status_code=400,\n",
    "            detail=\"User with this email or username exists\"\n",
    "        )\n",
    "    \n",
    "    # Hash password\n",
    "    from passlib.context import CryptContext\n",
    "    pwd_context = CryptContext(schemes=[\"bcrypt\"])\n",
    "    \n",
    "    # Create document\n",
    "    user = User(\n",
    "        username=user_data.username,\n",
    "        email=user_data.email,\n",
    "        hashed_password=pwd_context.hash(user_data.password),\n",
    "        full_name=user_data.full_name,\n",
    "        address=user_data.address,  # Can be None (flexible schema)\n",
    "        profile=user_data.profile or Profile()\n",
    "    )\n",
    "    \n",
    "    # Insert into MongoDB\n",
    "    # Beanie handles the insert and returns the document with ID\n",
    "    await user.insert()\n",
    "    \n",
    "    return user\n",
    "\n",
    "\n",
    "# READ with Querying\n",
    "@router.get(\"/\", response_model=List[User])\n",
    "async def list_users(\n",
    "    skip: int = Query(0, ge=0),\n",
    "    limit: int = Query(10, ge=1, le=100),\n",
    "    search: Optional[str] = None,\n",
    "    tag: Optional[str] = None,\n",
    "    is_active: Optional[bool] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Query users with filters.\n",
    "    \n",
    "    MongoDB queries use JSON-like syntax (dictionaries).\n",
    "    \"\"\"\n",
    "    # Build query dynamically\n",
    "    query = {}\n",
    "    \n",
    "    if search:\n",
    "        # Text search using $regex (case insensitive)\n",
    "        query[\"$or\"] = [\n",
    "            {\"username\": {\"$regex\": search, \"$options\": \"i\"}},\n",
    "            {\"email\": {\"$regex\": search, \"$options\": \"i\"}},\n",
    "            {\"full_name\": {\"$regex\": search, \"$options\": \"i\"}}\n",
    "        ]\n",
    "    \n",
    "    if tag:\n",
    "        query[\"tags\"] = {\"$in\": [tag]}  # Array contains\n",
    "    \n",
    "    if is_active is not None:\n",
    "        query[\"is_active\"] = is_active\n",
    "    \n",
    "    # Execute query with pagination\n",
    "    users = await User.find(query).skip(skip).limit(limit).to_list()\n",
    "    \n",
    "    return users\n",
    "\n",
    "\n",
    "# READ Single\n",
    "@router.get(\"/{user_id}\", response_model=User)\n",
    "async def get_user(user_id: str):\n",
    "    \"\"\"Get user by ID.\"\"\"\n",
    "    # Beanie provides get() for ID lookup\n",
    "    user = await User.get(user_id)\n",
    "    \n",
    "    if not user:\n",
    "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
    "    \n",
    "    return user\n",
    "\n",
    "\n",
    "# UPDATE (Partial - PATCH)\n",
    "@router.patch(\"/{user_id}\", response_model=User)\n",
    "async def update_user(user_id: str, update_data: UserUpdate):\n",
    "    \"\"\"\n",
    "    Partial update using Beanie's update methods.\n",
    "    \n",
    "    MongoDB updates can target specific fields without loading\n",
    "    the whole document (unlike SQLAlchemy).\n",
    "    \"\"\"\n",
    "    user = await User.get(user_id)\n",
    "    if not user:\n",
    "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
    "    \n",
    "    # Update only provided fields\n",
    "    update_dict = update_data.model_dump(exclude_unset=True)\n",
    "    \n",
    "    if update_dict:\n",
    "        # Use $set to update specific fields atomically\n",
    "        await user.set(update_dict)\n",
    "    \n",
    "    return user\n",
    "\n",
    "\n",
    "# UPDATE (Full - PUT)\n",
    "@router.put(\"/{user_id}\", response_model=User)\n",
    "async def replace_user(user_id: str, user_data: UserCreate):\n",
    "    \"\"\"\n",
    "    Replace entire document.\n",
    "    \n",
    "    Note: This replaces the entire document, removing fields not provided.\n",
    "    \"\"\"\n",
    "    user = await User.get(user_id)\n",
    "    if not user:\n",
    "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
    "    \n",
    "    # Update fields\n",
    "    user.username = user_data.username\n",
    "    user.email = user_data.email\n",
    "    if user_data.full_name:\n",
    "        user.full_name = user_data.full_name\n",
    "    # Note: This keeps old password, hashed_password not in UserCreate\n",
    "    \n",
    "    await user.replace()\n",
    "    return user\n",
    "\n",
    "\n",
    "# DELETE\n",
    "@router.delete(\"/{user_id}\", status_code=204)\n",
    "async def delete_user(user_id: str):\n",
    "    \"\"\"Delete user and optionally their items.\"\"\"\n",
    "    user = await User.get(user_id)\n",
    "    if not user:\n",
    "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
    "    \n",
    "    # Delete user's items first (manual cascade)\n",
    "    await Item.find({\"owner_id\": user_id}).delete()\n",
    "    \n",
    "    # Delete user\n",
    "    await user.delete()\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# Advanced Aggregation\n",
    "@router.get(\"/stats/activity\")\n",
    "async def get_user_stats():\n",
    "    \"\"\"\n",
    "    MongoDB aggregation pipeline example.\n",
    "    \n",
    "    Similar to SQL GROUP BY but with more flexible stages.\n",
    "    \"\"\"\n",
    "    pipeline = [\n",
    "        # Match stage (filter)\n",
    "        {\"$match\": {\"is_active\": True}},\n",
    "        \n",
    "        # Group stage (aggregation)\n",
    "        {\"$group\": {\n",
    "            \"_id\": \"$roles\",  # Group by roles array\n",
    "            \"count\": {\"$sum\": 1},\n",
    "            \"avg_tags\": {\"$avg\": {\"$size\": \"$tags\"}}\n",
    "        }},\n",
    "        \n",
    "        # Sort stage\n",
    "        {\"$sort\": {\"count\": -1}},\n",
    "        \n",
    "        # Limit results\n",
    "        {\"$limit\": 10}\n",
    "    ]\n",
    "    \n",
    "    results = await User.aggregate(pipeline).to_list()\n",
    "    return results\n",
    "\n",
    "\n",
    "# References and Joins (Manual)\n",
    "@router.get(\"/{user_id}/items\", response_model=List[Item])\n",
    "async def get_user_items(user_id: str):\n",
    "    \"\"\"\n",
    "    Get items belonging to user.\n",
    "    \n",
    "    MongoDB doesn't have JOINs\u2014we query separately or use $lookup.\n",
    "    \"\"\"\n",
    "    # Verify user exists\n",
    "    user = await User.get(user_id)\n",
    "    if not user:\n",
    "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
    "    \n",
    "    # Query items collection separately\n",
    "    # This is N+1 if done in a loop\u2014query all at once instead\n",
    "    items = await Item.find({\"owner_id\": user_id}).to_list()\n",
    "    \n",
    "    return items\n",
    "\n",
    "\n",
    "# Bulk Operations\n",
    "@router.post(\"/bulk\", status_code=201)\n",
    "async def bulk_create_users(users: List[UserCreate]):\n",
    "    \"\"\"\n",
    "    Bulk insert for better performance.\n",
    "    \n",
    "    MongoDB bulk writes are faster than individual inserts.\n",
    "    \"\"\"\n",
    "    from passlib.context import CryptContext\n",
    "    pwd_context = CryptContext(schemes=[\"bcrypt\"])\n",
    "    \n",
    "    documents = []\n",
    "    for user_data in users:\n",
    "        user = User(\n",
    "            username=user_data.username,\n",
    "            email=user_data.email,\n",
    "            hashed_password=pwd_context.hash(user_data.password),\n",
    "            full_name=user_data.full_name\n",
    "        )\n",
    "        documents.append(user)\n",
    "    \n",
    "    # Insert many\n",
    "    await User.insert_many(documents)\n",
    "    \n",
    "    return {\"created\": len(documents)}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 14.2 SQLModel: Using Tiangolo's SQLModel (Pydantic + SQLAlchemy)\n",
    "\n",
    "SQLModel is a library created by Sebasti\u00e1n Ram\u00edrez (creator of FastAPI) that combines Pydantic and SQLAlchemy into a single model. This eliminates the need to maintain separate Pydantic schemas and SQLAlchemy models.\n",
    "\n",
    "#### SQLModel Architecture\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    SQLModel Architecture                           \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Traditional Approach (without SQLModel):                      \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502\n",
    "\u2502  \u2502   Pydantic  \u2502          \u2502  SQLAlchemy \u2502                      \u2502\n",
    "\u2502  \u2502   Schema    \u2502          \u2502    Model    \u2502                      \u2502\n",
    "\u2502  \u2502  (API I/O)  \u2502          \u2502  (Database) \u2502                      \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502\n",
    "\u2502         \u2502                        \u2502                              \u2502\n",
    "\u2502         \u2502 Duplicate fields       \u2502                              \u2502\n",
    "\u2502         \u2502 (username, email, etc)\u2502                              \u2502\n",
    "\u2502         \u2502                        \u2502                              \u2502\n",
    "\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2502\n",
    "\u2502                     \u2502                                           \u2502\n",
    "\u2502              Manual mapping logic                               \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  SQLModel Approach (single source of truth):                     \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                        \u2502\n",
    "\u2502  \u2502              SQLModel               \u2502                        \u2502\n",
    "\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502                        \u2502\n",
    "\u2502  \u2502  \u2502      Pydantic BaseModel     \u2502    \u2502                        \u2502\n",
    "\u2502  \u2502  \u2502  (Validation + Serialization) \u2502    \u2502                        \u2502\n",
    "\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502                        \u2502\n",
    "\u2502  \u2502              \u2502                      \u2502                        \u2502\n",
    "\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502                        \u2502\n",
    "\u2502  \u2502  \u2502     SQLAlchemy Table        \u2502    \u2502                        \u2502\n",
    "\u2502  \u2502  \u2502    (Database persistence)    \u2502    \u2502                        \u2502\n",
    "\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502                        \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Benefits:                                                       \u2502\n",
    "\u2502  \u2713 One model for API and database                               \u2502\n",
    "\u2502  \u2713 Automatic validation from Pydantic                           \u2502\n",
    "\u2502  \u2713 Full SQLAlchemy compatibility                                \u2502\n",
    "\u2502  \u2713 Type hints throughout                                         \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "#### SQLModel Setup and Models\n",
    "\n",
    "```python\n",
    "# sqlmodel_models.py\n",
    "from sqlmodel import SQLModel, Field, Relationship, create_engine, Session, select\n",
    "from typing import Optional, List\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "# SQLModel uses table=True for database models\n",
    "# and inherits from SQLModel for Pydantic validation\n",
    "\n",
    "class Hero(SQLModel, table=True):\n",
    "    \"\"\"\n",
    "    SQLModel combines Pydantic and SQLAlchemy.\n",
    "    \n",
    "    - table=True makes it a database table\n",
    "    - Field() configures both Pydantic and SQLAlchemy\n",
    "    \"\"\"\n",
    "    \n",
    "    __tablename__ = \"heroes\"\n",
    "    \n",
    "    # Primary key with default\n",
    "    # Field(..., primary_key=True) marks as primary key\n",
    "    id: Optional[str] = Field(\n",
    "        default_factory=lambda: str(uuid.uuid4()),\n",
    "        primary_key=True\n",
    "    )\n",
    "    \n",
    "    # Indexed field\n",
    "    # index=True creates database index\n",
    "    name: str = Field(index=True)\n",
    "    \n",
    "    # Optional field with constraint\n",
    "    secret_name: str = Field(\n",
    "        min_length=3,\n",
    "        max_length=50,\n",
    "        description=\"Hero's secret identity\"\n",
    "    )\n",
    "    \n",
    "    # Integer with validation\n",
    "    age: Optional[int] = Field(\n",
    "        default=None,\n",
    "        ge=0,  # Pydantic validation: greater than or equal to 0\n",
    "        le=1000,  # Less than or equal to 1000\n",
    "        description=\"Age in years\"\n",
    "    )\n",
    "    \n",
    "    # Boolean with default\n",
    "    is_active: bool = Field(default=True)\n",
    "    \n",
    "    # Timestamp with default\n",
    "    created_at: datetime = Field(default_factory=datetime.utcnow)\n",
    "    \n",
    "    # Foreign key (optional, for relationships)\n",
    "    team_id: Optional[str] = Field(\n",
    "        default=None,\n",
    "        foreign_key=\"teams.id\"  # References Teams table\n",
    "    )\n",
    "    \n",
    "    # Relationship (not a column, just ORM navigation)\n",
    "    # sa_relationship_kwargs configures SQLAlchemy relationship\n",
    "    team: Optional[\"Team\"] = Relationship(\n",
    "        back_populates=\"heroes\",\n",
    "        sa_relationship_kwargs={\"lazy\": \"selectin\"}\n",
    "    )\n",
    "    \n",
    "    # Config for Pydantic\n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"name\": \"Deadpond\",\n",
    "                \"secret_name\": \"Dive Wilson\",\n",
    "                \"age\": 30\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "class Team(SQLModel, table=True):\n",
    "    \"\"\"Team model with relationship to Heroes.\"\"\"\n",
    "    \n",
    "    __tablename__ = \"teams\"\n",
    "    \n",
    "    id: Optional[str] = Field(\n",
    "        default_factory=lambda: str(uuid.uuid4()),\n",
    "        primary_key=True\n",
    "    )\n",
    "    name: str = Field(index=True)\n",
    "    headquarters: str\n",
    "    \n",
    "    # Relationship to heroes\n",
    "    heroes: List[\"Hero\"] = Relationship(back_populates=\"team\")\n",
    "\n",
    "\n",
    "# Pydantic-only models (for API requests/responses)\n",
    "# When table=False (default), it's just a Pydantic model\n",
    "\n",
    "class HeroCreate(SQLModel):\n",
    "    \"\"\"\n",
    "    Model for creating heroes.\n",
    "    \n",
    "    Without table=True, this is just Pydantic validation.\n",
    "    Excludes id (auto-generated) and created_at.\n",
    "    \"\"\"\n",
    "    name: str = Field(min_length=1, max_length=100)\n",
    "    secret_name: str = Field(min_length=3)\n",
    "    age: Optional[int] = Field(default=None, ge=0)\n",
    "    team_id: Optional[str] = None\n",
    "\n",
    "\n",
    "class HeroResponse(SQLModel):\n",
    "    \"\"\"Response model (excludes secret_name for privacy).\"\"\"\n",
    "    id: str\n",
    "    name: str\n",
    "    age: Optional[int]\n",
    "    is_active: bool\n",
    "    team_id: Optional[str]\n",
    "\n",
    "\n",
    "class HeroUpdate(SQLModel):\n",
    "    \"\"\"Update model - all fields optional.\"\"\"\n",
    "    name: Optional[str] = None\n",
    "    secret_name: Optional[str] = None\n",
    "    age: Optional[int] = None\n",
    "    is_active: Optional[bool] = None\n",
    "    team_id: Optional[str] = None\n",
    "\n",
    "\n",
    "# Database setup (using SQLAlchemy engine)\n",
    "# SQLModel uses SQLAlchemy under the hood\n",
    "DATABASE_URL = \"postgresql+asyncpg://user:pass@localhost/db\"\n",
    "\n",
    "# For async\n",
    "from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "engine = create_async_engine(DATABASE_URL, echo=True)\n",
    "AsyncSessionLocal = sessionmaker(\n",
    "    engine,\n",
    "    class_=AsyncSession,\n",
    "    expire_on_commit=False\n",
    ")\n",
    "\n",
    "\n",
    "# Dependency\n",
    "async def get_session() -> AsyncSession:\n",
    "    \"\"\"Get database session.\"\"\"\n",
    "    async with AsyncSessionLocal() as session:\n",
    "        yield session\n",
    "```\n",
    "\n",
    "**SQLModel Field Configuration:**\n",
    "\n",
    "1. **`Field()` parameters**:\n",
    "   - `primary_key=True`: Database primary key\n",
    "   - `index=True`: Create database index\n",
    "   - `foreign_key=\"table.column\"`: Foreign key constraint\n",
    "   - `min_length`, `max_length`, `ge`, `le`: Pydantic validation\n",
    "   - `default_factory`: Callable for default values (like UUID generation)\n",
    "\n",
    "2. **Relationships**:\n",
    "   - `Relationship(back_populates=...)`: Bidirectional navigation\n",
    "   - `sa_relationship_kwargs`: Pass additional SQLAlchemy config\n",
    "\n",
    "3. **Table vs Schema**:\n",
    "   - `table=True`: Database model (creates table)\n",
    "   - No `table` arg or `table=False`: Pydantic-only (validation/serialization)\n",
    "\n",
    "#### SQLModel CRUD Operations\n",
    "\n",
    "```python\n",
    "# sqlmodel_crud.py\n",
    "from fastapi import APIRouter, Depends, HTTPException, status\n",
    "from sqlalchemy.ext.asyncio import AsyncSession\n",
    "from sqlalchemy.orm import selectinload\n",
    "from sqlmodel import select\n",
    "from typing import List\n",
    "\n",
    "router = APIRouter(prefix=\"/heroes\", tags=[\"heroes\"])\n",
    "\n",
    "# CREATE\n",
    "@router.post(\"/\", response_model=HeroResponse, status_code=201)\n",
    "async def create_hero(\n",
    "    hero: HeroCreate,\n",
    "    session: AsyncSession = Depends(get_session)\n",
    "):\n",
    "    \"\"\"\n",
    "    Create hero using SQLModel.\n",
    "    \n",
    "    SQLModel instances work as both Pydantic models (validation)\n",
    "    and SQLAlchemy models (database).\n",
    "    \"\"\"\n",
    "    # Validate with Pydantic (automatic via FastAPI)\n",
    "    # hero is already validated HeroCreate instance\n",
    "    \n",
    "    # Convert to table model\n",
    "    db_hero = Hero(\n",
    "        name=hero.name,\n",
    "        secret_name=hero.secret_name,\n",
    "        age=hero.age,\n",
    "        team_id=hero.team_id\n",
    "    )\n",
    "    \n",
    "    # SQLAlchemy operations (same as Chapter 13)\n",
    "    session.add(db_hero)\n",
    "    await session.commit()\n",
    "    await session.refresh(db_hero)\n",
    "    \n",
    "    return db_hero\n",
    "\n",
    "\n",
    "# READ with eager loading\n",
    "@router.get(\"/\", response_model=List[HeroResponse])\n",
    "async def list_heroes(\n",
    "    session: AsyncSession = Depends(get_session),\n",
    "    offset: int = 0,\n",
    "    limit: int = 100\n",
    "):\n",
    "    \"\"\"\n",
    "    List heroes with team info.\n",
    "    \n",
    "    SQLModel works seamlessly with SQLAlchemy's select()\n",
    "    and eager loading options.\n",
    "    \"\"\"\n",
    "    statement = (\n",
    "        select(Hero)\n",
    "        .options(selectinload(Hero.team))  # Eager load team\n",
    "        .offset(offset)\n",
    "        .limit(limit)\n",
    "    )\n",
    "    \n",
    "    result = await session.execute(statement)\n",
    "    heroes = result.scalars().all()\n",
    "    \n",
    "    return heroes\n",
    "\n",
    "\n",
    "# READ single\n",
    "@router.get(\"/{hero_id}\", response_model=HeroResponse)\n",
    "async def get_hero(\n",
    "    hero_id: str,\n",
    "    session: AsyncSession = Depends(get_session)\n",
    "):\n",
    "    \"\"\"Get hero by ID.\"\"\"\n",
    "    # SQLModel works with SQLAlchemy select()\n",
    "    statement = select(Hero).where(Hero.id == hero_id)\n",
    "    result = await session.execute(statement)\n",
    "    hero = result.scalar_one_or_none()\n",
    "    \n",
    "    if not hero:\n",
    "        raise HTTPException(status_code=404, detail=\"Hero not found\")\n",
    "    \n",
    "    return hero\n",
    "\n",
    "\n",
    "# UPDATE\n",
    "@router.patch(\"/{hero_id}\", response_model=HeroResponse)\n",
    "async def update_hero(\n",
    "    hero_id: str,\n",
    "    hero_update: HeroUpdate,\n",
    "    session: AsyncSession = Depends(get_session)\n",
    "):\n",
    "    \"\"\"\n",
    "    Partial update with SQLModel.\n",
    "    \n",
    "    SQLModel's model_dump() works like Pydantic's dict().\n",
    "    \"\"\"\n",
    "    # Get existing\n",
    "    statement = select(Hero).where(Hero.id == hero_id)\n",
    "    result = await session.execute(statement)\n",
    "    db_hero = result.scalar_one_or_none()\n",
    "    \n",
    "    if not db_hero:\n",
    "        raise HTTPException(status_code=404, detail=\"Hero not found\")\n",
    "    \n",
    "    # Update only provided fields\n",
    "    update_data = hero_update.model_dump(exclude_unset=True)\n",
    "    \n",
    "    for key, value in update_data.items():\n",
    "        setattr(db_hero, key, value)\n",
    "    \n",
    "    await session.commit()\n",
    "    await session.refresh(db_hero)\n",
    "    \n",
    "    return db_hero\n",
    "\n",
    "\n",
    "# DELETE\n",
    "@router.delete(\"/{hero_id}\", status_code=204)\n",
    "async def delete_hero(\n",
    "    hero_id: str,\n",
    "    session: AsyncSession = Depends(get_session)\n",
    "):\n",
    "    \"\"\"Delete hero.\"\"\"\n",
    "    statement = select(Hero).where(Hero.id == hero_id)\n",
    "    result = await session.execute(statement)\n",
    "    hero = result.scalar_one_or_none()\n",
    "    \n",
    "    if not hero:\n",
    "        raise HTTPException(status_code=404, detail=\"Hero not found\")\n",
    "    \n",
    "    await session.delete(hero)\n",
    "    await session.commit()\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# Complex query with SQLModel\n",
    "@router.get(\"/teams/{team_id}/members\")\n",
    "async def get_team_members(\n",
    "    team_id: str,\n",
    "    session: AsyncSession = Depends(get_session)\n",
    "):\n",
    "    \"\"\"\n",
    "    Query with join using SQLModel.\n",
    "    \n",
    "    SQLModel tables are fully compatible with SQLAlchemy queries.\n",
    "    \"\"\"\n",
    "    statement = (\n",
    "        select(Hero, Team)\n",
    "        .join(Team, Hero.team_id == Team.id)\n",
    "        .where(Team.id == team_id)\n",
    "        .options(selectinload(Hero.team))\n",
    "    )\n",
    "    \n",
    "    result = await session.execute(statement)\n",
    "    heroes = result.scalars().all()\n",
    "    \n",
    "    return heroes\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 14.3 Migrations: Using Alembic for Database Schema Evolution\n",
    "\n",
    "Alembic is the database migration tool for SQLAlchemy. It manages schema changes (adding tables, columns, indexes) as versioned scripts, essential for production deployments.\n",
    "\n",
    "#### Understanding Migrations\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    Database Migration Workflow                   \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Without Migrations (Dangerous):                               \u2502\n",
    "\u2502  Developer A: ALTER TABLE users ADD COLUMN phone;                \u2502\n",
    "\u2502  Developer B: ALTER TABLE users ADD COLUMN mobile;               \u2502\n",
    "\u2502  Production: Inconsistent schema, data loss risk                \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  With Alembic (Safe):                                          \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Revision 001: Create users table                              \u2502\n",
    "\u2502  Revision 002: Add phone column                                 \u2502\n",
    "\u2502  Revision 003: Rename phone to mobile                           \u2502\n",
    "\u2502  Revision 004: Add indexes                                      \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Each revision has:                                            \u2502\n",
    "\u2502  - upgrade(): Apply changes                                     \u2502\n",
    "\u2502  - downgrade(): Revert changes                                  \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Production deployment:                                          \u2502\n",
    "\u2502  alembic upgrade head  \u2192 Applies all pending revisions          \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  Rollback if needed:                                           \u2502\n",
    "\u2502  alembic downgrade -1  \u2192 Revert last revision                   \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "#### Alembic Setup and Configuration\n",
    "\n",
    "```bash\n",
    "# Installation\n",
    "pip install alembic\n",
    "\n",
    "# Initialize Alembic (creates alembic/ directory and alembic.ini)\n",
    "alembic init alembic\n",
    "\n",
    "# Directory structure:\n",
    "# alembic/\n",
    "#   \u251c\u2500\u2500 versions/          # Migration scripts\n",
    "#   \u251c\u2500\u2500 env.py             # Configuration\n",
    "#   \u2514\u2500\u2500 script.py.mako     # Template for new revisions\n",
    "# alembic.ini              # Main config file\n",
    "```\n",
    "\n",
    "```python\n",
    "# alembic/env.py - Configuration file\n",
    "from logging.config import fileConfig\n",
    "from sqlalchemy import engine_from_config, pool\n",
    "from alembic import context\n",
    "import asyncio\n",
    "from sqlalchemy.ext.asyncio import AsyncEngine\n",
    "\n",
    "# Import your models' Base\n",
    "from app.database import Base\n",
    "from app.models import User, Item  # Import all models so Alembic detects them\n",
    "\n",
    "# this is the Alembic Config object\n",
    "config = context.config\n",
    "\n",
    "# Interpret the config file for Python logging\n",
    "if config.config_file_name is not None:\n",
    "    fileConfig(config.config_file_name)\n",
    "\n",
    "# Add your model's MetaData object here for 'autogenerate' support\n",
    "target_metadata = Base.metadata\n",
    "\n",
    "# other values from the config, defined by the needs of env.py,\n",
    "# can be acquired:\n",
    "# my_important_option = config.get_main_option(\"my_important_option\")\n",
    "\n",
    "\n",
    "def run_migrations_offline() -> None:\n",
    "    \"\"\"\n",
    "    Run migrations in 'offline' mode.\n",
    "    \n",
    "    This configures the context with just a URL and not an Engine.\n",
    "    \"\"\"\n",
    "    url = config.get_main_option(\"sqlalchemy.url\")\n",
    "    context.configure(\n",
    "        url=url,\n",
    "        target_metadata=target_metadata,\n",
    "        literal_binds=True,\n",
    "        dialect_opts={\"paramstyle\": \"named\"},\n",
    "    )\n",
    "\n",
    "    with context.begin_transaction():\n",
    "        context.run_migrations()\n",
    "\n",
    "\n",
    "async def run_migrations_online() -> None:\n",
    "    \"\"\"\n",
    "    Run migrations in 'online' mode with async engine.\n",
    "    \n",
    "    Creates an async engine and associates a connection with the context.\n",
    "    \"\"\"\n",
    "    # For async databases\n",
    "    connectable = AsyncEngine(\n",
    "        engine_from_config(\n",
    "            config.get_section(config.config_ini_section),\n",
    "            prefix=\"sqlalchemy.\",\n",
    "            poolclass=pool.NullPool,\n",
    "            future=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    async with connectable.connect() as connection:\n",
    "        await connection.run_sync(do_run_migrations)\n",
    "\n",
    "\n",
    "def do_run_migrations(connection):\n",
    "    \"\"\"Run migrations with connection.\"\"\"\n",
    "    context.configure(\n",
    "        connection=connection,\n",
    "        target_metadata=target_metadata,\n",
    "        compare_type=True,  # Detect column type changes\n",
    "        compare_server_default=True,  # Detect default changes\n",
    "    )\n",
    "    \n",
    "    with context.begin_transaction():\n",
    "        context.run_migrations()\n",
    "\n",
    "\n",
    "if context.is_offline_mode():\n",
    "    run_migrations_offline()\n",
    "else:\n",
    "    asyncio.run(run_migrations_online())\n",
    "```\n",
    "\n",
    "```ini\n",
    "# alembic.ini - Configuration\n",
    "[alembic]\n",
    "# path to migration scripts\n",
    "script_location = alembic\n",
    "\n",
    "# template used to generate migration files\n",
    "file_template = %%(rev)s_%%(slug)s\n",
    "\n",
    "# timezone to use when rendering the date\n",
    "# within the migration file\n",
    "timezone = UTC\n",
    "\n",
    "# max length of characters to apply to the\n",
    "# \"slug\" field\n",
    "truncate_slug_length = 40\n",
    "\n",
    "# set to 'true' to run the environment during\n",
    "# the 'revision' command, regardless of autogenerate\n",
    "# being enabled or not\n",
    "revision_environment = false\n",
    "\n",
    "# Logging configuration\n",
    "[loggers]\n",
    "keys = root,sqlalchemy,alembic\n",
    "\n",
    "[handlers]\n",
    "keys = console\n",
    "\n",
    "[formatters]\n",
    "keys = generic\n",
    "\n",
    "[logger_root]\n",
    "level = WARN\n",
    "handlers = console\n",
    "qualname =\n",
    "\n",
    "[logger_sqlalchemy]\n",
    "level = WARN\n",
    "handlers =\n",
    "qualname = sqlalchemy.engine\n",
    "\n",
    "[logger_alembic]\n",
    "level = INFO\n",
    "handlers =\n",
    "qualname = alembic\n",
    "\n",
    "[handler_console]\n",
    "class = StreamHandler\n",
    "args = (sys.stderr,)\n",
    "level = NOTSET\n",
    "formatter = generic\n",
    "\n",
    "[formatter_generic]\n",
    "format = %(levelname)-5.5s [%(name)s] %(message)s\n",
    "datefmt = %H:%M:%S\n",
    "\n",
    "# Database URL (can also be set via env variable)\n",
    "[alembic:exclude]\n",
    "# tables to exclude from autogenerate\n",
    "tables = spatial_ref_sys\n",
    "```\n",
    "\n",
    "#### Creating and Running Migrations\n",
    "\n",
    "```bash\n",
    "# Create a new migration (autogenerate detects model changes)\n",
    "alembic revision --autogenerate -m \"create users and items tables\"\n",
    "\n",
    "# Output:\n",
    "# Generating /app/alembic/versions/001_create_users_and_items_tables.py\n",
    "\n",
    "# Review the generated file, then apply:\n",
    "alembic upgrade head\n",
    "\n",
    "# Check current version:\n",
    "alembic current\n",
    "\n",
    "# View history:\n",
    "alembic history --verbose\n",
    "\n",
    "# Downgrade (rollback):\n",
    "alembic downgrade -1  # Downgrade 1 revision\n",
    "alembic downgrade base  # Downgrade all\n",
    "\n",
    "# Create empty migration (for manual SQL):\n",
    "alembic revision -m \"add custom index\"\n",
    "```\n",
    "\n",
    "#### Migration Script Structure\n",
    "\n",
    "```python\n",
    "# alembic/versions/001_create_users_and_items_tables.py\n",
    "\"\"\"create users and items tables\n",
    "\n",
    "Revision ID: 001\n",
    "Revises: \n",
    "Create Date: 2024-01-15 10:30:00.000000\n",
    "\n",
    "\"\"\"\n",
    "from alembic import op\n",
    "import sqlalchemy as sa\n",
    "import sqlmodel  # If using SQLModel\n",
    "\n",
    "# Revision identifiers\n",
    "revision = '001'\n",
    "down_revision = None  # Previous revision, None if first\n",
    "branch_labels = None\n",
    "depends_on = None\n",
    "\n",
    "\n",
    "def upgrade() -> None:\n",
    "    \"\"\"\n",
    "    Apply migration.\n",
    "    \n",
    "    Create tables, indexes, constraints.\n",
    "    \"\"\"\n",
    "    # Create users table\n",
    "    op.create_table(\n",
    "        'users',\n",
    "        sa.Column('id', sa.String(36), primary_key=True),\n",
    "        sa.Column('username', sa.String(50), nullable=False, unique=True),\n",
    "        sa.Column('email', sa.String(255), nullable=False, unique=True),\n",
    "        sa.Column('hashed_password', sa.String(255), nullable=False),\n",
    "        sa.Column('full_name', sa.String(100), nullable=True),\n",
    "        sa.Column('is_active', sa.Boolean(), default=True),\n",
    "        sa.Column('is_superuser', sa.Boolean(), default=False),\n",
    "        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.func.now()),\n",
    "        sa.Column('updated_at', sa.DateTime(timezone=True), onupdate=sa.func.now()),\n",
    "    )\n",
    "    \n",
    "    # Create indexes\n",
    "    op.create_index('ix_users_username', 'users', ['username'])\n",
    "    op.create_index('ix_users_email', 'users', ['email'])\n",
    "    \n",
    "    # Create items table with FK\n",
    "    op.create_table(\n",
    "        'items',\n",
    "        sa.Column('id', sa.String(36), primary_key=True),\n",
    "        sa.Column('title', sa.String(100), nullable=False),\n",
    "        sa.Column('description', sa.Text(), nullable=True),\n",
    "        sa.Column('owner_id', sa.String(36), nullable=False),\n",
    "        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.func.now()),\n",
    "        sa.ForeignKeyConstraint(['owner_id'], ['users.id'], ondelete='CASCADE'),\n",
    "    )\n",
    "    \n",
    "    op.create_index('ix_items_title', 'items', ['title'])\n",
    "    op.create_index('ix_items_owner_id', 'items', ['owner_id'])\n",
    "\n",
    "\n",
    "def downgrade() -> None:\n",
    "    \"\"\"\n",
    "    Revert migration.\n",
    "    \n",
    "    Drop in reverse order of creation.\n",
    "    \"\"\"\n",
    "    op.drop_index('ix_items_owner_id', table_name='items')\n",
    "    op.drop_index('ix_items_title', table_name='items')\n",
    "    op.drop_table('items')\n",
    "    \n",
    "    op.drop_index('ix_users_email', table_name='users')\n",
    "    op.drop_index('ix_users_username', table_name='users')\n",
    "    op.drop_table('users')\n",
    "\n",
    "\n",
    "# Example: Data migration (modify data, not just schema)\n",
    "def upgrade_data():\n",
    "    \"\"\"Optional: Migrate existing data.\"\"\"\n",
    "    # Example: Set default values for existing rows\n",
    "    op.execute(\"UPDATE users SET is_active = true WHERE is_active IS NULL\")\n",
    "\n",
    "\n",
    "def downgrade_data():\n",
    "    \"\"\"Revert data changes.\"\"\"\n",
    "    pass\n",
    "```\n",
    "\n",
    "#### Best Practices for Migrations\n",
    "\n",
    "```python\n",
    "# migrations_best_practices.py\n",
    "\"\"\"\n",
    "Alembic Best Practices:\n",
    "\n",
    "1. Always review autogenerated migrations\n",
    "   - Check column types, nullability, defaults\n",
    "   - Verify foreign key constraints\n",
    "   - Ensure indexes are created\n",
    "\n",
    "2. Never modify existing migration files after commit\n",
    "   - Create new migrations for fixes\n",
    "   - Downgrade and recreate if needed before commit\n",
    "\n",
    "3. Data migrations vs Schema migrations\n",
    "   - Separate data migrations when possible\n",
    "   - Use batch mode for large tables\n",
    "\n",
    "4. Testing migrations\n",
    "   - Test upgrade/downgrade in staging\n",
    "   - Backup database before production migration\n",
    "\"\"\"\n",
    "\n",
    "# Handling complex migrations\n",
    "from alembic import op\n",
    "import sqlalchemy as sa\n",
    "\n",
    "def upgrade():\n",
    "    # Add column as nullable first (safe for existing data)\n",
    "    op.add_column('users', sa.Column('phone', sa.String(20), nullable=True))\n",
    "    \n",
    "    # Update existing rows with default\n",
    "    op.execute(\"UPDATE users SET phone = 'unknown' WHERE phone IS NULL\")\n",
    "    \n",
    "    # Then make non-nullable\n",
    "    op.alter_column('users', 'phone', nullable=False)\n",
    "    \n",
    "    # Create index concurrently (PostgreSQL, doesn't lock table)\n",
    "    op.create_index(\n",
    "        'ix_users_phone',\n",
    "        'users',\n",
    "        ['phone'],\n",
    "        postgresql_concurrently=True\n",
    "    )\n",
    "\n",
    "\n",
    "# Batch operations for SQLite (which doesn't support ALTER)\n",
    "def upgrade_sqlite():\n",
    "    \"\"\"\n",
    "    SQLite has limited ALTER support.\n",
    "    Use batch operations to recreate table.\n",
    "    \"\"\"\n",
    "    with op.batch_alter_table('users') as batch_op:\n",
    "        batch_op.add_column(sa.Column('phone', sa.String(20)))\n",
    "        batch_op.create_index('ix_users_phone', ['phone'])\n",
    "\n",
    "\n",
    "# Handling dependencies between apps\n",
    "revision = '002'\n",
    "down_revision = '001'  # Points to previous revision\n",
    "depends_on = 'other_app_001'  # Cross-app dependency\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "In this chapter, you expanded your database capabilities beyond traditional SQL:\n",
    "\n",
    "1. **MongoDB with Motor/Beanie**: Set up async MongoDB connections using Motor driver, defined flexible document schemas with Beanie ODM, and implemented CRUD operations. You learned when to choose NoSQL (flexible schemas, horizontal scaling) over SQL.\n",
    "\n",
    "2. **SQLModel**: Integrated SQLModel to combine Pydantic validation with SQLAlchemy persistence in single models, reducing boilerplate code while maintaining type safety and full SQLAlchemy compatibility.\n",
    "\n",
    "3. **Alembic Migrations**: Configured Alembic for database schema version control, created revision scripts for schema changes, and managed database evolution safely across environments using upgrade/downgrade workflows.\n",
    "\n",
    "**Key Decisions:**\n",
    "- **SQL (PostgreSQL)**: Use for transactional data with complex relationships (users, orders, payments)\n",
    "- **NoSQL (MongoDB)**: Use for flexible content (logs, analytics, CMS content, real-time data)\n",
    "- **SQLModel**: Use when you want less boilerplate and single-source-of-truth models\n",
    "- **Alembic**: Always use for production SQL databases\u2014never use `create_all` in production\n",
    "\n",
    "---\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**Chapter 15: Testing Strategies** will cover:\n",
    "- **`TestClient`**: Writing unit and integration tests for FastAPI endpoints using the synchronous TestClient\n",
    "- **Testing Authentication**: Sending tokens and cookies in test requests, mocking authentication dependencies\n",
    "- **Dependency Overriding**: Replacing real database connections with test databases and mocking external services\n",
    "- **Async Testing**: Using `pytest-asyncio` to test async endpoints, database operations, and background tasks\n",
    "- **Test Database Management**: Setting up isolated test databases with rollback transactions for fast, isolated tests\n",
    "\n",
    "This next chapter ensures your application is robust and maintainable through comprehensive testing strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex; justify-content:space-between; align-items:center; margin: 1em 0;'>\n",
    "  <a href='13. sql_databases_with_sqlalchemy.ipynb' style='font-weight:bold; font-size:1.05em;'>&larr; Previous</a>\n",
    "  <a href='../TOC.md' style='font-weight:bold; font-size:1.05em; text-align:center;'>Table of Contents</a>\n",
    "  <a href='../7. testing_and_quality_assurance/15. testing_strategies.ipynb' style='font-weight:bold; font-size:1.05em;'>Next &rarr;</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}